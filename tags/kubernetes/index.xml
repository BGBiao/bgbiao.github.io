<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on CloudNativeOps - SRE，DevOps、Kubernetes 云原生运维。成长之路，一起前行！</title>
    <link>https://bgbiao.top/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on CloudNativeOps - SRE，DevOps、Kubernetes 云原生运维。成长之路，一起前行！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 02 Oct 2022 13:35:12 +0800</lastBuildDate><atom:link href="https://bgbiao.top/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2022 10 02 DevOps SRE外部文档</title>
      <link>https://bgbiao.top/devops/</link>
      <pubDate>Sun, 02 Oct 2022 13:35:12 +0800</pubDate>
      
      <guid>https://bgbiao.top/devops/</guid>
      <description>GitOps GitOps 标准以及最佳实践 SRE Google SRE Books RoadMap of SRE SRE 中的故障指标 SRE最佳实践之-容量管理 SRE workbook Tech RoadMap: roadmap.sh 新技术栈： the-new-stack</description>
    </item>
    
    <item>
      <title>2022 10 02 2022DevOps路线图</title>
      <link>https://bgbiao.top/devops/</link>
      <pubDate>Sun, 02 Oct 2022 13:13:39 +0800</pubDate>
      
      <guid>https://bgbiao.top/devops/</guid>
      <description>前言：前面我翻译了一篇关于DevOps 最佳实践工具 的文章，接下来以图形结构的方式来展现一些整个 SRE、DevOps 的技能路线图。 公众号: CloudNativeOps</description>
    </item>
    
    <item>
      <title>CoreDNS loop 插件异常问题</title>
      <link>https://bgbiao.top/post/coredns-loop/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/coredns-loop/</guid>
      <description>&lt;p&gt;关键技术:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;: 分布式的容器编排与调度系统，当前公认的云原生技术基础设施&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coredns.io&#34;&gt;CoreDNS&lt;/a&gt;: DNS and Service Discovery ，当前公认的云原生基础设施之名字服务系统&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coredns.io/plugins/loop/&#34;&gt;CoreDNS-plugins-loop&lt;/a&gt;: CoreDNS loop 插件文档&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;最近有遇到一个客户集群，发现集群中的 CoreDNS 老是异常(loop 插件检测到有回路后进行 panic)，因此怀疑是 K8S 集群在交付或者初始化过程中做了一些额外的动作，为了查明真相我们对客户环境进行一次排查和状况模拟，顺便来一起学习一下在 CoreDNS 中 loop 插件的相关知识。&lt;/p&gt;
&lt;h3 id=&#34;问题现象&#34;&gt;问题现象&lt;/h3&gt;
&lt;p&gt;在查看 coredns pod 启动日志时，发现有如下对应异常:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl  get pods -n kube-system | grep dns
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;coredns-bdbc5564-8qldp              0/1     CrashLoopBackOff   8          22m
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl  logs -n kube-system coredns-bdbc5564-8qldp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[INFO] plugin/kubernetes: Watching Endpoints instead of EndpointSlices in k8s versions &amp;lt; 1.19
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.:53
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[INFO] plugin/reload: Running configuration MD5 = 045400f7bc8c9f6aaf8ca5dade224266
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CoreDNS-1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;linux/amd64, go1.16.4, 053c4d5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[INFO] 127.0.0.1:34652 - 36041 &amp;#34;HINFO IN 2066162189351134310.8810881223121065474. udp 57 false 512&amp;#34; NOERROR - 0 6.002536937s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ERROR] plugin/errors: 2 2066162189351134310.8810881223121065474. HINFO: read udp 127.0.0.1:48503-&amp;gt;127.0.0.53:53: i/o timeout
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[FATAL] plugin/loop: Loop (127.0.0.1:48066 -&amp;gt; :53) detected for zone &amp;#34;.&amp;#34;, see https://coredns.io/plugins/loop#troubleshooting. Query: &amp;#34;HINFO 2066162189351134310.8810881223121065474.&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>一分钟构建高可用的分布式追踪系统-Jaeger</title>
      <link>https://bgbiao.top/post/kubernetes-helm-jaeger/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kubernetes-helm-jaeger/</guid>
      <description>&lt;p&gt;关键技术:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;: 分布式的容器编排与调度系统，当前公认的云原生技术基础设施&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jaegertracing.io/&#34;&gt;Jaeger&lt;/a&gt;: 开源端到端的分布式追踪系统&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://helm.sh/&#34;&gt;Helm&lt;/a&gt;: Kubernetes 中的包管理器&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Traefik中的502-500状态码异常排查</title>
      <link>https://bgbiao.top/post/traefik%E4%B8%AD%E7%9A%84502-500%E7%8A%B6%E6%80%81%E7%A0%81%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/traefik%E4%B8%AD%E7%9A%84502-500%E7%8A%B6%E6%80%81%E7%A0%81%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;我们都知道在Kubernetes集群中通常会使用Ingress方案来统一代理集群内部的流量，而常用的Ingress方案为&lt;a href=&#34;https://docs.traefik.io/&#34;&gt;traefik&lt;/a&gt;和&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;nginx&lt;/a&gt;，和传统的Nginx作为企业内部的反向代理以及负载设备一样，在不同的场景下可能需要专有的配置才能满足需求，否则会出现奇奇怪怪的异常状态码。本篇文章一起来看下，我们在&lt;code&gt;traefik&lt;/code&gt;中遇到的500和502异常。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Traefik的可观测性方案</title>
      <link>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;h2 id=&#34;traefik的可观测性支持&#34;&gt;Traefik的可观测性支持&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.traefik.io/observability/logs/&#34;&gt;traefik-observability&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在Traefik-2.X的生态里，将可观测性分为了如下几个部分，并提升到了专门的功能说明中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务日志: Traefik进程本身相关的操作日志&lt;/li&gt;
&lt;li&gt;访问日志: 由Traefik接管的代理服务的访问日志(access.log)&lt;/li&gt;
&lt;li&gt;Metrics: Traefik提供的自身详细的metrics数据&lt;/li&gt;
&lt;li&gt;Tracing: Traefik也提供了追踪相关的接口，用来可视化分布式或微服务中的调用情况&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>CronJob控制器中的一些绕坑指南</title>
      <link>https://bgbiao.top/post/cronjob%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%95%E5%9D%91%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/cronjob%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%95%E5%9D%91%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;背景: 作为企业里唯一熟悉各种云产品的工种，通常需要和各种云产品打交道。当前，我们大部分的云基础设施和云服务都运行在阿里云上，而每个云产品都有独立的管理系统，这使得我们在运维过程中经常无法将相关产品和关联信息有效的组织在一起，来进行快速的问题诊断和信息查询，这对于运维和开发同学来说，在多个系统之间来回跳转查找关联信息是一个低效且极易出错的事务，因此通常来讲，不论是作为运维和开发，我们都希望将企业关联的云资源和服务进行整合关联，以实现效率的最大化。而在这过程中，我们采用Kubernetes集群的CronJob来定期获取阿里云的一些资源，在这过程中，遇到一些问题，根据问题重新细读CronJob官方文档，特记录于此。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>基于阿里云Terway网络的Kubernetes集群实践</title>
      <link>https://bgbiao.top/post/k8s-ali-terway/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/k8s-ali-terway/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;背景: 众所周知的是在构建一个Kubernetes集群时，容器网络通常会使用一个独立的私有子网来构建Kubernetes集群内部的pod网络和service网络，但在实际的业务场景中，没有企业会在一段时间内将内部全部的服务都迁移到Kubernetes集群中(因为涉及到业务架构以及整体业务的可靠性)，因而会产生一些Kubernetes集群内部服务和集群外部服务互相调用的场景，当然如果是HTTP服务，我们可以采用LVS、Nginx、HAProxy之类的代理工具工具进行集群内外的流量转发，但如果是TCP服务，比如使用Dubbo框架时，生产者和消费者需要直连，当生产者和消费者不在一个可以互联互通的网络下会比较麻烦，这也就是为什么大厂在规模化使用Kubernetes时首先需要解决的就是网络问题的原因了。比如我们在数科的时候就采用的是&lt;a href=&#34;https://github.com/contiv/install&#34;&gt;Contiv&lt;/a&gt;+BGP的模式来实现容器网络和容器外网络的互联互通的，而这通常需要一个比较专业的SDN团队来构建和维护。而作为创业公司通常会使用公有云来承载自己的业务，这种轻资产模式的好处就是底层会有专业的团队来提供保障，因此考虑到业务需求我们采用了阿里云的terway网络插件来实现内部的Kubernetes集群网络.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>k8s删除Terminating状态的命名空间</title>
      <link>https://bgbiao.top/post/k8s-delete-namespace/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/k8s-delete-namespace/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;背景: 我们都知道在k8s中namespace有两种常见的状态，即Active和Terminating状态，其中后者一般会比较少见，只有当对应的命名空间下还存在运行的资源，但是该命名空间被删除时才会出现所谓的terminating状态，这种情况下只要等待k8s本身将命名空间下的资源回收后，该命名空间将会被系统自动删除。但是今天遇到命名空间下已没相关资源，但依然无法删除terminating状态的命名空间的情况，特此记录一下.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes-1.15管理NVIDIA GPU容器</title>
      <link>https://bgbiao.top/post/k8s-nvidia-gpu/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/k8s-nvidia-gpu/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;使用kubernetes来调度和管理nvidia gpu资源。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>k8s dashboard的http接口改造</title>
      <link>https://bgbiao.top/post/k8s-dashboard-http/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/k8s-dashboard-http/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;背景: 玩过Kubernetes的人都知道，官方提供了一种集群web插件&lt;a href=&#34;https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/&#34;&gt;dashboard&lt;/a&gt;,使用官方示例可以快速的部署一套dashboard,可以方便相关人员进行集群概况预览.但是官方的实例默认使用了&lt;code&gt;https&lt;/code&gt;并且需要通过证书或Token来进行统一认证,而dashboard这种内部基础工具增加了https和证书认证后不仅使得使用的成本高了起来，而且和内部的统一管理入口也不太好集成(通常内部系统都会统一使用nginx之类的代理工具进行统一代理).&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>容器生态技术</title>
      <link>https://bgbiao.top/post/%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Sun, 05 Nov 2017 22:30:59 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E6%8A%80%E6%9C%AF/</guid>
      <description>&lt;p&gt;2017年可谓是容器云领域发展最火的一年，同时也是Kubernetes崛起的一年，那么随着容器行业的大发展，基于以Docker和Kubernetes为核心的容器生态系统也慢慢在将自己的软件体系进行解耦拆分，以实现核心功能的最优化实现。很明显的一点就是Docker在不断的拆分自己的项目，不再试图将所有容器相关技术都囊括在自己碗里，而Kubernetes则一直保持开放的态度，对接不同的第三方生态体系，也使得K8S在整个容器界内获得了良好的口碑。那么想要从事容器相关领域的技术研究或者工作，个人建议也可以将整个容器生态技术拆分，对某个要点进行深入探索，这样能够让自己更加了解容器的生态技术，也更容易在容器云生态中贡献自己的力量。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spinnaker国内生产环境级别集群搭建</title>
      <link>https://bgbiao.top/post/spinnaker-install/</link>
      <pubDate>Thu, 26 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/spinnaker-install/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;前言: 之前在国际版环境使用Spinnaker集群进行k8s容器的部署管理，由于Spinnaker由Netflix开源，在集群安装过程中需要科学上网来安装一些包。本篇文章将简单记录下在国内如何快速搭建和配置可用的Spinnaker集群环境。并且在生产环境使用&lt;code&gt;minio&lt;/code&gt;作为持久化层，使用自定义域名，同时对接jenkine来统一对业务代码进行持续构建和管理。&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
  </channel>
</rss>
