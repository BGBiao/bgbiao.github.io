<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>GPU环境下玩转Docker(一) - BGBiao的Ops人生</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="BGBiao" />
  <meta name="description" content="背景： 随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。
从GPU到GPGPU CPU与GPU
" />

  <meta name="keywords" content="Ops, DevOps, Kubernetes, Docker, 云原生" />






<meta name="generator" content="Hugo 0.58.2" />


<link rel="canonical" href="https://bgbiao.top/post/gpu%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACdocker-%E4%B8%80/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.af20b78e95c84de86b00a0242a4a77bd2601700e1b250edf27537d957ac0041d.css" integrity="sha256-ryC3jpXITehrAKAkKkp3vSYBcA4bJQ7fJ1N9lXrABB0=" media="screen" crossorigin="anonymous">





<meta property="og:title" content="GPU环境下玩转Docker(一)" />
<meta property="og:description" content="背景：

随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。

从GPU到GPGPU
CPU与GPU" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bgbiao.top/post/gpu%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACdocker-%E4%B8%80/" />
<meta property="article:published_time" content="2017-10-26T10:07:34+00:00" />
<meta property="article:modified_time" content="2017-10-26T10:07:34+00:00" />
<meta itemprop="name" content="GPU环境下玩转Docker(一)">
<meta itemprop="description" content="背景：

随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。

从GPU到GPGPU
CPU与GPU">


<meta itemprop="datePublished" content="2017-10-26T10:07:34&#43;00:00" />
<meta itemprop="dateModified" content="2017-10-26T10:07:34&#43;00:00" />
<meta itemprop="wordCount" content="6002">



<meta itemprop="keywords" content="Docker,GPU,NVIDIA,NVIDIA-Docker," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GPU环境下玩转Docker(一)"/>
<meta name="twitter:description" content="背景：

随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。

从GPU到GPGPU
CPU与GPU"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">BGBiao的Ops人生</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/">首页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/post/">全部文章</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/tags/">标签</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/categories/">分类</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/about/">关于我</a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      BGBiao的Ops人生
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/">首页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/post/">全部文章</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/tags/">标签</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/categories/">分类</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://bgbiao.top/about/">关于我</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">GPU环境下玩转Docker(一)</h1>
      
      <div class="post-meta">
        <time datetime="2017-10-26" class="post-time">
          2017-10-26
        </time>
        <div class="post-category">
            <a href="https://bgbiao.top/categories/%E8%BF%90%E7%BB%B4/"> 运维 </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#背景">背景：</a></li>
<li><a href="#gpu准备">GPU准备</a></li>
<li><a href="#gpu驱动安装">GPU驱动安装</a>
<ul>
<li><a href="#系统需求">系统需求</a></li>
<li><a href="#安装前准备">安装前准备</a></li>
<li><a href="#安装包管理程序-package-manager">安装包管理程序(Package Manager)</a></li>
<li><a href="#安装后操作">安装后操作</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <h3 id="背景">背景：</h3>

<p>随着大数据、人工智能以及机器学习等技术的发展，CPU计算资源已经不能满足很多计算场景，而随着硬件技术的发展，越来越多的人工智能以及机器学习领域开始使用GPU进行计算任务。而GPU环境以及具体的应用方式又给真正做人工智能相关的同学造成了很多困扰，本系列文章将分为三篇，将介绍如何搭建部署GPU环境，使用Docker进行管理GPU容器，使用Kubernetes来调度GPU容器。</p>

<p><a href="http://www.jianshu.com/p/e72a352a2bd7">从GPU到GPGPU</a>
<a href="http://www.jianshu.com/p/609e0530a19c">CPU与GPU</a></p>

<h3 id="gpu准备">GPU准备</h3>

<p><a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#redhat-installation">CUDA安装部署</a></p>

<p><a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=CentOS&amp;target_version=7&amp;target_type=rpmlocal">CUDA Toolkit下载页面</a></p>

<p><a href="http://www.nvidia.cn/page/home.html">英伟达中文官网</a></p>

<h3 id="gpu驱动安装">GPU驱动安装</h3>

<p><code>注意：由于GPU需要在宿主机上安装相关驱动才能够被用户态的程序所识别，所以需要先安装CUDA</code></p>

<p>参考上述的<code>CUDA安装部署</code></p>

<h4 id="系统需求">系统需求</h4>

<p>想要在系统上使用<code>CUDA</code>，必须安装如下依赖：
- CUDA-capable CPU
- 一个特定版本的gcc编译器以及相关工具链
- <a href="http://developer.nvidia.com/cuda-downloads">NVIDIA CUDA Toolkit</a></p>

<p>在linux X86_64架构平台上建议的配置：</p>

<table>
<thead>
<tr>
<th>linux发行版</th>
<th>内核版本</th>
<th>GCC</th>
<th>GLIBC</th>
<th>ICC</th>
<th>PGI</th>
<th>XLC</th>
<th>CLANG</th>
</tr>
</thead>

<tbody>
<tr>
<td>RHEL 7.X</td>
<td>3.10</td>
<td>4.8.5</td>
<td>2.17</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>Centos 7.X</td>
<td>3.10</td>
<td>4.8.5</td>
<td>2.17</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>RHEL 6.X</td>
<td>2.6.32</td>
<td>4.4.7</td>
<td>2.12</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>Centos 6.X</td>
<td>2.6.32</td>
<td>4.4.7</td>
<td>2.12</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>Fedora 25</td>
<td>4.8.8</td>
<td>6.2.1</td>
<td>2.24-3</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>OpenSUSE Leap 42.2</td>
<td>4.4.27</td>
<td>4.8</td>
<td>2.22</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>SLES 12 SP2</td>
<td>4.4.21</td>
<td>4.8.5</td>
<td>2.22</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>Ubuntu 17.04</td>
<td>4.9.0</td>
<td>6.3.0</td>
<td>2.24-3</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>

<tr>
<td>Ubuntu 16.04</td>
<td>4.4</td>
<td>5.3.1</td>
<td>2.23</td>
<td>17.0</td>
<td>17.1</td>
<td>NO</td>
<td>3.9</td>
</tr>
</tbody>
</table>

<h4 id="安装前准备">安装前准备</h4>

<p>在安装CUDA Toolkit和驱动之前，需要在GPU主机上执行相关的操作：
- 检测系统中有CUDA-capable GPU卡
- 检测系统是否是上述列表中支持的linux发行版本
- 检测系统中是否安装了依赖的gcc编译器
- 检测系统中是否安装了正确的内核头文件以及开发包
- 下载NVIDIA CUDA Toolkit
- 处理一些安装过程中的冲突问题</p>

<p><strong>2.1 检测是否有一个CUDA-Capable GPU</strong></p>

<p>如下显示当前主机上支持并有四个GPU设备</p>

<pre><code>sh-4.2# lspci | grep -i nvidia
04:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)
05:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)
06:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)
07:00.0 3D controller: NVIDIA Corporation Device 17fd (rev a1)


</code></pre>

<p><code>注意：如果使用上述命令没有任何输出，那需要更新你的PCI 硬件数据库，然后再次执行；</code></p>

<p>安装nvidia-linux驱动:
<code>注意:</code> 用户可以在<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">nvidia-driver</a>页面选择相应型号相应环境的nvidia驱动，并下载rpm格式的驱动程序。同时用户也可以在<a href="https://www.nvidia.com/object/linux-amd64-display-archive.html">nvidia-driver-run</a>页面下载指定版本的二进制驱动程序。通常情况下，推荐使用后者安装nvidia的驱动，但是前者的rpm包中默认也包含了对应的cuda版本，因此rpm包方式更适合傻瓜式安装，而使用二进制方式用户可以自行安装cuda版本。</p>

<pre><code>sh-4.2# wget -O NVIDIA-Linux-x86_64-375.39.run https://www.nvidia.com/content/DriverDownload-March2009/confirmation.php?url=/XFree86/Linux-x86_64/375.39/NVIDIA-Linux-x86_64-375.39.run
sh-4.2# chmod a+x NVIDIA-Linux-x86_64-375.39.run
# 选择安静模式安装
sh-4.2# ./NVIDIA-Linux-x86_64-375.39.run -s

# 可能会遇到的问题:
## 1. 提示kernel-source相关的问题 (原因是kernel和kernel-devel包的版本不一致导致无法检测到内核相关库文件)
# 重新安装内核相关文件，保证内核头文件和库文件版本一致
sh-4.2# yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r) -y 
# 卸载错误版本的内核库文件
sh-4.2# rpm -qa | grep kernel-devel
kernel-devel-3.10.0-693.el7.x86_64
kernel-devel-3.10.0-862.el7.x86_64
sh-4.2# rpm -e kernel-devel-3.10.0-862.el7.x86_64
sh-4.2# rpm -qa | grep kernel-devel
kernel-devel-3.10.0-693.el7.x86_64
sh-4.2# ./NVIDIA-Linux-x86_64-396.45.run -s
Verifying archive integrity... OK
Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 396.45..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

## 2. 提示如下
ERROR: The Nouveau kernel driver is currently in use by your system.  This driver is incompatible with the NVIDIA driver, and must be disabled before proceeding.  Please consult the NVIDIA driver README and your Linux distribution's documentation for details on how to correctly disable the Nouveau kernel driver.

# 在centos7中需要禁止一个内核模块Nouveau
sh-4.2# lsmod | grep nouveau
nouveau              1622010  0
video                  24520  1 nouveau
mxm_wmi                13021  1 nouveau
drm_kms_helper        159169  2 mgag200,nouveau
ttm                    99345  2 mgag200,nouveau
drm                   370825  5 ttm,drm_kms_helper,mgag200,nouveau
i2c_algo_bit           13413  3 igb,mgag200,nouveau
i2c_core               40756  8 drm,igb,i2c_i801,ipmi_ssif,drm_kms_helper,mgag200,i2c_algo_bit,nouveau
wmi                    19070  2 mxm_wmi,nouveau

# 临时卸载该模块
sh-4.2# rmmod nouveau
sh-4.2# ./NVIDIA-Linux-x86_64-375.39.run -s

</code></pre>

<p>查看GPU显卡信息:</p>

<pre><code>sh-4.2# nvidia-smi
Wed Oct 18 11:58:03 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla M40 24GB      On   | 0000:04:00.0     Off |                    0 |
| N/A   23C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla M40           On   | 0000:05:00.0     Off |                    0 |
| N/A   26C    P8    17W / 250W |      0MiB / 11443MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla M40 24GB      On   | 0000:06:00.0     Off |                    0 |
| N/A   22C    P8    17W / 250W |      0MiB / 22939MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla M40           On   | 0000:07:00.0     Off |                    0 |
| N/A   23C    P8    16W / 250W |      0MiB / 11443MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

# Temp 标识GPU设备的温度
# Memory-Usage 表示内存使用率
# GPU-Util 表示GPU使用率
</code></pre>

<p><code>注意：上述输出也可以看出该系统上有4块GPU设备，使用Tesla M40型号。其中分别有两块卡24G内存，两块是12G内存，分别处于两个PCIE总线上</code></p>

<p><code>注意：宿主机内存为256G，cpu为Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz 开启超线程后为24颗逻辑cpu(两颗6核心的cpu开启了超线程)</code></p>

<p><code>注意：如果你的GPU卡是NVIDIA的，并且是在http://developer.nvidia.com/cuda-gpus中可用查看到的，那么你的GPU就是 CUDA-capable</code></p>

<p><a href="http://developer.nvidia.com/cuda-gpus">点击</a>查看不同型号的GPU的算力。</p>

<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/gpu-type.png" alt="" /></p>

<p><strong>2.2 检测Linux的架构和操作系统版本</strong></p>

<p>因为CUDA开发工具只支持一些指定发行版本的linux，需要用户查看操作系统的架构以及发行版本。可以在CUDA Toolkit发布版本的中查看支持的linux版本。</p>

<pre><code># uname -m &amp;&amp; cat /etc/redhat-release
x86_64
CentOS Linux release 7.2.1511 (Core)

</code></pre>

<p><strong>2.3 检测系统是否安装了gcc</strong></p>

<p>当使用CUDA Toolkit进行开发的时候，gcc编译器是必须需要的。一般情况下linux主机都会安装了gcc编译器，但是为确保之后的操作不会出现大问题，建议检查下gcc以及版本是否为对应的版本。</p>

<pre><code># gcc --version
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4)

</code></pre>

<p><strong>2.4 检测系统是否有正确的内核头文件以及一些开发包是否安装</strong></p>

<p>CUDA驱动需要内核头文件和开发工具包来保证驱动程序的安装以及rebuilt，比如你的内核版本为<code>3.17.4-301</code>，那么<code>3.17.4-301</code>的内核头文件以及相关的开发包也必须安装。</p>

<p>当驱动程序的安装过程没有进行包的验证，在使用RPM或者DEB包安装驱动的时候如果系统上没有安装正确的软件包，它将会尝试去安装内核头文件以及开发工具包。但是通常情况下，这种安装会默认去寻找仓库中最新版本的软件包，可能会导致内核版本的不匹配等问题。因此，在安装CUDA驱动之前，最好手动确认内核头文件的版本以及开发工具包的安装。</p>

<p>在centos系统上可以执行如下命令：</p>

<pre><code># uname -r
3.10.0-327.el7.x86_64

# yum install kernel-devel-$(uname -r) kernel-headers-$(uname -r) -y
</code></pre>

<p><strong>2.5 选择安装方式</strong></p>

<p>官方有两种方式去安装： distribution-specific packages (RPM and Deb packages)和distribution-independent package (runfile packages)。其中前者对接了linux发行版原生的包管理系统，是强烈建议的一种安装方式。</p>

<p><strong>2.6 下载NVIDIA CUDA Toolkit</strong></p>

<p><a href="http://developer.nvidia.com/cuda-downloads">下载地址</a>
根据当前系统的基础状况来选择相对应的版本。
<img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/nvidia-toolkit.png" alt="NVIDIA CUDA Toolkit" /></p>

<p>可以看到安装类型支持两种方式<code>runfile</code>和<code>rpm</code>,其中rpm方式又分为<code>local</code>和<code>network</code>方式，由于我们的宿主机不能直接访问外网，先使用rpm（local）方式进行安装下载。</p>

<p>下载完成之后需要使用<code>md5sum</code>进行文件验证，以保证最终的包一致性。官方提供的checksums文件被损坏，暂时无法检验。</p>

<p><strong>2.7 处理安装冲突的一些方法</strong></p>

<p>在安装CUDA之前，任何可能冲突的安装包都需要被卸载。
以下为相关细节。</p>

<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/conflict-specifics.png" alt="" /></p>

<p>使用如下方式去卸载相关的冲突包。</p>

<p>卸载runfile方式的Toolkit :</p>

<pre><code>/usr/local/cuda-X.Y/bin/uninstall_cuda_X.Y.pl
</code></pre>

<p>卸载runfile方式的Driver：</p>

<pre><code>/usr/bin/nvidia-uninstall
</code></pre>

<p>卸载RPM/Deb方式安装的包：</p>

<pre><code>$ yum remove &lt;package_name&gt;                      # Redhat/CentOS
$ dnf remove &lt;package_name&gt;                      # Fedora
$ zypper remove &lt;package_name&gt;                   # OpenSUSE/SLES
$ apt-get --purge remove &lt;package_name&gt;          # Ubuntu

</code></pre>

<h4 id="安装包管理程序-package-manager">安装包管理程序(Package Manager)</h4>

<p><a href="http://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#redhat-x86_64">快速安装指南</a></p>

<p><strong>3.1 在Redhat/CentOS上安装</strong></p>

<ul>
<li>1.执行2中的操作</li>
<li>2.确认DKMS依赖
NVIDIA驱动的RPM包会依赖一些额外的包，比如说<code>DKMS</code>和<code>libvdpau</code>,这些包在系统默认的仓库中是不包含的，只存在与第三方镜像仓库，比如<a href="http://fedoraproject.org/wiki/EPEL">EPEL</a>,因此在安装驱动之前，必须将第三方源添加到本地的仓库中，否则缺失依赖会阻止安装继续进行。</li>

<li><p>3.如果需要，自定义xorg.conf文件
驱动会依赖一个自动生成的xorg.conf文件<code>/etc/X11/xorg.conf</code>，该文件可能会影响驱动的正常工作，可以删除该文件，或者添加<code>/etc/X11/xorg.conf.d/00-nvidia.conf</code>的内容到xorg.conf文件中。</p></li>

<li><p>4.安装meta-data仓库</p>

<pre><code># rpm --install cuda-repo-&lt;distro&gt;-&lt;version&gt;.&lt;architecture&gt;.rpm
</code></pre></li>

<li><p>5.清除仓库缓存</p>

<pre><code># yum clean expire-cache
</code></pre></li>

<li><p>6.安装CUDA</p>

<pre><code># yum install cuda

</code></pre></li>
</ul>

<p>如果i686的libvdpau包安装失败，可以尝试以下步骤来修复该问题。</p>

<pre><code># yumdownloader libvdpau.i686
# sudo rpm -U --oldpackage libvdpau*.rpm
</code></pre>

<ul>
<li>7.如果需要，添加libcuda.so的软连接</li>
</ul>

<p>libcuda.so库文件被安装在<code>/usr/lib{,64}/nvidia</code>目录，如果已运行的项目需要使用libcuda.so文件，可以添加一个软连接到<code>/usr/lib{,64}</code>目录。</p>

<ul>
<li>8.执行<a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">安装后操作</a></li>
</ul>

<p><strong>3.2 包管理器的额外功能</strong></p>

<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/meta-packages.png" alt="cuda核心包" /></p>

<h4 id="安装后操作">安装后操作</h4>

<p><strong>4.1 必须执行的操作</strong></p>

<p>一些操作行为必须在安装后并且在使用CUDA Toolkit和Driver之前去执行。</p>

<p>4.1.1 环境设置</p>

<p><code>PATH</code>环境变量必须包含<code>/usr/local/cuda-8.0/bin</code></p>

<pre><code>export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
</code></pre>

<p><code>注意：</code>在使用runfile方式安装的时候，动态链接库<code>LD_LIBRARY_PATH</code>的环境变量需要包含<code>/usr/local/cuda-8.0/lib64</code>.</p>

<pre><code>$ export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</code></pre>

<p><strong>4.2 强烈推荐的操作</strong></p>

<p>4.2.1 安装可写的示例程序</p>

<p>为了修改，编译以及运行样品，样品程序必须也可写权限进行安装，安装脚本如下：</p>

<pre><code># cuda-install-samples-8.0.sh &lt;dir&gt;
</code></pre>

<p>该脚本会创建一个<code>/usr/local/cuda/samples</code>的只读拷贝，需要将拷贝的内容改为可写。</p>

<pre><code># cuda-install-samples-8.0.sh /export/biaoge/cuda-samples

# tree -L 2 /export/biaoge/cuda-samples/
/export/biaoge/cuda-samples/
└── NVIDIA_CUDA-8.0_Samples
    ├── 0_Simple
    ├── 1_Utilities
    ├── 2_Graphics
    ├── 3_Imaging
    ├── 4_Finance
    ├── 5_Simulations
    ├── 6_Advanced
    ├── 7_CUDALibraries
    ├── bin
    ├── common
    ├── EULA.txt
    ├── Makefile
    └── uninstall_cuda_samples_8.0.pl

</code></pre>

<p>4.2.2 验证所有的安装</p>

<p>在继续操作之前，验证一下<code>CUDA Toolkit</code>能够识别到正确的GPU硬件设备是非常重要的。因此这里需要编译一些样品程序来进行检验。</p>

<p>(1)验证驱动版本
如果安装了确定，需要验证下加载驱动的版本是否正确，如果没有安装驱动或者没有用过内核模块来加载，可以暂时跳过该步骤。</p>

<p>当驱动被加载后，可以通过如下命令查看到驱动的版本</p>

<pre><code># cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.39  Tue Jan 31 20:47:00 PST 2017
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)
</code></pre>

<p>(2) 编译样品程序
CUDA Toolkit的版本可以使用<code>nvcc --version/-V</code>查看，该命令运行编译驱动来编译CUDA程序，底层其实调用了gcc编译器来编译c代码，使用<code>NVIDIA PTX</code>编译器来调用CUDA代码。</p>

<pre><code># nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61
</code></pre>

<p>NVIDIA CUDA Toolkit在源文件中包含了一些示例程序，用户可以通过修改<code>~/NVIDIA_CUDA-8.0_Samples</code>并执行<code>make</code>来编译这些示例程序。编译的二进制文件将存放在<code>~/NVIDIA_CUDA-8.0_Samples/bin</code></p>

<pre><code># cd /export/biaoge/cuda-samples/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery

#编译生成deviceQuery二进制文件，在(3)中需要验证环境
# make

# cd /export/biaoge/cuda-samples/NVIDIA_CUDA-8.0_Samples/1_Utilities/bandwidthTest

#编译生成bandwidthTest二进制文件，在(3)中用来验证环境
# make

# ll ../bandwidthTest/bandwidthTest
-rwxr-xr-x 1 root root 603420 Oct 18 16:05 ../bandwidthTest/bandwidthTest
# ll ../deviceQuery/deviceQuery
-rwxr-xr-x 1 root root 582882 Oct 18 16:44 ../deviceQuery/deviceQuery
</code></pre>

<p>(3) 运行二进制文件</p>

<p>编译完成之后，在<code>~/NVIDIA_CUDA-8.0_Samples</code>下对应目录下运行<code>deviceQuery</code>.如果CUDA程序被正确安装和配置，<code>deviceQuery</code>的输出应该看起来如下所示。</p>

<pre><code># ./deviceQuery
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 4 CUDA Capable device(s)

Device 0: &quot;Tesla M40 24GB&quot;
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 22940 MBytes (24054136832 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1112 MHz (1.11 GHz)
  Memory Clock rate:                             3004 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

Device 1: &quot;Tesla M40&quot;
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 11443 MBytes (11998855168 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1112 MHz (1.11 GHz)
  Memory Clock rate:                             3004 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 5 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

Device 2: &quot;Tesla M40 24GB&quot;
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 22940 MBytes (24054136832 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1112 MHz (1.11 GHz)
  Memory Clock rate:                             3004 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 6 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

Device 3: &quot;Tesla M40&quot;
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    5.2
  Total amount of global memory:                 11443 MBytes (11998855168 bytes)
  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores
  GPU Max Clock rate:                            1112 MHz (1.11 GHz)
  Memory Clock rate:                             3004 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 3145728 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 7 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;
&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 (GPU1) : Yes
&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 24GB (GPU2) : Yes
&gt; Peer access from Tesla M40 24GB (GPU0) -&gt; Tesla M40 (GPU3) : Yes
&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 24GB (GPU0) : Yes
&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 24GB (GPU2) : Yes
&gt; Peer access from Tesla M40 (GPU1) -&gt; Tesla M40 (GPU3) : Yes
&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 24GB (GPU0) : Yes
&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 (GPU1) : Yes
&gt; Peer access from Tesla M40 24GB (GPU2) -&gt; Tesla M40 (GPU3) : Yes
&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 24GB (GPU0) : Yes
&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 (GPU1) : Yes
&gt; Peer access from Tesla M40 (GPU3) -&gt; Tesla M40 24GB (GPU2) : Yes

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 4, Device0 = Tesla M40 24GB, Device1 = Tesla M40, Device2 = Tesla M40 24GB, Device3 = Tesla M40
Result = PASS
</code></pre>

<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/cuda-sample.png" alt="官方文档中的示例程序" /></p>

<p><code>注意：</code>如果CUDA-capable设备和CUDA 驱动都已经成功安装，但是<code>deviceQuery</code>程序报告没有<code>CUDA-capable</code>设备在线，这个可能是<code>/dev/nvidia*</code>相关文件丢失或者没有相应的权限。</p>

<p>可以使用<code>setenforce 0</code>关闭SELinux后再进行测试。</p>

<p>运行<code>bandwidthTest</code>程序来确认系统和CUDA-capable设备可以正常通信，输出结果如下所示：</p>

<pre><code># ./bandwidthTest
[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: Tesla M40 24GB
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			11710.6

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			12464.9

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			210964.2

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</code></pre>

<p><img src="http://oyep1jupk.bkt.clouddn.com/docker/nvidia-docker/cuda-sample-1.png" alt="官方文档中的示例程序" /></p>

<p>上图表示测试通过，如果测试没有通过，可以确认下系统上CUDA-capable NVIDIA GPU是否正确安装。</p>

<p><code>注意：如果上述两个示例程序都可以正常输出，name恭喜您，GPU环境目前已经可用了！</code></p>

<p>4.2.3  安装Nsight Eclipse plugins</p>

<pre><code># /usr/local/cuda-9.0/bin/nsight_ee_plugins_manage.sh install &lt;eclipse-dir&gt;
</code></pre>

<p><strong>4.3 可选的操作</strong></p>

<p>在使用CUDA Toolkit中，有很多可选操作但是不是必须的但是可以提供额外的功能。</p>

<p>4.3.1 安装第三方库文件</p>

<pre><code># yum install freeglut-devel libX11-devel libXi-devel libXmu-devel \
    make mesa-libGLU-devel
</code></pre>

<p>4.3.2 为cuda-gdb安装源代码
使用<code>runfile</code>方式安装后<code>cuda-gdb</code>源代码会自动安装。</p>

<p>使用RPM或者Deb方式安装，需要为cuda-gbd拷贝一份源代码。<code>cuda-gdb-src</code>包必须被安装。源码包会被以一个tar包的方式安装在<code>/usr/local/cuda-9.0/extras</code>目录。</p>

<p><a href="http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">原文地址</a></p>
    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">BGBiao</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
      2017-10-26
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>


    
    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">Reward</label>
  <div class="qr-code">
    
    
    
  </div>
</div>

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://bgbiao.top/tags/docker/">Docker</a>
          <a href="https://bgbiao.top/tags/gpu/">GPU</a>
          <a href="https://bgbiao.top/tags/nvidia/">NVIDIA</a>
          <a href="https://bgbiao.top/tags/nvidia-docker/">NVIDIA-Docker</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/gpu%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACdocker-%E4%BA%8C/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">GPU环境下玩转Docker(二)</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/dockerfile-etcd/">
            <span class="next-text nav-default">手把手构建Etcd镜像</span>
            <span class="prev-text nav-mobile">Next</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:weichuangxxb@qq.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/BGBiao/" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://landing.google.com/sre/#sre" rel="me noopener" class="iconfont"
      title="coding"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  width="36" height="36">
  <path
      d="m 313.5359,557.51414 c 9.229,0 16.57801,8.88719 16.57801,19.99616 0,11.10899 -7.34901,19.99617 -16.57801,19.99617 -9.229,0 -16.57801,-8.88718 -16.57801,-19.99617 0,-11.10897 7.34901,-19.99616 16.57801,-19.99616 z m 393.7706,0 c 9.22899,0 16.57802,8.88719 16.57802,19.99616 0,11.10899 -7.34903,19.99617 -16.57802,19.99617 -9.229,0 -16.57802,-8.88718 -16.57802,-19.99617 0,-11.10897 7.34902,-19.99616 16.57802,-19.99616 z"
      id="path6"/>
  <path
      d="m 945.8932,448.98796 c -27.17427,0 -51.1013,17.26164 -64.43208,43.23957 C 836.17066,393.44306 741.8298,302.00762 625.27096,264.23708 562.37704,239.1137 518.28294,190.57601 512.8139,134.17657 507.34486,190.74691 463.25077,239.1137 400.35685,264.23708 283.79802,301.83671 189.45714,393.44306 144.16669,492.22753 130.83591,466.2496 107.07979,448.98796 79.734607,448.98796 c -41.701401,0 -75.541066,40.84686 -75.541066,91.26454 0,50.41768 33.839665,91.26454 75.541066,91.26454 12.64715,0 24.610663,-3.75996 35.206923,-10.42536 3.58906,163.55837 180.30728,269.69186 397.87237,270.03367 217.5651,-0.34181 394.28332,-106.4753 397.87238,-270.03367 10.42535,6.6654 22.55977,10.42536 35.20692,10.42536 41.7014,0 75.541,-40.84686 75.541,-91.26454 0.171,-50.41768 -33.6687,-91.26454 -75.541,-91.26454 z M 114.2579,568.79403 c -3.58906,13.15987 -19.312535,18.79981 -35.206921,12.47625 -15.894385,-6.15267 -25.977916,-21.87616 -22.388867,-35.03602 3.58906,-13.15987 19.312533,-18.79981 35.206919,-12.47624 15.894389,6.15267 25.807019,21.87614 22.388869,35.03601 z m 398.556,276.69904 C 338.31748,845.15126 196.97707,762.603 196.97707,644.33509 c 0,-2.56361 0.1709,-4.95631 0.1709,-7.34902 0,-0.85453 0,-1.53817 0.17092,-2.3927 0.1709,-1.70908 0.34181,-3.41814 0.34181,-4.95631 0.1709,-2.22179 0.51273,-4.44359 0.85454,-6.6654 0,-0.1709 0,-0.51271 0.1709,-0.68362 3.58906,-23.2434 12.47624,-58.79214 26.14883,-79.13012 32.64331,-47.51224 90.92273,-78.9592 157.23479,-78.9592 51.1013,0 97.41721,18.79981 130.91506,49.05041 33.49784,-30.2506 79.64283,-49.05041 130.91504,-49.05041 66.48298,0 124.59148,31.61786 157.23479,78.9592 13.67259,20.50889 22.55977,55.88672 26.14883,79.13012 0,0.17091 0,0.51272 0.17091,0.68362 0.34182,2.22181 0.51272,4.44361 0.85453,6.6654 0.17091,1.70907 0.34181,3.24723 0.34181,4.95631 0,0.85453 0.17092,1.53817 0.17092,2.3927 0.17091,2.39271 0.17091,4.95631 0.17091,7.34902 C 828.82165,762.603 687.48124,845.15126 512.8139,845.49307 Z M 946.74774,581.27028 c -15.89439,6.15265 -31.61787,0.68362 -35.20692,-12.47625 -3.58906,-13.15987 6.49448,-28.88334 22.38887,-35.03601 15.89438,-6.15267 31.61786,-0.68363 35.20692,12.47624 3.41815,12.98896 -6.49448,28.71243 -22.38887,35.03602 z"
      id="path8"/>
</svg>

    </a>


<a href="https://bgbiao.top/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2017 -
    2019
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        BGBiao
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  















</body>
</html>
