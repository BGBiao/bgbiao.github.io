<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BGBiao的Ops人生</title>
    <link>https://bgbiao.top/</link>
    <description>Recent content on BGBiao的Ops人生</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 02 Jan 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bgbiao.top/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2019年总结之瞎扯淡</title>
      <link>https://bgbiao.top/post/2019%E5%B9%B4%E6%80%BB%E7%BB%93%E4%B9%8B%E7%9E%8E%E6%89%AF%E6%B7%A1/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/2019%E5%B9%B4%E6%80%BB%E7%BB%93%E4%B9%8B%E7%9E%8E%E6%89%AF%E6%B7%A1/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;大胡子&lt;/code&gt;是我特别佩服的一位老师，第一次知道他是17年偶尔一次线上讲座，具体题目忘记了，内容大概是关于&amp;rdquo;技术人如何赚钱&amp;rdquo;，很real，告诉一些晚辈如何赚钱，以及拥有一些赚钱思维，我觉得这个真的很酷。后来才了解到他的&lt;code&gt;疯人院&lt;/code&gt;和星球，所以立马入会，所幸会费不是很高(这要是再高个几百的，当时的我是肯定不会去&amp;rdquo;割韭菜&amp;rdquo;社群)。不过，在这两年里，虽然不曾在社群发表自己的观点，但是通过群里各种大牛、前辈们的探讨，在加上自己的思考，也的确让自己再技术之外成长了很多，所以，在这里我向大家极力推荐大胡子老师，他的公众号是&lt;code&gt;姜胡说&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;年初了，总该总结总结过去一年的成长和收获，也该去梳理梳理新一年的征程如何走下去，这里有一篇胡子老师的文章，觉得很有意思，感兴趣的可以去仔细读读&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzIxMjE4NzM5MA==&amp;amp;mid=2651785933&amp;amp;idx=1&amp;amp;sn=867e1c2e54dc124d60d9ad3c7a759a49&amp;amp;chksm=8cb24b5cbbc5c24a7a3f51f882e2a8c13f05312bdf33d5a5e03e52ea89eb818b32dfad65a43b#rd&#34;&gt;早知道这个，我至少可以少奋斗3年&lt;/a&gt;，虽然有点标题档了，但不妨碍这依然是一篇值得看和值得思考的文章.&lt;/p&gt;

&lt;p&gt;以下摘录几个观点，用于鞭策自己:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.Stay hungry,Stay foolish&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Stay hungry,Stay foolish!&lt;/code&gt;是乔布斯老爷子在斯坦福大学大学演讲时结尾的一句话，翻译过来即为&amp;rdquo;求知若饥，虚心若愚&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;记得那个时候我还在上大学，乔老爷子的自传以及演讲都那么激动人心，我还曾经将&lt;code&gt;Stay hungry,Stay foolish!&lt;/code&gt;作为我的微信签名，直到后来我懂得了做的重要性，才将微信签名换成如今的&lt;code&gt;Never try,Never known!&lt;/code&gt;。要说&amp;rdquo;Stay hungry,Stay foolish&amp;rdquo;是内在修养的话，那么&amp;rdquo;Never try,Never known&amp;rdquo;就是外在表现，我们要一直对外保持不断的好奇心，不断尝试，只有不断尝试，我们才会发现我们是多么的无知，而当你长时间处于无知状态时，往往会被别人远远的甩在最后。&lt;/p&gt;

&lt;p&gt;所以，&lt;code&gt;当你对这个世界失去了敬畏和好奇心时，你就一定会落后&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;落后就肯定会挨打，我相信从小到大大家都不愿成为挨打的那个人。&lt;/p&gt;

&lt;p&gt;那该怎么办呢？我在&amp;rdquo;Stay hungry,Stay foolish&amp;rdquo;的后面再加一个&amp;rdquo;Never try,Never known!&amp;ldquo;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stay hungry: &lt;code&gt;保持对知识的敬畏，保持对这个世界的好奇心&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Stay foolish: &lt;code&gt;接触到新事物时，不要让固有的观念影响自己。真正强大的人，允许自己的大脑里同时存在两种或者两种以上完全相反的声音。&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Never try,Never known: &lt;code&gt;不去尝试，永远不知道这个世界本身的运行机制，当你知道再多也不去尝试仍然是不知道&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.技不压身&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;像我们搞运维的，最早之前可能会比较熟悉使用Linux，然后擅长Linux环境下一些常用服务的规划和实施，并且能够尽快排查故障和问题。在我刚开始从业的一段时间，我一度有点茫然，纠其原因是因为运维这个行业，起码像我上面提到的这个定义，其实任何一个有相关技术背景，并且本身还算是一个靠谱的人，及时对运维一点儿也不懂，如果有运维的活儿，那他也一定可以完成，不过就是多花点时间多花点儿精力而已。&lt;/p&gt;

&lt;p&gt;所以，我那个时候在想，作为一个运维从业者，未来将如何破局。这就跟一两年前同行相遇都会问&amp;rdquo;我们搞运维的，要不要去学点开发啊&amp;rdquo;，到目前为止，我想市面上应该再没有不懂开发的运维了吧。至少你写个Python、Shell、Perl脚本是最基本的吧,再有甚者可能还会对运维有Golang或者Java开发的能力的要求。&lt;/p&gt;

&lt;p&gt;那我想说的也是:&lt;code&gt;多了解一些其他技术，对运维，甚至是其他事情都会有莫大的好处&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这两年我也因此去多学习了一些其他技术，比如&lt;code&gt;Golang、Vue、基于Hadoop体系的大数据处理&lt;/code&gt;，虽然在这几个方面都不是很深入，也不是很资深，但此时作为一个运维从业者来说，或者想要成为一个更加优秀的运维从业者来说，这些技能都是非常有帮助的。&lt;/p&gt;

&lt;p&gt;2020年，我会在巩固常用技术的基础上再去多拓展一些技术，比如&lt;code&gt;Rust&lt;/code&gt;或者&lt;code&gt;JavaScript&lt;/code&gt;之类的，毕竟2020年都要实现全面建设小康社会了，我们自身的技能也应该再全面一些不是么？&lt;/p&gt;

&lt;p&gt;有些人可能就会说了，学那么多技术，也不一定用的上，其实古人有句话就是&amp;rdquo;书到用时，方恨少&amp;rdquo;，很多时候我们在不断学习和了解的过程中并不一定是在未来一定要用它，而是&lt;code&gt;用整个经历来还原他人决策的依据&lt;/code&gt;，让你能够以更贴近他人的角度去理解一件事，更何况万一在未来用上了，不是也不用去求他人了不是。&lt;/p&gt;

&lt;p&gt;这个时候，可能还会有人说了，我想去学习一些先进的技术，但是在国内网站上都无法找到，而且信息杂乱。其实，只要你确定了要去学习一些新技术，那怎么学就不是那么重要了，毕竟&lt;code&gt;做什么比怎么做更重要&lt;/code&gt;，是吧，只要目标明确，就一定能找到对应的途径。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.知识获取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接着上面说到的，我想学习一门新技术，我该如何去学习呢？&lt;/p&gt;

&lt;p&gt;我的建议其实如同大胡子老师的观点，一定要吸收&lt;code&gt;最原始的知识&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;一定要&lt;code&gt;拒绝二手知识。更何况是三手、四手。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前两天，偶然在群里看到有小伙伴说&amp;rdquo;现在就是照着网上的配置抄，然后埋大bug&amp;rdquo;。现实可能的确是这样的，因为大家时间都很宝贵，遇到问题也都着眼于解决眼下&amp;rdquo;问题&amp;rdquo;，所以对于本质问题也少有人会追根溯源了。这就是典型的多手知识，目前网络上充斥着各种良莠不齐的文章，我们可能不了解别人的场景，也不了解问题的上下文，照抄别人的配置，可能是暂时解决问题了，也许也埋下了一个祸根，但终究对于我们个人而言，没有任何成长。&lt;/p&gt;

&lt;p&gt;胡子老师在那篇文章说:
&amp;gt; 读书这种事很美妙。
&amp;gt; 思考也是。
&amp;gt; 不要让他人剥夺走。
&amp;gt; 获取一些有养料的知识。
&amp;gt; 不仅仅是读书。&lt;/p&gt;

&lt;p&gt;我们搞技术的人，大多数场景都在使用开源技术构建产品，所以在成长的路上我们完全可以阅读那些&lt;code&gt;官方文档&lt;/code&gt;，及时那些英文官方文档不那么容易理解，我也依然建议去阅读官方文档，起码在核心问题上，要比那些多手翻译的官方文档要好很多。再者，我们如果有时间和经历，其实是可以针对核心逻辑去阅读源代码来追溯源头。&lt;/p&gt;

&lt;p&gt;到现在为止，我在工作上遇到的任何技术问题，如果是开源组件，我都会第一时间去&lt;code&gt;GitHub&lt;/code&gt;或&lt;code&gt;Google&lt;/code&gt;上查找官方文档，当然我也会借鉴一些多手翻译的官方文档(毕竟英语水平不咋地)。&lt;/p&gt;

&lt;p&gt;当然这里并不是想说是怎么去获取知识的，而是一种思维模式，即&amp;rdquo;对于知识，我们一定要思考要不要去学习，然后找到一手渠道去学习最原始、最纯的知识&amp;rdquo;。知识其实是无处不在的，我们需要的是有鉴别知识的能力.&lt;/p&gt;

&lt;p&gt;然后，&lt;code&gt;基于需求或者人类的社会动机将那些想法进行分类整理&lt;/code&gt;。 这句话也是胡子老师文章中的，很有感触。将我们学到知识进行分门别类，仔细想想，&lt;code&gt;一个不能和人类需求和社会动机联系在一起的知识，它可以用在什么地方呢？&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以尝试思考一下:
&amp;gt; 这条信息主要覆盖哪个团体和人群？
&amp;gt; 这个想法代表了哪些深层的人类需求和行为？
&amp;gt; 这件事有趣的地方在哪里？
&amp;gt; 别人是怎么做的？
&amp;gt; 不同团体之间他们互相是如何做的？&lt;/p&gt;

&lt;p&gt;最后，依然以大胡子老师的话结尾。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;观察生活中既有的生活方式,
和那些新鲜事物做对比。看看发生了什么。
最后&lt;code&gt;把所有的问题全部回归到人类的需求和社会动机上来。&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;人活着都有什么需求，你考虑了，别人没考虑，那，这就是你和别人的差距。&lt;/p&gt;

&lt;p&gt;劳心者制人，劳力者制于人，这才是自然规律。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>2019年总结之财务投资</title>
      <link>https://bgbiao.top/post/2019%E5%B9%B4%E6%80%BB%E7%BB%93%E4%B9%8B%E8%B4%A2%E5%8A%A1%E6%8A%95%E8%B5%84/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/2019%E5%B9%B4%E6%80%BB%E7%BB%93%E4%B9%8B%E8%B4%A2%E5%8A%A1%E6%8A%95%E8%B5%84/</guid>
      
        <description>&lt;p&gt;18年的时候，我在个人公众号&lt;code&gt;BGBiao&lt;/code&gt;上写了一篇关于如何&amp;rdquo;选鸡&amp;rdquo;的文章，大概介绍下了作为一名不了解投资和没有投资经验的人如何选一只性价比较高的基金，感兴趣的同学可以回顾下&lt;a href=&#34;https://mp.weixin.qq.com/s/swAOiIT-tWkpC0wa24C51Q&#34;&gt;门外汉如何选择一只&amp;rdquo;鸡&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;作为一个在IT行业工作的人来说，我认为非常有必要提前考虑个人的投资和理财计划，毕竟年轻时的高薪和高强度工作很容易让你在后面很多年感觉到无所适从，因为随着年龄的增大，持续高薪的工作并不好找，而且高强度的工作，也可能没有小伙子们的那种撑劲儿，所以，提前规划自己的理财和投资，我个人觉得还是蛮重要的。&lt;/p&gt;

&lt;p&gt;2019年即将结束，回想一下自己过去一年的&amp;rdquo;选鸡&amp;rdquo;经历，还是想在这里总结一下，并希望和期待今后能够做的更好，同时也希望将自己总结的几个点分享出来。&lt;/p&gt;

&lt;p&gt;先晒一下过去一年入仓的一些&amp;rdquo;鸡&amp;rdquo;以及整体的收益状况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaf2h7cjwyj30cn29cn1y.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.基金投资如何开户&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;购买基金一般可以从基金公司官网、银行、以及第三方基金销售平台购买。&lt;/p&gt;

&lt;p&gt;不过通常情况下，我都会在第三方App上进行投资，比如我会使用&lt;code&gt;支付宝&lt;/code&gt;和&lt;code&gt;天天基金网&lt;/code&gt;来进行基金投资，一个是因为方便和权威，并且基金的种类也特别丰富，另外一个原因是在这些平台上通常都会有较低的费率(通常有1折优惠)。&lt;/p&gt;

&lt;p&gt;有些人可能会问，为什么同时使用两个软件进行基金投资，其实最早是因为刚工作那会，支付宝有余额，想着可以通过一种理财策略来省钱，但是又不甘心余额宝那么低的收益，所以当16年左右，支付宝刚开始推出&amp;rdquo;一天10块钱，轻轻松松做理财&amp;rdquo;时，就买了些基金，并一直观察持有，且不断加仓(搞理财的都知道，频繁换手其实是非常不利的，所以既然认定了一只好鸡，索性就一直将这只鸡重仓在支付宝了).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;天天基金网&lt;/code&gt;是在我开始玩基金一段时间后，向一个在银行从业的朋友那了解到的，当时是想象她请教如何选鸡，如何交易，所以后面更多就使用该软件来进行交易。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.投资基金应该如何配置基金&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基金其实分很多种类，在之前的文章中，我好想写过，比如说有纯债基金，混合基金，指数基金，股票型基金等等。&lt;/p&gt;

&lt;p&gt;通常情况下来讲，混合基金，要看基金经理本身的能力，这个需要有一定的经验去挑选基金经理。&lt;/p&gt;

&lt;p&gt;如果想简单操作，搭配纯债基金+指数基金，这个方案也是没问题的。&lt;/p&gt;

&lt;p&gt;不过在我入仓的一些基金里，大部分都是股票型基金，当然了风险也会相对的比较高，因此对于该基金背后的团队，以及基金经理还有所持有的股票都需要有一定的了解，相对于普通人来说会有一定的难度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.如何入仓&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我的建议是通过&amp;rdquo;基金定投&amp;rdquo;来入仓和不断加仓。&lt;/p&gt;

&lt;p&gt;因为使用基金定投从长远角度来考虑可以将整体的风险降低，并且可以不断的累计自己的基金池。&lt;/p&gt;

&lt;p&gt;相反，如果是追涨杀跌，看着基金涨了就想多买点，这会影响定投摊平风险的效果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.注意事项&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;建议在刚开始玩基金时，不要对收益有太大的幻想，因为任何成长都需要有成本的，不论是资金成本还是时间成本或者知识成本，但是如果选择定投基金，从长远角度是肯定会存储一笔资金的。另外，对于基金的买卖一定要沉住气，切勿&lt;code&gt;追涨杀跌&lt;/code&gt;，在我个人刚开始玩基金时，会频繁根据涨跌情况去调仓，后面会发现其实很多调仓都会出现反涨的情况，再加之费率的问题，其实整体会很不划算。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Tips: 其实还有另外一个技巧就是，当你看好一只基金时，除了定投之外，也可以定期的去看基金一天的估价，通常情况下，在交易日下午三点前会是一个相对稳定的估价，此时可以做一些类似买跌类的操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;先简单分享到这里，业余玩鸡，2020年一起进步。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexzwmo1wj30j60pa40b.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>CronJob控制器中的一些绕坑指南</title>
      <link>https://bgbiao.top/post/cronjob%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%95%E5%9D%91%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/cronjob%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%95%E5%9D%91%E6%8C%87%E5%8D%97/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 作为企业里唯一熟悉各种云产品的工种，通常需要和各种云产品打交道。当前，我们大部分的云基础设施和云服务都运行在阿里云上，而每个云产品都有独立的管理系统，这使得我们在运维过程中经常无法将相关产品和关联信息有效的组织在一起，来进行快速的问题诊断和信息查询，这对于运维和开发同学来说，在多个系统之间来回跳转查找关联信息是一个低效且极易出错的事务，因此通常来讲，不论是作为运维和开发，我们都希望将企业关联的云资源和服务进行整合关联，以实现效率的最大化。而在这过程中，我们采用Kubernetes集群的CronJob来定期获取阿里云的一些资源，在这过程中，遇到一些问题，根据问题重新细读CronJob官方文档，特记录于此。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;CronJob简单介绍&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个&lt;code&gt;CronJob&lt;/code&gt;对象就像是一个Linux环境的&lt;code&gt;crontab&lt;/code&gt;文件一样，它会在给定的调度周期(crontab格式)内定期的创建一些job.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;所有的定时任务的调度周期都依赖于k8s的master节点的时区&lt;/p&gt;

&lt;p&gt;通常情况下，CronJob对于创建定期和重复的任务非常有用，比如定期的备份和邮件发送之类的任务场景。&lt;/p&gt;

&lt;p&gt;当然了，在Kubernetes集群中，Cronjob也有一些局限性和特性，需要详细了解下才能用的比较好。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: Cronjob控制器当前官方仍然是beta版本，也就意味着还是有一些问题存在的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cronjob的局限性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个Cronjob会在它每执行一次调度就&lt;code&gt;大概&lt;/code&gt;会创建一个Jobs对象。&lt;code&gt;大概&lt;/code&gt;是因为有时候可能会有两个job被创建，或者没有任务创建。
官方实现中尝试去解决这种问题，但是目前仍然无法避免。因此在设计过程中，所有的Job都应该是幂等性的(idempotent)&lt;/p&gt;

&lt;p&gt;如果&lt;code&gt;startingDeadlineSeconds&lt;/code&gt;参数被设置为一个比较大的值，或者没有设置(默认)，并且&lt;code&gt;concurrencyPolicy&lt;/code&gt;设置为&lt;code&gt;Allow&lt;/code&gt;，那么Job总是会运行至少一次。&lt;/p&gt;

&lt;p&gt;对于每一个Cronjob来说，&lt;code&gt;CronJob&lt;/code&gt;控制器会检查从上一次调度时间到现在的持续时间内它错过了多少个调度，如果错过调度100次，它将不再执行调度，并且会有如下相关异常.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cannot determine if job needs to be started. Too many missed start time (&amp;gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;值得关注的是，如果设置了&lt;code&gt;startingDeadlineSeconds&lt;/code&gt;参数(不为空),控制器统计错过的调度次数将不再是从最后一次调度时间，而是
从&lt;code&gt;startingDeadlineSeconds&lt;/code&gt;的值到现在进行统计。比如，如果设置&lt;code&gt;startingDeadlineSeconds:200&lt;/code&gt;,控制器会统计在最后200秒内错
过了的调度次数。&lt;/p&gt;

&lt;p&gt;如果CronJob未能在预定时间创建，则该任务将被视为错过调度。比如，当设置&lt;code&gt;concurrencyPolicy: Forbid&lt;/code&gt;时，当前一个任务还在运
行时CronJob尝试再次被调度，此时会被&lt;code&gt;forbid&lt;/code&gt;掉，因此也会被记录为错过一次调度。&lt;/p&gt;

&lt;p&gt;再比如，我们假设一个定时任务被设置在&lt;code&gt;08:30:00&lt;/code&gt;后每一分钟执行一次，并且&lt;code&gt;startingDeadlineSeconds&lt;/code&gt;参数没有被设置。如果CronJob控制器在&lt;code&gt;08:29:00&lt;/code&gt;到&lt;code&gt;10:21:00&lt;/code&gt;之间故障了，Job将不会运行，因此错过调度的任务数量将远超过100。&lt;/p&gt;

&lt;p&gt;为了更深层次说明这个问题，假设一个定时任务被设置在&lt;code&gt;08:30:00&lt;/code&gt;开始每一分钟执行一次，并且&lt;code&gt;startingDeadlineSeconds:200&lt;/code&gt;。如果CronJob控制器依然在相同时间段故障了，Job将会在&lt;code&gt;10:22:00&lt;/code&gt;开始继续执行。 因为控制器仅会计算在过去的200秒内，错过调度的
次数有多少，因此仅会错过调度3次，远远小于100次，所有定时任务会在控制器恢复后继续调度，而不会影响正常的任务。&lt;/p&gt;

&lt;p&gt;另外需要注意的是，CronJob仅负责调度和创建匹配的Jobs，而由Jobs真正去管理真正执行任务的Pods。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cronjob的参数详情&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;spec.startingDeadlineSeconds&lt;/code&gt;: 表示统计错过调度次数(100次)的开始时间，默认从最后一次调度时间开始统计错过调度次数(超
过100不再调度)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.concurrencyPolicy&lt;/code&gt;: 并发调度策略，可选值:{&amp;ldquo;Allow&amp;rdquo;:&amp;ldquo;允许并发&amp;rdquo;,&amp;ldquo;Forbid&amp;rdquo;:&amp;ldquo;不允许&amp;rdquo;,&amp;ldquo;Replace&amp;rdquo;:&amp;ldquo;调度覆盖&amp;rdquo;}.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Allow&lt;/code&gt;: &lt;code&gt;注意:&lt;/code&gt;当设置为&lt;code&gt;Allow&lt;/code&gt;时，需要考虑到任务执行时间和调度周期，因为可能上个任务没执行成功，下个任务就到执行时间了，如此下来可能会有很多任务都执行积压，造成资源误使用;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Replace&lt;/code&gt;: 当使用&lt;code&gt;Replace&lt;/code&gt;遇到上述情况，后个任务会将前一个任务替换掉，如此以来所有的任务可能都不会完整执行;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Forbid&lt;/code&gt;: 则不允许并发调度，也即就调度一次，下一次调度周期再调度，但是可能由于任务执行过长，导致大部分的任务在每一
次调度时间都完美的错过了，此时&lt;code&gt;startingDeadlineSeconds&lt;/code&gt;参数也并没有设置，就可能会出现该任务不会再调度，对应到k8s里的事
件可能是&lt;code&gt;Cannot determine if job needs to be started: too many missed start time (&amp;gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.schedule&lt;/code&gt;: 调度周期，格式为标准的crontab格式[分 时 日 月 周]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.failedJobsHistoryLimit&lt;/code&gt;: 历史失败的任务数限制(通常可以保留1-2个，用于查看失败详情，以调整调度策略)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.successfulJobsHistoryLimit&lt;/code&gt;: 历史成功的任务数限制(可以自己决定保留多少个成功任务)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.jobTemplate&lt;/code&gt;: 标准的pod运行的模板(容器运行时的相关参数)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;spec.suspend&lt;/code&gt;: 可选参数，如果设置为&lt;code&gt;true&lt;/code&gt;,所有后续的任务都会被暂停执行，该参数不适用于已经运行的任务，默认为False&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;CronJob示例&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 配置了一个定期去阿里云云解析获取解析详情的数据
$ cat dnsall-cronjob.yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  labels:
    run: dnsall
  name: dnsall
  namespace: myapp
spec:
  # 强烈建议设置并发策略，根据调度周期和任务特性进行设置
  concurrencyPolicy: Forbid
  # 强烈建议设置失败任务数，用于排查任务失败根因，以优化任务
  failedJobsHistoryLimit: 1
  successfulJobsHistoryLimit: 3
  # 强烈建议设置错过调度的计算时间
  startingDeadlineSeconds: 600
  # 调度周期
  schedule: &#39;05,15,25,35,45,55 */1 * * *&#39;
  suspend: false
  jobTemplate:
    metadata:
    spec:
      template:
        metadata:
          labels:
            run: dnsall
        spec:
          imagePullSecrets:
          - name: mydocker
          containers:
          - args:
            - -cmdbtype
            - dns
            image: harbor.bgbiao.top/cron-job:2019-12-04
            imagePullPolicy: Always
            name: dnsall
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          # 强烈建议设置任务的重启策略(任务的失败会触及到Jobs控制器中的Backofflimit参数，导致job失败)
          restartPolicy: OnFailure
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30

$ kubectl  get cronjob -n myapp
NAME             SCHEDULE                      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
dnsall           05,15,25,35,45,55 */1 * * *   False     0        8m41s           23h

# cronjob其实定期的创建了job，因此具体的任务pod其实是由job控制器来维护的
# 这里可以看到，我们上面的cronjob保存的三个执行成功的任务
$ kubectl  get jobs -n myapp  | grep dns
dnsall-1577597100           1/1           23s        22m
dnsall-1577597700           1/1           24s        12m
dnsall-1577598300           1/1           24s        2m22s

# 再查看一个job真正管理的pod任务的执行
# 任务已经已完成，所以任务的期望值为1，当前值为0
$ kubectl  get pods -n myapp | grep dnsall-1577598300
dnsall-1577598300-hdl4z           0/1     Completed   0          3m29s

&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>软件工程师们必须了解的画图工具</title>
      <link>https://bgbiao.top/post/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BB%AC%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E7%94%BB%E5%9B%BE%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BB%AC%E5%BF%85%E9%A1%BB%E4%BA%86%E8%A7%A3%E7%9A%84%E7%94%BB%E5%9B%BE%E5%B7%A5%E5%85%B7/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;作为一名在IT行业摸爬滚打多年的少年，选择一款适手的画图工具可以说是爽到不行。记得学生时代，鉴于条件的限制，都只能选择Visio进行绘制流程图、类图、UML图等，但是微软家的东西，大家也懂。特别是作为一名长期混迹在开源世界的从业者，我们都喜欢使用一种免费且好用的替代方案来完成日常的工作需求。比如&lt;code&gt;Markdown&lt;/code&gt;就基本上成功替代了&lt;code&gt;Document&lt;/code&gt;去编写文档，然后&lt;code&gt;Xmind&lt;/code&gt;、&lt;code&gt;ProcessOn&lt;/code&gt;、&lt;code&gt;Draw&lt;/code&gt;之类的工具基本上也可以实现对&lt;code&gt;Visio&lt;/code&gt;的替代，当然我这里仅说的是我个人遇到的情况，不能以偏概全，微软家的很多产品也依然是不错的。接下来像大家推荐几个常用的画图工具.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;在线类产品&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.processon.com/&#34;&gt;ProcessOn&lt;/a&gt;: 很好用的产品，但是对于免费用户来说可保存的文件有限&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yuque.com/&#34;&gt;语雀&lt;/a&gt;: 阿里开源的一个在线知识写作平台，个人免费用户基本没什么限制，其中有个实验室功能，可以在线使用&lt;code&gt;PlantUML&lt;/code&gt;语法绘制各种图(流程图，时序图，UML图等)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://online.visual-paradigm.com/cn/&#34;&gt;Visual-paradigm&lt;/a&gt;: 和ProcessOn类似&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://draw.io/&#34;&gt;Draw&lt;/a&gt;: 开源免费的在线绘图(需要使用谷歌账号进行注册登录,不过既然开源是可以私有化部署，支持各种客户端)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;draw相关地址&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_33929309/article/details/91609993&#34;&gt;参考文章&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dl.elkpi.com:8080/draw/&#34;&gt;国内在线draw&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jgraph/drawio&#34;&gt;draw开源地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jgraph/drawio-desktop&#34;&gt;draw客户端&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Goroutine与主进程的通信</title>
      <link>https://bgbiao.top/post/goroutine%E4%B8%8E%E4%B8%BB%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%80%9A%E4%BF%A1/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/goroutine%E4%B8%8E%E4%B8%BB%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%80%9A%E4%BF%A1/</guid>
      
        <description>&lt;p&gt;还记得前半年去某条面试，面试小哥问我，当一个进程启动多个goroutine时，某个goroutine挂了，如何让主进程知道，当时大概知道可以通过&lt;code&gt;context&lt;/code&gt;这个包来实现，但是当时没有具体去了解和熟悉这块，在这里再总结下。&lt;/p&gt;

&lt;p&gt;子goroutine与主线程同步的集中方式:
- &lt;code&gt;channel&lt;/code&gt;: 每个goroutine往主进程的&lt;code&gt;chan&lt;/code&gt;写数据，然后由主进程去读取，直到读取完了全部goroutine的&lt;code&gt;chan&lt;/code&gt;就算运行完毕，此时主进程即可正常退出。这种方式是子线程通知主线程结束.
- &lt;code&gt;context&lt;/code&gt;: 使用&lt;code&gt;context&lt;/code&gt;中的&lt;code&gt;cancel&lt;/code&gt;，这种模式是主线程通知子线程结束
- &lt;code&gt;sync.WaitGroup&lt;/code&gt;: 通过&lt;code&gt;Add&lt;/code&gt;方法设置等待子goroutine的数量，使用&lt;code&gt;Done&lt;/code&gt;方法设置等待子goroutine的数量减1，当等待数量为0时，&lt;code&gt;Wait&lt;/code&gt;函数退出.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.通过channel实现同步&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat channel-sync.go
package main
import (
    &amp;quot;fmt&amp;quot;
)
// 通过向主进程中的channel来和主进程进行通信
func subTask(c chan int) {
    defer close(c)
    for i :=0;i&amp;lt; 10;i++ {
        c &amp;lt;- i
    }
}

func main() {
    isok := make(chan int,10)
    go subTask(isok)
    // 通过channel来让子goroutine和主线程共享内存(通过通信实现共享内存)
    for v := range isok {
        fmt.Println(v)
    }
}
$ go run channel-sync.go
0
1
2
3
4
5
6
7
8
9

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;**2.context方式传递数据给主线程 **&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat context-sync.go
package main
import (
    &amp;quot;context&amp;quot;
    &amp;quot;fmt&amp;quot;
)

func subTask(ctx context.Context) (chan int) {
    dst := make(chan int)
    n := 0
    go func() {
				// 通过使用select执行和channel相关的IO操作(类似switch)
				// select关键字其实是go并发模型中比较重要的
        for {
            select {
                case &amp;lt;- ctx.Done():
                    return
                case dst &amp;lt;- n:
                    n++
            }
        }
    }()
    return dst
}

func main() {
    ctx,cancel := context.WithCancel(context.Background())
    defer cancel()

    // subTask中其实是一个死循环会不断将n自增并返回到dst
    testChan := subTask(ctx)

    for n := range testChan {
        // 主进程通过chan中的值控制并发？然后通过cancel()来通知子routine结束
        if n == 9 {
          break
        }
        fmt.Println(n)
    }

}

$ go run context-sync.go
0
1
2
3
4
5
6
7
8

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.通过sync.WaitGroup来实现&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat waitgroup-sync.go
package main
import (
    &amp;quot;sync&amp;quot;
    &amp;quot;fmt&amp;quot;
)

func subTask(wg *sync.WaitGroup){
    // 在并发函数中通知waitgroup完成
    defer wg.Done()
    for i := 0;i &amp;lt; 10;i++ {
        fmt.Println(i)
    }
}

func main() {
    wg := &amp;amp;sync.WaitGroup{}
    // 设置waitgroup等待次数(并发次数)
    wg.Add(2)
    for i:=0;i&amp;lt;2;i++ {
      go subTask(wg)
    }
    wg.Wait()
}

$go run waitgroup-sync.go
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4.多个子goroutine之间通信&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat mutil-goroutines-sync.go
package main
import (
    &amp;quot;fmt&amp;quot;
)

// 两个task互相协作，通过两个channel来互相通知对方执行的阻塞和继续
// 因为c2其实是一个带缓冲的(1)的channel，会阻塞主直到另外一个task处理
func task1(c1 chan bool,c2 chan bool) {
    for i:= 1;i&amp;lt; 11;i += 2{
        // c2是一个带缓冲的channel，因此第一次打印12后到这里会等待读取c2
        &amp;lt;- c2
        fmt.Printf(&amp;quot;%d&amp;quot;,i)
        fmt.Printf(&amp;quot;%d&amp;quot;,i+1)
        c1 &amp;lt;- true

    }
}

func task2(c1 chan bool,c2 chan bool,c3 chan struct{}) {
    char_seq := [...]string{&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;H&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;J&amp;quot;}
    for i:=0;i&amp;lt;10;i += 2{
        &amp;lt;- c1
        fmt.Printf(&amp;quot;%s&amp;quot;, char_seq[i])
        fmt.Printf(&amp;quot;%s&amp;quot;, char_seq[i+1])
        c2 &amp;lt;- true
    }
    // 通知主进程任务执行完成
    c3 &amp;lt;- struct{}{}
}


func main() {
    c1 := make(chan bool)
    // 通过有缓冲的channel来争抢执行
    c2 := make(chan bool,1)
    // 定义一个struct{}类型的channel
    done := make(chan struct{})

    // 创建两个goroutine在后台执行
    go task1(c1,c2)
    go task2(c1,c2,done)

    // 继续执行，此时channel c2开始通过值告诉task1开始执行
    fmt.Println(&amp;quot;begin&amp;quot;)
    c2 &amp;lt;- true
    // 通过一个struct{}类型的channel将主进程阻塞住
    &amp;lt;- done
}

$ go run mutil-goroutines-sync.go
begin
12AB34CD56EF78GH910IJ%

&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>Linux下快速构建Android编译环境</title>
      <link>https://bgbiao.top/post/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BAandroid%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BAandroid%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 在移动互联网时代，大多数的企业内部都有移动客户端，而移动客户端又因为OS的不同产生了两个派系，即&lt;code&gt;安卓(Android)&lt;/code&gt;和&lt;code&gt;苹果(IOS)&lt;/code&gt;，而对于互联网技术从业者来说，这两者最直接的区别就是&lt;code&gt;开源&lt;/code&gt;和&lt;code&gt;闭源&lt;/code&gt;，因而也导致了在构建移动客户端时，为了整体的稳定性和可靠性的考虑(甚至有成本的考虑)，需要进行分别编译，本篇文章记录下如何在Linux环境下构建&lt;code&gt;Android&lt;/code&gt;编译环境.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;介绍&#34;&gt;介绍&lt;/h3&gt;

&lt;p&gt;通常，开发&lt;code&gt;苹果&lt;/code&gt;系列的软件均需要使用一些专有开发工具，比如&lt;a href=&#34;https://developer.apple.com/xcode/&#34;&gt;xcode&lt;/a&gt;,而此工具必须运行在&lt;code&gt;Mac OS X&lt;/code&gt;设备上(当然你也可以尝试各种黑苹果的方式)，所以不论是对于个人开发者还是企业构建服务器来说，都需要购买更多的&lt;code&gt;Mac&lt;/code&gt;设备，通常，我知道的企业内部会使用&lt;code&gt;Mac Mini&lt;/code&gt;来作为苹果系列的构建环境。&lt;/p&gt;

&lt;p&gt;而作为&lt;code&gt;安卓(Android)&lt;/code&gt;系列的软件，由于本身是谷歌开源的移动端操作系统，因此对于底层开发环境和构建环境没有太高的要求。一般而言，开发者会使用&lt;a href=&#34;https://developer.android.com/studio/&#34;&gt;Android Studio&lt;/a&gt;来开发安卓系列的软件，而内置的命令行工具&lt;a href=&#34;https://developer.android.com/studio/command-line/&#34;&gt;command-line&lt;/a&gt;则默认提供了安卓软件的编译工具和环境。值得一提的是，由于&lt;code&gt;Android Studio&lt;/code&gt;是开源的，因此该工具也提供了多个平台的支持(Windows,Mac,Linux,Chrome OS)。而这也极大的降低了企业的整体成本，通常开发环境可以在任意的OS环境中进行开发，而企业内部也可以使用&lt;code&gt;Linux&lt;/code&gt;环境进行安卓软件的持续集成和交付.&lt;/p&gt;

&lt;p&gt;接下来主要讲解下如何在Linux环境下构建安卓的编译环境。&lt;/p&gt;

&lt;h3 id=&#34;linux下安卓-android-编译环境的搭建&#34;&gt;Linux下安卓(Android)编译环境的搭建&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;前提条件&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是，对于&lt;code&gt;安卓(Android)&lt;/code&gt;应用来说，一些依赖包的管理主要依靠&lt;code&gt;sdkmanager&lt;/code&gt;这个命令行工具，该工具可以在&lt;a href=&#34;https://developer.android.com/studio/&#34;&gt;Android Studio&lt;/a&gt;页面找到，并且支持&lt;code&gt;Windows&lt;/code&gt;,&lt;code&gt;Mac&lt;/code&gt;,&lt;code&gt;Linux&lt;/code&gt;三个不同平台的版本。&lt;/p&gt;

&lt;p&gt;同时，&lt;code&gt;安卓(Android)&lt;/code&gt;应用的开发工具&lt;code&gt;Android Studio&lt;/code&gt;使用&lt;code&gt;[Gradle](https://github.com/gradle/gradle)&lt;/code&gt;来进行编译和打包，因此对于&lt;code&gt;安卓(Android)&lt;/code&gt;应用而言，也将使用&lt;code&gt;gradle&lt;/code&gt;来进行编译和打包操作，该软件可以在&lt;a href=&#34;https://services.gradle.org/distributions/&#34;&gt;Gradle&lt;/a&gt;页面找到。&lt;/p&gt;

&lt;p&gt;其次，&lt;code&gt;[NDK(原生开发套件)](https://developer.android.google.cn/ndk/guides/)&lt;/code&gt;是一套工具，可以使开发者能够在 Android 应用中使用 C 和 C++ 代码，并提供众多平台库，开发者可使用这些平台库管理原生 Activity 和访问物理设备组件，例如传感器和轻触输入。该开发套件可以在&lt;a href=&#34;https://developer.android.google.cn/ndk/downloads&#34;&gt;NDK&lt;/a&gt;页面找到.&lt;/p&gt;

&lt;p&gt;最后，如上几个组件的底层语言均使用&lt;code&gt;java&lt;/code&gt;进行开发，因此需要安装&lt;code&gt;JDK&lt;/code&gt;相关环境。&lt;/p&gt;

&lt;p&gt;综上所述，在Linux环境下编译安卓(Android)环境需要如下几个组件:
- &lt;a href=&#34;https://www.oracle.com/technetwork/java/javase/downloads/index.html&#34;&gt;JDK&lt;/a&gt;: java语言的基础编译和运行环境
- &lt;a href=&#34;https://developer.android.com/studio/&#34;&gt;sdkmanager&lt;/a&gt;: 安卓(Android)应用下的依赖包管理器
- &lt;a href=&#34;https://developer.android.google.cn/ndk/downloads&#34;&gt;NDK&lt;/a&gt;: 安卓原生开发套件，可调用底层&lt;code&gt;C&lt;/code&gt;和&lt;code&gt;C++&lt;/code&gt;代码
- &lt;a href=&#34;https://github.com/gradle/gradle&#34;&gt;Gradle&lt;/a&gt;: 安卓系列软件编译工具(类似&lt;code&gt;maven&lt;/code&gt;之类的工具)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;快速安装基本环境&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 下载基础软件包
$ mkdir -p /opt/servers/ &amp;amp;&amp;amp; cd /opt/servers/
# JDK(可以选择openjdk)
$ wget http://dl.bgbiao.top/dav/jdk1.8.0_191.tar.gz
$ tar -zxf jdk1.8.0_191.tar.gz -C /opt/servers/


# 下载并配置sdkmanager
$ wget https://dl.google.com/android/repository/sdk-tools-linux-4333796.zip
$ unzip sdk-tools-linux-4333796.zip 
$ mkdir -p /opt/sdk
$ ln -s /opt/servers/tools /opt/sdk/tools

# 配置环境变量
$ cat /etc/profile
export JAVA_HOME=/opt/servers/jdk1.8.0_191
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH
export PATH=${JAVA_HOME}/bin:${PATH}
export ANDROID_HOME=/opt/sdk
export PATH=${ANDROID_HOME}/tools/bin:${ANDROID_HOME}/tools/bin:${ANDROID_HOME}:${PATH}

# 测试sdkmanager使用
$ source /etc/profile
$ sdkmanager --list
Warning: File /root/.android/repositories.cfg could not be loaded.
Installed packages:
  Path    | Version | Description              | Location
  ------- | ------- | -------                  | -------
  tools   | 26.0.1  | Android SDK Tools 26.0.1 | tools/


# 安装指定版本的包
$ sdkmanager --list | grep cmake
Warning: File /root/.android/repositories.cfg could not be loaded.
  cmake;3.10.2.4988404              | 3.10.2       | CMake 3.10.2.4988404
  cmake;3.6.4111459                 | 3.6.4111459  | CMake 3.6.4111459

$ sdkmanager &#39;cmake;3.6.4111459&#39; 
....

# 下载并安装ndk
$ cd /opt/servers &amp;amp;&amp;amp; wget https://dl.google.com/android/repository/android-ndk-r16b-linux-x86_64.zip
$ unzip android-ndk-r16b-linux-x86_64.zip
$ ln -s /opt/servers/android-ndk-r16b /opt/ndk

# 配置ndk配置环境(增加如下配置)
$ cat /etc/profile
export NDK_HOME=/opt/ndk
export ANDROID_NDK_HOME=/opt/ndk
export PATH=$NDK_HOME:${ANDROID_NDK_HOME}:$PATH


# 下载并安装gradle
$ cd /opt/servers &amp;amp;&amp;amp; wget https://services.gradle.org/distributions/gradle-4.10.1-all.zip
$ unzip gradle-4.10.1-all.zip
$ ln -s /opt/servers/gradle-4.10.1 /opt/gradle

# 配置gradle环境(增加如下配置)
$ cat /etc/profile
export GRADLE_HOME=/opt/gradle
export PATH=${GRADLE_HOME}/bin:${PATH}

# 测试gradle
$ gradle -v

------------------------------------------------------------
Gradle 4.10.1
------------------------------------------------------------

Build time:   2018-09-12 11:33:27 UTC
Revision:     76c9179ea9bddc32810f9125ad97c3315c544919

Kotlin DSL:   1.0-rc-6
Kotlin:       1.2.61
Groovy:       2.4.15
Ant:          Apache Ant(TM) version 1.9.11 compiled on March 23 2018
JVM:          1.8.0_191 (Oracle Corporation 25.191-b12)
OS:           Linux 3.10.0-862.el7.x86_64 amd64


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;安装Android基础依赖&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 正式编译之前先生成license，并将&lt;code&gt;licenses&lt;/code&gt;目录移动到&lt;code&gt;/opt/sdk/&lt;/code&gt;下,和&lt;code&gt;sdkmanager&lt;/code&gt;的tools目录平级&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 安装android基础依赖包
$ sdkmanager &#39;build-tools;28.0.3&#39; &#39;platforms;android-28&#39; &#39;cmake;3.6.4111459&#39;

# 生成licences
$ sdkmanager --licenses
$ cp -rp licenses /opt/sdk/

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;编译Android包&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 加载下整体环境变量
$ cat /etc/profile
....
....
export JAVA_HOME=/opt/servers/jdk1.8.0_191
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH
export PATH=${JAVA_HOME}/bin:${PATH}
export ANDROID_HOME=/opt/sdk
export PATH=${ANDROID_HOME}/tools/bin:${ANDROID_HOME}/tools/bin:${ANDROID_HOME}:${PATH}
export GRADLE_HOME=/opt/gradle
export PATH=${GRADLE_HOME}/bin:${PATH}
export NDK_HOME=/opt/ndk
export ANDROID_NDK_HOME=/opt/ndk
export PATH=$NDK_HOME:${ANDROID_NDK_HOME}:$PATH

$ source /etc/profile

# 下载安卓(android)应用的源码文件
$ git clone http://git.bgbiao.top/test-app.git

$ cd test-app
$ export ENV=&amp;quot;fNormal&amp;quot;
$ gradle clean assemble${ENV}Release
Starting a Gradle Daemon, 2 busy Daemons could not be reused, use --status for details
Parallel execution with configuration on demand is an incubating feature.
&amp;lt;-------------&amp;gt; 0% CONFIGURING [29s]
&amp;gt; root project &amp;gt; Resolve dependencies of :classpath &amp;gt; guava-18.0.pom &amp;gt; 3 KB/5 KB downloaded
&amp;gt; IDLE
&amp;gt; root project &amp;gt; Resolve dependencies of :classpath &amp;gt; commons-lang-2.6.pom &amp;gt; 9 KB/17 KB downloaded
&amp;gt; root project &amp;gt; Resolve dependencies of :classpath &amp;gt; osdetector-gradle-plugin-1.4.0.pom
....
....

BUILD SUCCESSFUL in 7m 7s
501 actionable tasks: 164 executed, 288 from cache, 49 up-to-date


# 查看生成的apk包
$ ls app/build/outputs/apk/fNormal/release/
app-fNormal-release.apk  output.json


# 安装二维码生成器
$ yum install qrencode-3.4.1-3.el7.x86_64 -y

# 将生成的apk包上传到指定的http服务中
$ curl -T app/build/outputs/apk/fNormal/release/app-fNormal-release.apk http://dl.bgbiao.top/dav/

# 给apk下载文件生成一个二维码
$ qrencode -o test-android.png &amp;quot;http://dl.bgbiao.top/dav/app-fNormal-release.apk&amp;quot;

# 上传二维码
$ curl -T test-android.png http://dl.bgbiao.top/dav/

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来，开发者用户即可以使用&lt;code&gt;http://dl.bgbiao.top/dav/test-android.png&lt;/code&gt;二维码地址进行扫描安装，对该版本的app功能进行测试验证了。&lt;/p&gt;

&lt;p&gt;需要注意的是，通常情况下，开发者如果使用&lt;code&gt;Mac OSX&lt;/code&gt;来编写代码，可能会在代码里使用类似&lt;code&gt;#include &#39;MD5.h&#39;&lt;/code&gt;之类的代码，看起来好像没有什么问题，但是因为&lt;code&gt;Mac OSX&lt;/code&gt;或&lt;code&gt;Windows&lt;/code&gt;系统中对大小写不敏感，所以那样写不会有什么太大影响，因为编译器可以找到系统中的&lt;code&gt;md5.h&lt;/code&gt;，但是在&lt;code&gt;Linux&lt;/code&gt;环境下，系统对大小写很敏感，如果代码里写死了&lt;code&gt;MD5.h&lt;/code&gt;，而系统库中是&lt;code&gt;md5.h&lt;/code&gt;，那肯定会编译失败，而且一般人看到该异常情况不会想到是大小写的问题。&lt;/p&gt;

&lt;p&gt;好了，趟坑算是趟完了，接下来提供一个福利，我自己基于以上构建历史环境打包了一个docker镜像，用以封装&lt;code&gt;Android&lt;/code&gt;编译的基本环境.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker镜像&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat Dockerfile
FROM centos:7.5.1804
MAINTAINER &amp;quot;BGBiao &amp;lt;https://bgbiao.top/&amp;gt;&amp;quot;
ENV TZ &amp;quot;Asia/Shanghai&amp;quot;

RUN yum clean all &amp;amp;&amp;amp; \
    yum install unzip wget curl -y &amp;amp;&amp;amp; \
    mkdir -p /opt/{servers,app} &amp;amp;&amp;amp; \
    cd /opt/servers/ &amp;amp;&amp;amp; \
    wget  http://dl.bgbiao.top/hadoop/jdk1.8.0_191.tar.gz &amp;amp;&amp;amp; \
    wget http://dl.bgbiao.top/dav/android-build/android-ndk-r16b-linux-x86_64.zip &amp;amp;&amp;amp; \
    wget http://dl.bgbiao.top/dav/android-build/gradle-4.10.1-all.zip &amp;amp;&amp;amp; \
    wget http://dl.bgbiao.top/dav/android-build/sdk-tools-linux-4333796.zip

RUN pushd /opt/servers &amp;amp;&amp;amp; \
    tar -zxf jdk1.8.0_191.tar.gz &amp;amp;&amp;amp; \
    unzip android-ndk-r16b-linux-x86_64.zip &amp;amp;&amp;amp; \
    unzip gradle-4.10.1-all.zip &amp;amp;&amp;amp; \
    unzip sdk-tools-linux-4333796.zip &amp;amp;&amp;amp; \
    mkdir -p /opt/sdkmanager &amp;amp;&amp;amp; \
    ln -s /opt/servers/tools /opt/sdkmanager/tools &amp;amp;&amp;amp; \
    ln -s /opt/servers/gradle-4.10.1 /opt/gradle &amp;amp;&amp;amp; \
    ln -s /opt/servers/android-ndk-r16b /opt/ndk

COPY profile /opt/servers/setenv.sh
$ cat profile
export JAVA_HOME=/opt/servers/jdk1.8.0_191
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH
export PATH=${JAVA_HOME}/bin:${PATH}
export ANDROID_HOME=/opt/sdkmanager
export PATH=${ANDROID_HOME}/tools/bin:${ANDROID_HOME}/tools/bin:${ANDROID_HOME}:${PATH}
export GRADLE_HOME=/opt/gradle
export PATH=${GRADLE_HOME}/bin:${PATH}
export NDK_HOME=/opt/ndk
export ANDROID_NDK_HOME=/opt/ndk
export PATH=$NDK_HOME:${ANDROID_NDK_HOME}:$PATH

# 用户可以根据上述Dockerfile构建镜像，同时也可以直接使用我构建好的一个镜像
$ docker pull xxbandy123/android-build-env:19-12-12

# 使用方式
# 基于上述镜像，用户需要使用sdkmanager 安装依赖的安卓库，同时编排好自己的gradle打包命令，在自己的安卓项目中直接编译即可
$ docker run -itd --name android-build-env:19-12-12 bash 
[root@4c05d4ded28d /]# source /opt/servers/setenv.sh
[root@4c05d4ded28d /]# git clone your-android-app.git
[root@4c05d4ded28d /]# sdkmanager &#39;build-tools;28.0.3&#39; &#39;platforms;android-28&#39; &#39;cmake;3.6.4111459&#39;
[root@4c05d4ded28d /]# sdkmanager --licenses
[root@4c05d4ded28d /]# cp -rp licenses ${ANDROID_HOME}/
[root@4c05d4ded28d /]# ls ${ANDROID_HOME}
build-tools  cmake  licenses  platforms  platform-tools  tools
# 开始执行编译(之后就是漫长的等待了)
[root@4c05d4ded28d /]# cd your-android-app &amp;amp;&amp;amp; gradle clean assembleRelease

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.通常持续集成会使用&lt;code&gt;Jenkins&lt;/code&gt;来进行编译打包，因此以上环境再接入Jenkins-salve之前需要安装&lt;code&gt;git&lt;/code&gt;客户端名&lt;/li&gt;
&lt;li&gt;2.通常客户端在测试包时会通过二维码扫描来下载包，因此环境上需要安装&lt;code&gt;qrencode&lt;/code&gt;软件，用于生成二维码&lt;/li&gt;
&lt;li&gt;3.需要注意&lt;code&gt;gradle&lt;/code&gt;在编译过程中会启动一个守护进程，如果编译异常结束，该守护进程可能不会立即释放，此时立即再次编译将有可能导致OOM&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>salt-master高可用架构</title>
      <link>https://bgbiao.top/post/salt%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/salt%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 新来这家公司使用&lt;a href=&#34;https://docs.saltstack.com/en/latest/&#34;&gt;Salt&lt;/a&gt;来作为基础配置库管理和自动化运维的工具，但是前期同事刚开始使用时只是简单使用，因此对于可用性和可靠性来说都会存在很大问题(具体可能出现的问题下面会提到)。不过作为一个专业的SRE或者运维人员，在使用一个基础组件时，必须要考虑的一个问题就是&lt;code&gt;可用性&lt;/code&gt;和&lt;code&gt;可靠性&lt;/code&gt;，以前使用&lt;a href=&#34;https://docs.ansible.com/&#34;&gt;Ansible&lt;/a&gt;作为配置管理和自动化运维工具时只需对&lt;code&gt;ssh-key&lt;/code&gt;或者密码进行管理即可通过水平扩容来保证高可用，而在&lt;code&gt;Salt&lt;/code&gt;中需要涉及到&lt;code&gt;salt-minion&lt;/code&gt;的发现以及&lt;code&gt;key&lt;/code&gt;的管理，接下来对&lt;code&gt;高可用的Salt集群架构&lt;/code&gt;进行介绍和实施。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;单节点salt-master问题&#34;&gt;单节点salt-master问题&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;比如说2c2g的机器在管理500+左右的ECS时，就会发现异常慢，而且调用salt-api会出现异常，此时如果去检查资源使用率，就会发现cpu和load都会暴涨，这是因为在使用salt的场景中大部分会使用同步调用，此时salt相关的进程会一直占用资源，直到minion返回结果&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当单节点主机异常时，整体的salt管控端将会失效，也就意味着全量的主机将无法被统一管理，这对于任何一个基于salt的自动化管理系统来说都是一个大灾难&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因此，基于以上考虑，salt-master高可用架构的构建对于任何一个&lt;code&gt;生产环境&lt;/code&gt;的自动化基础设施来讲都是刻不容缓的。&lt;/p&gt;

&lt;h3 id=&#34;salt-master高可用架构方案&#34;&gt;salt-master高可用架构方案&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.saltstack.com/en/master/topics/highavailability/index.html&#34;&gt;salt高可用方案&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在salt的官方文档中提供了三种高可用的方案:
- &lt;a href=&#34;https://docs.saltstack.com/en/master/topics/tutorials/multimaster.html#tutorial-multi-master&#34;&gt;多Master结构&lt;/a&gt;: 该种方式需要在&lt;code&gt;minion&lt;/code&gt;中配置多个master，此时默认所有的master都是在线的，同时多个master必须共享相同的&lt;code&gt;cryptographic keys&lt;/code&gt;，而且&lt;code&gt;minion keys&lt;/code&gt;必须在所有的master节点单独允许，此外还需要&lt;code&gt;file_roots&lt;/code&gt;和&lt;code&gt;pillar_roots&lt;/code&gt;保持同步
- 故障切换的多Master结构: 同上，都是多Master架构，默认情况下采用的是顺序master，不过可以通过&lt;code&gt;master_type&lt;/code&gt;参数修改为&lt;code&gt;failover&lt;/code&gt;，以此来保障多Master节点之间的故障切换(通常failover需要&lt;code&gt;master_alive_interval&lt;/code&gt;和&lt;code&gt;master_shuffle: True&lt;/code&gt;参数支持)
- &lt;a href=&#34;https://docs.saltstack.com/en/master/topics/topology/syndic.html#syndic&#34;&gt;syndic&lt;/a&gt;: salt-syndic其实不能算是一种严格的高可用架构，它有点儿类似代理的方式，即在主控master节点下设置syndic节点，由syndic节点来管控旗下的minion节点
- [多Master结构下的syndic]: 同上&lt;/p&gt;

&lt;p&gt;大概了解了集中高可用方案之后，我们做一个简单分析:&lt;br /&gt;
1. 首先我们为了保障高可用，需要允许任意节点都是高可用的，因此排除&lt;code&gt;syndic&lt;/code&gt;方案
2. 在&lt;code&gt;多master&lt;/code&gt;，&lt;code&gt;故障切换的多master&lt;/code&gt;和&lt;code&gt;多master下的syndic&lt;/code&gt;中，在可用用性和性能承受范围内考虑架构的简洁性，排除&lt;code&gt;多master下的syndic&lt;/code&gt;方案&lt;/p&gt;

&lt;p&gt;因此，最终可供我们选择的即为&lt;code&gt;多master&lt;/code&gt;方案，至于&lt;code&gt;failover&lt;/code&gt;其实只是&lt;code&gt;多master&lt;/code&gt;下的一种类型。&lt;/p&gt;

&lt;h3 id=&#34;salt-master高可用实施&#34;&gt;salt-master高可用实施&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在&lt;code&gt;多Master结构&lt;/code&gt;中也提到了，&lt;code&gt;cryptographic key&lt;/code&gt;和&lt;code&gt;file_roots&lt;/code&gt;以及&lt;code&gt;pillar_roots&lt;/code&gt;需要保持同步，我们这里使用共享存储方式来实现多master节点的文件同步。&lt;/p&gt;

&lt;p&gt;如果使用的是阿里云，可以使用&lt;a href=&#34;https://www.aliyun.com/product/nas?source=5176.11533457&amp;amp;userCode=n0qkvlxu&amp;amp;type=copy&#34;&gt;NAS&lt;/a&gt;服务来实现多主机的共享文件存储.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.aliyun.com/product/nas?source=5176.11533457&amp;amp;userCode=n0qkvlxu&amp;amp;type=copy&#34;&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1g9sqdlv593j316i0eun0l.jpg&#34; alt=&#34;NAS存储&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果是非云，或者非阿里云的环境，可以采用传统的&lt;code&gt;NFS&lt;/code&gt;存储方式来实现共享存储，不过&lt;code&gt;NFS&lt;/code&gt;仅提供了共享，却不保证高可用性，如果需要大规模使用也是需要考虑备份错输。另外其他的方式就是采用&lt;code&gt;GlusterFS&lt;/code&gt;或者&lt;code&gt;CephFS&lt;/code&gt;之类的分布式共享存储方案。因此在迁移迁移阶段，我们先采用&lt;code&gt;GlusterFS&lt;/code&gt;来提供底层的高可用的共性存储(后期会直接迁移到阿里云的NAS服务)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.创建一个glusterfs volume&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 创建一个salt卷(复制卷)
$ gluster volume create salt replica 2 node4:/data/salt node5:/data/salt force

# 查看当前gluster集群下的volume(也供给k8s中的自建mysql使用)
$ gluster volume list
k8s
salt

# 启动salt volume
$ gluster volume start salt
$ gluster volume info salt


# 开启磁盘配额的限制
$ gluster volume quota salt enable
volume quota : success

$ gluster volume quota salt limit-usage / 200GB 90%
volume quota : success

# 查看磁盘配额情况
$ gluster volume quota salt list
+----  1 line: Path                   Hard-limit  Soft-limit      Used  Available  Soft-limit exceeded? Hard-limit exce
-------------------------------------------------------------------------------------------------------------------------------
/                                        200.0GB     90%(180.0GB)   0Bytes 200.0GB              No                   No

# 使用(被挂载节点需要绑定这个hosts)
# 所有的客户端主机均需要安装(glusterfs客户端)
$ yum install glusterfs glusterfs-client -y
$ cat /etc/hosts
10.0.21.74  node4
10.0.21.73 node5

$ mount -t glusterfs 10.0.21.73:/salt /opt/data/salt-data/
$ df -H | grep /opt/data/
10.0.21.73:/salt  215G     0  215G    0% /opt/data/salt-data

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2.修改salt-master配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 每次master接收minion的认证后会将认证文件统一存放在&lt;code&gt;pki_dir&lt;/code&gt;目录下，如果是在单master像多Master改造，需要保持该文件的全量同步&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# salt-master-1
$ grep -v ^#  /etc/salt/master  | grep -v ^$
interface: 10.0.217.78
pki_dir: /opt/data/salt-data/pki/master
timeout: 10
file_recv: True
log_file: /var/log/salt/master
log_level: info

# salt-master-2
$ grep -v ^#  /etc/salt/master  | grep -v ^$
interface: 10.0.79.88
pki_dir: /opt/data/salt-data/pki/master
timeout: 10
file_recv: True
log_file: /var/log/salt/master
log_level: info

# salt-minion配置示例
# 这里使用随机master，可以减少master的负载
# 如果使用failover模式的话，将永远只有失败之后使用另外的salt-master，整体性价比较低(不过可随时切换)
$ grep -v ^# /etc/salt/minion | grep -v ^$
master:
    - salt-master-2.bgbiao.top
    - salt-master-1.bgbiao.top
random_master: True
id: 10.0.79.90

# 分别重启salt-master和salt-minion进程
# 在任意一台salt-master中同步key
$ salt-key -a 10.0.79.90 -y

# 测试后发现两个salt-master均可以对目标主机执行操作
[root@salt-master-2 ~]# salt 10.0.79.90 test.ping
10.0.79.90:
    True

[root@salt-master-1 ~]# salt 10.0.79.90 test.ping
10.0.79.90:
    True

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.修改file_roots和pillar_sls目录&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 修改salt-master相关配置
# 增加file_roots目录(默认在/srv/salt/目录下)
$ grep -v ^#  /etc/salt/master  | grep -v ^$
interface: 10.0.79.88
pki_dir: /opt/data/salt-data/pki/master
timeout: 10
file_recv: True
file_roots:
  base:
    - /opt/data/salt-data/salt-sls/
log_file: /var/log/salt/master
log_level: info

# 将源master节点/srv/salt/下文件同步到/opt/data/salt-data/salt-sls/目录即可

# 测试salt state文件使用
# 测试hadoop客户端安装
[root@salt-master-2 salt-sls]# salt 10.0.79.90 state.sls hadoop-client.init-hadoop-env
....
....
Summary
-------------
Succeeded: 25 (changed=24)
Failed:     0
-------------
Total states run:     25

# 使用state初始化hadoop环境后测试hadoop客户端是否正常
[root@salt-master-2 salt-sls]# salt 10.0.79.90 cmd.run &#39;source /etc/profile &amp;amp;&amp;amp; hadoop fs -ls /hive;&#39;
10.0.79.90:
    19/12/10 16:37:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    19/12/10 16:38:00 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
    Found 3 items
    drwxr-x--x   - root   hadoop          0 2018-12-03 20:05 /hive/dw
    drwxr-x--x   - root   hadoop          0 2019-04-02 11:03 /hive/ods
    drwxr-x--x   - hadoop hadoop          0 2019-07-18 21:26 /hive/rpt

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;在新的master节点验证完毕后，将全部master节点的&lt;code&gt;/etc/salt/master&lt;/code&gt;配置文件进行同步(&lt;code&gt;interface&lt;/code&gt;参数需要为指定的地址)即可.&lt;/p&gt;

&lt;h3 id=&#34;salt-minion接入使用&#34;&gt;salt-minion接入使用&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# 安装salt-minion
$ yum install salt-minion -y

# 修改salt-minion配置文件(id为唯一标识salt-minion)
$ cat /etc/salt/minion
master:
    - salt-master-2.bgbiao.top
    - salt-master-1.bgbiao.top
random_master: True
# 其实这里的id可以不用指定，默认为socket.getfqdn()函数值(其实就是ipv4)
id: 10.0.79.90

# 重启salt-minion
$ systemctl daemon-reload &amp;amp;&amp;amp; systemctl restart salt-minion

# salt-master手动同意请求(可用设置成定期accept all)
$ salt-key -a 10.0.79.90 -y

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;salt使用问题和注意事项&#34;&gt;salt使用问题和注意事项&lt;/h3&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; checked disabled class=&#34;task-list-item&#34;&gt; master设备会为每个minion的auth-request请求计算签名。 在有许多minions和频繁的auth请求时，这可以消耗掉master服务器上相当多的CPU资源.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>快速使用互联网检索有用数据</title>
      <link>https://bgbiao.top/post/%E4%BA%92%E8%81%94%E7%BD%91%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E4%BA%92%E8%81%94%E7%BD%91%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 随着互联网的普及和发展，互联网上充斥了大量的数据，如何从海量数据中识别自己最想要的数据成为了很多人头疼的问题，接下来给大家分享一些自己常用的检索数据的网站和方法.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;搜索引擎&#34;&gt;搜索引擎&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1.搜索关键字&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在搜索关键字的时候，尽量选择具体的关键字，比如&lt;code&gt;大数据&lt;/code&gt;就没有&lt;code&gt;大数据就业&lt;/code&gt;，&lt;code&gt;大数据行业&lt;/code&gt;，&lt;code&gt;大数据企业&lt;/code&gt;具体；另外在搜索关键词的时候，通常推荐使用多次分词，也就是使用一个词一个词，词词之间使用空格分开，比如&lt;code&gt;大数据 云计算&lt;/code&gt;,同时在检索内容时，也可以根据关键程度将词前后位置进行转换。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.搜索技巧&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.文件类型搜索:在搜索引擎搜索框最后增加&lt;code&gt;空格 filetype:type&lt;/code&gt; type可以是[pdf,ppt,xls,doc]中的任意一个&lt;/li&gt;
&lt;li&gt;2.网站定位搜索:在搜索引擎搜索框最后增加&lt;code&gt;空格 site:URL&lt;/code&gt;  URL即为指定网站(其实各种搜索引擎都是去定向爬取各个网站的关键字进行收录的)&lt;/li&gt;
&lt;li&gt;3.限制性搜索: 使用&lt;code&gt;intitle&lt;/code&gt;,如在百度键入&lt;code&gt;intitie:大数据&lt;/code&gt;，限定于搜索标题中含有&lt;code&gt;大数据&lt;/code&gt;网页，如果输入&lt;code&gt;intitie:大数据市场规模&lt;/code&gt;限定于搜索标题中含有&lt;code&gt;大数据&lt;/code&gt;和&lt;code&gt;市场规模&lt;/code&gt;的网页&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其实上述三个搜索技巧，在各个搜索引擎中会默认支持工具，但是通常会被放在很隐蔽的地方&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1g9rfguy2qoj310m0hc42h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;另外，除了常用的搜索引擎:百度,谷歌,必应,搜狗之外，通常还会有一些垂直领域或者非商业化的搜索引擎.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google学术搜索: &lt;a href=&#34;http://scholar.google.com/&#34;&gt;http://scholar.google.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;科技文献搜索: &lt;a href=&#34;http://www.scirus.com&#34;&gt;http://www.scirus.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;学术搜索引擎: &lt;a href=&#34;http://www.base-search.net/&#34;&gt;http://www.base-search.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;交叉学科门户网站: &lt;a href=&#34;http://www.vascoda.de/&#34;&gt;http://www.vascoda.de/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一个神奇的网站: &lt;a href=&#34;http://www.goole.com/&#34;&gt;http://www.goole.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Amazon推出的: &lt;a href=&#34;http://www.a9.com&#34;&gt;http://www.a9.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;免费paper检索: &lt;a href=&#34;http://www.findarticles.com/&#34;&gt;http://www.findarticles.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;计算机和信息科学: &lt;a href=&#34;http://citeseer.ist.psu.edu/&#34;&gt;http://citeseer.ist.psu.edu/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;谷歌马甲: &lt;a href=&#34;https://search.aol.com/&#34;&gt;https://search.aol.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;数据库&#34;&gt;数据库&lt;/h3&gt;

&lt;p&gt;数据库是研究人员重要的数据来源之一，目前券商、基金研究研究机构都购买有商业数据库，目前研究用的数据库主要分为两大类，一是商业数据库，二是学术数据库。&lt;/p&gt;

&lt;p&gt;由于一般是个人使用，这里仅介绍一些免费可用的数据库.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据汇: &lt;a href=&#34;http://www.shujuhui.com/database/&#34;&gt;http://www.shujuhui.com/database/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;数据圈子: &lt;a href=&#34;http://www.shujuquan.com.cn/&#34;&gt;http://www.shujuquan.com.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FRED: &lt;a href=&#34;http://research.stlouisfed.org/fred2/&#34;&gt;http://research.stlouisfed.org/fred2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OECD: &lt;a href=&#34;http://www.oecd-ilibrary.org/economics&#34;&gt;http://www.oecd-ilibrary.org/economics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;台湾学术数据库: &lt;a href=&#34;http://fedetd.mis.nsysu.edu.tw/&#34;&gt;http://fedetd.mis.nsysu.edu.tw/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;台湾大学电子书: &lt;a href=&#34;http://ebooks.lib.ntu.edu.tw/Home/ListBooks&#34;&gt;http://ebooks.lib.ntu.edu.tw/Home/ListBooks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;共享文库&#34;&gt;共享文库&lt;/h3&gt;

&lt;p&gt;主要介绍下国外的，国内的&lt;code&gt;百度文库&lt;/code&gt;,&lt;code&gt;道客巴巴&lt;/code&gt;之类的文档太差，而且还收费.&lt;/p&gt;

&lt;p&gt;Scribd：&lt;a href=&#34;http://www.scribd.com&#34;&gt;http://www.scribd.com&lt;/a&gt;
Docstoc: &lt;a href=&#34;http://www.docstoc.com&#34;&gt;http://www.docstoc.com&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;专业网站&#34;&gt;专业网站&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;人大经济论坛: &lt;a href=&#34;http://bbs.pinggu.org/&#34;&gt;http://bbs.pinggu.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;经济学家: &lt;a href=&#34;http://bbs.jjxj.org/&#34;&gt;http://bbs.jjxj.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;随意网-经济论坛: &lt;a href=&#34;http://economic.5d6d.net/&#34;&gt;http://economic.5d6d.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;理想在线: &lt;a href=&#34;http://www.55188.com&#34;&gt;股票券商研究报告&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;迈博汇金: &lt;a href=&#34;http://www.hibor.com.cn/&#34;&gt;股票券商研究报告&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;博瑞金融: &lt;a href=&#34;http://www.brjr.com.cn/forum.php&#34;&gt;金融行业专业型论坛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;华尔街社区: &lt;a href=&#34;http://forum.cnwallstreet.com/index.php&#34;&gt;国内专业的金融论坛&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;中华股权投资论坛: &lt;a href=&#34;http://www.tzluntan.com/&#34;&gt;pe投资专业型论坛&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;政府数据&#34;&gt;政府数据&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;国家统计局: &lt;a href=&#34;http://www.stats.gov.cn/&#34;&gt;http://www.stats.gov.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;工业和信息化部: &lt;a href=&#34;http://www.miit.gov.cn&#34;&gt;http://www.miit.gov.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;中国人民银行: &lt;a href=&#34;http://www.pbc.gov.cn/&#34;&gt;http://www.pbc.gov.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;银监会: &lt;a href=&#34;http://www.cbrc.gov.cn&#34;&gt;http://www.cbrc.gov.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;中国海关: &lt;a href=&#34;http://www.customs.gov.cn&#34;&gt;http://www.customs.gov.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;国家知识产权局: &lt;a href=&#34;http://www.sipo.gov.cn&#34;&gt;http://www.sipo.gov.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;中国证监会: &lt;a href=&#34;http://www.csrc.gov.cn&#34;&gt;http://www.csrc.gov.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;巨潮信息网:&lt;a href=&#34;http://www.cninfo.com.cn/&#34;&gt;中国资本市场指定披露平台&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;证券交易所&#34;&gt;证券交易所&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;上海证券交易所: &lt;a href=&#34;http://www.sse.com.cn/&#34;&gt;http://www.sse.com.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;深圳证券交易所: &lt;a href=&#34;http://www.szse.cn/&#34;&gt;http://www.szse.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;全国中小企业股份转让系统: &lt;a href=&#34;http://www.neeq.com.cn/&#34;&gt;http://www.neeq.com.cn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;香港证券交易所: &lt;a href=&#34;http://www.hkexnews.hk/index_c.htm&#34;&gt;http://www.hkexnews.hk/index_c.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;台湾证券交易所: &lt;a href=&#34;http://www.tse.com.tw/ch/index.php&#34;&gt;http://www.tse.com.tw/ch/index.php&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;新加坡证券交易所: &lt;a href=&#34;http://www.sgx.com/&#34;&gt;http://www.sgx.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;纽约证券交易所: &lt;a href=&#34;http://www.nyse.com&#34;&gt;http://www.nyse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;纳斯达克证券交易所: &lt;a href=&#34;http://www.nasdaq.com&#34;&gt;http://www.nasdaq.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;行业网站&#34;&gt;行业网站&lt;/h3&gt;

&lt;p&gt;互联网及传媒
1）资讯类
新浪科技 &lt;a href=&#34;http://tech.sina.com.cn/&#34;&gt;http://tech.sina.com.cn/&lt;/a&gt;
腾讯科技 &lt;a href=&#34;http://tech.qq.com/&#34;&gt;http://tech.qq.com/&lt;/a&gt;
艾瑞网 &lt;a href=&#34;http://www.iresearch.cn/&#34;&gt;http://www.iresearch.cn/&lt;/a&gt;
艺恩网 &lt;a href=&#34;http://www.entgroup.cn/&#34;&gt;http://www.entgroup.cn/&lt;/a&gt;
虎嗅网 &lt;a href=&#34;http://wwww.huxiu.com/&#34;&gt;http://wwww.huxiu.com/&lt;/a&gt;
36kr &lt;a href=&#34;http://36kr.com/&#34;&gt;http://36kr.com/&lt;/a&gt;
钛媒体 &lt;a href=&#34;http://www.tmtpost.com/&#34;&gt;http://www.tmtpost.com/&lt;/a&gt;
游戏大观 &lt;a href=&#34;http://www.gamelook.com.cn/&#34;&gt;http://www.gamelook.com.cn/&lt;/a&gt;
亿欧网 &lt;a href=&#34;http://www.iyiou.com/&#34;&gt;http://www.iyiou.com/&lt;/a&gt;
媒介360 &lt;a href=&#34;http://www.chinamedia360.com/main&#34;&gt;http://www.chinamedia360.com/main&lt;/a&gt;
　
2）数据类
中国票房 &lt;a href=&#34;http://www.cbooo.cn/&#34;&gt;http://www.cbooo.cn/&lt;/a&gt;
中国互联网络信息中心 &lt;a href=&#34;http://www.cnnic.net.cn/&#34;&gt;http://www.cnnic.net.cn/&lt;/a&gt;
艾瑞网
&lt;a href=&#34;http://www.iresearch.com.cn/report/viewlist.aspx&#34;&gt;http://www.iresearch.com.cn/report/viewlist.aspx&lt;/a&gt;
易观智库 &lt;a href=&#34;http://www.analysys.cn/&#34;&gt;http://www.analysys.cn/&lt;/a&gt;
游戏产业网
&lt;a href=&#34;http://www.cgigc.com.cn/list/79644663134.html&#34;&gt;http://www.cgigc.com.cn/list/79644663134.html&lt;/a&gt;
百度指数 &lt;a href=&#34;http://index.baidu.com/&#34;&gt;http://index.baidu.com/&lt;/a&gt;
大数据导航 &lt;a href=&#34;http://hao.199it.com/&#34;&gt;http://hao.199it.com/&lt;/a&gt;
CSM（电视收视率） &lt;a href=&#34;http://www.csm.com.cn/&#34;&gt;http://www.csm.com.cn/&lt;/a&gt;
微排片 &lt;a href=&#34;http://www.weipaipian.com&#34;&gt;http://www.weipaipian.com&lt;/a&gt;
　
医药行业
1）样本医院数据
化药、生物药和中药注射剂 &lt;a href=&#34;http://pdb.pharmadl.com/&#34;&gt;http://pdb.pharmadl.com/&lt;/a&gt;
中成药、化药 &lt;a href=&#34;http://www.menet.com.cn/&#34;&gt;http://www.menet.com.cn/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;银行业
1）新闻资讯
中证网 &lt;a href=&#34;http://www.cs.com.cn/xwzx/hg/&#34;&gt;http://www.cs.com.cn/xwzx/hg/&lt;/a&gt;
一财网 &lt;a href=&#34;http://www.yicai.com/economy&#34;&gt;http://www.yicai.com/economy&lt;/a&gt;
财新网 &lt;a href=&#34;http://finance.caixin.com/bank/&#34;&gt;http://finance.caixin.com/bank/&lt;/a&gt;
华尔街见闻 &lt;a href=&#34;http://wallstreetcn.com/news?cid=19&#34;&gt;http://wallstreetcn.com/news?cid=19&lt;/a&gt;
新浪财经 finance.sina.com.cn/
证券时报网 &lt;a href=&#34;http://www.stcn.com/&#34;&gt;http://www.stcn.com/&lt;/a&gt;
中国金融新闻网
&lt;a href=&#34;http://www.financialnews.com.cn/yh/xw/&#34;&gt;http://www.financialnews.com.cn/yh/xw/&lt;/a&gt;
　
2）公告、数据查找
中国货币网 &lt;a href=&#34;http://www.chinamoney.com.cn/index.html&#34;&gt;http://www.chinamoney.com.cn/index.html&lt;/a&gt;
巨潮网 &lt;a href=&#34;http://www.cninfo.com.cn/&#34;&gt;http://www.cninfo.com.cn/&lt;/a&gt;
统计局 www.stats.gov.cn/
中国人民银行 www.pbc.gov.cn
银监会 &lt;a href=&#34;http://www.cbrc.gov.cn/index.html&#34;&gt;http://www.cbrc.gov.cn/index.html&lt;/a&gt;
上海证券交易所 www.sse.com.cn/
深圳证券交易所 www.szse.cn/
最常用wind股票数据库。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang中的单元测试、基准测试、覆盖测试</title>
      <link>https://bgbiao.top/post/go-unit-test/</link>
      <pubDate>Sun, 20 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/go-unit-test/</guid>
      
        <description>&lt;h2 id=&#34;单元测试-基准测试-覆盖测试&#34;&gt;单元测试、基准测试、覆盖测试&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;背景: 之前很长一段时间再写Golang程序时，不会有意识去写单元测试，直到后来写了独立项目后，慢慢才发现给一个功能编写对应的单元测试是多么高效和方便，接下来就再一起复习下Golang中的测试.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;UnitTest(单元测试)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;单元测试是程序开发者适用一段代码来验证另外一段代码写的是否符合预期的一种相对高效的自我测试方法。&lt;/p&gt;

&lt;p&gt;还记得最早开始搞运维时，写的程序基本上是通过&lt;code&gt;main&lt;/code&gt;程序去调用具体的功能函数，然后通过具体的输出来主观验证结果是否符合预期，这种方式对于搞正统的软件开发者而言会感觉很傻，但这对于运维领域来说却很实用，很有效，因为通常运维工作中需要的一些开发都不会是逻辑较为复杂的程序，所以没有必要专门去写测试程序去测试另外一个程序是否符合预期。&lt;/p&gt;

&lt;p&gt;但是随着工作内容和运维需求的变化，不得不使用一些正规软件工程领域的相关方法来进行测试，因为对于程序开发来说，经过长期的积累和方法总结，单元测试是一种比较好的开发程序验证方式，而且能够提高程序开发的质量。而在&lt;code&gt;Golang&lt;/code&gt;语言中内置了一系列的测试框架，加下来就主要讲讲&lt;code&gt;UnitTest&lt;/code&gt;单元测试的相关知识点。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UnitTest的编写&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;在Golang中，对于单元测试程序来说通常会有一些重要约束，主要如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单元测试文件名必须为&lt;code&gt;xxx_test.go&lt;/code&gt;(其中xxx为业务逻辑程序)&lt;/li&gt;
&lt;li&gt;单元测试的函数名必须为&lt;code&gt;Testxxx&lt;/code&gt;(xxx可用来识别业务逻辑函数)&lt;/li&gt;
&lt;li&gt;单元测试函数参数必须为&lt;code&gt;t *testing.T&lt;/code&gt;(测试框架强要求)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;测试程序和被测试程序文件在一个包&lt;code&gt;package&lt;/code&gt;中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 示例文件
# 假设我们为某段业务逻辑专门写了一个package(用来初始化一个矩形，并计算体积)，此时看到到整体结构如下
$ tree -L 2 ./unittest
./unittest
├── area.go
└── area_test.go

# 业务逻辑代码(业务逻辑需要和单元测试在一个package下)
$ cat ./unittest/area.go
package unittest

type box struct {
length  int
width   int
height  int
name    string
}

// 初始化一个结构体指针对象，后面使用结构体指针方法来设置和获取对象属性
func Newbox() (*box) {
return &amp;amp;box{}
}

// 给结构体对象设置具体的属性(名称，规格大小)
// 注意: 在如下几个方法中，方法接受者为指针类型，而方法参数为值类型，因此在赋值时可能有人产生疑惑，这里其实是Golang底层做了优化(v.name = name 等同于(*v).name = name)
func (v *box) SetName(name string) {
v.name = name
}
func (v *box) SetSize(l,w,h int) {
v.length = l
v.width = w
v.height = h
}

// 获取对象的一些属性(名称和体积)
func (v *box) GetName() (string) {
return v.name
}
func (v *box) GetVolume() (int) {
return (v.length)*(v.width)*(v.height)
}

# 对应业务逻辑的单元测试逻辑
$ cat unittest/area_test.go
package unittest
// 必须导入testing模块，并且方法的接受者为(t *testing.T)
import (
&amp;quot;fmt&amp;quot;
&amp;quot;testing&amp;quot;
)
// 测试1: 测试名称是否符合预期
func TestSetSomething(t *testing.T) {
box := Newbox()
box.SetName(&amp;quot;bgbiao&amp;quot;)
if box.GetName() == &amp;quot;bgbiao&amp;quot; {
    fmt.Println(&amp;quot;the rectangular name&#39;s result is ok&amp;quot;)
}
}
// 测试2: 测试计算出来的体积是否符合预期
func TestGetSomething(t *testing.T) {
box := Newbox()
box.SetSize(3,4,5)
if box.GetVolume() == 60 {
    fmt.Println(&amp;quot;the rectangular volume&#39;s result is ok&amp;quot;)
}
}

# 运行单元测试程序
# 可以看到我们编写的两个单元测试都经过预期测试
$ cd unittest
$ go test
the rectangular name&#39;s result is ok
the rectangular volume&#39;s result is ok
PASS
ok  	_/User/BGBiao/unittest	0.005s
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;单元测试的运行&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过上面那个测试示例，我们都知道了可以使用&lt;code&gt;go test&lt;/code&gt;来对Golang代码进行测试，接下来具体讲解一些&lt;code&gt;go test&lt;/code&gt;的其他用法(其实上面说的那些规则也可以在&lt;code&gt;go help test&lt;/code&gt;帮助文档中找到)&lt;/p&gt;

&lt;p&gt;这里主要总结下几个常用的参数:
- -args: 指定一些测试时的参数(可以指定超时时间,cpu绑定,压测等等(go test包含单元测试，压力测试等))
- - -test.v: 是否输出全部的单元测试用例（不管成功或者失败），默认没有加上，所以只输出失败的单元测试用例
- - -test.run pattern: 只跑哪些单元测试用例
- - -test.bench patten: 只跑那些性能测试用例
- - -test.benchmem : 是否在性能测试的时候输出内存情况
- - -test.benchtime t : 性能测试运行的时间，默认是1s
- - -test.cpuprofile cpu.out : 是否输出cpu性能分析文件
- - -test.memprofile mem.out : 是否输出内存性能分析文件
- - -test.blockprofile block.out : 是否输出内部goroutine阻塞的性能分析文件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;-c: 编译测试文件到pkg.test,但是不会运行测试程序&lt;/li&gt;
&lt;li&gt;-exec xprog: 使用xprog参数来运行编译的测试文件(参数类似go run后的参数)&lt;/li&gt;
&lt;li&gt;-i: 安装测试程序中的依赖包，但是不运行测试程序&lt;/li&gt;
&lt;li&gt;-json: 以json格式输出测试结果&lt;/li&gt;
&lt;li&gt;-o file: 指定测试程序编译后生成的文件名&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;单元测试中常用的命令参数:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 对当前目录下的全部单元测试程序进行运行测试(也就是所有的xxx_test.go文件中的所有function都会运行)
$ go test
the rectangular name&#39;s result is ok
the rectangular volume&#39;s result is ok
PASS
ok  	_/Users/BGBiao/unittest	0.005s

# 查看详细的单元测试结果
# (go test -v 等同于go test -args -test.v)
$ go test -v
=== RUN   TestSetSomething
the rectangular name&#39;s result is ok
--- PASS: TestSetSomething (0.00s)
=== RUN   TestGetSomething
the rectangular volume&#39;s result is ok
--- PASS: TestGetSomething (0.00s)
PASS
ok  	_/Users/BGBiao/unittest	0.005s

# 指定单元测试function来进行测试(-run参数可以指定正则匹配模式-run=&amp;quot;test1|test2&amp;quot;)
# go test -v -run functionname 
$ go test -v -test.run TestGetSomething
=== RUN   TestGetSomething
the rectangular volume&#39;s result is ok
--- PASS: TestGetSomething (0.00s)
PASS
ok  	_/Users/BGBiao/unittest	0.005s

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;单元测试注意事项&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在单元测试时，一个比较重要的事情就是如何构造测试数据，因为通常我们能够想到的测试数据都是在预期之中的，有些核心逻辑的测试数据往往不能考虑到，因此构造测试数据时可考虑如下几个方面:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1. 正常输入: 正常的可预测的测试用例&lt;/li&gt;
&lt;li&gt;2. 边界输入: 极端情况下的输入来测试容错性&lt;/li&gt;
&lt;li&gt;3. 非法输入: 输入异常数据类型，整个逻辑是否能够正常处理或者捕获&lt;/li&gt;
&lt;li&gt;4. 白盒覆盖: 需要设计的测试用例能够覆盖所有代码(语句覆盖、条件覆盖、分支覆盖、分支/条件覆盖、条件组合覆盖)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在写项目时，对于基础的工具层&lt;code&gt;util&lt;/code&gt;的逻辑代码，一定要进行全方位，多场景的进行测试，否则当项目大起来后到处引用可能会造成较大麻烦;其次，我们的代码逻辑通常是更新迭代的，单元测试代码也应该进行定期更新.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;华丽的分割线&#34;&gt;华丽的分割线&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Golang的测试断言工具&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;在&lt;code&gt;testing&lt;/code&gt;包中包含了一些常用的断言工具&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func TestPrint(t *testing.T) {
    // 输出测试日志
    t.Logf()
    // 标记错误，但仍然执行后面的语句
    t.Fail()
    // 获取是否当前用例是执行错误的
    t.Failed()
    // 错误输出，等于 t.Logf 再执行 t.Fail()
    t.Errorf(&amp;quot;%s&amp;quot;, &amp;quot;run ErrorF&amp;quot;)
    // 标记函数错误，并中断后面的执行
    t.FailNow()
    // 致命错误输出，等同于调用了 t.Logf 然后调用 t.FailNow()
    t.Fatalf(&amp;quot;%s&amp;quot;, &amp;quot;run Fatelf&amp;quot;)
    // 测试用例的名字
    t.Name()
    //运行子测试用例
    t.Run()
    // 跳过后面的内容，后面将不再运行
    t.SkipNow()
    // 告知当前的测试是否已被忽略
    t.Skipped()
    // 并行测试
    t.Parallel()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;测试覆盖率统计&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;Golang内置工具包中也提供了测试覆盖率相关的工具，&lt;code&gt;go test&lt;/code&gt;常用参数如下:
- &lt;code&gt;-cover&lt;/code&gt;: 是否开启覆盖测试率统计的开关.(当有&lt;code&gt;-covermode&lt;/code&gt;、&lt;code&gt;-coverpkg&lt;/code&gt;、&lt;code&gt;-coverprofile&lt;/code&gt;参数时会自动打开)
- &lt;code&gt;-covermode&lt;/code&gt;: 设置覆盖测试率模式(可选值:set,count,atomic). set(默认)仅统计语法块是否覆盖;count 会统计语法块覆盖了多少次;atomic 用于多线程测试中统计语法块覆盖了多少次
- &lt;code&gt;-coverpkg&lt;/code&gt;: 指定覆盖率统计package的范围(默认只统计有执行了测试的packages)
- &lt;code&gt;-timeout&lt;/code&gt;: 指定单个测试用例的超时时间，默认10分钟
- &lt;code&gt;-coverprofile&lt;/code&gt;: 指定覆盖率profile文件的输出地址&lt;/p&gt;

&lt;p&gt;&lt;code&gt;第三方的测试覆盖统计&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://goconvey.co/&#34;&gt;goconvey&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://github.com/smartystreets/goconvey&#34;&gt;goconvey&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://codecov.io/&#34;&gt;codecov&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 使用golang内置的工具来执行覆盖测试，执行之后生成.test的执行文件，执行后会执行所有单元测试代码，然后输出覆盖率的报告
$ go test -c -covermode=count -coverpkg ./
➜  unittest git:(master) ✗ ls
area.go       area_test.go  unittest.test
➜  unittest git:(master) ✗ ./unittest.test
the rectangular name&#39;s result is ok
the rectangular volume&#39;s result is ok
PASS
coverage: 100.0% of statements in ./
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;统计单元测试的覆盖率，也就是白盒测试的覆盖率.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;覆盖率测试报告&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 将测试覆盖率结果写入一个数据文件
$ go test -coverpkg=./ -coverprofile=coverage.data -timeout=5s

# 将覆盖率报告数据文件转化成对应的人类可识别模式(go tool cover可查看覆盖率相关的工具)
$  go tool cover -func=coverage.data -o coverage.txt
➜  unittest git:(master) ✗ cat coverage.txt
/Users/BGBiao/unittest/area.go:19:	Newbox		100.0%
/Users/BGBiao/unittest/area.go:23:	SetName		100.0%
/Users/BGBiao/unittest/area.go:27:	SetSize		100.0%
/Users/BGBiao/unittest/area.go:33:	GetName		100.0%
/Users/BGBiao/unittest/area.go:37:	GetVolume	100.0%
total:										(statements)	100.0%

# 转化成html格式(会在本地生成html文件)
$ go tool cover -html=coverage.data -o coverage.html

# 直接以html形式展示覆盖测试率报告
$ go tool cover -html=coverage.data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006y8mN6ly1g8tw12ghvej317l0u0jvu.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基准测试&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基准测试是测量一个程序在固定工作负载下的性能。在Golang中，基准测试函数和普通的单元测试函数写法类似，同样需要遵循以下规则:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.函数以&lt;code&gt;Benchmark&lt;/code&gt;开头&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;2.函数参数为&lt;code&gt;b *testing.B&lt;/code&gt; (区别于单元测试的&lt;code&gt;t *testing.T&lt;/code&gt;)&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: &lt;code&gt;*testing.B&lt;/code&gt;参数提供了一些额外的性能测量相关的方法，同时还提供了一个随机整数&lt;code&gt;N&lt;/code&gt;，用于限定执行的循环次数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 编写benchmark函数
func Benchmark_GetSomething(b *testing.B) {
    box := Newbox()
    volume := 0
    for i := 0; i &amp;lt; b.N; i++ {
        box.SetSize(10,1111,2222)
        volume = box.GetVolume()
    }
    b.Log(volume)
}

# 运行测试(运行所有的基准测试，-bench可以指定函数名，-benchmem可以指定分配内存的次数和字节数)
# 和单元测试不同的是，我们需要使用-bench来手工指定需运行的基准测试函数(.表示全部的基准测试函数)
# 如下输出结果表示:GOMAXPROCS为4核心,每次调用GetSomething函数平均花费0.35ns(调用了2000000000次)
$ go test -v -run=&amp;quot;none&amp;quot; -bench=Benchmark_GetSomething -benchmem
goos: darwin
goarch: amd64
Benchmark_GetSomething-4   	2000000000	         0.35 ns/op	       0 B/op	       0 allocs/op
--- BENCH: Benchmark_GetSomething-4
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
PASS
ok  	_/Users/BGBiao/unittest	0.749s

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;性能分析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 当我们的程序在运行过程中可能会消耗非常多的资源(通常是程序性价比较低时，比如处理一个很小的数据，却占用了几个G的内存，并且CPU长期处于高负荷状态)，此时我们就需要通过一些技术手段来分析程序性能损耗点，以此来提高程序的性价比。&lt;/p&gt;

&lt;p&gt;Go语言支持多种类型的剖析性能分析，每一种关注不同的方面，但它们都涉及到每个采样记录的感兴趣的一系列事件消息，每个事件都包含函数调用时函数调用堆栈的信息。基本上常用的为&lt;code&gt;MEM分析&lt;/code&gt;、&lt;code&gt;CPU分析&lt;/code&gt;以及&lt;code&gt;block分析&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MEM分析: 主要是堆分析，可以标识出最耗内存的逻辑，内置库会会记录调用内部内存分配的操作，平均每512KB的内存申请会触发一个剖析数据.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;CPU分析: 可以标识最耗CPU时间的函数,每个CPU上运行的线程在每隔几毫秒都会遇到操作系统的中断事件，每次中断时都会记录一个剖析数据然后恢复正常的运行.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Block分析: 记录阻塞goroutine最久的操作，例如系统调用、管道发送和接收，还有获取锁; 当goroutine被这些操作阻塞时，剖析库都会记录相应的事件.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 剖析对于长期运行的程序尤其有用，因此可以通过调用Go的&lt;code&gt;runtime API&lt;/code&gt;来启用运行时剖析。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 通过不同的参数来获取指定性能分析数据
$ go test -cpuprofile=cpu.out
$ go test -blockprofile=block.out
$ go test -memprofile=mem.out
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一旦我们通过上述内置工具获取到相关的分析数据，我们就可以使用&lt;code&gt;pprof&lt;/code&gt;来分析数据，使用&lt;code&gt;go help pprof&lt;/code&gt;可以查看更多帮助信息，最常用的即: 生成这个概要文件的可执行程序和对应的剖析数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 获取CPU基准测试数据
$ go test  -run=&amp;quot;none&amp;quot; -bench=Benchmark_GetSomething -cpuprofile=cpu.log
goos: darwin
goarch: amd64
Benchmark_GetSomething-4   	2000000000	         0.36 ns/op
--- BENCH: Benchmark_GetSomething-4
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
    area_test.go:40: 24686420
PASS
ok  	_/Users/BGBiao/unittest	0.944s
➜  unittest git:(master) ✗ ls
area.go       area_test.go  cpu.log       unittest.test

# 之后会生成测试程序和cpu分析数据(unittest.test和cpu.log) 
# 使用pprof工具分析相关数据(-text用于指定输出格式;-nodecount=10限制只输出前10行结果)
$ go tool pprof -text -nodecount=10 ./unittest.test cpu.log
File: unittest.test
Type: cpu
Time: Nov 11, 2019 at 12:12pm (CST)
Duration: 938ms, Total samples = 680ms (72.49%)
Showing nodes accounting for 680ms, 100% of 680ms total
      flat  flat%   sum%        cum   cum%
     510ms 75.00% 75.00%      680ms   100%  _/Users/BGBiao/unittest.Benchmark_GetSomething
     170ms 25.00%   100%      170ms 25.00%  _/Users/BGBiao/unittest.(*box).GetVolume
         0     0%   100%      680ms   100%  testing.(*B).launch
         0     0%   100%      680ms   100%  testing.(*B).runN

# web可视化分析(会弹出web页面,可查看程序每个逻辑的cpu使用)
$ go tool pprof -http=:8080 -nodecount=10 ./unittest.test cpu.log

# 对应的，我们也可以使用-memprofile参数来获取内存分析数据，来查看处理逻辑对内存的消耗状况
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006y8mN6ly1g8tz9u4xz2j30u00xxdjd.jpg&#34; alt=&#34;cpu性能分析&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006y8mN6ly1g8u1yeltk4j305p0ptgmk.jpg&#34; alt=&#34;mem分配&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;示例程序&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://johng.cn/go-test-profile-and-cover/&#34;&gt;Go性能测试、单元测试以及代码覆盖率&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Prometheus入门实践</title>
      <link>https://bgbiao.top/post/prometheus%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 20 Jun 2019 17:33:14 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/prometheus%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</guid>
      
        <description>&lt;h2 id=&#34;prometheus入门实践&#34;&gt;Prometheus入门实践&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://prometheus.io/download/&#34;&gt;Prometheus下载地址&lt;/a&gt;
&lt;a href=&#34;https://www.kubernetes.org.cn/tags/prometheus&#34;&gt;Prometheus相关文档&lt;/a&gt;
&lt;a href=&#34;https://prometheus.io/docs/introduction/overview/&#34;&gt;Prometheus官方文档&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;一-基本原理&#34;&gt;一、基本原理&lt;/h3&gt;

&lt;p&gt;通过&lt;code&gt;HTTP协议周期性抓取被监控组件的状态&lt;/code&gt;,任意组件只要提供对应的HTTP接口就可以接入监控。&lt;/p&gt;

&lt;p&gt;输出被监控组件信息的HTTP接口被叫做&lt;code&gt;exporter&lt;/code&gt;,也就是数据采集端，通常来说，最需要接入改造的就是expoter. 当前互联网上已经有很多成熟的&lt;code&gt;exporter&lt;/code&gt;组件，当然用户也可用根据官方提供的sdk自行编写exporter.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bookstack.cn/read/prometheus-manual/instrumenting-exporters.md&#34;&gt;开箱即用的exporter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://prometheus.io/docs/instrumenting/clientlibs/&#34;&gt;官方的sdk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/oliver006/redis_exporter&#34;&gt;redis-exporter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:prometheus的时间序列数据分为四种类型&lt;/code&gt;
- Counter: 收集的数据是按照某个趋势（增加／减少）一直变化的，我们往往用它记录服务请求总量，错误总数等
- Gauge: 搜集的数据是一个瞬时的，与时间没有关系，可以任意变高变低，往往可以用来记录内存使用率、磁盘使用率等
- Histogram: 用于表示一段时间范围内对数据进行采样,并能够对其指定区间以及总数进行统计，通常我们用它计算分位数的直方图。
- Summary: 和Histogram类似，用于表示一段时间内数据采样结果。它直接存储了 quantile 数据，而不是根据统计区间计算出来的&lt;/p&gt;

&lt;h3 id=&#34;二-组件介绍&#34;&gt;二、组件介绍&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1. Prometheus-server: 负责&lt;code&gt;数据采集和存储(TSDB)&lt;/code&gt;,提供PromQL查询语言的支持&lt;/li&gt;
&lt;li&gt;2. Alertmanager: 警告管理器，用来进行报警&lt;/li&gt;
&lt;li&gt;3. Push Gateway: 支持临时性Job主动推送指标的中间网关(通常对应于短声明周期的任务监控)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;三-服务过程&#34;&gt;三、服务过程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1. &lt;code&gt;Prometheus Daemon&lt;/code&gt;定时去目标上抓取&lt;code&gt;metrics(指标)数据&lt;/code&gt;,每个抓取目标需要暴露一个http服务的接口给server进行定时获取。支持配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup方式抓取目标；对于长生命周期的服务，采用Pull模式定期拉取数据，对于段生命周期的任务，通过push-gateway来主动推送数据&lt;/li&gt;
&lt;li&gt;2. &lt;code&gt;Prometheus&lt;/code&gt;本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。&lt;/li&gt;
&lt;li&gt;3. Prometheus通过PromQL和其他API可视化地展示收集的数据. 可以作为&lt;code&gt;Grafana&lt;/code&gt;的数据源进行图标输出，也可通过API对外提供数据展示&lt;/li&gt;
&lt;li&gt;4. &lt;code&gt;PushGateway&lt;/code&gt;支持client主动推送metrics到push-gateway(相当于是一个常驻的exporter服务),prometheus定期去push-gateway中获取数据&lt;/li&gt;
&lt;li&gt;5. &lt;code&gt;Alertmanager&lt;/code&gt;是独立于prometheus的一个组件，支持PromQL查询语句，提供灵活的报警功能&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;四-pronetheus服务构建使用&#34;&gt;四、pronetheus服务构建使用&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://prometheus.io/download/&#34;&gt;下载地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;源码安装&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 三个组件
$ wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz -O node_exporter-0.18.1.tar.gz

$ wget https://github.com/prometheus/prometheus/releases/download/v2.10.0/prometheus-2.10.0.linux-amd64.tar.gz -O prometheus-2.10.0.linux-amd64.tar.gz

$ wget https://github.com/prometheus/pushgateway/releases/download/v0.8.0/pushgateway-0.8.0.linux-amd64.tar.gz -O pushgateway-0.8.0.linux-amd64.tar.gz


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;docker方式安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:prometheus默认使用yaml格式来定义配置文件&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 编写prometheus默认配置文件
$ cat prometheus.yml
global:
  scrape_interval:     15s
  evaluation_interval: 15s

rule_files:
  # - &amp;quot;first.rules&amp;quot;
  # - &amp;quot;second.rules&amp;quot;

scrape_configs:
  # 会在每个metrics数据中增加job=&amp;quot;prometheus&amp;quot;和instance=&amp;quot;localhost:9090&amp;quot;的基本数据
  - job_name: prometheus
    static_configs:
      - targets: [&#39;localhost:9090&#39;]

# 热启动prometheus服务
$ docker run --name=prometheus -d -p 9090:9090  -v /Users/xuxuebiao/Desktop/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml --web.enable-lifecycle

$ docker ps -l
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
5e1698a320b2        prom/prometheus     &amp;quot;/bin/prometheus -...&amp;quot;   3 days ago          Up 2 minutes        0.0.0.0:9090-&amp;gt;9090/tcp   prometheus


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; prometheus为golang编写的程序，因此只有一个二进制文件，使用&amp;ndash;config.file来制定配置文件，使用&amp;ndash;web.enable-lifecycle来启用远程热加载配置文件. 调用指令&lt;code&gt;curl -X POST http://localhost:9090/-/reload&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;此时可以访问&lt;a href=&#34;http://localhost:9090&#34;&gt;prometheus-web&lt;/a&gt;即可查看prometheus的状态页面。此时它会每30s对自己暴露的http metrics数据进行采集。可以访问prometheus本身的&lt;a href=&#34;http://localhost:9090/metrics&#34;&gt;metrics数据&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-e6e1d386fcd43a0c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus-graph&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-64dcaa81e432aa04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus-metrics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-746ef7f040089d80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus-当前收集上来的指标项&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-5d97ef27b313ef6a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;go-info指标&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-943befcf74a6d6a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;单metrics指标数据&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;通过node exporter提供metrics&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 启动node-exporter
$ docker run -d --name=node-exporter -p 9100:9100  prom/node-exporter
$ docker ps -l
CONTAINER ID        IMAGE                COMMAND                CREATED             STATUS              PORTS                    NAMES
0f60bcce1ea6        prom/node-exporter   &amp;quot;/bin/node_exporter&amp;quot;   3 days ago          Up 42 seconds       0.0.0.0:9100-&amp;gt;9100/tcp   node-exporter
# 查看服务暴露的metrics
$ curl http://localhost:9100/metrics

# 将配置暴露给prometheus，并重载prometheus
$ cat prometheus.yml
global:
  scrape_interval:     15s
  evaluation_interval: 15s

rule_files:
  # - &amp;quot;first.rules&amp;quot;
  # - &amp;quot;second.rules&amp;quot;

scrape_configs:
  - job_name: prometheus
    static_configs:
      - targets: [&#39;localhost:9090&#39;]
			# 增加一个target 并附加一个label来标记该metrics
      # 注意:在prometheus启动时增加了一些参数,因此target不需要写协议和uri(http和/metrics)
      - targets: [&#39;10.13.13.60:9100&#39;]
        labels:
          group: &amp;quot;client-node-exporter&amp;quot;


# prometheus服务重载
$ curl -X POST http://localhost:9090/-/reload

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-0daae077328b80f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;node-exporter数据采集到prometheus&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-4461cc2d08501e1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;node-exporter采集的15分钟平均负载&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:如果需要同时查找多个项，其实需要熟悉prometheus的表达式编写&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;五-安装pushgateway&#34;&gt;五、安装pushgateway&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:push-gateway服务启动后也需要将endpoint加入prometheus中&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 启动push-gateway服务
docker run -d -p 9091:9091 --name pushgateway prom/pushgateway

# 查看push-gateway服务
$ curl localhost:9091

# 测试push一条metrics数据到Push-gateway
echo &amp;quot;tps 100&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb

# 多指标推送
cat &amp;lt;&amp;lt;EOF | curl --data-binary @- http://localhost:9091/metrics/job/xxb/instance/bgbiao
tps{label=&amp;quot;xxb&amp;quot;} 8800
tps1 100
tps2 160
tps3 160
EOF

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-e7a94dd04483137d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;push-gateway服务&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-1956a56a26dda95f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus增加push-gateway&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-1b3319b62dfd036d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;push-gateway采集上来的数据&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-e2e614fc197f2a50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus上查看push-gateway上报的数据&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;六-安装grafana进行图标展示&#34;&gt;六、安装Grafana进行图标展示&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# 创建grafana服务
$ docker run -d -p 3000:3000 --name grafana grafana/grafana

$ curl localhost:3000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加数据源，以及基本数据验证&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 向prometheus的push-gateway上主动push数据模拟数据上报
➜  Desktop echo &amp;quot;tps 10&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
➜  Desktop echo &amp;quot;tps 9&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
➜  Desktop echo &amp;quot;tps 20&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
➜  Desktop echo &amp;quot;tps 30&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
➜  Desktop echo &amp;quot;tps 310&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
➜  Desktop echo &amp;quot;tps 222&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-d442c89b5796b2da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;grafana数据源配置&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-6f234d69ad8ff8e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;grafana查看prometheus中收集的metrics数据&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;七-安装altermanager&#34;&gt;七、安装AlterManager&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Prometheus&lt;/code&gt;中的告警由独立的两部分组成
- 1. Prometheus服务中的警告规则发送警告到Alertmanager
- 2. Alertmanager管理这些警告.包含:silencing, inhibition, aggregation 并通过一些方式发送通知&lt;/p&gt;

&lt;p&gt;建立告警和通知的基本步骤:
- 1. 创建和配置alertmanager
- 2. 启动prometheus服务时，通过alertmanager.url 配置报警服务alertmanager服务，prometheus和alertmanager通信连接&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;启动altermanager服务&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 编辑alertmanager配置文件
$cat alertmanager.yml
global:
  resolve_timeout: 5m
route:
  group_by: [&#39;cqh&#39;]
  group_wait: 10s #组报警等待时间
  group_interval: 10s #组报警间隔时间
  repeat_interval: 1m #重复报警间隔时间
  receiver: &#39;web.hook&#39;
receivers:
  - name: &#39;web.hook&#39;
    webhook_configs:
      - url: &#39;http://10.13.118.71:8889/open/test&#39;
inhibit_rules:
  - source_match:
      severity: &#39;critical&#39;
    target_match:
      severity: &#39;warning&#39;
    equal: [&#39;alertname&#39;, &#39;dev&#39;, &#39;instance&#39;]

# 启动服务
$ docker run -d -p 9093:9093 --name alertmanager -v /Users/xuxuebiao/Desktop/alertmanager.yml:/etc/alertmanager/alertmanager.yml prom/alertmanager

$ docker ps -l
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
c6ba74bfd03b        prom/alertmanager   &amp;quot;/bin/alertmanager...&amp;quot;   3 days ago          Up 7 seconds        0.0.0.0:9093-&amp;gt;9093/tcp   alertmanager

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-f2e6dec465c35f4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;alertmanager服务&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在prometheus中配置altermanager服务&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 编辑rule配置
$ cat rules.yml
groups:
  # tps 超过150 并且持续10s就报警告通知
  - name: bgbiao
    rules:
      - alert: bgbiao测试
        expr: tps &amp;gt; 150
        for: 10s
        labels:
          status: warning
        annotations:
          summary: &amp;quot;{{$labels.instance}}:tps 超过阈值150.&amp;quot;
          description: &amp;quot;{{$labels.instance}}:tps 超过阈值!. 当前值: {{ $value }}&amp;quot;



# 修改prometheus主配置文件
$ cat prometheus.yml
global:
  # 默认抓取时间间隔为15s
  scrape_interval:     15s
  # 计算rule的间隔
  evaluation_interval: 15s
  # 定义额外的label
  external_labels:
    monitor: &amp;quot;bgbiao-monitor&amp;quot;

rule_files:
  - /etc/prometheus/rules.yml
  # - &amp;quot;first.rules&amp;quot;
  # - &amp;quot;second.rules&amp;quot;

# 抓取对象
scrape_configs:
  - job_name: prometheus
    # 重写数据抓取时间(局部生效)
    scrape_interval: 5s
    static_configs:
      - targets: [&#39;localhost:9090&#39;]
        labels:
          group: &amp;quot;prom&amp;quot;
      - targets: [&#39;10.13.118.71:9100&#39;]
        labels:
          group: &amp;quot;node-exporter&amp;quot;
      - targets: [&#39;10.13.118.71:9091&#39;]
        labels:
          group: &amp;quot;push-gateway&amp;quot;

# 配置报警对象
alerting:
  alertmanagers:
    - static_configs:
        - targets: [&amp;quot;10.13.118.71:9093&amp;quot;]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;重载prometheus服务&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:9090/-/reload

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;重新导入数据测试&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 循环向push-gateway推送数据
$ cat test-abc.sh
#!/bin/bash
#Author_by:Andy_xu @JR-OPS
num=`date +%s | cut -c10-13`
metrics=`date +%s | cut -c${num}-13`
echo $metrics
echo &amp;quot;tps $metrics&amp;quot; | curl --data-binary @- http://localhost:9091/metrics/job/xxb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-b710723c6e4f9e9a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;模拟报警数据&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-2e90930e7db5d1e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;alertmanager中显示的报警规则&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-e3fb656620be40e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus中已出现红色报警&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/2577135-1e0a57bafbb71e5a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&#34; alt=&#34;prometheus报警详细内容&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;八-后续优化&#34;&gt;八、后续优化&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 此时使用prometheus可以监控到基础服务的资源使用情况，并且也可用借用&lt;code&gt;alertmanager&lt;/code&gt;服务对相关报警规则进行检测和报警，那么需要如何把相关报警及时的通知到相关负责人呢。我们前面在&lt;code&gt;alertmanager&lt;/code&gt;服务中配置了一个web-hook,即&lt;code&gt;http://10.13.118.71:8889/open/test&lt;/code&gt;，可以在alertmanager服务的&lt;code&gt;status&lt;/code&gt;中找到。我们可以很好的借助这个web-hook来对相关的报警发送。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 一个临时用来测试的web-hook服务
$ cat test-web-hook.go
/**
 * @File Name: test-web-hook.go
 * @Author: xxbandy @http://xxbandy.github.io
 * @Email:
 * @Create Date: 2019-06-19 14:06:48
 * @Last Modified: 2019-06-19 15:06:13
 * @Description: 一个临时用来测试的web-hook服务
 * @build:
 GOOS=darwin GOARCH=amd64 CGO_ENABLED=0  build -ldflags &#39;-w -s&#39; -o prometheus-web-hook test-web-hook.go
 */

package main
import (
    &amp;quot;github.com/gin-gonic/gin&amp;quot;
    &amp;quot;net/http&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;fmt&amp;quot;
)


func main() {
   router := gin.Default()
   router.GET(&amp;quot;/open/test&amp;quot;, CollectData)
   router.POST(&amp;quot;/open/test&amp;quot;, CollectData)

   router.Run(&amp;quot;:8889&amp;quot;)

}

func CollectData(c *gin.Context) {
    alertdata,_ := ioutil.ReadAll(c.Request.Body)
    fmt.Println(string(alertdata))
    c.JSON(http.StatusOK,nil)

}

# 构建成二进制文件
$ GOOS=darwin GOARCH=amd64 CGO_ENABLED=0  build -ldflags &#39;-w -s&#39; -o prometheus-web-hook test-web-hook.go
$ chmod a+x prometheus-web-hook

# 运行web-hook并收集报警信息
➜  ./prometheus-web-hook
[GIN-debug] [WARNING] Now Gin requires Go 1.6 or later and Go 1.7 will be required soon.

[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &amp;quot;debug&amp;quot; mode. Switch to &amp;quot;release&amp;quot; mode in production.
 - using env:	export GIN_MODE=release
 - using code:	gin.SetMode(gin.ReleaseMode)

[GIN-debug] GET    /open/test                --&amp;gt; main.CollectData (3 handlers)
[GIN-debug] POST   /open/test                --&amp;gt; main.CollectData (3 handlers)
[GIN-debug] Listening and serving HTTP on :8889
{&amp;quot;receiver&amp;quot;:&amp;quot;web\\.hook&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;firing&amp;quot;,&amp;quot;alerts&amp;quot;:[{&amp;quot;status&amp;quot;:&amp;quot;firing&amp;quot;,&amp;quot;labels&amp;quot;:{&amp;quot;alertname&amp;quot;:&amp;quot;bgbiao测试&amp;quot;,&amp;quot;exported_job&amp;quot;:&amp;quot;xxb&amp;quot;,&amp;quot;group&amp;quot;:&amp;quot;push-gateway&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;10.13.118.71:9091&amp;quot;,&amp;quot;job&amp;quot;:&amp;quot;prometheus&amp;quot;,&amp;quot;monitor&amp;quot;:&amp;quot;bgbiao-monitor&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;warning&amp;quot;},&amp;quot;annotations&amp;quot;:{&amp;quot;description&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值!. 当前值: 26986&amp;quot;,&amp;quot;summary&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值150.&amp;quot;},&amp;quot;startsAt&amp;quot;:&amp;quot;2019-06-19T06:17:19.247257311Z&amp;quot;,&amp;quot;endsAt&amp;quot;:&amp;quot;0001-01-01T00:00:00Z&amp;quot;,&amp;quot;generatorURL&amp;quot;:&amp;quot;http://5e1698a320b2:9090/graph?g0.expr=tps+%3E+150\u0026g0.tab=1&amp;quot;}],&amp;quot;groupLabels&amp;quot;:{},&amp;quot;commonLabels&amp;quot;:{&amp;quot;alertname&amp;quot;:&amp;quot;bgbiao测试&amp;quot;,&amp;quot;exported_job&amp;quot;:&amp;quot;xxb&amp;quot;,&amp;quot;group&amp;quot;:&amp;quot;push-gateway&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;10.13.118.71:9091&amp;quot;,&amp;quot;job&amp;quot;:&amp;quot;prometheus&amp;quot;,&amp;quot;monitor&amp;quot;:&amp;quot;bgbiao-monitor&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;warning&amp;quot;},&amp;quot;commonAnnotations&amp;quot;:{&amp;quot;description&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值!. 当前值: 26986&amp;quot;,&amp;quot;summary&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值150.&amp;quot;},&amp;quot;externalURL&amp;quot;:&amp;quot;http://c6ba74bfd03b:9093&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;4&amp;quot;,&amp;quot;groupKey&amp;quot;:&amp;quot;{}:{}&amp;quot;}

[GIN] 2019/06/19 - 15:24:10 | 200 |     727.873µs |    10.13.118.71 | POST     /open/test
{&amp;quot;receiver&amp;quot;:&amp;quot;web\\.hook&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;firing&amp;quot;,&amp;quot;alerts&amp;quot;:[{&amp;quot;status&amp;quot;:&amp;quot;firing&amp;quot;,&amp;quot;labels&amp;quot;:{&amp;quot;alertname&amp;quot;:&amp;quot;bgbiao测试&amp;quot;,&amp;quot;exported_job&amp;quot;:&amp;quot;xxb&amp;quot;,&amp;quot;group&amp;quot;:&amp;quot;push-gateway&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;10.13.118.71:9091&amp;quot;,&amp;quot;job&amp;quot;:&amp;quot;prometheus&amp;quot;,&amp;quot;monitor&amp;quot;:&amp;quot;bgbiao-monitor&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;warning&amp;quot;},&amp;quot;annotations&amp;quot;:{&amp;quot;description&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值!. 当前值: 26986&amp;quot;,&amp;quot;summary&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值150.&amp;quot;},&amp;quot;startsAt&amp;quot;:&amp;quot;2019-06-19T06:17:19.247257311Z&amp;quot;,&amp;quot;endsAt&amp;quot;:&amp;quot;0001-01-01T00:00:00Z&amp;quot;,&amp;quot;generatorURL&amp;quot;:&amp;quot;http://5e1698a320b2:9090/graph?g0.expr=tps+%3E+150\u0026g0.tab=1&amp;quot;}],&amp;quot;groupLabels&amp;quot;:{},&amp;quot;commonLabels&amp;quot;:{&amp;quot;alertname&amp;quot;:&amp;quot;bgbiao测试&amp;quot;,&amp;quot;exported_job&amp;quot;:&amp;quot;xxb&amp;quot;,&amp;quot;group&amp;quot;:&amp;quot;push-gateway&amp;quot;,&amp;quot;instance&amp;quot;:&amp;quot;10.13.118.71:9091&amp;quot;,&amp;quot;job&amp;quot;:&amp;quot;prometheus&amp;quot;,&amp;quot;monitor&amp;quot;:&amp;quot;bgbiao-monitor&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;warning&amp;quot;},&amp;quot;commonAnnotations&amp;quot;:{&amp;quot;description&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值!. 当前值: 26986&amp;quot;,&amp;quot;summary&amp;quot;:&amp;quot;10.13.118.71:9091:tps 超过阈值150.&amp;quot;},&amp;quot;externalURL&amp;quot;:&amp;quot;http://c6ba74bfd03b:9093&amp;quot;,&amp;quot;version&amp;quot;:&amp;quot;4&amp;quot;,&amp;quot;groupKey&amp;quot;:&amp;quot;{}:{}&amp;quot;}

[GIN] 2019/06/19 - 15:25:20 | 200 |     129.897µs |    10.13.118.71 | POST     /open/test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意:我们这里的web-hook服务其实是将报警信息临时全部打印出来了，其实可以根据用户关心程度，将相关值取出来直接发送至用户终端，比如钉钉，微信，或者短信&lt;/code&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang中的异常处理</title>
      <link>https://bgbiao.top/post/golang-expect/</link>
      <pubDate>Wed, 06 Mar 2019 16:01:23 +0800</pubDate>
      
      <guid>https://bgbiao.top/post/golang-expect/</guid>
      
        <description>&lt;h2 id=&#34;golang的异常处理和单元测试&#34;&gt;Golang的异常处理和单元测试&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;1.Golang语言中没有其他语言中的&lt;code&gt;try...catch...&lt;/code&gt;语句来捕获异常和异常恢复&lt;/li&gt;
&lt;li&gt;2.在Golang中我们通常会使用&lt;code&gt;panic&lt;/code&gt;关键字来抛出异常，在&lt;code&gt;defer&lt;/code&gt;中使用&lt;code&gt;recover&lt;/code&gt;来捕获异常进行具体逻辑处理&lt;/li&gt;
&lt;li&gt;3.Golang中我们通常会在函数或方法中返回&lt;code&gt;error&lt;/code&gt;结构对象来判断是否有异常出现&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意事项&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.利用&lt;code&gt;recover&lt;/code&gt;和&lt;code&gt;panic&lt;/code&gt;指令，&lt;code&gt;defer&lt;/code&gt;必须放在panic之前定义(&lt;code&gt;panic会终止其后要执行的代码&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;2.&lt;code&gt;recover&lt;/code&gt;只有在&lt;code&gt;defer&lt;/code&gt;调用的函数中才有效，否则&lt;code&gt;recover&lt;/code&gt;无法捕获到&lt;code&gt;panic&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;3.&lt;code&gt;recover&lt;/code&gt;处理异常后，业务逻辑会跑到&lt;code&gt;defer&lt;/code&gt;之后的处理片段中&lt;/li&gt;
&lt;li&gt;4.多个&lt;code&gt;defer&lt;/code&gt;会形成&lt;code&gt;defer栈&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;5.panic会等到整个&lt;code&gt;goroutine&lt;/code&gt;退出才会报告错误&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;常规使用&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;panic&lt;/code&gt;以及&lt;code&gt;recover&lt;/code&gt;参数类型为空接口(可存储任何类型对象)&lt;code&gt;interface{}&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
func panic(v interface{})
func recover() interface{}
执行顺序:panic()-&amp;gt;带recover的defer
输出结果:
oh my god!panic.
解释:
defer中的recover成功捕获到了panic的异常
*/

package main
import (
&amp;quot;fmt&amp;quot;
)
func main() {
defer func() {
    if err := recover(); err != nil {
        fmt.Println(err)    
    }
}()
panic(&amp;quot;oh my god!panic.&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;延迟调用中引发的错误，可被后续延迟调用捕获(&lt;code&gt;仅最后一个错误被捕获&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
执行顺序:panic()-&amp;gt;带panic的defer匿名函数-&amp;gt;带recover()的defer匿名函数
输出结果:
catch the panic
解释:
defer中的recover仅能捕获最后一个错误
package main
import (
&amp;quot;fmt&amp;quot;
)
func main() {
defer func() {
    if err := recover();err != nil {
        fmt.Println(&amp;quot;catch the panic&amp;quot;)
    }
}()
defer func() {
    panic(&amp;quot;oh my god! panic.&amp;quot;)
}()

panic(&amp;quot;something panic!&amp;quot;)

}

&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;捕获函数&lt;code&gt;recover()&lt;/code&gt;只有在&lt;code&gt;defer&lt;/code&gt;调用内直接调用才会终止，否则返回&lt;code&gt;nil&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
代码执行顺序:panic-&amp;gt;在匿名函数中嵌套recover的defer函数-&amp;gt;带fmt的defer-&amp;gt;带recover的defer-&amp;gt;在匿名函数中调用recover的defer
输出结果:
defer inner
&amp;lt;nil&amp;gt;
defer recover panic error
解释: 多个defer之间形成defer栈，最底部的defer优先执行;第三个defer打印了recover()的零值`nil`，仅有第一个defer成功捕获了最底部的panic(&amp;quot;panic error&amp;quot;)
*/
package main
import &amp;quot;fmt&amp;quot;
func main() {
defer func() {
    fmt.Println(&amp;quot;defer recover&amp;quot;,recover())
}()
defer recover()
defer fmt.Println(recover())
defer func() {
    func(){
        fmt.Println(&amp;quot;defer inner&amp;quot;)
        recover()
    }()
}()
panic(&amp;quot;panic error&amp;quot;)
}      
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将代码块放置在匿名函数中可实现在函数逻辑中进行异常恢复，而不影响主函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
代码执行顺序:匿名函数中的panic语句-&amp;gt;匿名函数中i自加运算-&amp;gt;匿名函数中的fmt-&amp;gt;匿名函数中的defer-&amp;gt;主函数中的fmt
输出结果:
i is: 2
解释:panic会终止其之后的执行，因此优先执行匿名函数中的panic之后便被defer中的recover捕获，将i赋值为2，其后匿名函数退出开始继续执行主函数中的fmt.Println语句
*/
package main
import &amp;quot;fmt&amp;quot;
func main() {
test()
}
func test() {
var i int
func() {
    defer func(){
        if err := recover();err != nil {
            i = 2
        }
    }()
    panic(&amp;quot;something panic!&amp;quot;)
    i += 8
    fmt.Println(&amp;quot;no panic, i is:&amp;quot;,i)
}()
fmt.Println(&amp;quot;i is:&amp;quot;,i)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;goroutine中的recover&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;如果一个没有&lt;code&gt;recover&lt;/code&gt;的&lt;code&gt;goroutine&lt;/code&gt;发生了panic，那么整个进程都会挂掉&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
sync.WaitGroup用来等待一组goroutine的结束,Add方法用来设置等待的goroutine数量,Done方法表示一个goroutine运行结束,使用Wait方法将全部的goroutine阻塞住,直到全部goroutine执行完毕

代码执行顺序:goroutine中的逻辑-&amp;gt;wg.Wait()-&amp;gt;fmt.Println
输出结果:
panic recover assignment to entry in nil map
donw
解释:
在goroutine中我们声明了一个info的map[string]string类型，我们都知道在map,slice,channel都是引用类型，需要使用make函数进行初始化操作之后进行赋值。而这里直接使用info[&amp;quot;name&amp;quot;] = &amp;quot;BGBiao&amp;quot;进行赋值导致panic，fmt.Println函数就会被终止执行，从而执行带recover的defer，之后执行带wg.Done()的defer并退出goroutine执行主程序逻辑
*/
package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;sync&amp;quot;
)
func main() {
    var wg sync.WaitGroup
    wg.Add(4)
    go func() {
        defer wg.Done()
        defer func() {
            if err := recover();err != nil {
                fmt.Println(&amp;quot;panic recover&amp;quot;,err)
            }
        }()
        var info map[string]string
        info[&amp;quot;name&amp;quot;] = &amp;quot;BGBiao&amp;quot;
        fmt.Println(info)
    }()
    wg.Wait()
    fmt.Println(&amp;quot;done&amp;quot;)
}

&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>使用Python来操作Hive中的数据</title>
      <link>https://bgbiao.top/post/operatehivewithpython/</link>
      <pubDate>Sun, 28 Oct 2018 14:14:39 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/operatehivewithpython/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景:在整个运维内部数据仓库构建中，我们使用了Hadoop大数据生态圈中的组件来支撑运维数据的数据仓库构建。我们使用了&lt;a href=&#34;http://hive.apache.org/&#34;&gt;Hive&lt;/a&gt;作为数据仓库工具，同时使用&lt;a href=&#34;https://github.com/cloudera/hue&#34;&gt;Hue&lt;/a&gt;来对整个运维数据进行管理和查询，最终根据部门需求生成结构化数据存入关系型或K/V型数据库，以供其他部门进行商业化决策。但是在使用command-line方式和hue上操作hive时，经常会有些许问题，并且灵活性交差，因此为了改善数据到Hive的加载过程以及对Hive库中数据的操作，借此机会使用PyHive库进行操作管理Hive.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;本篇简单记录下使用Python操作Hive。&lt;/p&gt;

&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;

&lt;p&gt;我们当前整个&lt;a href=&#34;https://baike.baidu.com/item/ETL/1251949&#34;&gt;ETL&lt;/a&gt;过程大概如下:
- 1.使用Python程序对各个维度的运维数据进行采集、加工和初步的清洗处理,按照一定的数据标准和数仓模型进行数据存储
- 2.将上述抽取出来的相对结构化的数据存储到HDFS集群中
- 3.使用Hive定期从HDFS集群中加载数据，并根据已有数据进行再次加工处理，并提取价值信息&lt;/p&gt;

&lt;p&gt;ETL的质量问题具体表现为正确性、完整性、一致性、完备性、有效性、时效性和可获取性等几个特性。由于我们构建的运维数据仓库需要涉及到不同的数据源，且数据源的数据模型各不相同，为保证数据的正确性和完整性，数据加工过程选择在源数据库端执行，进行初步清洗加工后再进行转储到目标数据仓库中。&lt;/p&gt;

&lt;h3 id=&#34;python操作hive&#34;&gt;Python操作Hive&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:想要使用hive，必须要有一个可用的hive集群，同时为了保证可用使用API操作hive，我们需要要求提供hiveserver2服务&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;假设我们的hiveserver2地址为&lt;code&gt;10.0.1.18:10000&lt;/code&gt;,且用户为&lt;code&gt;hdfs&lt;/code&gt;.使用&lt;a href=&#34;https://pypi.org/project/PyHive/&#34;&gt;PyHive&lt;/a&gt;库链接Hive.&lt;/p&gt;

&lt;h4 id=&#34;安装pyhive模块&#34;&gt;安装pyhive模块&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# 过程中可能需要依赖sasl，thrift等相关服务，如有需要可以使用系统的包管理器安装(apt-get或yum)
pip install sasl thrift thrift-sasl PyHive
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;python链接hive以及基本使用&#34;&gt;Python链接Hive以及基本使用&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ cat pytest_hive.py
# 导入hive模块
from pyhive import hive

# 获取一个hive链接对象(链接到HiveServer2上)
## Connection类的__init__方法:__init__(self, host=None, port=None, username=None, database=u&#39;default&#39;, auth=None, configuration=None, kerberos_service_name=None, password=None, thrift_transport=None)
hiveconn = hive.Connection(host=&#39;10.0.1.18&#39;, port=10000, username=&#39;hdfs&#39;, database=&#39;aiops&#39;)

# 使用连接的cursor()方法获取一个游标对象
hivecur = hiveconn.cursor()

# 使用游标对象的execute()方法进行执行hivesql语句
## execute(self, operation, parameters=None, **kwargs)
hivecur.execute(&amp;quot;show databases&amp;quot;)
## executemany(self, operation, seq_of_parameters) method of pyhive.hive.Cursor instance 参数是一个序列
hivecur.executemany()

# 使用游标对象的fetch类方法获取执行结果(fetchone和fetchall以及fetchmany)
onedata = hivecur.fetchone()
alldata = hivecur.fetchall()
## fetchmany(self, size=None) method of pyhive.hive.Cursor instance
manydata = hivecur.fetchmany()

# 关闭cursor游标对象和conn连接对象
hivecur.close()
hiveconn.close()

# hive的回滚操作
hiveconn.rollback()

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;尝试用python脚本进行数据库操作&#34;&gt;尝试用python脚本进行数据库操作&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;1. 数据库查询操作&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 首先我们使用pyhive库链接hive并查看指定数据库下的表
$ cat pyhive_test.py
import sys
reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)
from pyhive import hive

class hiveObj:
    def __init__(self,host,user,dbname=u&#39;default&#39;,port=10000):
        self.host = host
        self.dbname = dbname
        self.user = user
        self.port = port
    def hiveConIns(self):
        conn = hive.Connection(host=self.host, port=self.port, username=self.user, database=self.dbname)
        return conn
    #通常查询个别数量的数据建议在sql中进行优化，可以仅使用cursor的fetchall()方法进行批量操作
    def querydata(self,sql,args=None):
        conn = self.hiveConIns()
        cur = conn.cursor()
        cur.execute(sql,args)
        alldata = cur.fetchall()
        cur.close()
        #cur.fetch类方法返回一个[tuple,tuple]
        for data in alldata:
            print(data)
        conn.close()

if __name__ == &#39;__main__&#39;:
    #默认database为default,默认port为10000
    hiveobj = hiveObj(&amp;quot;10.0.1.18&amp;quot;,&amp;quot;hdfs&amp;quot;)
    #查询数据
    sql = &#39;&#39;&#39;show tables&#39;&#39;&#39;
    hiveobj.querydata(sql)

$ python pyhive_test.py
(u&#39;asset&#39;,)


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2. 数据库更新操作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;思考:其实数据库可以分为两种操作(读和写)，一种为单纯的查询操作，不会对库表结构和数据造成变更，也即为读操作;另外一种为写操作，会对库表结构和数据造成的变更操作，也即写操作.&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 给我们的hiveObj类增加一个写数据操作方法
$ cat pyhive_test.py
....
....
    def changedata(self,sql,args=None):
        conn = self.hiveConIns()
        cur = conn.cursor()
        try:
            #做一个粗暴的判断当args是list时就进行批量插入
            if isinstance(args,list):
                #executemany(sql,args)方法args支持tuple或者list类型
                cur.executemany(sql,args)
            else:
                #execute(sql,args)方法args支持string,tuple,list,dict
                cur.execute(sql,args)
            conn.commit()
        except Exception as e:
            #因为hive不支持事务，因此虽然提供了rollback()但是是没用的
            #conn.rollback()
            print(e)
        finally:
            cur.close()
            conn.close()



# 使用创建表来模拟库表变更(实际上库的变更操作应该由专业的管理员进行审核后操作)
if __name__ == &#39;__main__&#39;:
    #默认database为default,默认port为10000
    hiveobj = hiveObj(&amp;quot;10.0.1.18&amp;quot;,&amp;quot;hdfs&amp;quot;)
    #查询数据
    sql = &#39;&#39;&#39;show tables&#39;&#39;&#39;
    hiveobj.querydata(sql)

    #hive库表变更操作
    tabledesc = &#39;&#39;&#39;
     create table appinfo (
        appname string,
        level string,
        leader string,
        dep string,
        ips  array&amp;lt;string&amp;gt;)
     ROW FORMAT DELIMITED
     FIELDS TERMINATED BY &#39;|&#39;
     COLLECTION ITEMS TERMINATED BY &#39;,&#39;
    &#39;&#39;&#39;
    print(&amp;quot;creating a table....&amp;quot;)
    hiveobj.changedata(tabledesc)
    hiveobj.querydata(sql)

$ python pyhive_test.py
(u&#39;asset&#39;,)
creating a table....
(u&#39;appinfo&#39;,)
(u&#39;asset&#39;,) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3. 进行数据加载和读取操作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:上面其实我们已经封装了两个抽象的读写方法，可以对hive表进行数据加载和读取操作了&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 假如我们的hdfs上已经存在一份如下结构化的数据
$ hdfs dfs -cat /ips.txt;
data-web|p0|bgbiao|ops1|10.0.0.1,10.0.0.2
data-api|p0|biaoge|sre1|192.168.0.1,192.168.0.2
data-models|p1|xxbandy|sre1|10.0.0.3,192.168.0.3

$ cat pyhive_test.py
...
...
if __name__ == &#39;__main__&#39;:
		#首先进行将hdfs中的数据加载到appinfo表中,加载完成后查询appinfo表
    sql1 = &amp;quot;load data  inpath &#39;hdfs://hdfs-name/ips.txt&#39; overwrite into table appinfo&amp;quot;
    hiveobj.changedata(sql1)
    hiveobj.querydata(&#39;select * from appinfo&#39;)

$ python pyhive_test.py
(u&#39;data-web&#39;, u&#39;p0&#39;, u&#39;bgbiao&#39;, u&#39;ops1&#39;, u&#39;[&amp;quot;10.0.0.1&amp;quot;,&amp;quot;10.0.0.2&amp;quot;]&#39;)
(u&#39;data-api&#39;, u&#39;p0&#39;, u&#39;biaoge&#39;, u&#39;sre1&#39;, u&#39;[&amp;quot;192.168.0.1&amp;quot;,&amp;quot;192.168.0.2&amp;quot;]&#39;)
(u&#39;data-models&#39;, u&#39;p1&#39;, u&#39;xxbandy&#39;, u&#39;sre1&#39;, u&#39;[&amp;quot;10.0.0.3&amp;quot;,&amp;quot;192.168.0.3&amp;quot;]&#39;)

# 接下来我们对上述表进行一个拆分查询
$ cat pyhive_test.py
...
...
if __name__ == &#39;__main__&#39;:
    #对array对象中的元素进行遍历查询
    sql = &amp;quot;select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    hiveobj.querydata(sql)

# 这样子我们就知道每个ip对应的关联关系了
$ python pyhive_test.py
(u&#39;10.0.0.1&#39;, u&#39;data-web&#39;, u&#39;bgbiao&#39;, u&#39;ops1&#39;)
(u&#39;10.0.0.2&#39;, u&#39;data-web&#39;, u&#39;bgbiao&#39;, u&#39;ops1&#39;)
(u&#39;192.168.0.1&#39;, u&#39;data-api&#39;, u&#39;biaoge&#39;, u&#39;sre1&#39;)
(u&#39;192.168.0.2&#39;, u&#39;data-api&#39;, u&#39;biaoge&#39;, u&#39;sre1&#39;)
(u&#39;10.0.0.3&#39;, u&#39;data-models&#39;, u&#39;xxbandy&#39;, u&#39;sre1&#39;)
(u&#39;192.168.0.3&#39;, u&#39;data-models&#39;, u&#39;xxbandy&#39;, u&#39;sre1&#39;)

# 临时表的创建和使用
    #对array对象中的元素进行遍历查询[临时表的创建第一次必须使用create table name as select ],更新数据需要使用[insert into|overwrite table name select] into是追加数据，overwrite是覆盖数据
    #sql = &amp;quot;create  table tmpapp as select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    #sql = &amp;quot;insert into table tmpapp select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    sql = &amp;quot;insert overwrite table tmpapp select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    hiveobj.changedata(sql)
    hiveobj.querydata(&#39;select * from tmpapp limit 1&#39;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4. 源码文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat pyhive_test.py
import sys
reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)
from pyhive import hive

class hiveObj:
    def __init__(self,host,user,dbname=u&#39;default&#39;,port=10000):
        self.host = host
        self.dbname = dbname
        self.user = user
        self.port = port
    def hiveConIns(self):
        conn = hive.Connection(host=self.host, port=self.port, username=self.user, database=self.dbname)
        return conn
    #通常查询个别数量的数据建议在sql中进行优化，可以仅使用cursor的fetchall()方法进行批量操作
    def querydata(self,sql,args=None):
        conn = self.hiveConIns()
        cur = conn.cursor()
        cur.execute(sql,args)
        alldata = cur.fetchall()
        cur.close()
        #cur.fetch类方法返回一个[tuple,tuple]
        for data in alldata:
            print(data)
        conn.close()
    #注意:hivesql的execute类方法的args是执行过程的参数，而不是sql的参数.比如cursor.execute(&#39;SELECT * FROM my_awesome_data LIMIT 10&#39;, async=True)表示异步执行
    def changedata(self,sql,args=None):
        conn = self.hiveConIns()
        cur = conn.cursor()
        try:
            #做一个粗暴的判断当args是list时就进行批量插入
            if isinstance(args,list):
                #executemany(sql,args)方法args支持tuple或者list类型
                cur.executemany(sql,args)
            else:
                #execute(sql,args)方法args支持string,tuple,list,dict
                cur.execute(sql,args)
            conn.commit()
        except Exception as e:
            #因为hive不支持事务，因此虽然提供了rollback()但是是没用的
            #conn.rollback()
            print(e)
        finally:
            cur.close()
            conn.close()

if __name__ == &#39;__main__&#39;:
    #默认database为default,默认port为10000
    hiveobj = hiveObj(&amp;quot;10.0.1.18&amp;quot;,&amp;quot;hdfs&amp;quot;)
    &#39;&#39;&#39;
    #查询数据
    sql = &amp;quot;show tables&amp;quot;
    hiveobj.querydata(sql)

    #hive创建表
    tabledesc = &amp;quot;create table appinfo (appname string,level string,leader string,dep string,ips  array&amp;lt;string&amp;gt;) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;|&#39; COLLECTION ITEMS TERMINATED BY &#39;,&#39; &amp;quot;
    print(&amp;quot;creating a table....&amp;quot;)
    hiveobj.changedata(tabledesc)
    hiveobj.querydata(sql)

    #插入数据
    sql1 = &amp;quot;load data  inpath &#39;hdfs://hdfs-name/ips.txt&#39; overwrite into table appinfo&amp;quot;
    hiveobj.changedata(sql1)
    hiveobj.querydata(&#39;select * from appinfo&#39;)
    &#39;&#39;&#39;
    #对array对象中的元素进行遍历查询[临时表的创建第一次必须使用create table name as select ],更新数据需要使用[insert into|overwrite table name select] into是追加数据，overwrite是覆盖数据
    #sql = &amp;quot;create  table tmpapp as select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    #sql = &amp;quot;insert into table tmpapp select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    sql = &amp;quot;insert overwrite table tmpapp select ip,appname,leader,dep from appinfo  LATERAL VIEW explode(ips) appinfo  AS ip&amp;quot;
    hiveobj.changedata(sql)
    hiveobj.querydata(&#39;select * from tmpapp limit 1&#39;)
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>使用Python操作MySQL</title>
      <link>https://bgbiao.top/post/operatemysqlwithpython/</link>
      <pubDate>Sat, 27 Oct 2018 13:53:40 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/operatemysqlwithpython/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 最近做内部运维数据的数据仓库，最终将Hive中的数据清洗后需要业务决策相关的数据进行结构化处理，并存储到关系型数据库MySQL中，以供后期对外接口使用。本篇简单记录下使用Python操作MySQL数据库的简单操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;mysql数据库环境准备&#34;&gt;MySQL数据库环境准备&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:在当前容器化基础设施已经全面覆盖的时代，为了快速验证效果，我们及其推荐使用以Docker为代表的容器化基础设施来快速构建你的基础环境。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在&lt;a href=&#34;https://hub.docker.com/&#34;&gt;DockerHub&lt;/a&gt;上有丰富的基础中间件的镜像，我们可以使用Docker快速的构建我们的MySQL基础环境，而不必每次重新安装各种复杂的中间件环境，因为我们只是使用者，我相信每个团队都会有专门的中间件维护者。好吧，如果没有，那你依然可以自己根据实际的需求和标准进行构建Docker镜像，这样就为我们创造了一个未来很长一段时间可复用的组件。总之，想说的一件事就是，下面的MySQL环境是用Docker容器跑的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 确保docker环境正常
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

# 下载MySQL指定版本的镜像
$ docker pull mysql:5.6
$ docker images | grep mysql
mysql                                     5.6                 d1f491b20727        2 days ago          256 MB

# 创建一个mysql实例[需要指定至少一个环境变量:MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD]
$ docker run -itd --name mysql -e MYSQL_ROOT_PASSWORD=&amp;quot;123456&amp;quot;  -P mysql:5.6
6c4428b341516c7eeec48cbc5b658a464f76b5f7d42b3e689151392f5cd8ac56

# MySQL密码为123456,端口为32773
$ docker ps
CONTAINER ID        IMAGE                                          COMMAND                  CREATED             STATUS              PORTS                                               NAMES
6c4428b34151        mysql:5.6                                      &amp;quot;docker-entrypoint.sh&amp;quot;   5 seconds ago       Up 3 seconds        0.0.0.0:32773-&amp;gt;3306/tcp                             mysql

# mysql数据库登录测试
$ mysql -h 127.0.0.1 -uroot -P 32773 -p123456
...
Server version: 5.6.42 MySQL Community Server (GPL)
Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.
...
mysql&amp;gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
3 rows in set (0.00 sec)

# 查看数据库字符编码格式
mysql&amp;gt; show variables like &#39;%char%&#39;;
+--------------------------+----------------------------+
| Variable_name            | Value                      |
+--------------------------+----------------------------+
| character_set_client     | utf8                       |
| character_set_connection | utf8                       |
| character_set_database   | utf8                       |
| character_set_filesystem | binary                     |
| character_set_results    | utf8                       |
| character_set_server     | utf8                       |
| character_set_system     | utf8                       |
| character_sets_dir       | /usr/share/mysql/charsets/ |
+--------------------------+----------------------------+
8 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，一个MySQL数据库已经准备好，需要我们注意的是，因为使用的是官方的Docker image，我们需要进行相关配置的检查和设置，否则可能会为后期的操作造成一定麻烦，比如设置数据库的字符编码.&lt;br /&gt;
让MySQL支持中文，一般而言需要关注以下几个点:
- 1. 修改MySQL配置中客户端和服务端的字符编码为&lt;code&gt;utf8&lt;/code&gt;，分别为[mysqld的default-character-set和character-set-server参数以及client的default-character-set参数]
- 2. 创建表时指定表的字符编码(default charset=utf8;)
- 3. 链接数据库的时候指定链接字符编码(charset=utf8)
- 4. 使用Python操作数据库时需要对Python文件进行utf8支持(#encoding=utf-8和sys.setdefaultencoding(utf-8))
- 5. 使用&lt;code&gt;show variables like &#39;%char%&#39;;&lt;/code&gt;命令检查mysql字符集是否为&lt;code&gt;utf8格式&lt;/code&gt;，并使用&lt;code&gt;SET NAMES UTF8; 或者set character_set_server = utf8;&lt;/code&gt;进行设置&lt;/p&gt;

&lt;h3 id=&#34;使用python进行操作mysql&#34;&gt;使用Python进行操作MySQL&lt;/h3&gt;

&lt;p&gt;首先，在使用之前我们需要对Python版的MySQL库有一个了解，当前主流的库有&lt;code&gt;MySQLdb&lt;/code&gt;,&lt;code&gt;PyMySQL&lt;/code&gt;和&lt;code&gt;SQLAlchemy&lt;/code&gt;.&lt;br /&gt;
- &lt;code&gt;MySQLdb&lt;/code&gt;:一般是Linux系统发行版中默认支持的，通常包名为&lt;code&gt;Python-MySQL&lt;/code&gt;，核心由C语言打造，接口精炼，性能最棒，缺点是环境依赖较多，安装复杂，近两年已停止更新，只支持Python2，不支持Python3
- &lt;code&gt;PyMySQL&lt;/code&gt;:纯python打造，接口与Python-MySQL兼容，安装方便，支持Python3
- &lt;code&gt;SQLAlchemy&lt;/code&gt;: 一个ORM框架，它并不提供底层的数据库操作，而是要借助于MySQLdb、PyMySQL等第三方库来完成，目前SQLAlchemy在Web编程领域应用广泛
&lt;code&gt;备注:其实还有类似mysqlclient之类的库，主要集成在一些web框架中作为依赖&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由于为了快速实现业务逻辑，在接下来的操作中主要使用&lt;code&gt;PyMySQL&lt;/code&gt;库进行操作数据库，虽然性能不及&lt;code&gt;MySQLdb&lt;/code&gt;，但是可以使用&lt;code&gt;pymysql.install_as_MySQLdb()&lt;/code&gt;来兼容&lt;code&gt;MySQLdb&lt;/code&gt;，在业务正式上线时可以不改变业务代码逻辑而平滑的使用&lt;code&gt;MySQLdb&lt;/code&gt;库。&lt;/p&gt;

&lt;h4 id=&#34;安装pymysql库&#34;&gt;安装pymysql库&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;Linux&lt;/code&gt;环境下，大多数系统工具使用Python语言进行编写，因此在安装额外的Python模块时，通常会有几种选择:
- 1. 使用系统自带工具安装&lt;code&gt;apt-get install or yum install&lt;/code&gt;，该种方式会将模块默认安装的系统环境，可能会影响系统环境
- 2. 使用Python原声的包管理工具&lt;code&gt;pip install&lt;/code&gt; ，该种方式会默认安装到&lt;code&gt;pip&lt;/code&gt;命令所在的Python解释环境下，因此取决于Python环境是否独立于系统环境的Python，通常情况下会使用&lt;code&gt;pyenv&lt;/code&gt;之类的工具进行环境隔离
- 3. 使用包管理工具&lt;code&gt;conda&lt;/code&gt;相关工具进行管理python，可以有效管理python多环境依赖，并且可以很方便构建数据科学相关环境.&lt;a href=&#34;https://www.jianshu.com/c/d2372cb5978e&#34;&gt;conda使用指南&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 安装pymysql库
$ pip install pymysql
or 
$ conda install pymysql

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;python链接mysql以及基本使用&#34;&gt;python链接MySQL以及基本使用&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;使用pymysql库操作mysql&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat pytest_mysql.py
import pymysql
# 获取一个mysql链接对象
conn = pymysql.connect(host=host, port=port, user=user, passwd=passwd, db=db, charset=&#39;utf8&#39;)
# 使用数据库链接的cursor()方法获取一个游标对象
cursor = conn.cursor()
# 使用游标对象的execute()方法进行执行sql语句
cursor.execute(&amp;quot;SELECT VERSION()&amp;quot;)
## execute方法的定义如下,其中args可以是tuple, list or dict,如果是list or tuple的话，%s会被当做查询的一个占位符;如果是dict的话%(name)s会被当做一个占位符
## execute(self, query, args=None) 


# 使用游标对象的fetch类方法获取数据
## fetchone返回一条数据,fetchall返回查询的所有数据。fetch类方法会返回一个list类型的tuple结构类型对象.[(),()...]
onedata = cursor.fetchone()
alldata = cursor.fetchall()

# 提交数据库操作[一般在更新数据库操作时需要注意执行]
conn.commit()

# 及时关闭数据库链接以及打开的游标[以防止在并发情况下系统打开连接数过多]
cursor.close()
conn.close()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;尝试用python脚本进行数据库操作&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat test_show_table.py
import sys
reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)
import pymysql

class mysqlObj:
    def __init__(self,host,dbname,user,passwd,port=3306):
        self.host = host
        self.dbname = dbname
        self.user = user
        self.passwd = passwd
        self.port = port
    def mysqlConIns(self):
        conn = pymysql.connect(host=self.host, port=self.port, user=self.user, passwd=self.passwd, db=self.dbname, charset=&#39;utf8&#39;)
        return conn
    def querydata(self,sql,args=None):
        conn = self.mysqlConIns()
        cur = conn.cursor()
        cur.execute(sql,args)
        alldata = cur.fetchall()
        cur.close()
        for data in alldata:
            print(data)
        conn.close()


if __name__ == &#39;__main__&#39;:
    mysqlobj = mysqlObj(&#39;localhost&#39;,&#39;mysql&#39;,&#39;root&#39;,&#39;123456&#39;,32773)
    mysqlobj.querydata(&amp;quot;show tables;&amp;quot;)

# 对mysql库进行查看tables操作，返回的是一个tuple
$ python test_show_table.py
(u&#39;columns_priv&#39;,)
(u&#39;db&#39;,)
(u&#39;event&#39;,)
(u&#39;func&#39;,)
(u&#39;general_log&#39;,)
(u&#39;help_category&#39;,)
(u&#39;help_keyword&#39;,)
(u&#39;help_relation&#39;,)
(u&#39;help_topic&#39;,)
(u&#39;innodb_index_stats&#39;,)
(u&#39;innodb_table_stats&#39;,)
(u&#39;ndb_binlog_index&#39;,)
(u&#39;plugin&#39;,)
(u&#39;proc&#39;,)
(u&#39;procs_priv&#39;,)
(u&#39;proxies_priv&#39;,)
(u&#39;servers&#39;,)
(u&#39;slave_master_info&#39;,)
(u&#39;slave_relay_log_info&#39;,)
(u&#39;slave_worker_info&#39;,)
(u&#39;slow_log&#39;,)
(u&#39;tables_priv&#39;,)
(u&#39;time_zone&#39;,)
(u&#39;time_zone_leap_second&#39;,)
(u&#39;time_zone_name&#39;,)
(u&#39;time_zone_transition&#39;,)
(u&#39;time_zone_transition_type&#39;,)
(u&#39;user&#39;,)

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;mysql数据库常用的一些操作&#34;&gt;MySQL数据库常用的一些操作&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;注意:在之前我们创建的MySQL实例中仅是一个空的数据库，在实际使用之前，我们需要进行数据库的库表结构创建，以及相关的数据库授权，而这一部分操作通常会由专业的数据库管理员(DBA)进行操作和处理&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;接下来对一个&lt;code&gt;website&lt;/code&gt;数据库和&lt;code&gt;use&lt;/code&gt;表进行操作:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create database website;
Query OK, 1 row affected (0.00 sec)
mysql&amp;gt; CREATE TABLE  IF NOT EXISTS useinfo (userid int(10) primary key not null auto_increment,username varchar(20) not null,usersite varchar(50),other varchar(50)) DEFAULT CHARSET=utf8;
Query OK, 0 rows affected (0.02 sec)
mysql&amp;gt; describe useinfo;
+----------+-------------+------+-----+---------+----------------+
| Field    | Type        | Null | Key | Default | Extra          |
+----------+-------------+------+-----+---------+----------------+
| userid   | int(10)     | NO   | PRI | NULL    | auto_increment |
| username | varchar(20) | NO   |     | NULL    |                |
| usersite | varchar(50) | YES  |     | NULL    |                |
| other    | varchar(50) | YES  |     | NULL    |                |
+----------+-------------+------+-----+---------+----------------+
4 rows in set (0.00 sec)

# 数据库授权[授权所有的主机可以以root用户,123456的密码去操作website库]
mysql&amp;gt; grant all on website.* to root@&#39;%&#39; identified by &amp;quot;123456&amp;quot;;
Query OK, 0 rows affected (0.00 sec)

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;对指定数据库进行相关查询操作&#34;&gt;对指定数据库进行相关查询操作&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# 依然是上面那个test_show_table.py脚本,不过我们改变一下`__main__`
$ cat test_show_table.py
.....
if __name__ == &#39;__main__&#39;:
    mysqlobj = mysqlObj(&#39;localhost&#39;,&#39;website&#39;,&#39;root&#39;,&#39;123456&#39;,32773)
    args = [&amp;quot;show tables;&amp;quot;,&amp;quot;describe useinfo;&amp;quot;]
    for arg in args:
        mysqlobj.querydata(arg)

# 可以看到我们的website库下有useinfo一张表，并且该表包含userid,username,usersite,other4个字段
$ python test_show_table.py
(u&#39;useinfo&#39;,)
(u&#39;userid&#39;, u&#39;int(10)&#39;, u&#39;NO&#39;, u&#39;PRI&#39;, None, u&#39;auto_increment&#39;)
(u&#39;username&#39;, u&#39;varchar(20)&#39;, u&#39;NO&#39;, u&#39;&#39;, None, u&#39;&#39;)
(u&#39;usersite&#39;, u&#39;varchar(20)&#39;, u&#39;YES&#39;, u&#39;&#39;, None, u&#39;&#39;)
(u&#39;other&#39;, u&#39;varchar(20)&#39;, u&#39;YES&#39;, u&#39;&#39;, None, u&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;对mysql数据库进行插入操作&#34;&gt;对MySQL数据库进行插入操作&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;注意:插入操作分为单条记录插入和批量插入,一般数据库都支持批量插入方法,在pysql中为cursor.executemany(sql,args)&lt;/code&gt;
&lt;code&gt;为我们的mysqlObj类增加一个插入操作:&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat test_show_table.py
....
....
    #注意插入数据时单条记录使用tuple()类型;批量插入数据时使用list()类型
    def changedata(self,sql,args=None):
        conn = self.mysqlConIns()
        cur = conn.cursor()
        try:
            #做一个粗暴的判断当args是list时就进行批量插入
            if isinstance(args,list):
                #executemany(sql,args)方法args支持tuple或者list类型
                cur.executemany(sql,args)
            else:
                #execute(sql,args)方法args支持string,tuple,list,dict
                cur.execute(sql,args)
            conn.commit()
        except Exception as e:
            conn.rollback()
            print(e)
        finally:
            cur.close()
            conn.close()
....
...
if __name__ == &#39;__main__&#39;:
    mysqlobj = mysqlObj(&#39;localhost&#39;,&#39;website&#39;,&#39;root&#39;,&#39;123456&#39;,32773)
    &#39;&#39;&#39;
    args = [&amp;quot;show tables;&amp;quot;,&amp;quot;describe useinfo;&amp;quot;]
    for arg in args:
        mysqlobj.querydata(arg)
    &#39;&#39;&#39;
    #插入一条数据
    sql = &amp;quot;insert into  useinfo (username) values(%s)&amp;quot;
    arg = &amp;quot;彪哥&amp;quot;
    mysqlobj.changedata(sql,arg)
    sql1 = &amp;quot;insert into  useinfo (username,usersite) values(%s,%s)&amp;quot;
    arg1 = (&amp;quot;xxbandy&amp;quot;,&amp;quot;http://xxbandy.github.io&amp;quot;)
    mysqlobj.changedata(sql1,arg1)
    #批量插入数据

    argslist = [(&amp;quot;彪哥&amp;quot;,&amp;quot;http://xxbandy.github.io&amp;quot;),(&amp;quot;bgbiao&amp;quot;,&amp;quot;https://www.jianshu.com/u/9c46ece5b7bd&amp;quot;)]
    mysqlobj.changedata(sql1,argslist)
    #查询数据
    mysqlobj.querydata(&amp;quot;select * from useinfo&amp;quot;)
	
		print(&amp;quot;updating the data&amp;quot;)
		#更新数据[需要注意的是指定了字段之后由于usersite是varchar类型，占位符必须是&amp;quot;%s&amp;quot;,如果是&#39;%s&#39;会有问题]
    data = &amp;quot;https://my.oschina.net/xxbAndy&amp;quot;
    mysqlobj.changedata(&#39;update useinfo set usersite=%s where userid = 1&#39;,data)
    mysqlobj.querydata(&amp;quot;select * from useinfo&amp;quot;)

# 插入数据并查看数据
$ python /tmp/abc.py
(1, u&#39;\u5f6a\u54e5&#39;, None, None)
(2, u&#39;xxbandy&#39;, u&#39;http://xxbandy.github.io&#39;, None)
(3, u&#39;\u5f6a\u54e5&#39;, u&#39;http://xxbandy.github.io&#39;, None)
(4, u&#39;bgbiao&#39;, u&#39;https://www.jianshu.com/u/9c46ece5b7bd&#39;, None)
updating the data
(1, u&#39;\u5f6a\u54e5&#39;, u&#39;https://my.oschina.net/xxbAndy&#39;, None)
(2, u&#39;xxbandy&#39;, u&#39;http://xxbandy.github.io&#39;, None)
(3, u&#39;\u5f6a\u54e5&#39;, u&#39;http://xxbandy.github.io&#39;, None)
(4, u&#39;bgbiao&#39;, u&#39;https://www.jianshu.com/u/9c46ece5b7bd&#39;, None)

# 数据库查询记录
mysql&amp;gt; select * from website.useinfo;
+--------+----------+----------------------------------------+-------+
| userid | username | usersite                               | other |
+--------+----------+----------------------------------------+-------+
|      1 | 彪哥   | https://my.oschina.net/xxbAndy         | NULL  |
|      2 | xxbandy  | http://xxbandy.github.io               | NULL  |
|      3 | 彪哥   | http://xxbandy.github.io               | NULL  |
|      4 | bgbiao   | https://www.jianshu.com/u/9c46ece5b7bd | NULL  |
+--------+----------+----------------------------------------+-------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;源码&#34;&gt;源码&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;import sys
reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)
import pymysql

class mysqlObj:
    def __init__(self,host,dbname,user,passwd,port=3306):
        self.host = host
        self.dbname = dbname
        self.user = user
        self.passwd = passwd
        self.port = port
    def mysqlConIns(self):
        conn = pymysql.connect(host=self.host, port=self.port, user=self.user, passwd=self.passwd, db=self.dbname, charset=&#39;utf8&#39;)
        return conn
    def querydata(self,sql,args=None):
        conn = self.mysqlConIns()
        cur = conn.cursor()
        cur.execute(sql,args)
        alldata = cur.fetchall()
        cur.close()
        for data in alldata:
            print(data)
        conn.close()
    #注意插入数据时单条记录使用tuple()类型;批量插入数据时使用list()类型
    def changedata(self,sql,args=None):
        conn = self.mysqlConIns()
        cur = conn.cursor()
        try:
            #做一个粗暴的判断当args是list时就进行批量插入
            if isinstance(args,list):
                #executemany(sql,args)方法args支持tuple或者list类型
                cur.executemany(sql,args)
            else:
                #execute(sql,args)方法args支持string,tuple,list,dict
                cur.execute(sql,args)
            conn.commit()
        except Exception as e:
            conn.rollback()
            print(e)
        finally:
            cur.close()
            conn.close()



if __name__ == &#39;__main__&#39;:

    mysqlobj = mysqlObj(&#39;localhost&#39;,&#39;website&#39;,&#39;root&#39;,&#39;123456&#39;,32773)
    &#39;&#39;&#39;
    args = [&amp;quot;show tables;&amp;quot;,&amp;quot;describe useinfo;&amp;quot;]
    for arg in args:
        mysqlobj.querydata(arg)
    &#39;&#39;&#39;
    #插入一条数据
    sql = &amp;quot;insert into  useinfo (username) values(%s)&amp;quot;
    arg = &amp;quot;彪哥&amp;quot;
    mysqlobj.changedata(sql,arg)
    sql1 = &amp;quot;insert into  useinfo (username,usersite) values(%s,%s)&amp;quot;
    arg1 = (&amp;quot;xxbandy&amp;quot;,&amp;quot;http://xxbandy.github.io&amp;quot;)
    mysqlobj.changedata(sql1,arg1)
    #批量插入数据

    argslist = [(&amp;quot;彪哥&amp;quot;,&amp;quot;http://xxbandy.github.io&amp;quot;),(&amp;quot;bgbiao&amp;quot;,&amp;quot;https://www.jianshu.com/u/9c46ece5b7bd&amp;quot;)]
    mysqlobj.changedata(sql1,argslist)


    #查询数据
    mysqlobj.querydata(&amp;quot;select * from useinfo&amp;quot;)
    print(&amp;quot;updating the data&amp;quot;)
    #更新数据
    data = &amp;quot;https://my.oschina.net/xxbAndy&amp;quot;
    mysqlobj.changedata(&#39;&#39;&#39;update useinfo set usersite=%s where userid = 1&#39;&#39;&#39;,data)
    mysqlobj.querydata(&amp;quot;select * from useinfo&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>使用nvidia-smi来对Tesla-GPU进行故障排查</title>
      <link>https://bgbiao.top/post/troubleshooting-teslagpu-with-nvidia-smi/</link>
      <pubDate>Mon, 20 Aug 2018 14:34:43 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/troubleshooting-teslagpu-with-nvidia-smi/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景:生产环境中使用Tesla P40型号的进行线上模型训练，突然收到业务方反馈某一块卡好像坏了，无法使用。经了解后，发现业务方无法使用某一块卡进行运行程序，而其他GPU卡设备均正常。本篇文章记录如何排查并修复该问题。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;gpu卡异常现象&#34;&gt;GPU卡异常现象&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/issue_with_p40.png&#34; alt=&#34;gpu卡异常测试&#34; /&gt;&lt;br /&gt;
如上的的&lt;code&gt;bandwidthTest&lt;/code&gt;是nvidia-cuda官方提供的测试样例，具体可以查看&lt;a href=&#34;https://xxbandy.github.io/2017/10/26/GPU%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%8E%A9%E8%BD%ACDocker-%E4%B8%80/&#34;&gt;GPU环境的构建&lt;/a&gt;.当然用户也可以使用&lt;code&gt;tensorflow-gpu&lt;/code&gt;的如下代码来测试程序是否可以识别到GPU设备:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import tensorflow as tf 
import os
os.environ[&amp;quot;CUDA_VISIBLE_DEVICES&amp;quot;] = &amp;quot;3&amp;quot;
tf.test.gpu_device_name()
段错误(吐核)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;问题排查&#34;&gt;问题排查&lt;/h3&gt;

&lt;p&gt;由于问题出现原因仅为服务器的其中一块卡，因此我们可以使用&lt;code&gt;nvidia-smi&lt;/code&gt;命令对多卡之间的信息进行对比排查.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.使用&lt;code&gt;nvidia-smi -q -d PERFORMANCE&lt;/code&gt;查看GPU设备的性能&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## 经对比各个GPU卡设备性能够发现仅有id=3这块卡的`SW Power Cap`参数为active
# nvidia-smi -q -d PERFORMANCE -i 3
==============NVSMI LOG==============

Timestamp                           : Mon Aug 20 15:08:18 2018
Driver Version                      : 384.81

Attached GPUs                       : 8
GPU 00000000:11:00.0
    Performance State               : P8
    Clocks Throttle Reasons
        Idle                        : Not Active
        Applications Clocks Setting : Not Active
        SW Power Cap                : Active
        HW Slowdown                 : Not Active
        Sync Boost                  : Not Active
        SW Thermal Slowdown         : Not Active
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是在性能参数中有&lt;code&gt;Active&lt;/code&gt;其实并不能说明很大的问题，但看到这里其实也可以发现该卡的确是比较慢一些了，详细可以看&lt;a href=&#34;https://xxbandy.github.io/2017/10/30/Manager-your-GPUs/&#34;&gt;manage-your-gpus&lt;/a&gt;中的&lt;code&gt;监控和管理GPU Boost&lt;/code&gt;部分.&lt;/p&gt;

&lt;p&gt;原文为:
&amp;gt; If any of the GPU clocks is running at a slower speed, one or more of the above Clocks Throttle Reasons will be marked as active. The most concerning condition would be if HW Slowdown or Unknown are active, as these would most likely indicate a power or cooling issue. The remaining conditions typically indicate that the card is idle or has been manually set into a slower mode by a system administrator.&lt;/p&gt;

&lt;p&gt;大概意思是只要GPU的时钟频率以一个比较低的速度运行的话，在&lt;code&gt;Clocks Throttle Reasons&lt;/code&gt;列就会有一个或多个被设置为&lt;code&gt;active&lt;/code&gt;状态。而如果&lt;code&gt;HW Slowdown&lt;/code&gt;和&lt;code&gt;Unknown&lt;/code&gt;只要不是&lt;code&gt;active&lt;/code&gt;就说明硬件其实还好啦，起码电源是没问题的。其他几个选项需要继续排查下是否为管理员手动设置的或GPU卡正在使用中。&lt;/p&gt;

&lt;p&gt;由刚开始的测试程序可以看出，我们&lt;code&gt;id=3&lt;/code&gt;的这块卡其实已经无法检测，那既没有人手动设置，也没有程序在使用该卡，说明该卡其实还是有些问题的。&lt;/p&gt;

&lt;p&gt;至于为什么会出现&lt;code&gt;SW Power Cap: Active&lt;/code&gt;,在&lt;a href=&#34;http://international.download.nvidia.com/tesla/pdf/gpu-boost-tesla-k40-app-note.pdf&#34;&gt;gpu-boost-tesla-k40&lt;/a&gt;中看到如下一句话:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;When the GPU is in a lower performance (idle) state, the GPU clock is fixed. However,
when the GPU is operating in a high performance state (P0), the highest GPU
performance is typically desired. NVIDIA GPU Boost maximizes the GPU performance
by automatically raising the GPU clock when there is thermal and power headroom
available. Likewise, if the power or thermal limit is reached, the GPU clock scales down
to the next available clock setting so that the board remains below the power and
thermal limit.
NVIDIA products that support NVIDIA GPU Boost have multiple high-performance
GPU clocks defined. That is, when the GPU is operating in its high performance mode
(P0 state; determined automatically by the driver software), it has an array of GPU
clocks available.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是在程序运行过程中可能会导致&lt;code&gt;SW Power Cap&lt;/code&gt;状态进行变化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.使用&lt;code&gt;nvidia-smi -q -d ecc&lt;/code&gt;查看GPU的ecc信息&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nvidia-smi -i 3 -q -d ecc

==============NVSMI LOG==============

Timestamp                           : Mon Aug 20 15:34:05 2018
Driver Version                      : 384.81

Attached GPUs                       : 8
GPU 00000000:11:00.0
    Ecc Mode
        Current                     : Enabled
        Pending                     : Enabled
    ECC Errors
        Volatile
            Single Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0
            Double Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0
        Aggregate
            Single Bit
                Device Memory       : 524
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 524
            Double Bit
                Device Memory       : 36
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 36
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现该卡&lt;code&gt;ECC Errors&lt;/code&gt;的&lt;code&gt;Aggregate&lt;/code&gt;有&lt;code&gt;Device Memory&lt;/code&gt;错误信息.&lt;/p&gt;

&lt;p&gt;而&lt;code&gt;nvidia-smi&lt;/code&gt;有一个&lt;code&gt;nvidia-smi -r&lt;/code&gt;参数用来进行对GPU卡进行重置，相关说明如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    -r    --gpu-reset           Trigger reset of the GPU.
                                Can be used to reset the GPU HW state in situations
                                that would otherwise require a machine reboot.
                                Typically useful if a double bit ECC error has
                                occurred.
                                Reset operations are not guarenteed to work in
                                all cases and should be used with caution.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说当&lt;code&gt;a double bit ECC error&lt;/code&gt;出现时，gpu卡的重置是很有效的.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.尝试使用&lt;code&gt;nvidia-smi -r&lt;/code&gt;对异常的GPU卡进行恢复&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# nvidia-smi -r -i 3
Unable to reset GPU 00000000:11:00.0 because it&#39;s being used by some other process (e.g. CUDA application, graphics application like X server, monitoring application like other instance of nvidia-smi). Please first kill all processes using this GPU and all compute applications running in the system (even when they are running on other GPUs) and then try to reset the GPU again.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;意思是在对GPU卡进行重置之前，建议kill掉服务器上的所有使用GPU卡的程序，所以停止掉程序后继续执行。&lt;/p&gt;

&lt;h3 id=&#34;临时修复&#34;&gt;临时修复&lt;/h3&gt;

&lt;p&gt;在临时关闭服务器上其他使用GPU资源的程序后，再次对id=3的GPU卡进行重置操作.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ nvidia-smi -r -i 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;再次测试GPU卡检测程序&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; tf.test.gpu_device_name()
2018-08-20 14:52:27.958572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:11:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-08-20 14:52:27.958641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2018-08-20 14:52:27.958651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2018-08-20 14:52:27.958668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&amp;gt; (device: 0, name: Tesla P40, pci bus id: 0000:11:00.0)
u&#39;/gpu:0&#39;
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，重置GPU后可以正常识别到GPU设备。&lt;/p&gt;

&lt;h3 id=&#34;善后处理&#34;&gt;善后处理&lt;/h3&gt;

&lt;p&gt;其实找了这么多，虽然临时将异常的GPU卡恢复使用了，但是对于底层具体的原因其实还有待排查，因为需要设计到cuda以及Tesla不同型号产品的配置以及参数优化调整。但为了便于问题的排查和修复以及对于业务使用的快速反应，我们需要尽快恢复资源使用。因此建议将&lt;code&gt;ECC Errors&lt;/code&gt;进行归零操作，以便后期问题的继续排查.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;将ECC Errors置零操作&lt;/strong&gt;
&lt;code&gt;CUDA_ERROR_ECC_UNCORRECTABLE&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# nvidia-smi -p 1 -i 3
Reset aggregate ECC errors to zero for GPU 00000000:11:00.0.
All done.

# nvidia-smi -i 3 -q -d ecc

==============NVSMI LOG==============

Timestamp                           : Mon Aug 20 15:50:22 2018
Driver Version                      : 384.81

Attached GPUs                       : 8
GPU 00000000:11:00.0
    Ecc Mode
        Current                     : Enabled
        Pending                     : Enabled
    ECC Errors
        Volatile
            Single Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0
            Double Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0
        Aggregate
            Single Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0
            Double Bit
                Device Memory       : 0
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : 0

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;参考文章&#34;&gt;参考文章&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/en/SSFHY8_5.5.0/com.ibm.cluster.essl.v5r5.essl100.doc/am5gr_nvidcap.htm&#34;&gt;GPU-Power-Cap&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://international.download.nvidia.com/tesla/pdf/gpu-boost-tesla-k40-app-note.pdf&#34;&gt;gpu-boost-tesla-k40&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang下的protobuf初体验</title>
      <link>https://bgbiao.top/post/golang%E4%B8%8B%E7%9A%84protobuf%E5%88%9D%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Tue, 03 Apr 2018 15:01:07 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang%E4%B8%8B%E7%9A%84protobuf%E5%88%9D%E4%BD%93%E9%AA%8C/</guid>
      
        <description>&lt;h3 id=&#34;protpbuf简介&#34;&gt;protpbuf简介&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;protobuffer(以下简称PB)是google 的一种数据交换的格式，它独立于语言，独立于平台。&lt;br /&gt;
google 提供了多种语言的实现：Java、c#、c++、Go 和 Python，每一种实现都包含了相应语言的编译器以及库文件。由于它是一种二进制的格式，比使用 xml、json等 进行数据交换快许多。&lt;br /&gt;
可以把它用于分布式应用之间的数据通信或者异构环境下的&lt;code&gt;数据交换&lt;/code&gt;。&lt;br /&gt;
作为一种效率和兼容性都很优秀的二进制数据传输格式，可以用于诸如网络传输、配置文件、数据存储等诸多领域。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;准备golang的基础环境，GOPATH等等&lt;/li&gt;
&lt;li&gt;准备protobuf底层库环境(conda或者源码编译)&lt;/li&gt;
&lt;li&gt;准备protobuf相关包和插件&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;准备基础环境&#34;&gt;准备基础环境&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sh-4.2# go version
go version go1.8.3 linux/amd64
sh-4.2# go env
....
GOROOT=&amp;quot;/usr/lib/golang&amp;quot;
GOPATH=&amp;quot;/root/go&amp;quot;
....
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;准备protobuf底层库环境&#34;&gt;准备protobuf底层库环境&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# 因为工作原因会使用conda管理一些基础包，所以可以使用conda去安装基础模块

$ source /export/python2.7/setenv.sh
$ conda install libprotobuf -y
$ protoc --version
libprotoc 3.0.0

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;准备protobuf模块以及插件&#34;&gt;准备protobuf模块以及插件&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# protoc-gen-go是用来将protobuf的的代码转换成go语言代码的一个插件
$ go get -u github.com/golang/protobuf/protoc-gen-go
# proto是protobuf在golang中的接口模块
$ go get -u github.com/golang/protobuf/proto
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用protobuf构造golang的模块代码&#34;&gt;使用protobuf构造golang的模块代码&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://segmentfault.com/a/1190000007917576&#34;&gt;Protobuf语法&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 创建项目
$ mkdir -p &amp;quot;${GOPATH}/src/protobuf-study&amp;quot;

# 生成protobuf和相应的golang代码
$ mkdir -p &amp;quot;${GOPATH}/src/protobuf-study/protobuf&amp;quot; &amp;amp;&amp;amp; pushd &amp;quot;${GOPATH}/src/protobuf-study/goprotobuf&amp;quot;

# 定义protobuf消息格式
sh-4.2# cat test.proto
//这里的语法必须使用proto2,在proto3的版本中和optional参数冲突了
syntax = &amp;quot;proto2&amp;quot;;
//显式生命报名，在其他消息格式定义中可以使用package.message的方式来使用类型
//比如goprotobuf.HelloWorld
package goprotobuf;
//声明一个消息体描述一个请求或者响应的消息格式
message HelloWorld {
    required int32     id = 1;
    required string    name = 2;
    optional int32     opt = 3;
}

# 生成对应的golang模块代码(会将protobuf消息格式转换为对应golang结构体)
sh-4.2# protoc --go_out=./ test.proto
sh-4.2# ls
test.pb.go  test.proto

# 看一下生成的test.pd.go的核心代码
// 声明一个消息体描述一个请求或者响应的消息格式
type HelloWorld struct {
	Id               *int32  `protobuf:&amp;quot;varint,1,req,name=id&amp;quot; json:&amp;quot;id,omitempty&amp;quot;`
	Name             *string `protobuf:&amp;quot;bytes,2,req,name=name&amp;quot; json:&amp;quot;name,omitempty&amp;quot;`
	Opt              *int32  `protobuf:&amp;quot;varint,3,opt,name=opt&amp;quot; json:&amp;quot;opt,omitempty&amp;quot;`
	XXX_unrecognized []byte  `json:&amp;quot;-&amp;quot;`
}

func (m *HelloWorld) Reset()                    { *m = HelloWorld{} }
func (m *HelloWorld) String() string            { return proto.CompactTextString(m) }
func (*HelloWorld) ProtoMessage()               {}
func (*HelloWorld) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *HelloWorld) GetId() int32 {
	if m != nil &amp;amp;&amp;amp; m.Id != nil {
		return *m.Id
	}
	return 0
}

func (m *HelloWorld) GetName() string {
	if m != nil &amp;amp;&amp;amp; m.Name != nil {
		return *m.Name
	}
	return &amp;quot;&amp;quot;
}

func (m *HelloWorld) GetOpt() int32 {
	if m != nil &amp;amp;&amp;amp; m.Opt != nil {
		return *m.Opt
	}
	return 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;使用-goprotobuf-包中定义的protobuf数据格式进行通信&#34;&gt;使用&lt;code&gt;goprotobuf&lt;/code&gt;包中定义的protobuf数据格式进行通信&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ pushd $GOPATH/src/protobuf-study

# 一个简单使用protobuf进行读写文件的例子
$ cat write.go
package main
import (
    protobuf &amp;quot;github.com/golang/protobuf/proto&amp;quot;
    &amp;quot;protobuf-study/goprotobuf&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;os&amp;quot;
)

func main() {
    //初始化protobuf数据格式
    msg := &amp;amp;goprotobuf.HelloWorld{
        Id:     protobuf.Int32(17),
        Name:   protobuf.String(&amp;quot;BGbiao&amp;quot;),
        Opt:    protobuf.Int32(18),

    }

    filename := &amp;quot;./protobuf-test.txt&amp;quot;
    fmt.Printf(&amp;quot;使用protobuf创建文件 %s\n&amp;quot;,filename)
    fObj,_ := os.Create(filename)
    defer fObj.Close()
    buffer,_ := protobuf.Marshal(msg)
    fObj.Write(buffer)

}

# 测试执行写文件程序
sh-4.2# go run write.go
使用protobuf创建文件 ./protobuf-test.txt
sh-4.2# cat -A protobuf-test.txt
^H^Q^R^FBGbiao^X^R
sh-4.2#

# 一个简单的通过之前定义的protobuf格式进行读取文件内容的例子
sh-4.2# cat read.go
package main
import (
    protobuf &amp;quot;github.com/golang/protobuf/proto&amp;quot;
    &amp;quot;protobuf-study/goprotobuf&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;
    &amp;quot;os&amp;quot;
)

func checkError(err error) {
    if err != nil {
        fmt.Println(err.Error())
        os.Exit(-1)
    }
}

func main() {
    filename := &amp;quot;protobuf-test.txt&amp;quot;
    file,fileErr := os.Open(filename)
    checkError(fileErr)

    defer file.Close()
    fs,fsErr := file.Stat()
    checkError(fsErr)
    buffer := make([]byte,fs.Size())
    //把file文件内容读取到buffer
    _,readErr := io.ReadFull(file,buffer)
    checkError(readErr)

    //初始化pb结构体对象并将buffer中的文件内容读取到pb结构体中
    msg := &amp;amp;goprotobuf.HelloWorld{}
    pbErr := protobuf.Unmarshal(buffer, msg)
    checkError(pbErr)
    fmt.Printf(&amp;quot;读取文件:%s \r\nname:%s\nid:%d\nopt:%d\n&amp;quot;,filename,msg.GetName(),msg.GetId(),msg.GetOpt())
}
sh-4.2# go run read.go
读取文件:protobuf-test.txt
name:BGbiao
id:17
opt:18
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;相关链接&#34;&gt;相关链接&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://segmentfault.com/a/1190000007917576&#34;&gt;Protobuf语法&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>NVIDIA-DIGITS测试使用</title>
      <link>https://bgbiao.top/post/nvidia-digits%E6%B5%8B%E8%AF%95%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 02 Jan 2018 10:14:32 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/nvidia-digits%E6%B5%8B%E8%AF%95%E4%BD%BF%E7%94%A8/</guid>
      
        <description>&lt;h3 id=&#34;digits简介&#34;&gt;DIGITS简介&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/DIGITS&#34;&gt;DIGITS&lt;/a&gt;: Deep Learning GPU Training System1，是由英伟达（NVIDIA）公司开发的第一个交互式深度学习GPU训练系统。目的在于整合现有的Deep Learning开发工具，实现深度神经网络（Deep Neural Network，DNN）设计、训练和可视化等任务变得简单化。DIGITS是基于浏览器的接口，因而通过实时的网络行为的可视化，可以快速设计最优的DNN。DIGITS是开源软件，可在GitHub上找到，因而开发人员可以扩展和自定义DIGITS。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/digits-deep-learning-gpu-training-system/&#34;&gt;英文介绍&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;digits特性&#34;&gt;DIGITS特性&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;提供了友好的用户界面，只需简单的点击即完成DNNs的训练。DIGITS是一个Web应用，用浏览器访问，上图是典型的工作流程图。&lt;/li&gt;
&lt;li&gt;DIGITS用户接口提供了DNN优化工具。主控制台列出了现有的数据库和机器上可用的先前训练好的网络模型以及正在进行的训练活动。&lt;/li&gt;
&lt;li&gt;DIGITS使可视化网络和快速对比精度变得简单。你选择一个模型，DIGITS显示训练状态和精度，并提供在网络训练时或训练完毕后加载和分类图像的选项。&lt;/li&gt;
&lt;li&gt;由于DIGITS运行在一个web服务器上，团队用户可以很方便地分享数据库和网络配置，以及测试和分享结果。&lt;/li&gt;
&lt;li&gt;DIGITS集成了流行的Caffe deep learning framework，并支持使用cudnn进行GPU加速。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;尝试使用DIGITS进行模型训练后，不得不说，这个平台功能做的真心不错。&lt;/p&gt;

&lt;h3 id=&#34;部署测试&#34;&gt;部署测试&lt;/h3&gt;

&lt;p&gt;官方给了基于&lt;code&gt;Ubuntu&lt;/code&gt;发行版的部署指南(估计是因为ubuntu上比较好处理python的各种依赖吧)，不过官方也构建的相关的Docker image来帮助用户进行部署。用户可以&lt;code&gt;docker pull nvidia/digits&lt;/code&gt;直接下载最新版本。&lt;/p&gt;

&lt;p&gt;容器镜像中使用5000端口来暴露web服务，因此需要将5000端口映射出来。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# docker run -itd --name digits -p 5000:5000 nvidia/digits:6.0
# docker logs digits 
  ___ ___ ___ ___ _____ ___
 |   \_ _/ __|_ _|_   _/ __|
 | |) | | (_ || |  | | \__ \
 |___/___\___|___| |_| |___/ 6.0.0

libdc1394 error: Failed to initialize libdc1394
/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn(&#39;Matplotlib is building the font cache using fc-list. This may take a moment.&#39;)
2017-12-27 13:24:54 [INFO ] Loaded 0 jobs.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看日志如上环境即部署成功。&lt;/p&gt;

&lt;h3 id=&#34;环境测试&#34;&gt;环境测试&lt;/h3&gt;

&lt;p&gt;官方也给了一份测试数据以及文档来运行模型训练。
&lt;a href=&#34;https://github.com/NVIDIA/DIGITS/blob/master/docs/GettingStarted.md&#34;&gt;doc&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;下载模型数据&#34;&gt;下载模型数据&lt;/h4&gt;

&lt;p&gt;可以登录到&lt;code&gt;digits&lt;/code&gt;容器内部执行以下命令进行模型数据初始化。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python -m digits.download_data mnist ~/mnist
Downloading url=http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz ...
Downloading url=http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz ...
Downloading url=http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz ...
Downloading url=http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz ...
Uncompressing file=train-images-idx3-ubyte.gz ...
Uncompressing file=train-labels-idx1-ubyte.gz ...
Uncompressing file=t10k-images-idx3-ubyte.gz ...
Uncompressing file=t10k-labels-idx1-ubyte.gz ...
Reading labels from /home/username/mnist/train-labels.bin ...
Reading images from /home/username/mnist/train-images.bin ...
Reading labels from /home/username/mnist/test-labels.bin ...
Reading images from /home/username/mnist/test-images.bin ...
Dataset directory is created successfully at &#39;/home/username/mnist&#39;
Done after 16.722807169 seconds.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然如果容器内部无法访问外网，也可以将相关模型数据下载后进行解压。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
# ls dataset/
  t10k-images-idx3-ubyte.gz  t10k-labels-idx1-ubyte.gz  train-images-idx3-ubyte.gz  train-labels-idx1-ubyte.gz 
# docker cp dataset digits:/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是，该模型文件好像不能直接解压。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# docker exec -it digits bash
root@aa3e7a2437af:/# cd dataset/
root@aa3e7a2437af:/dataset# ls
t10k-images-idx3-ubyte.gz  t10k-labels-idx1-ubyte.gz  train-images-idx3-ubyte.gz  train-labels-idx1-ubyte.gz
root@aa3e7a2437af:/dataset# python -m digits.download_data mnist .
Uncompressing file=train-images-idx3-ubyte.gz ...
Uncompressing file=train-labels-idx1-ubyte.gz ...
Uncompressing file=t10k-images-idx3-ubyte.gz ...
Uncompressing file=t10k-labels-idx1-ubyte.gz ...
Reading labels from ./train-labels.bin ...
Reading images from ./train-images.bin ...
Reading labels from ./test-labels.bin ...
Reading images from ./test-images.bin ...
Dataset directory is created successfully at &#39;.&#39;
Done after 18.2706720829 seconds.
root@aa3e7a2437af:/dataset#
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;使用webapp&#34;&gt;使用WebApp&lt;/h4&gt;

&lt;p&gt;使用浏览器访问容器宿主机的5000端口，即可看到首页数据&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/index.png&#34; alt=&#34;index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;登录&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;点击右上角的&lt;code&gt;login&lt;/code&gt;按钮进行登录。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;这里其实没有认证信息，用户随便输入就可以登录&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/login.png&#34; alt=&#34;login&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建DataSet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;登录后点击&amp;rdquo;New Image Classification Dataset&amp;rdquo;
并进行相关设置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/dataset.png&#34; alt=&#34;dataset&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当job运行时，就可以在右侧看到运行的时间，以及结果。
&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/dataset1.png&#34; alt=&#34;dataset1&#34; /&gt;
&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/dataset2.png&#34; alt=&#34;dataset2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当运行完成之后，点击左上角的&lt;code&gt;DIGITS&lt;/code&gt;,可以看到创建的&lt;code&gt;dataset&lt;/code&gt;
&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/dataset-final.png&#34; alt=&#34;dataset-final&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;训练模型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;点击 &lt;code&gt;Models &amp;gt; New Model &amp;gt; Images &amp;gt; Classification&lt;/code&gt;.将引导你到&lt;code&gt;New Image Classification Model&lt;/code&gt; 页面。&lt;/p&gt;

&lt;p&gt;按照以下步骤进行操作&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;Select Dataset field&lt;/code&gt;选择 &amp;ldquo;testbiaoge&amp;rdquo; 数据集&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;Standard Networks&lt;/code&gt;窗口选择&lt;code&gt;LeNet&lt;/code&gt;网络&lt;/li&gt;
&lt;li&gt;填写GPU卡数量以及模型名称&lt;/li&gt;
&lt;li&gt;点击&lt;code&gt;Create&lt;/code&gt;按钮进行创建&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/model.png&#34; alt=&#34;model-1&#34; /&gt;
&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/model2.png&#34; alt=&#34;model-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在训练过程中用户可以看到悬链环境以及训练时间等相关信息。&lt;/p&gt;

&lt;p&gt;训练完成的状态：
&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/model-train.png&#34; alt=&#34;model-train&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了测试这个模型，可以拉到页面最底部&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;点击&lt;code&gt;Upload image&lt;/code&gt; 按钮选择一个文件，测试过程中选择&lt;code&gt;/dataset/test/2/00035.png&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;或者在网络上找一张图片，黏贴URL到&lt;code&gt;Image URL&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选中&lt;code&gt;Show visualizations and statistics&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;点击&lt;code&gt;Classify One&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在页面顶部，展示了五个分类以及相关的值。&lt;code&gt;DIGITS&lt;/code&gt;也提供了一些可视化以及网络中每个层的权重和激活统计信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/test-model-1.png&#34; alt=&#34;test-model&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://oyep1jupk.bkt.clouddn.com/test-model.png&#34; alt=&#34;test-model2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;查看最终任务运行的过程信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-12-29 06:50:54 [20171229-065052-5cc9] [INFO ] Infer Model task started.
2017-12-29 06:50:54 [20171229-065052-5cc9] [INFO ] Task subprocess args: &amp;quot;/usr/bin/python /usr/local/lib/python2.7/dist-packages/digits/tools/inference.py /jobs/20171229-065052-5cc9/tmpctzfnI.txt /jobs/20171229-065052-5cc9 20171229-064432-4c8a --jobs_dir=/jobs --epoch=30.0 --layers=all --gpu=0&amp;quot;
2017-12-29 06:50:54 [20171229-065052-5cc9] [WARNING] Infer Model unrecognized output: libdc1394 error: Failed to initialize libdc1394



2017-12-29 06:52:43 [20171229-065052-5cc9] [INFO ] Infer Model task completed.
2017-12-29 06:52:43 [20171229-065052-5cc9] [INFO ] Job complete.
2017-12-29 06:52:43 [20171229-065052-5cc9] [INFO ] Job deleted.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，使用NVIDIA-DIGITS已经完成了一个模型训练。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang中GBK和UTF-8格式互相转换</title>
      <link>https://bgbiao.top/post/golang%E4%B8%ADgbk%E5%92%8Cutf-8%E6%A0%BC%E5%BC%8F%E7%94%BB%E5%83%8F%E8%BD%AC%E6%8D%A2/</link>
      <pubDate>Sun, 24 Dec 2017 17:36:14 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang%E4%B8%ADgbk%E5%92%8Cutf-8%E6%A0%BC%E5%BC%8F%E7%94%BB%E5%83%8F%E8%BD%AC%E6%8D%A2/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 刚开始学习&lt;code&gt;Golang&lt;/code&gt;的时候，做一些简单数据处理发现总是会出现乱码，通常是因为字符集的问题，这里记录下如何在&lt;code&gt;GBK&lt;/code&gt;和&lt;code&gt;UTF-8&lt;/code&gt;之间进行格式转换&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;直接上代码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**
 * @File Name: gb2312-utf8.go
 * @Author:
 * @Email:
 * @Create Date: 2017-12-18 14:12:25
 * @Last Modified: 2017-12-18 14:12:00
 * @Description:
 */
package main
import (
    &amp;quot;bytes&amp;quot;
    &amp;quot;golang.org/x/text/encoding/simplifiedchinese&amp;quot;
    &amp;quot;golang.org/x/text/transform&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;fmt&amp;quot;
)

func GbkToUtf8(s []byte) ([]byte, error) {
    reader := transform.NewReader(bytes.NewReader(s), simplifiedchinese.GBK.NewDecoder())
    d, e := ioutil.ReadAll(reader)
    if e != nil {
        return nil, e
    }
    return d, nil
}

func Utf8ToGbk(s []byte) ([]byte, error) {
    reader := transform.NewReader(bytes.NewReader(s), simplifiedchinese.GBK.NewEncoder())
    d, e := ioutil.ReadAll(reader)
    if e != nil {
        return nil, e
    }
    return d, nil
}

func main() {

    s := &amp;quot;GBK 与 UTF-8 编码转换测试&amp;quot;
    gbk, err := Utf8ToGbk([]byte(s))
    if err != nil {
        fmt.Println(err)
    } else {
        fmt.Println(string(gbk))
    }

    utf8, err := GbkToUtf8(gbk)
    if err != nil {
        fmt.Println(err)
    } else {
        fmt.Println(string(utf8))
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ go run gbktoutf-8.go
GBK �� UTF-8 ����ת������
GBK 与 UTF-8 编码转换测试
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>Golang正则模块使用</title>
      <link>https://bgbiao.top/post/golang%E6%AD%A3%E5%88%99%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sun, 24 Dec 2017 16:39:14 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang%E6%AD%A3%E5%88%99%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8/</guid>
      
        <description>&lt;p&gt;最近在开发过程中会遇到一些字符串匹配相关的内容，正好去大概学习了下Golang中的&lt;code&gt;regexp&lt;/code&gt;模块。因为目前正则模块对我来说更多的就是去匹配并处理字符串的，因此目前主要关注几个返回为&lt;code&gt;string&lt;/code&gt;类型的方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;regexp&lt;/code&gt;模块的结构体和方法定义&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//正则结构体
type Regexp struct {
        // contains filtered or unexported fields
}

//初始化结构体对象的方法
func Compile(expr string) (*Regexp, error)
func CompilePOSIX(expr string) (*Regexp, error)
func MustCompile(str string) *Regexp
func MustCompilePOSIX(str string) *Regexp


//结构体方法.常用的几个
//在字符串s中查找完全匹配正则表达式re的字符串.如果匹配到就停止不进行全部匹配，如果匹配不到就输出空字符串
func (re *Regexp) FindString(s string) string

//在字符串s中匹配re表达式，n表示匹配的次数，-1表示匹配整个字符串。返回字符串切片
func (re *Regexp) FindAllString(s string, n int) []string

//在src中匹配re，并替换为repl，该种方式中repl中的$符号会展开实际的变量，通常用在回溯查找中
func (re *Regexp) ReplaceAllString(src, repl string) string

//在src中匹配re，并替换为repl,该方法会按照repl中的字面意思进行替换，不支持高级变量匹配，比如回溯等等
func (re *Regexp) ReplaceAllLiteralString(src, repl string) string
 
 
//在字符串中是否匹配到re定义的字符串，匹配返回true
func (re *Regexp) MatchString(s string) bool

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;简单示例&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat regexp-test.go
/**
 * @File Name: test.go
 * @Author:
 * @Email:
 * @Create Date: 2017-12-24 15:12:31
 * @Last Modified: 2017-12-24 16:12:12
 * @Description:
 */
package main

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;regexp&amp;quot;
)

func main() {
  testString := &amp;quot;k8s-test-pod-12343k811sadsxsakxz-test-k8s-container.k8s-@xxbandy.github.io&amp;quot;
	re := regexp.MustCompile(&amp;quot;k8s?&amp;quot;)
  fmt.Println(&amp;quot;src string:&amp;quot;,testString)
  fmt.Println(&amp;quot;regular expression:&amp;quot;,re)

  fmt.Println(&amp;quot;FindAllString matching all:&amp;quot;,re.FindAllString(testString,-1))
  fmt.Println(&amp;quot;FindAllString matching twice:&amp;quot;,re.FindAllString(testString,2))
  fmt.Println(&amp;quot;FindString:&amp;quot;,re.FindString(testString))
  fmt.Println(&amp;quot;ReplaceAllString:&amp;quot;,re.ReplaceAllString(testString,&amp;quot;biaoge&amp;quot;))
  fmt.Println(&amp;quot;ReplaceAllLiteralString:&amp;quot;,re.ReplaceAllLiteralString(testString,&amp;quot;BIAOGE&amp;quot;))
  fmt.Println(&amp;quot;Match String:&amp;quot;,re.MatchString(testString))
}

$ go run regexp-test.go
src string: k8s-test-pod-12343k811sadsxsakxz-test-k8s-container.k8s-@xxbandy.github.io
regular expression: k8s?
FindAllString matching all: [k8s k8 k8s k8s]
FindAllString matching twice: [k8s k8]
FindString: k8s
ReplaceAllString: biaoge-test-pod-12343biaoge11sadsxsakxz-test-biaoge-container.biaoge-@xxbandy.github.io
ReplaceAllLiteralString: BIAOGE-test-pod-12343BIAOGE11sadsxsakxz-test-BIAOGE-container.BIAOGE-@xxbandy.github.io
Match String: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不论是哪种语言的正则模块，个人认为语法都不是最重要的，最重要我认为还是正则表达式本身，如果对正则表达式本身认识比较深的话，不论用哪种语言工具都可以很灵活的处理各种业务场景。这里附上一篇当年写的正则表达式相关的&lt;a href=&#34;https://my.oschina.net/xxbAndy/blog/370806&#34;&gt;文章&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;看到另外一篇文章的正则总结的挺好，分享下来.
&lt;a href=&#34;http://blog.csdn.net/zfy1355/article/details/52959803&#34;&gt;http://blog.csdn.net/zfy1355/article/details/52959803&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang读写文件操作</title>
      <link>https://bgbiao.top/post/golang%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Sun, 17 Dec 2017 23:25:25 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</guid>
      
        <description>&lt;p&gt;最近在使用Golang进行文件读写的过程中，遇到几个细节问题导致程序写入数据时有一定脏数据的残留，最后发现是使用os.OpenFile在进行文件操作的时候没有使用正确的flag造成的。因此专门去学习了下Golang中读写文件的几种方式方法,在此记录下一些简单的操作，防止以后遗忘。&lt;/p&gt;

&lt;h3 id=&#34;读文件&#34;&gt;读文件&lt;/h3&gt;

&lt;p&gt;使用golang语言去读取一个文件默认会有多种方式，这里主要介绍以下几种。&lt;/p&gt;

&lt;h4 id=&#34;使用-ioutil-直接读取&#34;&gt;使用&lt;code&gt;ioutil&lt;/code&gt;直接读取&lt;/h4&gt;

&lt;p&gt;需要引入&lt;code&gt;io/ioutil&lt;/code&gt;包，该包默认拥有以下函数供用户调用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func NopCloser(r io.Reader) io.ReadCloser
func ReadAll(r io.Reader) ([]byte, error)
func ReadDir(dirname string) ([]os.FileInfo, error)
func ReadFile(filename string) ([]byte, error)
func TempDir(dir, prefix string) (name string, err error)
func TempFile(dir, prefix string) (f *os.File, err error)
func WriteFile(filename string, data []byte, perm os.FileMode) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读文件，我们可以看以下三个函数:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//从一个io.Reader类型中读取内容直到返回错误或者EOF时返回读取的数据，当err == nil时，数据成功读取到[]byte中
//ReadAll函数被定义为从源中读取数据直到EOF，它是不会去从返回数据中去判断EOF来作为读取成功的依据
func ReadAll(r io.Reader) ([]byte, error)

//读取一个目录，并返回一个当前目录下的文件对象列表和错误信息
func ReadDir(dirname string) ([]os.FileInfo, error)

//读取文件内容，并返回[]byte数据和错误信息。err == nil时，读取成功
func ReadFile(filename string) ([]byte, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;读取文件示例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat readfile.go
package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;strings&amp;quot;
)
func main() {
   Ioutil(&amp;quot;mytestfile.txt&amp;quot;)
    }

func Ioutil(name string) {
    if contents,err := ioutil.ReadFile(name);err == nil {
        //因为contents是[]byte类型，直接转换成string类型后会多一行空格,需要使用strings.Replace替换换行符
        result := strings.Replace(string(contents),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
        fmt.Println(result)
        }
    }
    
$ go run readfile.go
xxbandy.github.io @by Andy_xu
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;借助-os-open-进行读取文件&#34;&gt;借助&lt;code&gt;os.Open&lt;/code&gt;进行读取文件&lt;/h4&gt;

&lt;p&gt;由于&lt;code&gt;os.Open&lt;/code&gt;是打开一个文件并返回一个文件对象，因此其实可以结合&lt;code&gt;ioutil.ReadAll(r io.Reader)&lt;/code&gt;来进行读取。
&lt;code&gt;io.Reader&lt;/code&gt;其实是一个包含&lt;code&gt;Read&lt;/code&gt;方法的接口类型，而文件对象本身是实现了了&lt;code&gt;Read&lt;/code&gt;方法的。&lt;/p&gt;

&lt;p&gt;我们先来看下&lt;code&gt;os.Open&lt;/code&gt;家族的相关函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//打开一个需要被读取的文件，如果成功读取，返回的文件对象将可用被读取，该函数默认的权限为O_RDONLY，也就是只对文件有只读权限。如果有错误，将返回*PathError类型
func Open(name string) (*File, error)

//大部分用户会选择该函数来代替Open or Create函数。该函数主要用来指定参数(os.O_APPEND|os.O_CREATE|os.O_WRONLY)以及文件权限(0666)来打开文件，如果打开成功返回的文件对象将被用作I/O操作
func OpenFile(name string, flag int, perm FileMode) (*File, error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;os.Open&lt;/code&gt;家族函数和&lt;code&gt;ioutil.ReadAll()&lt;/code&gt;读取文件示例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func OsIoutil(name string) {
      if fileObj,err := os.Open(name);err == nil {
      //if fileObj,err := os.OpenFile(name,os.O_RDONLY,0644); err == nil {
        defer fileObj.Close()
        if contents,err := ioutil.ReadAll(fileObj); err == nil {
            result := strings.Replace(string(contents),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
            fmt.Println(&amp;quot;Use os.Open family functions and ioutil.ReadAll to read a file contents:&amp;quot;,result)
            }

        }
}

# 在main函数中调用OsIoutil(name)函数就可以读取文件内容了
$ go run readfile.go
Use os.Open family functions and ioutil.ReadAll to read a file contents: xxbandy.github.io @by Andy_xu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然而上述方式会比较繁琐一些，因为使用了&lt;code&gt;os&lt;/code&gt;的同时借助了&lt;code&gt;ioutil&lt;/code&gt;,但是在读取大文件的时候还是比较有优势的。不过读取小文件可以直接使用文件对象的一些方法。&lt;/p&gt;

&lt;p&gt;不论是上边说的&lt;code&gt;os.Open&lt;/code&gt;还是&lt;code&gt;os.OpenFile&lt;/code&gt;他们最终都返回了一个&lt;code&gt;*File&lt;/code&gt;文件对象，而该文件对象默认是有很多方法的，其中读取文件的方法有如下几种:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//从文件对象中读取长度为b的字节，返回当前读到的字节数以及错误信息。因此使用该方法需要先初始化一个符合内容大小的空的字节列表。读取到文件的末尾时，该方法返回0，io.EOF
func (f *File) Read(b []byte) (n int, err error)

//从文件的off偏移量开始读取长度为b的字节。返回读取到字节数以及错误信息。当读取到的字节数n小于想要读取字节的长度len(b)的时候，该方法将返回非空的error。当读到文件末尾时，err返回io.EOF
func (f *File) ReadAt(b []byte, off int64) (n int, err error)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用文件对象的&lt;code&gt;Read&lt;/code&gt;方法读取：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func FileRead(name string) {
    if fileObj,err := os.Open(name);err == nil {
        defer fileObj.Close()
        //在定义空的byte列表时尽量大一些，否则这种方式读取内容可能造成文件读取不完整
        buf := make([]byte, 1024)
        if n,err := fileObj.Read(buf);err == nil {
               fmt.Println(&amp;quot;The number of bytes read:&amp;quot;+strconv.Itoa(n),&amp;quot;Buf length:&amp;quot;+strconv.Itoa(len(buf)))
               result := strings.Replace(string(buf),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
               fmt.Println(&amp;quot;Use os.Open and File&#39;s Read method to read a file:&amp;quot;,result)
            }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;使用-os-open-和-bufio-reader-读取文件内容&#34;&gt;使用&lt;code&gt;os.Open&lt;/code&gt;和&lt;code&gt;bufio.Reader&lt;/code&gt;读取文件内容&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;bufio&lt;/code&gt;包实现了缓存IO,它本身包装了&lt;code&gt;io.Reader&lt;/code&gt;和&lt;code&gt;io.Writer&lt;/code&gt;对象，创建了另外的Reader和Writer对象，不过该种方式是带有缓存的，因此对于文本I/O来说，该包是提供了一些便利的。&lt;/p&gt;

&lt;p&gt;先看下&lt;code&gt;bufio&lt;/code&gt;模块下的相关的&lt;code&gt;Reader&lt;/code&gt;函数方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//首先定义了一个用来缓冲io.Reader对象的结构体，同时该结构体拥有以下相关的方法
type Reader struct {
}

//NewReader函数用来返回一个默认大小buffer的Reader对象(默认大小好像是4096) 等同于NewReaderSize(rd,4096)
func NewReader(rd io.Reader) *Reader

//该函数返回一个指定大小buffer(size最小为16)的Reader对象，如果 io.Reader参数已经是一个足够大的Reader，它将返回该Reader
func NewReaderSize(rd io.Reader, size int) *Reader


//该方法返回从当前buffer中能被读到的字节数
func (b *Reader) Buffered() int

//Discard方法跳过后续的 n 个字节的数据，返回跳过的字节数。如果0 &amp;lt;= n &amp;lt;= b.Buffered(),该方法将不会从io.Reader中成功读取数据。
func (b *Reader) Discard(n int) (discarded int, err error)

//Peekf方法返回缓存的一个切片，该切片只包含缓存中的前n个字节的数据
func (b *Reader) Peek(n int) ([]byte, error)

//把Reader缓存对象中的数据读入到[]byte类型的p中，并返回读取的字节数。读取成功，err将返回空值
func (b *Reader) Read(p []byte) (n int, err error)

//返回单个字节，如果没有数据返回err
func (b *Reader) ReadByte() (byte, error)

//该方法在b中读取delimz之前的所有数据，返回的切片是已读出的数据的引用，切片中的数据在下一次的读取操作之前是有效的。如果未找到delim，将返回查找结果并返回nil空值。因为缓存的数据可能被下一次的读写操作修改，因此一般使用ReadBytes或者ReadString，他们返回的都是数据拷贝
func (b *Reader) ReadSlice(delim byte) (line []byte, err error)

//功能同ReadSlice，返回数据的拷贝
func (b *Reader) ReadBytes(delim byte) ([]byte, error)

//功能同ReadBytes,返回字符串
func (b *Reader) ReadString(delim byte) (string, error)

//该方法是一个低水平的读取方式，一般建议使用ReadBytes(&#39;\n&#39;) 或 ReadString(&#39;\n&#39;)，或者使用一个 Scanner来代替。ReadLine 通过调用 ReadSlice 方法实现，返回的也是缓存的切片，用于读取一行数据，不包括行尾标记（\n 或 \r\n）
func (b *Reader) ReadLine() (line []byte, isPrefix bool, err error)

//读取单个UTF-8字符并返回一个rune和字节大小
func (b *Reader) ReadRune() (r rune, size int, err error)


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func BufioRead(name string) {
    if fileObj,err := os.Open(name);err == nil {
        defer fileObj.Close()
        //一个文件对象本身是实现了io.Reader的 使用bufio.NewReader去初始化一个Reader对象，存在buffer中的，读取一次就会被清空
        reader := bufio.NewReader(fileObj)
        //使用ReadString(delim byte)来读取delim以及之前的数据并返回相关的字符串.
        if result,err := reader.ReadString(byte(&#39;@&#39;));err == nil {
            fmt.Println(&amp;quot;使用ReadSlince相关方法读取内容:&amp;quot;,result)
        }
        //注意:上述ReadString已经将buffer中的数据读取出来了，下面将不会输出内容
        //需要注意的是，因为是将文件内容读取到[]byte中，因此需要对大小进行一定的把控
        buf := make([]byte,1024)
        //读取Reader对象中的内容到[]byte类型的buf中
        if n,err := reader.Read(buf); err == nil {
            fmt.Println(&amp;quot;The number of bytes read:&amp;quot;+strconv.Itoa(n))
            //这里的buf是一个[]byte，因此如果需要只输出内容，仍然需要将文件内容的换行符替换掉
            fmt.Println(&amp;quot;Use bufio.NewReader and os.Open read file contents to a []byte:&amp;quot;,string(buf))
        }


    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;读文件所有方式示例&#34;&gt;读文件所有方式示例&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;/**
 * @File Name: readfile.go
 * @Author:
 * @Email:
 * @Create Date: 2017-12-16 16:12:01
 * @Last Modified: 2017-12-17 12:12:02
 * @Description:读取指定文件的几种方法，需要注意的是[]byte类型在转换成string类型的时候，都会在最后多一行空格，需要使用result := strings.Replace(string(contents),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1) 方式替换换行符
 */
package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;strings&amp;quot;
    &amp;quot;os&amp;quot;
    &amp;quot;strconv&amp;quot;
    &amp;quot;bufio&amp;quot;
)

func main() {
   Ioutil(&amp;quot;mytestfile.txt&amp;quot;)
   OsIoutil(&amp;quot;mytestfile.txt&amp;quot;)
   FileRead(&amp;quot;mytestfile.txt&amp;quot;)
   BufioRead(&amp;quot;mytestfile.txt&amp;quot;)
    }


func Ioutil(name string) {
    if contents,err := ioutil.ReadFile(name);err == nil {
        //因为contents是[]byte类型，直接转换成string类型后会多一行空格,需要使用strings.Replace替换换行符
        result := strings.Replace(string(contents),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
        fmt.Println(&amp;quot;Use ioutil.ReadFile to read a file:&amp;quot;,result)
        }
    }

func OsIoutil(name string) {
      if fileObj,err := os.Open(name);err == nil {
      //if fileObj,err := os.OpenFile(name,os.O_RDONLY,0644); err == nil {
        defer fileObj.Close()
        if contents,err := ioutil.ReadAll(fileObj); err == nil {
            result := strings.Replace(string(contents),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
            fmt.Println(&amp;quot;Use os.Open family functions and ioutil.ReadAll to read a file :&amp;quot;,result)
            }

        }
}


func FileRead(name string) {
    if fileObj,err := os.Open(name);err == nil {
        defer fileObj.Close()
        //在定义空的byte列表时尽量大一些，否则这种方式读取内容可能造成文件读取不完整
        buf := make([]byte, 1024)
        if n,err := fileObj.Read(buf);err == nil {
               fmt.Println(&amp;quot;The number of bytes read:&amp;quot;+strconv.Itoa(n),&amp;quot;Buf length:&amp;quot;+strconv.Itoa(len(buf)))
               result := strings.Replace(string(buf),&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;,1)
               fmt.Println(&amp;quot;Use os.Open and File&#39;s Read method to read a file:&amp;quot;,result)
            }
    }
}

func BufioRead(name string) {
    if fileObj,err := os.Open(name);err == nil {
        defer fileObj.Close()
        //一个文件对象本身是实现了io.Reader的 使用bufio.NewReader去初始化一个Reader对象，存在buffer中的，读取一次就会被清空
        reader := bufio.NewReader(fileObj)
        //使用ReadString(delim byte)来读取delim以及之前的数据并返回相关的字符串.
        if result,err := reader.ReadString(byte(&#39;@&#39;));err == nil {
            fmt.Println(&amp;quot;使用ReadSlince相关方法读取内容:&amp;quot;,result)
        }
        //注意:上述ReadString已经将buffer中的数据读取出来了，下面将不会输出内容
        //需要注意的是，因为是将文件内容读取到[]byte中，因此需要对大小进行一定的把控
        buf := make([]byte,1024)
        //读取Reader对象中的内容到[]byte类型的buf中
        if n,err := reader.Read(buf); err == nil {
            fmt.Println(&amp;quot;The number of bytes read:&amp;quot;+strconv.Itoa(n))
            //这里的buf是一个[]byte，因此如果需要只输出内容，仍然需要将文件内容的换行符替换掉
            fmt.Println(&amp;quot;Use bufio.NewReader and os.Open read file contents to a []byte:&amp;quot;,string(buf))
        }


    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;写文件&#34;&gt;写文件&lt;/h3&gt;

&lt;p&gt;那么上述几种方式来读取文件的方式也支持文件的写入，相关的方法如下:&lt;/p&gt;

&lt;h4 id=&#34;使用-ioutil-包进行文件写入&#34;&gt;使用&lt;code&gt;ioutil&lt;/code&gt;包进行文件写入&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;// 写入[]byte类型的data到filename文件中，文件权限为perm
func WriteFile(filename string, data []byte, perm os.FileMode) error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat writefile.go
/**
 * @File Name: writefile.go
 * @Author:
 * @Email:
 * @Create Date: 2017-12-17 12:12:09
 * @Last Modified: 2017-12-17 12:12:30
 * @Description:使用多种方式将数据写入文件
 */
package main
import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
)

func main() {
      name := &amp;quot;testwritefile.txt&amp;quot;
      content := &amp;quot;Hello, xxbandy.github.io!\n&amp;quot;
      WriteWithIoutil(name,content)
}

//使用ioutil.WriteFile方式写入文件,是将[]byte内容写入文件,如果content字符串中没有换行符的话，默认就不会有换行符
func WriteWithIoutil(name,content string) {
    data :=  []byte(content)
    if ioutil.WriteFile(name,data,0644) == nil {
        fmt.Println(&amp;quot;写入文件成功:&amp;quot;,content)
        }
    }
 
# 会有换行符    
$ go run writefile.go
写入文件成功: Hello, xxbandy.github.io!

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;使用-os-open-相关函数进行文件写入&#34;&gt;使用&lt;code&gt;os.Open&lt;/code&gt;相关函数进行文件写入&lt;/h4&gt;

&lt;p&gt;因为&lt;code&gt;os.Open&lt;/code&gt;系列的函数会打开文件，并返回一个文件对象指针，而该文件对象是一个定义的结构体，拥有一些相关写入的方法。&lt;/p&gt;

&lt;p&gt;文件对象结构体以及相关写入文件的方法:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//写入长度为b字节切片到文件f中，返回写入字节号和错误信息。当n不等于len(b)时，将返回非空的err
func (f *File) Write(b []byte) (n int, err error)
//在off偏移量出向文件f写入长度为b的字节
func (f *File) WriteAt(b []byte, off int64) (n int, err error)
//类似于Write方法，但是写入内容是字符串而不是字节切片
func (f *File) WriteString(s string) (n int, err error)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意：&lt;/code&gt;使用WriteString()j进行文件写入发现经常新内容写入时无法正常覆盖全部新内容。(是因为字符串长度不一样)&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//使用os.OpenFile()相关函数打开文件对象，并使用文件对象的相关方法进行文件写入操作
func WriteWithFileWrite(name,content string){
    fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_TRUNC,0644)
    if err != nil {
        fmt.Println(&amp;quot;Failed to open the file&amp;quot;,err.Error())
        os.Exit(2)
    }
    defer fileObj.Close()
    if _,err := fileObj.WriteString(content);err == nil {
        fmt.Println(&amp;quot;Successful writing to the file with os.OpenFile and *File.WriteString method.&amp;quot;,content)
    }
    contents := []byte(content)
    if _,err := fileObj.Write(contents);err == nil {
        fmt.Println(&amp;quot;Successful writing to thr file with os.OpenFile and *File.Write method.&amp;quot;,content)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;使用&lt;code&gt;os.OpenFile(name string, flag int, perm FileMode)&lt;/code&gt;打开文件并进行文件内容更改，需要注意&lt;code&gt;flag&lt;/code&gt;相关的参数以及含义。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const (
        O_RDONLY int = syscall.O_RDONLY // 只读打开文件和os.Open()同义
        O_WRONLY int = syscall.O_WRONLY // 只写打开文件
        O_RDWR   int = syscall.O_RDWR   // 读写方式打开文件
        O_APPEND int = syscall.O_APPEND // 当写的时候使用追加模式到文件末尾
        O_CREATE int = syscall.O_CREAT  // 如果文件不存在，此案创建
        O_EXCL   int = syscall.O_EXCL   // 和O_CREATE一起使用, 只有当文件不存在时才创建
        O_SYNC   int = syscall.O_SYNC   // 以同步I/O方式打开文件，直接写入硬盘.
        O_TRUNC  int = syscall.O_TRUNC  // 如果可以的话，当打开文件时先清空文件
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;使用-io-包中的相关函数写入文件&#34;&gt;使用&lt;code&gt;io&lt;/code&gt;包中的相关函数写入文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;io&lt;/code&gt;包中有一个&lt;code&gt;WriteString()&lt;/code&gt;函数，用来将字符串写入一个&lt;code&gt;Writer&lt;/code&gt;对象中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//将字符串s写入w(可以是一个[]byte)，如果w实现了一个WriteString方法，它可以被直接调用。否则w.Write会再一次被调用
func WriteString(w Writer, s string) (n int, err error)

//Writer对象的定义
type Writer interface {
        Write(p []byte) (n int, err error)
}


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//使用io.WriteString()函数进行数据的写入
func WriteWithIo(name,content string) {
    fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_APPEND,0644)
    if err != nil {
        fmt.Println(&amp;quot;Failed to open the file&amp;quot;,err.Error())
        os.Exit(2)
    }
    if  _,err := io.WriteString(fileObj,content);err == nil {
        fmt.Println(&amp;quot;Successful appending to the file with os.OpenFile and io.WriteString.&amp;quot;,content)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;使用-bufio-包中的相关函数写入文件&#34;&gt;使用&lt;code&gt;bufio&lt;/code&gt;包中的相关函数写入文件&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;bufio&lt;/code&gt;和&lt;code&gt;io&lt;/code&gt;包中很多操作都是相似的，唯一不同的地方是&lt;code&gt;bufio&lt;/code&gt;提供了一些缓冲的操作，如果对文件I/O操作比较频繁的，使用&lt;code&gt;bufio&lt;/code&gt;还是能增加一些性能的。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;bufio&lt;/code&gt;包中，有一个&lt;code&gt;Writer&lt;/code&gt;结构体，而其相关的方法也支持一些写入操作。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//Writer是一个空的结构体，一般需要使用NewWriter或者NewWriterSize来初始化一个结构体对象
type Writer struct {
        // contains filtered or unexported fields
}

//NewWriterSize和NewWriter函数
//返回默认缓冲大小的Writer对象(默认是4096)
func NewWriter(w io.Writer) *Writer

//指定缓冲大小创建一个Writer对象
func NewWriterSize(w io.Writer, size int) *Writer

//Writer对象相关的写入数据的方法

//把p中的内容写入buffer,返回写入的字节数和错误信息。如果nn&amp;lt;len(p),返回错误信息中会包含为什么写入的数据比较短
func (b *Writer) Write(p []byte) (nn int, err error)
//将buffer中的数据写入 io.Writer
func (b *Writer) Flush() error

//以下三个方法可以直接写入到文件中
//写入单个字节
func (b *Writer) WriteByte(c byte) error
//写入单个Unicode指针返回写入字节数错误信息
func (b *Writer) WriteRune(r rune) (size int, err error)
//写入字符串并返回写入字节数和错误信息
func (b *Writer) WriteString(s string) (int, error)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;注意：如果需要再写入文件时利用缓冲的话只能使用bufio包中的Write方法&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;示例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//使用bufio包中Writer对象的相关方法进行数据的写入
func WriteWithBufio(name,content string) {
    if fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_APPEND,0644);err == nil {
        defer fileObj.Close()
        writeObj := bufio.NewWriterSize(fileObj,4096)
        //
       if _,err := writeObj.WriteString(content);err == nil {
              fmt.Println(&amp;quot;Successful appending buffer and flush to file with bufio&#39;s Writer obj WriteString method&amp;quot;,content)
           }

        //使用Write方法,需要使用Writer对象的Flush方法将buffer中的数据刷到磁盘
        buf := []byte(content)
        if _,err := writeObj.Write(buf);err == nil {
            fmt.Println(&amp;quot;Successful appending to the buffer with os.OpenFile and bufio&#39;s Writer obj Write method.&amp;quot;,content)
            if  err := writeObj.Flush(); err != nil {panic(err)}
            fmt.Println(&amp;quot;Successful flush the buffer data to file &amp;quot;,content)
        }
        }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;写文件全部示例&#34;&gt;写文件全部示例&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;/**
 * @File Name: writefile.go
 * @Author:
 * @Email:
 * @Create Date: 2017-12-17 12:12:09
 * @Last Modified: 2017-12-17 23:12:10
 * @Description:使用多种方式将数据写入文件
 */
package main
import (
    &amp;quot;os&amp;quot;
    &amp;quot;io&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io/ioutil&amp;quot;
    &amp;quot;bufio&amp;quot;
)

func main() {
      name := &amp;quot;testwritefile.txt&amp;quot;
      content := &amp;quot;Hello, xxbandy.github.io!\n&amp;quot;
      WriteWithIoutil(name,content)
      contents := &amp;quot;Hello, xuxuebiao\n&amp;quot;
      //清空一次文件并写入两行contents
      WriteWithFileWrite(name,contents)
      WriteWithIo(name,content)
      //使用bufio包需要将数据先读到buffer中，然后在flash到磁盘中
      WriteWithBufio(name,contents)
}

//使用ioutil.WriteFile方式写入文件,是将[]byte内容写入文件,如果content字符串中没有换行符的话，默认就不会有换行符
func WriteWithIoutil(name,content string) {
    data :=  []byte(content)
    if ioutil.WriteFile(name,data,0644) == nil {
        fmt.Println(&amp;quot;写入文件成功:&amp;quot;,content)
        }
    }

//使用os.OpenFile()相关函数打开文件对象，并使用文件对象的相关方法进行文件写入操作
//清空一次文件
func WriteWithFileWrite(name,content string){
    fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_TRUNC,0644)
    if err != nil {
        fmt.Println(&amp;quot;Failed to open the file&amp;quot;,err.Error())
        os.Exit(2)
    }
    defer fileObj.Close()
    if _,err := fileObj.WriteString(content);err == nil {
        fmt.Println(&amp;quot;Successful writing to the file with os.OpenFile and *File.WriteString method.&amp;quot;,content)
    }
    contents := []byte(content)
    if _,err := fileObj.Write(contents);err == nil {
        fmt.Println(&amp;quot;Successful writing to thr file with os.OpenFile and *File.Write method.&amp;quot;,content)
    }
}


//使用io.WriteString()函数进行数据的写入
func WriteWithIo(name,content string) {
    fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_APPEND,0644)
    if err != nil {
        fmt.Println(&amp;quot;Failed to open the file&amp;quot;,err.Error())
        os.Exit(2)
    }
    if  _,err := io.WriteString(fileObj,content);err == nil {
        fmt.Println(&amp;quot;Successful appending to the file with os.OpenFile and io.WriteString.&amp;quot;,content)
    }
}

//使用bufio包中Writer对象的相关方法进行数据的写入
func WriteWithBufio(name,content string) {
    if fileObj,err := os.OpenFile(name,os.O_RDWR|os.O_CREATE|os.O_APPEND,0644);err == nil {
        defer fileObj.Close()
        writeObj := bufio.NewWriterSize(fileObj,4096)
        //
       if _,err := writeObj.WriteString(content);err == nil {
              fmt.Println(&amp;quot;Successful appending buffer and flush to file with bufio&#39;s Writer obj WriteString method&amp;quot;,content)
           }

        //使用Write方法,需要使用Writer对象的Flush方法将buffer中的数据刷到磁盘
        buf := []byte(content)
        if _,err := writeObj.Write(buf);err == nil {
            fmt.Println(&amp;quot;Successful appending to the buffer with os.OpenFile and bufio&#39;s Writer obj Write method.&amp;quot;,content)
            if  err := writeObj.Flush(); err != nil {panic(err)}
            fmt.Println(&amp;quot;Successful flush the buffer data to file &amp;quot;,content)
        }
        }
}
&lt;/code&gt;&lt;/pre&gt;</description>
      
    </item>
    
    <item>
      <title>开源OCR引擎tesseract的构建使用</title>
      <link>https://bgbiao.top/post/%E5%BC%80%E6%BA%90ocr%E5%BC%95%E6%93%8Etesseract%E7%9A%84%E6%9E%84%E5%BB%BA%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 09 Dec 2017 15:59:29 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%BC%80%E6%BA%90ocr%E5%BC%95%E6%93%8Etesseract%E7%9A%84%E6%9E%84%E5%BB%BA%E4%BD%BF%E7%94%A8/</guid>
      
        <description>&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;h4 id=&#34;ocr&#34;&gt;OCR&lt;/h4&gt;

&lt;p&gt;光学字符识别(OCR,Optical Character Recognition)是指对文本资料进行扫描，然后对图像文件进行分析处理，获取文字及版面信息的过程。OCR技术非常专业，一般多是印刷、打印行业的从业人员使用。而在人工智能快速发展阶段，该技术也被大量运用在一些常见的业务场景来提高业务流程效率，比如像一些文件扫描，身份证识别，图片识别等相关业务场景。&lt;/p&gt;

&lt;h4 id=&#34;tesseract&#34;&gt;tesseract&lt;/h4&gt;

&lt;p&gt;Tesseract的OCR引擎最先由HP实验室于1985年开始研发，至1995年时已经成为OCR业内最准确的三款识别引擎之一。然而，HP不久便决定放弃OCR业务，Tesseract也从此尘封。
数年以后，HP意识到，与其将Tesseract束之高阁，不如贡献给开源软件业，让其重焕新生－－2005年，Tesseract由美国内华达州信息技术研究所获得，并求诸于Google对Tesseract进行改进、消除Bug、优化工作。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract&#34;&gt;tesseract官方地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是，tesseract3.0以上才支持中文，而且从官方文档上看4.0版本（2017年1月左右发布）显著的提高了识别率，同时也加大了性能的消耗。&lt;/p&gt;

&lt;h4 id=&#34;场景&#34;&gt;场景&lt;/h4&gt;

&lt;p&gt;一个亲身经历的场景就是以前去开户可能需要带上身份证资料各种去打印复印件进行物理备份，而使用OCR等相关人工智能技术后就可以通过手机摄像头快速识别身份证相关信息来存储个人资料，整个开户体验相当高效简单。&lt;/p&gt;

&lt;p&gt;另外一个常见的场景可能就是我们手写的文章需要扫描成电子版，在以前我们可能需要专业的打印机设备才能够进行电子扫描，而当OCR相关技术普及到普通业务场景后，我们就可以使用手持设备进行纸质版的文件进行电子扫描。[个人之前尝试使用有道云笔记中的电子扫描功能还是相当不错的]&lt;/p&gt;

&lt;h3 id=&#34;部署安装&#34;&gt;部署安装&lt;/h3&gt;

&lt;p&gt;tesseract需要&lt;a href=&#34;http://www.leptonica.org/download.html&#34;&gt;Leptonica&lt;/a&gt;的支持，leptonica是一个开源的面向教学的软件，通常被用来作为图像处理和图像分析的一个底层库支持。&lt;/p&gt;

&lt;h4 id=&#34;使用yum安装&#34;&gt;使用yum安装&lt;/h4&gt;

&lt;p&gt;Centos7中的epel源中包含了tesseract的3.05版本的包，可以直接安装使用。而在tesseract的github官方项目中最新版本也只到&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/releases&#34;&gt;3.05.01&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum install epel-release
 -y
# 查看epel源
$ cat /etc/yum.repos.d/epel.repo 
[epel]
name=Extra Packages for Enterprise Linux 7 - $basearch
#baseurl=http://download.fedoraproject.org/pub/epel/7/$basearch
metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;amp;arch=$basearch
failovermethod=priority
enabled=1
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7

[epel-debuginfo]
name=Extra Packages for Enterprise Linux 7 - $basearch - Debug
#baseurl=http://download.fedoraproject.org/pub/epel/7/$basearch/debug
metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-7&amp;amp;arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=1

[epel-source]
name=Extra Packages for Enterprise Linux 7 - $basearch - Source
#baseurl=http://download.fedoraproject.org/pub/epel/7/SRPMS
metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-source-7&amp;amp;arch=$basearch
failovermethod=priority
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
gpgcheck=1


# 安装tesseract 以及相关的库依赖
$ sudo yum install tesseract tesseract-devel -y 

# 安装中文库支持
$ sudo yum install -y tesseract-langpack-chi_sim.noarch tesseract-langpack-chi_tra.noarch


# 查看默认的配置以及语言库
$ ls /usr/share/tesseract/tessdata
chi_sim.traineddata  chi_tra.traineddata

# 默认只支持eng英语一种语言，安装中文包之后查看语言支持
$ tesseract --list-langs
List of available languages (3):
eng
chi_sim
chi_tra

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-源码编译最新版本-4-00-00alpha版本&#34;&gt;2.源码编译最新版本(4.00.00alpha版本)&lt;/h4&gt;

&lt;p&gt;从官网上看，4.0版本在识别率以及性能等各方面上要比3.0版本高好多，但是官方又没有提供4.0的release版本，因此接下来使用github上的源码来手动编译&lt;a href=&#34;https://github.com/tesseract-ocr/tesseract/tree/4.00.00alpha&#34;&gt;tesseract4.00.00alpha&lt;/a&gt;版本。同时由于对底层Leptonica的依赖，需要优先编译该库的依赖。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意：宿主操作系统仍然是一个纯净的Centos7.3.1611的OS&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 安装基础依赖
# sudo yum install gcc git gcc-c++ make automake libtool libpng-devel libjpeg-devel libtiff-devel zlib-devel -y

# 安装leptonica-1.74.4
# wget http://www.leptonica.org/source/leptonica-1.74.4.tar.gz  &amp;amp;&amp;amp; tar -zxf leptonica-1.74.4.tar.gz &amp;amp;&amp;amp; cd  leptonica ;./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install

........
 /usr/bin/mkdir -p &#39;/usr/local/lib&#39;
 /bin/sh ../libtool   --mode=install /usr/bin/install -c   liblept.la &#39;/usr/local/lib&#39;
libtool: install: /usr/bin/install -c .libs/liblept.so.5.0.1 /usr/local/lib/liblept.so.5.0.1
libtool: install: (cd /usr/local/lib &amp;amp;&amp;amp; { ln -s -f liblept.so.5.0.1 liblept.so.5 || { rm -f liblept.so.5 &amp;amp;&amp;amp; ln -s liblept.so.5.0.1 liblept.so.5; }; })
libtool: install: (cd /usr/local/lib &amp;amp;&amp;amp; { ln -s -f liblept.so.5.0.1 liblept.so || { rm -f liblept.so &amp;amp;&amp;amp; ln -s liblept.so.5.0.1 liblept.so; }; })
libtool: install: /usr/bin/install -c .libs/liblept.lai /usr/local/lib/liblept.la
libtool: install: /usr/bin/install -c .libs/liblept.a /usr/local/lib/liblept.a
libtool: install: chmod 644 /usr/local/lib/liblept.a
libtool: install: ranlib /usr/local/lib/liblept.a
libtool: finish: PATH=&amp;quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin&amp;quot; ldconfig -n /usr/local/lib
----------------------------------------------------------------------

Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the `-LLIBDIR&#39;
flag during linking and do at least one of the following:
   - add LIBDIR to the `LD_LIBRARY_PATH&#39; environment variable
     during execution
   - add LIBDIR to the `LD_RUN_PATH&#39; environment variable
     during linking
   - use the `-Wl,-rpath -Wl,LIBDIR&#39; linker flag
   - have your system administrator add LIBDIR to `/etc/ld.so.conf&#39;

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------

 /usr/bin/mkdir -p &#39;/usr/local/include/leptonica&#39;
 /usr/bin/mkdir -p &#39;/usr/local/bin&#39;
  /bin/sh ../libtool   --mode=install /usr/bin/install -c convertfilestopdf convertfilestops convertformat convertsegfilestopdf convertsegfilestops converttopdf converttops fileinfo printimage printsplitimage printtiff splitimage2pdf xtractprotos &#39;/usr/local/bin&#39;
......

make[2]: Nothing to be done for `install-data-am&#39;.
make[2]: Leaving directory `/export/servers/leptonica-1.74.4/prog&#39;
make[1]: Leaving directory `/export/servers/leptonica-1.74.4/prog&#39;
make[1]: Entering directory `/export/servers/leptonica-1.74.4&#39;
make[2]: Entering directory `/export/servers/leptonica-1.74.4&#39;
make[2]: Nothing to be done for `install-exec-am&#39;.
 /usr/bin/mkdir -p &#39;/usr/local/lib/pkgconfig&#39;
 /usr/bin/install -c -m 644 lept.pc &#39;/usr/local/lib/pkgconfig&#39;

# 以上输出显示leptonica已经成功编译，并给出相关提示知名动态链接库的地址以及头文件等相关地址，需要注意的在使用之前一定要加载动态链接库/usr/local/lib
# ldconfig -n /usr/local/lib

# 安装tesseract，由于作者在github上设置了tag来区分各个版本，因此我们需要切换到源码的指定分支进行源码编译
# git clone https://github.com/tesseract-ocr/tesseract.git；
cd tesseract &amp;amp;&amp;amp; git checkout -b biaoge 4.00.00alpha &amp;amp;&amp;amp; ./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install

 /usr/bin/mkdir -p &#39;/usr/local/include/tesseract

 /usr/bin/mkdir -p &#39;/usr/local/lib&#39;

libtool: finish: PATH=&amp;quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin&amp;quot; ldconfig -n /usr/local/lib

----------------------------------------------------------------------
Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the `-LLIBDIR&#39;
flag during linking and do at least one of the following:
   - add LIBDIR to the `LD_LIBRARY_PATH&#39; environment variable
     during execution
   - add LIBDIR to the `LD_RUN_PATH&#39; environment variable
     during linking
   - use the `-Wl,-rpath -Wl,LIBDIR&#39; linker flag
   - have your system administrator add LIBDIR to `/etc/ld.so.conf&#39;

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /usr/bin/mkdir -p &#39;/usr/local/bin&#39;
  /bin/sh ../libtool   --mode=install /usr/bin/install -c tesseract &#39;/usr/local/bin&#39;
libtool: install: /usr/bin/install -c .libs/tesseract /usr/local/bin/tesseract
 /usr/bin/mkdir -p &#39;/usr/local/include/tesseract&#39;
 /usr/bin/install -c -m 644 apitypes.h baseapi.h capi.h renderer.h &#39;/usr/local/include/tesseract&#39;

 /usr/bin/mkdir -p &#39;/usr/local/lib/pkgconfig&#39;
 /usr/bin/install -c -m 644 tesseract.pc &#39;/usr/local/lib/pkgconfig&#39;

 /usr/bin/mkdir -p &#39;/usr/local/share/tessdata/configs&#39;
 /usr/bin/install -c -m 644 inter makebox box.train unlv ambigs.train api_config kannada box.train.stderr quiet logfile digits hocr tsv linebox pdf rebox strokewidth bigram txt &#39;/usr/local/share/tessdata/configs&#39;


 /usr/bin/mkdir -p &#39;/usr/local/share/tessdata/tessconfigs&#39;
 /usr/bin/install -c -m 644 batch batch.nochop nobatch matdemo segdemo msdemo &#39;/usr/local/share/tessdata/tessconfigs&#39;


 /usr/bin/mkdir -p &#39;/usr/local/share/tessdata&#39;
 /usr/bin/install -c -m 644 pdf.ttf &#39;/usr/local/share/tessdata&#39;


 /usr/bin/mkdir -p &#39;/usr/local/share/man/man1&#39;
 /usr/bin/install -c -m 644 cntraining.1 combine_tessdata.1 mftraining.1 tesseract.1 unicharset_extractor.1 wordlist2dawg.1 ambiguous_words.1 shapeclustering.1 dawg2wordlist.1 &#39;/usr/local/share/man/man1&#39;
 /usr/bin/mkdir -p &#39;/usr/local/share/man/man5&#39;
 /usr/bin/install -c -m 644 unicharambigs.5 unicharset.5 &#39;/usr/local/share/man/man5&#39;
 
# 以上输出也标明tesseract已经成功安装在了/usr/local/lib目录，并给出了一些tesseract相关的配置路径以及注意事项。特别需要注意的是，也需要加载动态链接库，否则程序可能无法识别相关的库文件。

# ldconfig -n /usr/local/lib

# 安装成功，即可使用tesseract命令(默认在/usr/local/bin/)
# tesseract --version
tesseract 4.00.00alpha
 leptonica-1.74.4


# 查看当前的语言库支持
# tesseract --list-langs
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your &amp;quot;tessdata&amp;quot; directory.
Failed loading language &#39;eng&#39;
Tesseract couldn&#39;t load any languages!
Could not initialize tesseract.

# 提示已经很明显，需要配置TESSDATA_PREFIX环境变量

# 配置环境变量和相关的语言库
# export TESSDATA_PREFIX=/usr/local/share/
# cd $TESSDATA_PREFIX/tessdata 
# for font in chi_sim chi_tra eng ;do wget https://github.com/tesseract-ocr/tessdata/raw/master/$font.traineddata;done 

# 再次查看语言支持
# tesseract --list-langs
List of available languages (3):
chi_sim
eng
chi_tra


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此，环境中已经能够正常使用&lt;code&gt;tesseract&lt;/code&gt;命令了，基本上可以认为tesseract环境已经编译完成，接下来就是具体看看如何去使用tesseract了&lt;/p&gt;

&lt;h3 id=&#34;简单使用&#34;&gt;简单使用&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://img.alicdn.com/simba/img/TB1L8SKhwnH8KJjSspcSuv3QFXa.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tesseract TB1L8SKhwnH8KJjSspcSuv3QFXa.jpg test -l chi_sim
Tesseract Open Source OCR Engine v3.04.00 with Leptonica


$ cat test.txt 
走心特惠
不玩套路



&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出来对比较规范的字体还是可以正常识别的。&lt;/p&gt;

&lt;h3 id=&#34;可能遇到的问题&#34;&gt;可能遇到的问题&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# 测试使用
# tesseract 5a0178d2N01754832.jpg test -l chi_sim 
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
pixReadStreamJpeg: function not present
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.

# 以上提示是因为Leptonica不支持某些图片格式
# yum install ImageMagick -y 
# 重新编译Leptonica(增加--with-libpng参数)
# cd /export/servers/leptonica-1.74 ;./configure --with-libpng &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install 

 
# 再次测试
$ tesseract TB1L8SKhwnH8KJjSspcSuv3QFXa.jpg test -l chi_sim
Tesseract Open Source OCR Engine v3.04.00 with Leptonica


$ cat test.txt 
走心特惠
不玩套路


&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;福利&#34;&gt;福利&lt;/h3&gt;

&lt;p&gt;由于目前tesseract官方并未直接提供4.0的软件包，并且tesseract环境的构建也是稍微比较复杂，为了秉承造福群众的理念，我将以上环境封装成Docker image供各位网友使用。具体使用方式如下：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;前提：需要有一个可用的Docker环境，任何版本都可以&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 下载镜像(稍微有点大1.6G)
# docker pull xxbandy123/tesseract-ocr4.00.00alpha:17-12-05

# 运行tesseract环境
# docker run -itd  xxbandy123/tesseract-ocr4.00.00alpha:17-12-05
2b4df1a1e9d20426aefa32ba79066b561fe66c623986b76634012ac9cae40e64

# 进入环境测试运行
# docker exec -it $(docker ps -a -q -l) bash
[root@2b4df1a1e9d2 /]# tesseract
Usage:
  tesseract --help | --help-psm | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]
  
# 测试环境运行
# wget https://img.alicdn.com/tfs/TB16FK4SXXXXXXUXXXXXXXXXXXX-790-180.jpg
[root@2b4df1a1e9d2 /]# tesseract TB16FK4SXXXXXXUXXXXXXXXXXXX-790-180.jpg test -l chi_sim
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
[root@2b4df1a1e9d2 /]# cat test.txt
一天猫电器全新服务保障

胁 售后无忧

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;测试原图&lt;img src=&#34;https://img.alicdn.com/tfs/TB16FK4SXXXXXXUXXXXXXXXXXXX-790-180.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由此可见，开源的tesseract目前并不能完全识别所有的图片文字，如果需要借助于开源去做业务场景，可能还需要更多的二次改造才能够有所应用。&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
