<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BGBiao的SRE人生</title>
    <link>https://bgbiao.top/</link>
    <description>Recent content on BGBiao的SRE人生</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Jun 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bgbiao.top/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>kafka中关于HW(High Watermark)和Leader Epoch的讨论</title>
      <link>https://bgbiao.top/post/kafka%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8Cleader-epoch%E7%9A%84%E8%AE%A8%E8%AE%BA/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8Cleader-epoch%E7%9A%84%E8%AE%A8%E8%AE%BA/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;我们知道在kafka中有一个名词叫做HW(High Watermark)，但是具体这个高水位是用来做什么的呢？我们一起来学习下&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;kafka中的高水位的作用:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。&lt;/li&gt;
&lt;li&gt;帮助 Kafka 完成副本同步&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfva86hzzrj31bc0h6go3.jpg&#34; alt=&#34;kafka高水位以及消息提交图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;值得注意的是，在kafka的某个topic中，分区和副本都有HW的概念，而分区的HW是所有副本HW的最小值，也是消费者能够消费到最大消息。(即: 消费者只能消费已经提交的消息)&lt;/p&gt;

&lt;p&gt;另外，位移值等于高水位的消息也属于未提交消息。也就是说，&lt;code&gt;高水位上的消息是不能被消费者消费&lt;/code&gt;的。&lt;/p&gt;

&lt;p&gt;图中还有一个日志末端位移的概念，即 Log End Offset，简写是 LEO。它表示副本写入下一条消息的位移值。注意，数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15。显然，介于高水位和 LEO 之间的消息就属于未提交消息。这也从侧面告诉了我们一个重要的事实，那就是：&lt;code&gt;同一个副本对象，其高水位值不会大于 LEO 值&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;高水位更新机制&#34;&gt;高水位更新机制&lt;/h3&gt;

&lt;p&gt;现在，我们知道了每个副本对象都保存了一组高水位值和 LEO 值，但实际上，在 Leader 副本所在的 Broker 上，还保存了其他 Follower 副本的 LEO 值。我们一起来看看下面这张图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvb7on0vpj316f0u0dju.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在这张图中，我们可以看到，Broker 0 上保存了某分区的 Leader 副本和所有 Follower 副本的 LEO 值，而 Broker 1 上仅仅保存了该分区的某个 Follower 副本。Kafka 把 Broker 0 上保存的这些 Follower 副本又称为&lt;code&gt;远程副本&lt;/code&gt; Remote Replica）。Kafka 副本机制在运行过程中，会更新 Broker 1 上 Follower 副本的高水位和 LEO 值，同时也会更新 Broker 0 上 Leader 副本的高水位和 LEO 以及所有远程副本的 LEO，但它不会更新远程副本的高水位值，也就是我在图中标记为灰色的部分。&lt;/p&gt;

&lt;p&gt;为什么要在 Broker 0 上保存这些远程副本呢？其实，它们的主要作用是，&lt;code&gt;帮助 Leader 副本确定其高水位，也就是分区高水位&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;为了帮助你更好地记忆这些值被更新的时机，我做了一张表格。只有搞清楚了更新机制，我们才能开始讨论 Kafka 副本机制的原理，以及它是如何使用高水位来执行副本消息同步的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvb9nilwvj30h60fogo4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;判断Leader 副本保持同步的条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;远程 Follower 副本在 ISR 中&lt;/li&gt;
&lt;li&gt;Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参数 replica.lag.time.max.ms 的值。如果使用默认值的话，就是不超过 10 秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;乍一看，这两个条件好像是一回事，因为目前某个副本能否进入 ISR 就是靠第 2 个条件判断的。但有些时候，会发生这样的情况：即 Follower 副本已经 “追上” 了 Leader 的进度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 1 个条件的话，就可能出现某些副本具备了 “进入 ISR” 的资格，但却尚未进入到 ISR 中的情况。此时，分区高水位值就可能超过 ISR 中副本 LEO，而高水位 &amp;gt; LEO 的情形是不被允许的。&lt;/p&gt;

&lt;h3 id=&#34;副本同步机制解析&#34;&gt;副本同步机制解析&lt;/h3&gt;

&lt;p&gt;副本同步的全过程:&lt;/p&gt;

&lt;p&gt;首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbgu2idsj30nd03awet.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当生产者给主题分区发送一条消息后，状态变更为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbh4glr3j30nd07wwf7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。&lt;/p&gt;

&lt;p&gt;Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbhh5e15j30nc08a3z8.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。&lt;code&gt;它们需要在下一轮的fetch request中被更新&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbi5gvykj30nu0cft9w.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 =1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。&lt;/p&gt;

&lt;h3 id=&#34;leader-epoch-登场&#34;&gt;Leader Epoch 登场&lt;/h3&gt;

&lt;p&gt;从刚才的分析中，我们知道，Follower 副本的高水位更新需要一轮额外的拉取请求才能实现。如果把上面那个例子扩展到多个 Follower 副本，情况可能更糟，也许需要多轮拉取请求。也就是说，Leader 副本高水位更新和 Follower 副本高水位更新在时间上是存在错配的。这种错配是很多 “数据丢失” 或 “数据不一致” 问题的根源。基于此，社区在 0.11 版本正式引入了 Leader Epoch 概念，来规避因高水位更新错配导致的各种不一致问题。&lt;/p&gt;

&lt;p&gt;所谓 Leader Epoch，我们大致可以认为是 &lt;code&gt;Leader 版本&lt;/code&gt;。它由两部分数据组成。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力&lt;/li&gt;
&lt;li&gt;起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我举个例子来说明一下 Leader Epoch。假设现在有两个 Leader Epoch&lt;0, 0&gt; 和 &lt;1, 120&gt;，那么，第一个 Leader Epoch 表示版本号是 0，这个版本的 Leader 从位移 0 开始保存消息，一共保存了 120 条消息。之后，Leader 发生了变更，版本号增加到 1，新版本的起始位移是 120。&lt;/p&gt;

&lt;p&gt;Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目，否则就不做更新。这样，每次有 Leader 变更时，新的 Leader 副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。&lt;/p&gt;

&lt;p&gt;接下来，我们来看一个实际的例子，它展示的是 Leader Epoch 是如何防止数据丢失的。请先看下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbnxpmjcj30x30u0q75.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我稍微解释一下，单纯依赖高水位是怎么造成数据丢失的。开始时，副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。现在我们假设 Leader 和 Follower 都写入了这两条消息，而且 Leader 副本的高水位也已经更新了，但 Follower 副本高水位还未更新 —— 这是可能出现的。还记得吧，Follower 端高水位的更新与 Leader 端有时间错配。倘若此时副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 LEO 值调整为之前的高水位值，也就是 1。这就是说，位移值为 1 的那条消息被副本 B 从磁盘中删除，此时副本 B 的底层磁盘文件中只保存有 1 条消息，即位移值为 0 的那条消息。&lt;/p&gt;

&lt;p&gt;当执行完截断操作后，副本 B 开始从 A 拉取消息，执行正常的消息同步。如果就在这个节骨眼上，副本 A 所在的 Broker 宕机了，那么 Kafka 就别无选择，只能让副本 B 成为新的 Leader，此时，当 A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。这样操作之后，位移值为 1 的那条消息就从这两个副本中被永远地抹掉了。这就是这张图要展示的数据丢失场景。&lt;/p&gt;

&lt;p&gt;严格来说，这个场景发生的前提是 Broker 端参数 &lt;code&gt;min.insync.replicas 设置为 1&lt;/code&gt;。此时一旦消息被写入到 Leader 副本的磁盘，就会被认为是 “已提交状态”，但现有的时间错配问题导致 Follower 端的高水位更新是有滞后的。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，那么这类数据的丢失就是不可避免的。&lt;/p&gt;

&lt;p&gt;现在，我们来看下如何利用 Leader Epoch 机制来规避这种数据丢失。我依然用图的方式来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbp51hefj319g0u0wj2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;场景和之前大致是类似的，只不过引用 Leader Epoch 机制后，Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 Leader 的 LEO 值。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &amp;gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。这是对高水位机制的一个明显改进，即副本是否执行日志截断不再依赖于高水位进行判断。&lt;/p&gt;

&lt;p&gt;现在，副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。这样，通过 Leader Epoch 机制，Kafka 完美地规避了这种数据丢失场景。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka经典面试题详解</title>
      <link>https://bgbiao.top/post/kafka%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AF%A6%E8%A7%A3/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;无论是作为面试官，还是应聘者，我都接触过很多 Kafka 面试题。而在最近面试了很多候选人，发现写了熟悉Kafka，但是对于Kafka相关的知识却是只知道大概用处，简单搭建和使用。我想说，虽然我们是SRE(可靠性工程师)，但不论你是业务层的SRE还是基础设施层的SRE，我们都需要对业务方的使用场景有足够理解，或者对我们要提供的服务有足够的了解才行，这样你才能整体的保证你的业务连续性以及业务可靠性。因此，专门总结了如下经典的kafka面试详解。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;以下面试题，参考胡大的&lt;code&gt;Kafka 核心源码解读&lt;/code&gt;，对相关的知识进行了补充和思考。&lt;/p&gt;

&lt;h3 id=&#34;基础题目&#34;&gt;基础题目&lt;/h3&gt;

&lt;h4 id=&#34;1-apache-kafka-是什么&#34;&gt;1.Apache Kafka 是什么？&lt;/h4&gt;

&lt;p&gt;能问这道题，主要是想看候选人对于kafka的使用场景以及定位认知理解有多深，同时候可以知道候选人对于这项技术的关注度。&lt;/p&gt;

&lt;p&gt;我们都知道，在开源软件中，大部分软件随着用户量的增加，整个软件的功能和定位也有了新的变化，而Apache Kafka 一路发展到现在，已经由最初的分布式提交日志系统逐渐演变成了实时流处理框架。&lt;/p&gt;

&lt;p&gt;因此，这道题你最好这么回答：&lt;strong&gt;Apach Kafka 是一款分布式流处理平台，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用(通常也会称之为消息总线message bus)。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于&lt;code&gt;分布式流处理平台&lt;/code&gt;，其实从它官方的logo以及slogan我们就很容易看出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kafka.apache.org/images/logo.png&#34; alt=&#34;kafka-logo&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-什么是消费者组&#34;&gt;2.什么是消费者组?&lt;/h4&gt;

&lt;p&gt;消费者组是 Kafka 独有的概念，如果面试官问这个，就说明他对此是有一定了解的。&lt;/p&gt;

&lt;p&gt;胡大给的标准答案是: &lt;strong&gt;官网上的介绍言简意赅，即消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;但实际上，消费者组(Consumer Group)其实包含两个概念，作为&lt;code&gt;队列&lt;/code&gt;，消费者组允许你分割数据处理到一组进程集合上(即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据)，这有助于你的消费能力的动态调整；作为&lt;code&gt;发布-订阅模型(publish-subscribe)&lt;/code&gt;，kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。&lt;/p&gt;

&lt;p&gt;需要注意的是: &lt;strong&gt;在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组 ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。&lt;/strong&gt; 因此，消费者组在一定程度上也保证了消费者程序的高可用性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfs6dbcw1yj30d6070aar.jpg&#34; alt=&#34;kafka-consumer-group&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 消费者组的题目，能够帮你在某种程度上掌控下面的面试方向。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你擅长&lt;code&gt;位移值原理(Offset)&lt;/code&gt;，就不妨再提一下消费者组的位移提交机制；&lt;/li&gt;
&lt;li&gt;如果你擅长&lt;code&gt;Kafka Broker&lt;/code&gt;，可以提一下消费者组与 Broker 之间的交互；&lt;/li&gt;
&lt;li&gt;如果你擅长与消费者组完全不相关的 &lt;code&gt;Producer&lt;/code&gt;，那么就可以这么说：“消费者组要消费的数据完全来自于 Producer 端生产的消息，我对 Producer 还是比较熟悉的。”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总之，你总得对&lt;code&gt;consumer group&lt;/code&gt;相关的方向有一定理解，然后才能像面试官表名你对某一块很理解。&lt;/p&gt;

&lt;h4 id=&#34;3-在-kafka-中-zookeeper-的作用是什么&#34;&gt;3.在 Kafka 中，ZooKeeper 的作用是什么？&lt;/h4&gt;

&lt;p&gt;这道题，也是我经常会问候选人的题，因为任何分布式系统中虽然都通过一些列的算法去除了传统的关系型数据存储，但是毕竟还是有些数据要存储的，同时分布式系统的特性往往是需要有一些中间人角色来统筹集群。比如我们在整个微服务框架中的&lt;code&gt;Dubbo&lt;/code&gt;，它也是需要依赖一些注册中心或配置中心类的中间件的，以及云原生的Kubernetes使用&lt;code&gt;Etcd&lt;/code&gt;作为整个集群的枢纽。&lt;/p&gt;

&lt;p&gt;标准答案: &lt;strong&gt;目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。之后，等 KIP-500 提案完成后，Kafka 将完全不再依赖于 ZooKeeper。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“存放元数据” 是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。&lt;/li&gt;
&lt;li&gt;“成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。&lt;/li&gt;
&lt;li&gt;“Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;KIP-500 思想，是使用社区自研的基于 Raft 的共识算法，替代 ZooKeeper，实现 Controller 自选举。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-解释下-kafka-中位移-offset-的作用&#34;&gt;4.解释下 Kafka 中位移（offset）的作用&lt;/h4&gt;

&lt;p&gt;标准答案: &lt;strong&gt;在 Kafka 中，每个主题分区下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。这个 ID 数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;答完这些之后，你还可以把整个面试方向转移到你希望的地方:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你深谙 Broker 底层日志写入的逻辑，可以强调下消息在日志中的存放格式&lt;/li&gt;
&lt;li&gt;如果你明白位移值一旦被确定不能修改，可以强调下 “Log Cleaner 组件都不能影响位移值” 这件事情&lt;/li&gt;
&lt;li&gt;如果你对消费者的概念还算熟悉，可以再详细说说&lt;code&gt;位移值&lt;/code&gt;和&lt;code&gt;消费者位移值&lt;/code&gt;之间的区别&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-阐述下-kafka-中的领导者副本-leader-replica-和追随者副本-follower-replica-的区别&#34;&gt;5.阐述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别&lt;/h4&gt;

&lt;p&gt;推荐的答案: &lt;strong&gt;Kafka 副本当前分为领导者副本和追随者副本。只有 Leader 副本才能对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉（PULL）的方式，被动地同步 Leader 副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备应聘 Leader 副本。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;加分点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;强调 Follower 副本也能对外提供读服务&lt;/strong&gt;。自 Kafka 2.4 版本开始，社区通过引入新的 Broker 端参数，允许 Follower 副本有限度地提供读服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强调 Leader 和 Follower 的消息序列在实际场景中不一致&lt;/strong&gt;。通常情况下，很多因素可能造成leader和follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注(秒级别)，但长时间的不同步可能就需要深入排查了，因为一旦leader所在节点异常，可能直接影响可用性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 之前确保一致性的主要手段是高水位机制(HW)，但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了&lt;code&gt;Leader Epoch&lt;/code&gt; 机制，来修复高水位值的弊端。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/112118?utm_source=pinpaizhuanqu&amp;amp;utm_medium=geektime&amp;amp;utm_campaign=guanwang&amp;amp;utm_term=guanwang&amp;amp;utm_content=0511&#34;&gt;关于高水位和 Leader Epoch 的讨论&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;实操题目&#34;&gt;实操题目&lt;/h3&gt;

&lt;h4 id=&#34;6-如何设置-kafka-能接收的最大消息的大小&#34;&gt;6.如何设置 Kafka 能接收的最大消息的大小?&lt;/h4&gt;

&lt;p&gt;对于SRE来讲，该题简直是送分题啊，但是，最大消息的设置通常情况下有生产者端，消费者端，broker端和topic级别的参数，我们需要正确设置，以保证可以正常的生产和消费。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Broker端参数: &lt;code&gt;message.max.bytes&lt;/code&gt;,&lt;code&gt;max.message.bytes(topic级别)&lt;/code&gt;,&lt;code&gt;replica.fetch.max.bytes(否则follow会同步失败)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Consumer端参数: &lt;code&gt;fetch.message.max.bytes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;7-监控-kafka-的框架都有哪些&#34;&gt;7.监控 Kafka 的框架都有哪些？&lt;/h4&gt;

&lt;p&gt;对于SRE来讲，依然是送分题。但基础的我们要知道，kafka本身是提供了&lt;code&gt;jmx(Java Management Extensions)&lt;/code&gt;的，我们可以通过它来获取到kafka内部的一些基本数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kafka Manager&lt;/strong&gt;: 更多是kafka的管理，对于SRE非常友好，也提供了简单的瞬时指标监控&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Monitor&lt;/strong&gt;: LinkedIn 开源的免费框架，支持对集群进行系统测试，并实时监控测试结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CruiseControl&lt;/strong&gt;: 也是 LinkedIn 公司开源的监控框架，用于实时监测资源使用率，以及提供常用运维操作等。无 UI 界面，只提供 REST API，可以进行多集群管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMX 监控&lt;/strong&gt;: 由于 Kafka 提供的监控指标都是基于 JMX 的，因此，市面上任何能够集成 JMX 的框架都可以使用，比如 Zabbix 和 Prometheus。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;已有大数据平台自己的监控体系&lt;/strong&gt;: 像 Cloudera 提供的 CDH 这类大数据平台，天然就提供 Kafka 监控方案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMXTool&lt;/strong&gt;: 社区提供的命令行工具，能够实时监控 JMX 指标。可以使用&lt;code&gt;kafka-run-class.sh kafka.tools.JmxTool&lt;/code&gt;来查看具体的用法。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;8-broker-的-heap-size-如何设置&#34;&gt;8.Broker 的 Heap Size 如何设置？&lt;/h4&gt;

&lt;p&gt;其实对于SRE还是送分题，因为目前来讲大部分公司的业务系统都是使用Java开发，因此SRE对于基本的JVM相关的参数应该至少都是非常了解的，核心就在于JVM的配置以及GC相关的知识。&lt;/p&gt;

&lt;p&gt;标准答案: &lt;strong&gt;任何 Java 进程 JVM 堆大小的设置都需要仔细地进行考量和测试。一个常见的做法是，以默认的初始 JVM 堆大小运行程序，当系统达到稳定状态后，手动触发一次 Full GC，然后通过 JVM 工具查看 GC 后的存活对象大小。之后，将堆大小设置成存活对象总大小的 1.5~2 倍。对于 Kafka 而言，这个方法也是适用的。不过，业界有个最佳实践，那就是将 Broker 的 Heap Size 固定为 6GB。经过很多公司的验证，这个大小是足够且良好的。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;9-如何估算-kafka-集群的机器数量&#34;&gt;9.如何估算 Kafka 集群的机器数量?&lt;/h4&gt;

&lt;p&gt;该题也算是SRE的送分题吧，对于SRE来讲，任何生产的系统第一步需要做的就是容量预估以及集群的架构规划，实际上也就是&lt;strong&gt;机器数量和所用资源之间的关联关系&lt;/strong&gt;，资源通常来讲就是cpu，内存，磁盘容量，带宽。但需要注意的是，kafka因为独有的设计，对于磁盘的要求并不是特别高，普通机械硬盘足够，而通常的瓶颈会出现在带宽上。&lt;/p&gt;

&lt;p&gt;在预估磁盘的占用时，你一定不要忘记计算副本同步的开销。如果一条消息占用 1KB 的磁盘空间，那么，在有 3 个副本的主题中，你就需要 3KB 的总空间来保存这条消息。同时，需要考虑到整个业务Topic数据保存的最大时间，以上几个因素，基本可以预估出来磁盘的容量需求。&lt;/p&gt;

&lt;p&gt;需要注意的是: 对于磁盘来讲，一定要提前和业务沟通好场景，而不是等待真正有磁盘容量瓶颈了才去扩容磁盘或者找业务方沟通方案。&lt;/p&gt;

&lt;p&gt;对于带宽来说，常见的带宽有 1Gbps 和 10Gbps，通常我们需要知道，当带宽占用接近总带宽的 90% 时，丢包情形就会发生。&lt;/p&gt;

&lt;h4 id=&#34;10-leader-总是-1-怎么破&#34;&gt;10.Leader 总是 -1，怎么破？&lt;/h4&gt;

&lt;p&gt;对于有经验的SRE来讲，早期的kafka版本应该多多少少都遇到过该种情况，通常情况下就是&lt;code&gt;controller&lt;/code&gt;不工作了，导致无法分配leader，那既然知道问题后，解决方案也就很简单了。重启controller节点上的kafka进程，让其他节点重新注册controller角色，但是如上面&lt;code&gt;zookeeper&lt;/code&gt;的作用，你要知道为什么&lt;code&gt;controller&lt;/code&gt;可以自动注册。&lt;/p&gt;

&lt;p&gt;当然了，当你知道&lt;code&gt;controller&lt;/code&gt;的注册机制后，你也可以说: &lt;strong&gt;删除 ZooKeeper 节点 /controller，触发 Controller 重选举。Controller 重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题&lt;/strong&gt;。但是，需要注意的是，直接操作&lt;code&gt;zookeeper&lt;/code&gt;是一件风险很大的操作，就好比在Linux中执行了&lt;strong&gt;rm -rf /xxx&lt;/strong&gt;一样，如果在&lt;code&gt;/&lt;/code&gt;和&lt;code&gt;xxx&lt;/code&gt;之间不小心多了几个空格，那&amp;rdquo;恭喜你&amp;rdquo;，今年白干了。&lt;/p&gt;

&lt;h3 id=&#34;炫技式题目&#34;&gt;炫技式题目&lt;/h3&gt;

&lt;h4 id=&#34;11-leo-lso-ar-isr-hw-都表示什么含义&#34;&gt;11.LEO、LSO、AR、ISR、HW 都表示什么含义？&lt;/h4&gt;

&lt;p&gt;讲真，我不认为这是炫技的题目，特别是作为SRE来讲，对于一个开源软件的原理以及概念的理解，是非常重要的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LEO(Log End Offset)&lt;/strong&gt;: 日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。举个例子，如果日志有 10 条消息，位移值从 0 开始，那么，第 10 条消息的位移值就是 9。此时，LEO = 10。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSO(Log Stable Offset)&lt;/strong&gt;: 这是 Kafka 事务的概念。如果你没有使用到事务，那么这个值不存在（其实也不是不存在，只是设置成一个无意义的值）。该值控制了事务型消费者能够看到的消息范围。它经常与 Log Start Offset，即日志起始位移值相混淆，因为有些人将后者缩写成 LSO，这是不对的。在 Kafka 中，LSO 就是指代 Log Stable Offset。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AR(Assigned Replicas)&lt;/strong&gt;: AR 是主题被创建后，分区创建时被分配的副本集合，副本个数由副本因子决定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISR(In-Sync Replicas)&lt;/strong&gt;: Kafka 中特别重要的概念，指代的是 AR 中那些与 Leader 保持同步的副本集合。在 AR 中的副本可能不在 ISR 中，但 Leader 副本天然就包含在 ISR 中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HW(High watermark)&lt;/strong&gt;: 高水位值，这是控制消费者可读取消息范围的重要字段。一个普通消费者只能 “看到” Leader 副本上介于 Log Start Offset 和 HW（不含）之间的所有消息。水位以上的消息是对消费者不可见的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是，通常在&lt;code&gt;ISR&lt;/code&gt;中，可能会有人问到为什么有时候副本不在ISR中，这其实也就是上面说的Leader和Follower不同步的情况，为什么我们前面说，短暂的不同步我们可以关注，但是长时间的不同步，我们需要介入排查了，因为ISR里的副本后面都是通过&lt;code&gt;replica.lag.time.max.ms&lt;/code&gt;，即Follower 副本的 LEO 落后 Leader LEO 的时间是否超过阈值来决定副本是否在ISR内部的。&lt;/p&gt;

&lt;h4 id=&#34;12-kafka-能手动删除消息吗&#34;&gt;12.Kafka 能手动删除消息吗？&lt;/h4&gt;

&lt;p&gt;Kafka 不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。当然，它是支持手动删除消息的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于设置了 Key 且参数 &lt;code&gt;cleanup.policy=compact&lt;/code&gt; 的主题而言，我们可以构造一条 的消息发送给 Broker，依靠 Log Cleaner 组件提供的功能删除掉该 Key 的消息。&lt;/li&gt;
&lt;li&gt;对于普通主题而言，我们可以使用 kafka-delete-records 命令，或编写程序调用 Admin.deleteRecords 方法来删除消息。这两种方法殊途同归，底层都是调用 Admin 的 deleteRecords 方法，通过将分区 Log Start Offset 值抬高的方式间接删除消息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;13-consumer-offsets-是做什么用的&#34;&gt;13.__consumer_offsets 是做什么用的？&lt;/h4&gt;

&lt;p&gt;这是一个内部主题，主要用于存储消费者的偏移量，以及消费者的元数据信息(&lt;code&gt;消费者实例，消费者id&lt;/code&gt;等等)&lt;/p&gt;

&lt;p&gt;需要注意的是: Kafka 的 &lt;code&gt;GroupCoordinator&lt;/code&gt; 组件提供对该主题完整的管理功能，包括该主题的创建、写入、读取和 Leader 维护等。&lt;/p&gt;

&lt;h4 id=&#34;14-分区-leader-选举策略有几种&#34;&gt;14.分区 Leader 选举策略有几种？&lt;/h4&gt;

&lt;p&gt;分区的 Leader 副本选举对用户是完全透明的，它是由 &lt;code&gt;Controller&lt;/code&gt; 独立完成的。你需要回答的是，在哪些场景下，需要执行分区 Leader 选举。每一种场景对应于一种选举策略。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OfflinePartition Leader 选举&lt;/strong&gt;: 每当有分区上线时，就需要执行 Leader 选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区 Leader 选举场景。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReassignPartition Leader 选举&lt;/strong&gt;: 当你手动运行 kafka-reassign-partitions 命令，或者是调用 Admin 的 alterPartitionReassignments 方法执行分区副本重分配时，可能触发此类选举。假设原来的 AR 是 [1，2，3]，Leader 是 1，当执行副本重分配后，副本集合 AR 被设置成 [4，5，6]，显然，Leader 必须要变更，此时会发生 Reassign Partition Leader 选举。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PreferredReplicaPartition Leader 选举&lt;/strong&gt;: 当你手动运行 kafka-preferred-replica-election 命令，或自动触发了 Preferred Leader 选举时，该类策略被激活。所谓的 Preferred Leader，指的是 AR 中的第一个副本。比如 AR 是 [3，2，1]，那么，Preferred Leader 就是 3。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ControlledShutdownPartition Leader 选举&lt;/strong&gt;: 当 Broker 正常关闭时，该 Broker 上的所有 Leader 副本都会下线，因此，需要为受影响的分区执行相应的 Leader 选举。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这 4 类选举策略的大致思想是类似的，即从 AR 中挑选首个在 ISR 中的副本，作为新 Leader。&lt;/p&gt;

&lt;h4 id=&#34;15-kafka-的哪些场景中使用了零拷贝-zero-copy&#34;&gt;15.Kafka 的哪些场景中使用了零拷贝（Zero Copy）&lt;/h4&gt;

&lt;p&gt;其实这道题对于SRE来讲，有点超纲了，不过既然&lt;code&gt;Zero Copy&lt;/code&gt;是kafka高性能的保证，我们需要了解它。&lt;/p&gt;

&lt;p&gt;Zero Copy 是特别容易被问到的高阶题目。在 Kafka 中，体现 Zero Copy 使用场景的地方有两处：&lt;strong&gt;基于 mmap 的索引和日志文件读写所用的 TransportLayer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先说第一个。索引都是基于 MappedByteBuffer 的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap 虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap 的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消 Zero Copy 带来的性能优势。由于这种不确定性，在 Kafka 中，只有索引应用了 mmap，最核心的日志并未使用 mmap 机制。&lt;/p&gt;

&lt;p&gt;再说第二个。TransportLayer 是 Kafka 传输层的接口。它的某个实现类使用了 FileChannel 的 transferTo 方法。该方法底层使用 sendfile 实现了 Zero Copy。对 Kafka 而言，如果 I/O 通道使用普通的 PLAINTEXT，那么，Kafka 就可以利用 Zero Copy 特性，直接将页缓存中的数据发送到网卡的 Buffer 中，避免中间的多次拷贝。相反，如果 I/O 通道启用了 SSL，那么，Kafka 便无法利用 Zero Copy 特性了。&lt;/p&gt;

&lt;h3 id=&#34;深度思考题&#34;&gt;深度思考题&lt;/h3&gt;

&lt;h4 id=&#34;16-kafka-为什么不支持读写分离&#34;&gt;16.Kafka 为什么不支持读写分离？&lt;/h4&gt;

&lt;p&gt;这其实是分布式场景下的通用问题，因为我们知道CAP理论下，我们只能保证C(可用性)和A(一致性)取其一，如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣，因为通常的场景下，副本之间都是通过同步来实现副本数据一致的，那同步过程中肯定会有时间的消耗，如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。&lt;/p&gt;

&lt;p&gt;Leader/Follower 模型并没有规定 Follower 副本不可以对外提供读服务。很多框架都是允许这么做的，只是 Kafka 最初为了避免不一致性的问题，而采用了让 Leader 统一提供服务的方式。&lt;/p&gt;

&lt;p&gt;不过，&lt;strong&gt;自 Kafka 2.4 之后，Kafka 提供了有限度的读写分离，也就是说，Follower 副本能够对外提供读服务&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;17-如何调优-kafka&#34;&gt;17.如何调优 Kafka？&lt;/h4&gt;

&lt;p&gt;作为SRE来讲，任何生产环境的调优，首先需要&lt;strong&gt;识别问题和瓶颈点&lt;/strong&gt;，而不是随意的进行臆想调优。随后，需要&lt;strong&gt;确定优化目标，并且定量给出目标&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于kafka来讲，常见的调优方向基本为: 吞吐量、延时、持久性和可用性，每种目标之前都是由冲突点，这也就要求了，我们在对业务接入使用时，要进行业务场景的了解，以对业务进行相对的集群隔离，因为每一个方向的优化思路都是不同的，甚至是相反的。&lt;/p&gt;

&lt;p&gt;确定了目标之后，还要明确优化的维度。有些调优属于通用的优化思路，比如对操作系统、JVM 等的优化；有些则是有针对性的，比如要优化 Kafka 的 TPS。我们需要从 3 个方向去考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Producer 端&lt;/strong&gt;: 增加&lt;code&gt;batch.size&lt;/code&gt;和&lt;code&gt;linger.ms&lt;/code&gt;，启用压缩，关闭重试&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Broker 端&lt;/strong&gt;: 增加&lt;code&gt;num.replica.fetchers&lt;/code&gt;提升 Follower 同步 TPS，避免 Broker Full GC 等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer&lt;/strong&gt;: 增加&lt;code&gt;fetch.min.bytes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;18-controller-发生网络分区-network-partitioning-时-kafka-会怎么样&#34;&gt;18.Controller 发生网络分区（Network Partitioning）时，Kafka 会怎么样&lt;/h4&gt;

&lt;p&gt;这道题目能够诱发我们对分布式系统设计、CAP 理论、一致性等多方面的思考。&lt;/p&gt;

&lt;p&gt;一旦发生 Controller 网络分区，那么，第一要务就是查看集群是否出现 “脑裂”，即同时出现两个甚至是多个 Controller 组件。这可以根据 Broker 端监控指标 ActiveControllerCount 来判断。&lt;/p&gt;

&lt;p&gt;不过，通常而言，我们在设计整个部署架构时，为了避免这种网络分区的发生，一般会将broker节点尽可能的防止在一个机房或者可用区。&lt;/p&gt;

&lt;p&gt;由于 Controller 会给 Broker 发送 3 类请求，&lt;code&gt;LeaderAndIsrRequest&lt;/code&gt;，&lt;code&gt;StopReplicaRequest&lt;/code&gt;，&lt;code&gt;UpdateMetadataRequest&lt;/code&gt;，因此，一旦出现网络分区，这些请求将不能顺利到达 Broker 端。&lt;/p&gt;

&lt;p&gt;这将影响主题的创建、修改、删除操作的信息同步，表现为集群仿佛僵住了一样，无法感知到后面的所有操作。因此，网络分区通常都是非常严重的问题，要赶快修复。&lt;/p&gt;

&lt;h4 id=&#34;19-java-consumer-为什么采用单线程来获取消息&#34;&gt;19.Java Consumer 为什么采用单线程来获取消息？&lt;/h4&gt;

&lt;p&gt;在回答之前，如果先把这句话说出来，一定会加分：&lt;strong&gt;Java Consumer 是双线程的设计。一个线程是用户主线程，负责获取消息；另一个线程是心跳线程，负责向 Kafka 汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的 “假死” 情况。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。另外一个可能的好处是，可以简化代码的开发。多线程交互的代码是非常容易出错的。&lt;/p&gt;

&lt;h4 id=&#34;20-简述-follower-副本消息同步的完整流程&#34;&gt;20.简述 Follower 副本消息同步的完整流程&lt;/h4&gt;

&lt;p&gt;首先，Follower 发送 FETCH 请求给 Leader。&lt;/p&gt;

&lt;p&gt;接着，Leader 会读取底层日志文件中的消息数据，再更新它内存中的 Follower 副本的 LEO 值，更新为 FETCH 请求中的 fetchOffset 值。&lt;/p&gt;

&lt;p&gt;最后，尝试更新分区高水位值。Follower 接收到 FETCH 响应之后，会把消息写入到底层日志，接着更新 LEO 和 HW 值。&lt;/p&gt;

&lt;p&gt;Leader 和 Follower 的 HW 值更新时机是不同的，Follower 的 HW 更新永远落后于 Leader 的 HW。这种时间上的错配是造成各种不一致的原因。&lt;/p&gt;

&lt;p&gt;因此，对于消费者而言，消费到的消息永远是所有副本中最小的那个HW。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfs986oapjj30u01hdaj9.jpg&#34; alt=&#34;胡大的kafka源码课程&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Git常用命令</title>
      <link>https://bgbiao.top/post/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;在日常工作中，可能经常会遇到一些一致性需求，需要将本地代码和Git远端代码保持一致，因此这里就主要来记录一些Git的日常操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;强制覆盖本地代码&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有时候，我们不小心修改错了代码或者之前构思的业务逻辑被推翻了，但是这个迭代中我们增加了很多代码，想要尽快回滚到上一个稳定版本的分支，我们就可以采用强制覆盖本地代码的方式来实现，此时距离上一次commit修改的代码将会被强制覆盖，可以很好的将我们本次的错误需求代码清理掉。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 首先将远端代码全部fetch下来
➜  kafka git:(master) ✗ git fetch --all
Fetching origin
Fetching bgbiao
From https://github.com/goops-top/utils
 * [new branch]      master     -&amp;gt; bgbiao/master

# 将本地代码设置到远端的稳定版本
➜  kafka git:(master) ✗ git reset --hard origin/master
HEAD is now at 1223981 update the go.mod fix the &amp;#39;module declares its path as:&amp;#39;

# 重新pull
➜  kafka git:(master) git pull
Already up to date.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>一文帮你快速回顾正则表达式知识</title>
      <link>https://bgbiao.top/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 在日常工作中，我们经常会使用正则表达式来快速匹配和过滤一些我们期望的字符串来处理一些简单又繁琐的文字统计和过滤操作；而作为一名技术从业者，我们也经常会在程序中或者配置文件中使用正则表达式来处理字符或进行批量配置项的查询和更改，但通常情况下，我们需要对编写的正则表达式进行不断测试才能满足我们的需求，本篇文章带你重新回顾正则表达式，并分享一个在线的正则表达式工具(&lt;a href=&#34;https://regex101.com/)，帮你在工作中快速测试你的正则表达式。&#34;&gt;https://regex101.com/)，帮你在工作中快速测试你的正则表达式。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;什么是正则表达式&#34;&gt;什么是正则表达式？&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;正则表达式是一组由字母和符号组成的特殊文本，它可以用来从文本中找出满足你想要的格式的句子。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个正则表达式是一种从左到右匹配主体字符串的模式。
“Regular expression”这个词比较拗口，我们常使用缩写的术语“regex”或“regexp”。
正则表达式可以从一个基础字符串中根据一定的匹配模式替换文本中的字符串、验证表单、提取字符串等等。&lt;/p&gt;

&lt;p&gt;想象你正在写一个应用，然后你想设定一个用户命名的规则，让用户名包含字符、数字、下划线和连字符，以及限制字符的个数，好让名字看起来没那么丑。
我们使用以下正则表达式来验证一个用户名：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gficxu10luj30hl0bsq3e.jpg&#34; alt=&#34;用户名匹配&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以上的正则表达式可以接受 &lt;code&gt;john_doe&lt;/code&gt;、&lt;code&gt;jo-hn_doe&lt;/code&gt;、&lt;code&gt;john12_as&lt;/code&gt;。
但不匹配&lt;code&gt;Jo&lt;/code&gt;，因为它包含了大写的字母而且太短了。&lt;/p&gt;

&lt;h1 id=&#34;目录&#34;&gt;目录&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#1-基本匹配&#34;&gt;1. 基本匹配&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2-元字符&#34;&gt;2. 元字符&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#21-点运算符-&#34;&gt;2.1 点运算符 .&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#22-字符集&#34;&gt;2.2 字符集&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#221-否定字符集&#34;&gt;2.2.1 否定字符集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#23-重复次数&#34;&gt;2.3 重复次数&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#231--号&#34;&gt;2.3.1 * 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#232--号&#34;&gt;2.3.2 + 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#233--号&#34;&gt;2.3.3 ? 号&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#24--号&#34;&gt;2.4 {} 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#25--特征标群&#34;&gt;2.5 (&amp;hellip;) 特征标群&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#26--或运算符&#34;&gt;2.6 | 或运算符&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#27-转码特殊字符&#34;&gt;2.7 转码特殊字符&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#28-锚点&#34;&gt;2.8 锚点&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#281--号&#34;&gt;2.8.1 ^ 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#282--号&#34;&gt;2.8.2 $ 号&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3-简写字符集&#34;&gt;3. 简写字符集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#4-零宽度断言前后预查&#34;&gt;4. 零宽度断言(前后预查)&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#41--正先行断言&#34;&gt;4.1 ?=&amp;hellip; 正先行断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#42--负先行断言&#34;&gt;4.2 ?!&amp;hellip; 负先行断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#43---正后发断言&#34;&gt;4.3 ?&amp;lt;= &amp;hellip; 正后发断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#44--负后发断言&#34;&gt;4.4 ?&amp;lt;!&amp;hellip; 负后发断言&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#5-标志&#34;&gt;5. 标志&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#51-忽略大小写-case-insensitive&#34;&gt;5.1 忽略大小写（Case Insensitive）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#52-全局搜索-global-search&#34;&gt;5.2 全局搜索（Global search）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#53-多行修饰符-multiline&#34;&gt;5.3 多行修饰符（Multiline）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#额外补充&#34;&gt;额外补充&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#贡献&#34;&gt;贡献&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#许可证&#34;&gt;许可证&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;1-基本匹配&#34;&gt;1. 基本匹配&lt;/h2&gt;

&lt;p&gt;正则表达式其实就是在执行搜索时的格式，它由一些字母和数字组合而成。
例如：一个正则表达式 &lt;code&gt;the&lt;/code&gt;，它表示一个规则：由字母&lt;code&gt;t&lt;/code&gt;开始，接着是&lt;code&gt;h&lt;/code&gt;，再接着是&lt;code&gt;e&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;the&#34; =&gt; The fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dmRygT/1&#34;&gt;https://regex101.com/r/dmRygT/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;正则表达式&lt;code&gt;123&lt;/code&gt;匹配字符串&lt;code&gt;123&lt;/code&gt;。它逐个字符的与输入的正则表达式做比较。&lt;/p&gt;

&lt;p&gt;正则表达式是大小写敏感的，所以&lt;code&gt;The&lt;/code&gt;不会匹配&lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;The&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/1paXsy/1&#34;&gt;https://regex101.com/r/1paXsy/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-元字符&#34;&gt;2. 元字符&lt;/h2&gt;

&lt;p&gt;正则表达式主要依赖于元字符。
元字符不代表他们本身的字面意思，他们都有特殊的含义。一些元字符写在方括号中的时候有一些特殊的意思。以下是一些元字符的介绍：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;元字符&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;.&lt;/td&gt;
&lt;td&gt;句号匹配任意单个字符除了换行符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;[ ]&lt;/td&gt;
&lt;td&gt;字符种类。匹配方括号内的任意字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;[^ ]&lt;/td&gt;
&lt;td&gt;否定的字符种类。匹配除了方括号里的任意字符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;*&lt;/td&gt;
&lt;td&gt;匹配&amp;gt;=0个重复的在*号之前的字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;+&lt;/td&gt;
&lt;td&gt;匹配&amp;gt;=1个重复的+号前的字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&lt;/td&gt;
&lt;td&gt;标记?之前的字符为可选.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;{n,m}&lt;/td&gt;
&lt;td&gt;匹配num个大括号之前的字符或字符集 (n &amp;lt;= num &amp;lt;= m).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;(xyz)&lt;/td&gt;
&lt;td&gt;字符集，匹配与 xyz 完全相等的字符串.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&amp;#124;&lt;/td&gt;
&lt;td&gt;或运算符，匹配符号前或后的字符.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&amp;#92;&lt;/td&gt;
&lt;td&gt;转义字符,用于匹配一些保留的字符 &lt;code&gt;[ ] ( ) { } . * + ? ^ $ \ &amp;#124;&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;^&lt;/td&gt;
&lt;td&gt;从开始行开始匹配.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;$&lt;/td&gt;
&lt;td&gt;从末端开始匹配.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;2-1-点运算符&#34;&gt;2.1 点运算符 &lt;code&gt;.&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt;是元字符中最简单的例子。
&lt;code&gt;.&lt;/code&gt;匹配任意单个字符，但不匹配换行符。
例如，表达式&lt;code&gt;.ar&lt;/code&gt;匹配一个任意字符后面跟着是&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;r&lt;/code&gt;的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;.ar&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/xc9GkU/1&#34;&gt;https://regex101.com/r/xc9GkU/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-2-字符集&#34;&gt;2.2 字符集&lt;/h2&gt;

&lt;p&gt;字符集也叫做字符类。
方括号用来指定一个字符集。
在方括号中使用连字符来指定字符集的范围。
在方括号中的字符集不关心顺序。
例如，表达式&lt;code&gt;[Tt]he&lt;/code&gt; 匹配 &lt;code&gt;the&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;[Tt]he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/2ITLQ4/1&#34;&gt;https://regex101.com/r/2ITLQ4/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;方括号的句号就表示句号。
表达式 &lt;code&gt;ar[.]&lt;/code&gt; 匹配 &lt;code&gt;ar.&lt;/code&gt;字符串&lt;/p&gt;

&lt;pre&gt;
&#34;ar[.]&#34; =&gt; A garage is a good place to park a c&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;ar.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/wL3xtE/1&#34;&gt;https://regex101.com/r/wL3xtE/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-2-1-否定字符集&#34;&gt;2.2.1 否定字符集&lt;/h3&gt;

&lt;p&gt;一般来说 &lt;code&gt;^&lt;/code&gt; 表示一个字符串的开头，但它用在一个方括号的开头的时候，它表示这个字符集是否定的。
例如，表达式&lt;code&gt;[^c]ar&lt;/code&gt; 匹配一个后面跟着&lt;code&gt;ar&lt;/code&gt;的除了&lt;code&gt;c&lt;/code&gt;的任意字符。&lt;/p&gt;

&lt;pre&gt;
&#34;[^c]ar&#34; =&gt; The car &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/nNNlq3/1&#34;&gt;https://regex101.com/r/nNNlq3/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-3-重复次数&#34;&gt;2.3 重复次数&lt;/h2&gt;

&lt;p&gt;后面跟着元字符 &lt;code&gt;+&lt;/code&gt;，&lt;code&gt;*&lt;/code&gt; or &lt;code&gt;?&lt;/code&gt; 的，用来指定匹配子模式的次数。
这些元字符在不同的情况下有着不同的意思。&lt;/p&gt;

&lt;h3 id=&#34;2-3-1-号&#34;&gt;2.3.1 &lt;code&gt;*&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;*&lt;/code&gt;号匹配 在&lt;code&gt;*&lt;/code&gt;之前的字符出现&lt;code&gt;大于等于0&lt;/code&gt;次。
例如，表达式 &lt;code&gt;a*&lt;/code&gt; 匹配0或更多个以a开头的字符。表达式&lt;code&gt;[a-z]*&lt;/code&gt; 匹配一个行中所有以小写字母开头的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;[a-z]*&#34; =&gt; T&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;he&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;parked&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;in&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;garage&lt;/strong&gt;&lt;/a&gt; #21.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/7m8me5/1&#34;&gt;https://regex101.com/r/7m8me5/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;*&lt;/code&gt;字符和&lt;code&gt;.&lt;/code&gt;字符搭配可以匹配所有的字符&lt;code&gt;.*&lt;/code&gt;。
&lt;code&gt;*&lt;/code&gt;和表示匹配空格的符号&lt;code&gt;\s&lt;/code&gt;连起来用，如表达式&lt;code&gt;\s*cat\s*&lt;/code&gt;匹配0或更多个空格开头和0或更多个空格结尾的cat字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;\s*cat\s*&#34; =&gt; The fat&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt; cat &lt;/strong&gt;&lt;/a&gt;sat on the con&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt;enation.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/gGrwuz/1&#34;&gt;https://regex101.com/r/gGrwuz/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-3-2-号&#34;&gt;2.3.2 &lt;code&gt;+&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;+&lt;/code&gt;号匹配&lt;code&gt;+&lt;/code&gt;号之前的字符出现 &amp;gt;=1 次。
例如表达式&lt;code&gt;c.+t&lt;/code&gt; 匹配以首字母&lt;code&gt;c&lt;/code&gt;开头以&lt;code&gt;t&lt;/code&gt;结尾，中间跟着至少一个字符的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;c.+t&#34; =&gt; The fat &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat sat on the mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Dzf9Aa/1&#34;&gt;https://regex101.com/r/Dzf9Aa/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-3-3-号&#34;&gt;2.3.3 &lt;code&gt;?&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;在正则表达式中元字符 &lt;code&gt;?&lt;/code&gt; 标记在符号前面的字符为可选，即出现 0 或 1 次。
例如，表达式 &lt;code&gt;[T]?he&lt;/code&gt; 匹配字符串 &lt;code&gt;he&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;[T]he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in the garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/cIg9zm/1&#34;&gt;https://regex101.com/r/cIg9zm/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;[T]?he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in t&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;he&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/kPpO2x/1&#34;&gt;https://regex101.com/r/kPpO2x/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-4-号&#34;&gt;2.4 &lt;code&gt;{}&lt;/code&gt; 号&lt;/h2&gt;

&lt;p&gt;在正则表达式中 &lt;code&gt;{}&lt;/code&gt; 是一个量词，常用来限定一个或一组字符可以重复出现的次数。
例如， 表达式 &lt;code&gt;[0-9]{2,3}&lt;/code&gt; 匹配最少 2 位最多 3 位 0~9 的数字。&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{2,3}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;999&lt;/strong&gt;&lt;/a&gt;7 but we rounded it off to &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/a&gt;.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/juM86s/1&#34;&gt;https://regex101.com/r/juM86s/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;我们可以省略第二个参数。
例如，&lt;code&gt;[0-9]{2,}&lt;/code&gt; 匹配至少两位 0~9 的数字。&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{2,}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;9997&lt;/strong&gt;&lt;/a&gt; but we rounded it off to &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/a&gt;.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Gdy4w5/1&#34;&gt;https://regex101.com/r/Gdy4w5/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;如果逗号也省略掉则表示重复固定的次数。
例如，&lt;code&gt;[0-9]{3}&lt;/code&gt; 匹配3位数字&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{3}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;999&lt;/strong&gt;&lt;/a&gt;7 but we rounded it off to 10.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Sivu30/1&#34;&gt;https://regex101.com/r/Sivu30/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-5-特征标群&#34;&gt;2.5 &lt;code&gt;(...)&lt;/code&gt; 特征标群&lt;/h2&gt;

&lt;p&gt;特征标群是一组写在 &lt;code&gt;(...)&lt;/code&gt; 中的子模式。&lt;code&gt;(...)&lt;/code&gt; 中包含的内容将会被看成一个整体，和数学中小括号（ ）的作用相同。例如, 表达式 &lt;code&gt;(ab)*&lt;/code&gt; 匹配连续出现 0 或更多个 &lt;code&gt;ab&lt;/code&gt;。如果没有使用 &lt;code&gt;(...)&lt;/code&gt; ，那么表达式 &lt;code&gt;ab*&lt;/code&gt; 将匹配连续出现 0 或更多个 &lt;code&gt;b&lt;/code&gt; 。再比如之前说的 &lt;code&gt;{}&lt;/code&gt; 是用来表示前面一个字符出现指定次数。但如果在 &lt;code&gt;{}&lt;/code&gt; 前加上特征标群 &lt;code&gt;(...)&lt;/code&gt; 则表示整个标群内的字符重复 N 次。&lt;/p&gt;

&lt;p&gt;我们还可以在 &lt;code&gt;()&lt;/code&gt; 中用或字符 &lt;code&gt;|&lt;/code&gt; 表示或。例如，&lt;code&gt;(c|g|p)ar&lt;/code&gt; 匹配 &lt;code&gt;car&lt;/code&gt; 或 &lt;code&gt;gar&lt;/code&gt; 或 &lt;code&gt;par&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;
&#34;(c|g|p)ar&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; is &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/tUxrBG/1&#34;&gt;https://regex101.com/r/tUxrBG/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-6-或运算符&#34;&gt;2.6 &lt;code&gt;|&lt;/code&gt; 或运算符&lt;/h2&gt;

&lt;p&gt;或运算符就表示或，用作判断条件。&lt;/p&gt;

&lt;p&gt;例如 &lt;code&gt;(T|t)he|car&lt;/code&gt; 匹配 &lt;code&gt;(T|t)he&lt;/code&gt; 或 &lt;code&gt;car&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he|car&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; is parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/fBXyX0/1&#34;&gt;https://regex101.com/r/fBXyX0/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-7-转码特殊字符&#34;&gt;2.7 转码特殊字符&lt;/h2&gt;

&lt;p&gt;反斜线 &lt;code&gt;\&lt;/code&gt; 在表达式中用于转码紧跟其后的字符。用于指定 &lt;code&gt;{ } [ ] / \ + * . $ ^ | ?&lt;/code&gt; 这些特殊字符。如果想要匹配这些特殊字符则要在其前面加上反斜线 &lt;code&gt;\&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;例如 &lt;code&gt;.&lt;/code&gt; 是用来匹配除换行符外的所有字符的。如果想要匹配句子中的 &lt;code&gt;.&lt;/code&gt; 则要写成 &lt;code&gt;\.&lt;/code&gt; 以下这个例子 &lt;code&gt;\.?&lt;/code&gt;是选择性匹配&lt;code&gt;.&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;
&#34;(f|c|m)at\.?&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt; sat on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/DOc5Nu/1&#34;&gt;https://regex101.com/r/DOc5Nu/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-8-锚点&#34;&gt;2.8 锚点&lt;/h2&gt;

&lt;p&gt;在正则表达式中，想要匹配指定开头或结尾的字符串就要使用到锚点。&lt;code&gt;^&lt;/code&gt; 指定开头，&lt;code&gt;$&lt;/code&gt; 指定结尾。&lt;/p&gt;

&lt;h3 id=&#34;2-8-1-号&#34;&gt;2.8.1 &lt;code&gt;^&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;^&lt;/code&gt; 用来检查匹配的字符串是否在所匹配字符串的开头。&lt;/p&gt;

&lt;p&gt;例如，在 &lt;code&gt;abc&lt;/code&gt; 中使用表达式 &lt;code&gt;^a&lt;/code&gt; 会得到结果 &lt;code&gt;a&lt;/code&gt;。但如果使用 &lt;code&gt;^b&lt;/code&gt; 将匹配不到任何结果。因为在字符串 &lt;code&gt;abc&lt;/code&gt; 中并不是以 &lt;code&gt;b&lt;/code&gt; 开头。&lt;/p&gt;

&lt;p&gt;例如，&lt;code&gt;^(T|t)he&lt;/code&gt; 匹配以 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt; 开头的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/5ljjgB/1&#34;&gt;https://regex101.com/r/5ljjgB/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;^(T|t)he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in the garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/jXrKne/1&#34;&gt;https://regex101.com/r/jXrKne/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-8-2-号&#34;&gt;2.8.2 &lt;code&gt;$&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;同理于 &lt;code&gt;^&lt;/code&gt; 号，&lt;code&gt;$&lt;/code&gt; 号用来匹配字符是否是最后一个。&lt;/p&gt;

&lt;p&gt;例如，&lt;code&gt;(at\.)$&lt;/code&gt; 匹配以 &lt;code&gt;at.&lt;/code&gt; 结尾的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;(at\.)&#34; =&gt; The fat c&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt; s&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt; on the m&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/y4Au4D/1&#34;&gt;https://regex101.com/r/y4Au4D/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;(at\.)$&#34; =&gt; The fat cat. sat. on the m&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/t0AkOd/1&#34;&gt;https://regex101.com/r/t0AkOd/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;3-简写字符集&#34;&gt;3. 简写字符集&lt;/h2&gt;

&lt;p&gt;正则表达式提供一些常用的字符集简写。如下:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;简写&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;.&lt;/td&gt;
&lt;td&gt;除换行符外的所有字符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\w&lt;/td&gt;
&lt;td&gt;匹配所有字母数字，等同于 &lt;code&gt;[a-zA-Z0-9_]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\W&lt;/td&gt;
&lt;td&gt;匹配所有非字母数字，即符号，等同于： &lt;code&gt;[^\w]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\d&lt;/td&gt;
&lt;td&gt;匹配数字： &lt;code&gt;[0-9]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\D&lt;/td&gt;
&lt;td&gt;匹配非数字： &lt;code&gt;[^\d]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\s&lt;/td&gt;
&lt;td&gt;匹配所有空格字符，等同于： &lt;code&gt;[\t\n\f\r\p{Z}]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\S&lt;/td&gt;
&lt;td&gt;匹配所有非空格字符： &lt;code&gt;[^\s]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\f&lt;/td&gt;
&lt;td&gt;匹配一个换页符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\n&lt;/td&gt;
&lt;td&gt;匹配一个换行符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\r&lt;/td&gt;
&lt;td&gt;匹配一个回车符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\t&lt;/td&gt;
&lt;td&gt;匹配一个制表符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\v&lt;/td&gt;
&lt;td&gt;匹配一个垂直制表符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\p&lt;/td&gt;
&lt;td&gt;匹配 CR/LF（等同于 &lt;code&gt;\r\n&lt;/code&gt;），用来匹配 DOS 行终止符&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;4-零宽度断言-前后预查&#34;&gt;4. 零宽度断言（前后预查）&lt;/h2&gt;

&lt;p&gt;先行断言和后发断言都属于&lt;strong&gt;非捕获簇&lt;/strong&gt;（不捕获文本 ，也不针对组合计进行计数）。
先行断言用于判断所匹配的格式是否在另一个确定的格式之前，匹配结果不包含该确定格式（仅作为约束）。&lt;/p&gt;

&lt;p&gt;例如，我们想要获得所有跟在 &lt;code&gt;$&lt;/code&gt; 符号后的数字，我们可以使用正后发断言 &lt;code&gt;(?&amp;lt;=\$)[0-9\.]*&lt;/code&gt;。
这个表达式匹配 &lt;code&gt;$&lt;/code&gt; 开头，之后跟着 &lt;code&gt;0,1,2,3,4,5,6,7,8,9,.&lt;/code&gt; 这些字符可以出现大于等于 0 次。&lt;/p&gt;

&lt;p&gt;零宽度断言如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;符号&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?=&lt;/td&gt;
&lt;td&gt;正先行断言-存在&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?!&lt;/td&gt;
&lt;td&gt;负先行断言-排除&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&amp;lt;=&lt;/td&gt;
&lt;td&gt;正后发断言-存在&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&amp;lt;!&lt;/td&gt;
&lt;td&gt;负后发断言-排除&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;4-1-正先行断言&#34;&gt;4.1 &lt;code&gt;?=...&lt;/code&gt; 正先行断言&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;?=...&lt;/code&gt; 正先行断言，表示第一部分表达式之后必须跟着 &lt;code&gt;?=...&lt;/code&gt;定义的表达式。&lt;/p&gt;

&lt;p&gt;返回结果只包含满足匹配条件的第一部分表达式。
定义一个正先行断言要使用 &lt;code&gt;()&lt;/code&gt;。在括号内部使用一个问号和等号： &lt;code&gt;(?=...)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;正先行断言的内容写在括号中的等号后面。
例如，表达式 &lt;code&gt;(T|t)he(?=\sfat)&lt;/code&gt; 匹配 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt;，在括号中我们又定义了正先行断言 &lt;code&gt;(?=\sfat)&lt;/code&gt; ，即 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt; 后面紧跟着 &lt;code&gt;(空格)fat&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he(?=\sfat)&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/IDDARt/1&#34;&gt;https://regex101.com/r/IDDARt/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-2-负先行断言&#34;&gt;4.2 &lt;code&gt;?!...&lt;/code&gt; 负先行断言&lt;/h3&gt;

&lt;p&gt;负先行断言 &lt;code&gt;?!&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其后不跟随着断言中定义的格式。
&lt;code&gt;正先行断言&lt;/code&gt;  定义和 &lt;code&gt;负先行断言&lt;/code&gt; 一样，区别就是 &lt;code&gt;=&lt;/code&gt; 替换成 &lt;code&gt;!&lt;/code&gt; 也就是 &lt;code&gt;(?!...)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;表达式 &lt;code&gt;(T|t)he(?!\sfat)&lt;/code&gt; 匹配 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt;，且其后不跟着 &lt;code&gt;(空格)fat&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he(?!\sfat)&#34; =&gt; The fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/V32Npg/1&#34;&gt;https://regex101.com/r/V32Npg/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-3-正后发断言&#34;&gt;4.3 &lt;code&gt;?&amp;lt;= ...&lt;/code&gt; 正后发断言&lt;/h3&gt;

&lt;p&gt;正后发断言 记作&lt;code&gt;(?&amp;lt;=...)&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其前跟随着断言中定义的格式。
例如，表达式 &lt;code&gt;(?&amp;lt;=(T|t)he\s)(fat|mat)&lt;/code&gt; 匹配 &lt;code&gt;fat&lt;/code&gt; 和 &lt;code&gt;mat&lt;/code&gt;，且其前跟着 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(?&lt;=(T|t)he\s)(fat|mat)&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; cat sat on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/avH165/1&#34;&gt;https://regex101.com/r/avH165/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-4-负后发断言&#34;&gt;4.4 &lt;code&gt;?&amp;lt;!...&lt;/code&gt; 负后发断言&lt;/h3&gt;

&lt;p&gt;负后发断言 记作 &lt;code&gt;(?&amp;lt;!...)&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其前不跟随着断言中定义的格式。
例如，表达式 &lt;code&gt;(?&amp;lt;!(T|t)he\s)(cat)&lt;/code&gt; 匹配 &lt;code&gt;cat&lt;/code&gt;，且其前不跟着 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(?&amp;lt;!(T|t)he\s)(cat)&#34; =&gt; The cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/8Efx5G/1&#34;&gt;https://regex101.com/r/8Efx5G/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;5-标志&#34;&gt;5. 标志&lt;/h2&gt;

&lt;p&gt;标志也叫模式修正符，因为它可以用来修改表达式的搜索结果。
这些标志可以任意的组合使用，它也是整个正则表达式的一部分。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;标志&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;i&lt;/td&gt;
&lt;td&gt;忽略大小写。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;g&lt;/td&gt;
&lt;td&gt;全局搜索。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;m&lt;/td&gt;
&lt;td&gt;多行修饰符：锚点元字符 &lt;code&gt;^&lt;/code&gt; &lt;code&gt;$&lt;/code&gt; 工作范围在每行的起始。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;5-1-忽略大小写-case-insensitive&#34;&gt;5.1 忽略大小写（Case Insensitive）&lt;/h3&gt;

&lt;p&gt;修饰语 &lt;code&gt;i&lt;/code&gt; 用于忽略大小写。
例如，表达式 &lt;code&gt;/The/gi&lt;/code&gt; 表示在全局搜索 &lt;code&gt;The&lt;/code&gt;，在后面的 &lt;code&gt;i&lt;/code&gt; 将其条件修改为忽略大小写，则变成搜索 &lt;code&gt;the&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;，&lt;code&gt;g&lt;/code&gt; 表示全局搜索。&lt;/p&gt;

&lt;pre&gt;
&#34;The&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dpQyf9/1&#34;&gt;https://regex101.com/r/dpQyf9/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/The/gi&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/ahfiuh/1&#34;&gt;https://regex101.com/r/ahfiuh/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;5-2-全局搜索-global-search&#34;&gt;5.2 全局搜索（Global search）&lt;/h3&gt;

&lt;p&gt;修饰符 &lt;code&gt;g&lt;/code&gt; 常用于执行一个全局搜索匹配，即（不仅仅返回第一个匹配的，而是返回全部）。
例如，表达式 &lt;code&gt;/.(at)/g&lt;/code&gt; 表示搜索 任意字符（除了换行）+ &lt;code&gt;at&lt;/code&gt;，并返回全部结果。&lt;/p&gt;

&lt;pre&gt;
&#34;/.(at)/&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/jnk6gM/1&#34;&gt;https://regex101.com/r/jnk6gM/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/.(at)/g&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;sat&lt;/strong&gt;&lt;/a&gt; on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dO1nef/1&#34;&gt;https://regex101.com/r/dO1nef/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;5-3-多行修饰符-multiline&#34;&gt;5.3 多行修饰符（Multiline）&lt;/h3&gt;

&lt;p&gt;多行修饰符 &lt;code&gt;m&lt;/code&gt; 常用于执行一个多行匹配。&lt;/p&gt;

&lt;p&gt;像之前介绍的 &lt;code&gt;(^,$)&lt;/code&gt; 用于检查格式是否是在待检测字符串的开头或结尾。但我们如果想要它在每行的开头和结尾生效，我们需要用到多行修饰符 &lt;code&gt;m&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;例如，表达式 &lt;code&gt;/at(.)?$/gm&lt;/code&gt; 表示小写字符 &lt;code&gt;a&lt;/code&gt; 后跟小写字符 &lt;code&gt;t&lt;/code&gt; ，末尾可选除换行符外任意字符。根据 &lt;code&gt;m&lt;/code&gt; 修饰符，现在表达式匹配每行的结尾。&lt;/p&gt;

&lt;pre&gt;
&#34;/.at(.)?$/&#34; =&gt; The fat
                cat sat
                on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/hoGMkP/1&#34;&gt;https://regex101.com/r/hoGMkP/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/.at(.)?$/gm&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt;
                  cat &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;sat&lt;/strong&gt;&lt;/a&gt;
                  on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/E88WE2/1&#34;&gt;https://regex101.com/r/E88WE2/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;6-贪婪匹配与惰性匹配-greedy-vs-lazy-matching&#34;&gt;6. 贪婪匹配与惰性匹配（Greedy vs lazy matching）&lt;/h3&gt;

&lt;p&gt;正则表达式默认采用贪婪匹配模式，在该模式下意味着会匹配尽可能长的子串。我们可以使用 &lt;code&gt;?&lt;/code&gt; 将贪婪匹配模式转化为惰性匹配模式。&lt;/p&gt;

&lt;pre&gt;
&#34;/(.*at)/&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The fat cat sat on the mat&lt;/strong&gt;&lt;/a&gt;. &lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/AyAdgJ/1&#34;&gt;https://regex101.com/r/AyAdgJ/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/(.*?at)/&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The fat&lt;/strong&gt;&lt;/a&gt; cat sat on the mat. &lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/AyAdgJ/2&#34;&gt;https://regex101.com/r/AyAdgJ/2&lt;/a&gt;)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>ElasticSearch架构解析与最佳实践</title>
      <link>https://bgbiao.top/post/elasticsearch%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/elasticsearch%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6talv0b0j30u00gwgmv.jpg&#34; alt=&#34;目录&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6taz9e6mj30u00gwgn1.jpg&#34; alt=&#34;应用概述-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tbcoytlj30u00gw0v2.jpg&#34; alt=&#34;应用概述-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tc1k3flj30u00gwdih.jpg&#34; alt=&#34;应用概述-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tcd3b6zj30u00gw416.jpg&#34; alt=&#34;应用概述-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tcptmk3j30u00gwju7.jpg&#34; alt=&#34;Lucene内核原理-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tdh8oo9j30u00gwq5d.jpg&#34; alt=&#34;Lucene内核原理-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tdtnjioj30u00gwq67.jpg&#34; alt=&#34;Lucene内核原理-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6te64te2j30u00gw76q.jpg&#34; alt=&#34;Lucene内核原理-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tegzbfej30u00gwgnr.jpg&#34; alt=&#34;Lucene内核原理-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tesbdjrj30u00gwq4l.jpg&#34; alt=&#34;Lucene内核原理-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tf62pxfj30u00gwmzk.jpg&#34; alt=&#34;Lucene内核原理-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tfo8dnyj30u00gwdit.jpg&#34; alt=&#34;ElasticSearch架构解析&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tg98nsrj30u00gwwgz.jpg&#34; alt=&#34;ElasticSearch架构解析-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tgl8k6aj30u00gw41m.jpg&#34; alt=&#34;ElasticSearch架构解析-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tgy5lhqj30u00gwtbh.jpg&#34; alt=&#34;ElasticSearch架构解析-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6th9bynxj30u00gwgoi.jpg&#34; alt=&#34;ElasticSearch架构解析-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6thjuhgtj30u00gwwgb.jpg&#34; alt=&#34;ElasticSearch架构解析-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6thyvb72j30u00gwwgy.jpg&#34; alt=&#34;ElasticSearch架构解析-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tiaoksoj30u00gwq57.jpg&#34; alt=&#34;最佳实践-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tinieeyj30u00gwq51.jpg&#34; alt=&#34;最佳实践-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tiy8yc4j30u00gw40r.jpg&#34; alt=&#34;最佳实践-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tj6kki5j30u00gwmz3.jpg&#34; alt=&#34;最佳实践-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tjflhouj30u00gwmzs.jpg&#34; alt=&#34;最佳实践-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tjrhom9j30u00gw414.jpg&#34; alt=&#34;最佳实践-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tk30ujjj30u00gwwgd.jpg&#34; alt=&#34;最佳实践-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tkez1t6j30u00gwacw.jpg&#34; alt=&#34;最佳实践-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tksdke2j30u00gwgmw.jpg&#34; alt=&#34;性能调优-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tl2qkemj30u00gw76f.jpg&#34; alt=&#34;性能调优-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlejqftj30u00gwjtk.jpg&#34; alt=&#34;性能调优-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlpduy6j30u00gw0ut.jpg&#34; alt=&#34;性能调优-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlz6ifvj30u00gwmzi.jpg&#34; alt=&#34;性能调优-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tm9ln5dj30u00gw410.jpg&#34; alt=&#34;性能调优-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tmjx424j30u00gwmyd.jpg&#34; alt=&#34;性能调优-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tmta1rxj30u00gwacb.jpg&#34; alt=&#34;性能调优-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tn4mub6j30u00gw76f.jpg&#34; alt=&#34;性能调优-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tni8rnxj30u00gw410.jpg&#34; alt=&#34;性能调优-10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tnset4mj30u00gwacc.jpg&#34; alt=&#34;性能调优-11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6to3orh5j30u00gwmxu.jpg&#34; alt=&#34;性能调优-12&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>kafka端到端的延迟</title>
      <link>https://bgbiao.top/post/kafka%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%BB%B6%E8%BF%9F/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%BB%B6%E8%BF%9F/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 在大规模的使用kafka过程中，我们通常会遇到各种各样的问题，比如说，通常会有一些大数据集群中的Job发现总有几个task会比较慢，导致整体的任务迟迟不能完成运行，这种情况通常问题会比较复杂，想要知道具体延迟在哪里，我们需要知道在Kafka集群中哪些点可能会增加端到端的延迟。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;接下来的内容翻译自&lt;code&gt;confluent&lt;/code&gt;官网博客中的一篇文章，希望能够帮助大家理解kafka使用过程中端到端的延迟。&lt;a href=&#34;https://www.confluent.io/blog/configure-kafka-to-minimize-latency/&#34;&gt;99th Percentile Latency at Scale with Apache Kafka&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;欺诈检测、支付系统和股票交易平台只是许多Apache Kafka用例中的一小部分，这些用例需要快速且可预测的数据交付。例如，在线银行交易的欺诈检测必须实时发生，以交付业务价值，而不需要为每个交易增加超过50 100毫秒的开销，以保持良好的客户体验。&lt;/p&gt;

&lt;p&gt;在Kafka术语中，数据交付时间(data delivery time)是由&lt;code&gt;端到端延迟(end-to-end latency)&lt;/code&gt;定义的，即&lt;code&gt;消费者获取一条向Kafka生成的记录所需的时间&lt;/code&gt;。延迟目标表示为目标延迟和满足此目标的重要性。例如，您的延迟目标可以表示为:我希望99%的情况下从Kafka获得端到端延迟为50 ms。&lt;/p&gt;

&lt;p&gt;这将增加&lt;code&gt;可用性、持久性和吞吐量&lt;/code&gt;目标。实现高持久性和高吞吐量两个目标，我们需要进行一定的权衡，挑战在于在保持延迟界限的同时扩展应用程序的吞吐量，并调整Kafka集群的大小以使用可接受的Broker延迟来处理客户端和复制的请求。延迟也取决于您对硬件或云提供商的选择，所以您需要能够监视和调优您的客户端，以在您独特的环境中实现您的特定延迟目标。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 通常情况下，Broker所在的网络区域其实也会对延迟造成很大影响，当然这仍然取决于您对可用性和延迟的权衡。&lt;/p&gt;

&lt;p&gt;之前，我们有写过白皮书&lt;a href=&#34;https://www.confluent.io/white-paper/optimizing-your-apache-kafka-deployment/&#34;&gt;optimizing-your-apache-kafka-deployment&lt;/a&gt;，其中列出了配置Kafka部署以优化各种目标的指导原则。&lt;/p&gt;

&lt;p&gt;这篇文章将帮助您进一步获得更好的直觉和对端到端延迟的理解，并配置和扩展您的应用程序的吞吐量，同时保持延迟的界限。&lt;/p&gt;

&lt;h4 id=&#34;理解到端的延迟-end-to-end-latency&#34;&gt;理解到端的延迟(end-to-end latency)&lt;/h4&gt;

&lt;p&gt;端到端延时是指应用逻辑调用&lt;code&gt;KafkaProducer.send()&lt;/code&gt;生产消息到该消息被应用逻辑通过&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;消费到之间的时间。&lt;/p&gt;

&lt;p&gt;下图显示了一条记录在系统中的路径，从Kafkas生产者到Kafka的Broker节点，副本的复制，以及消费者最终在其主体分区日志中获取到具体的消息。&lt;/p&gt;

&lt;p&gt;因此，端到端的延迟主要会由以下几个部分组成:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Produce time&lt;/code&gt;: 内部Kafka producer处理消息并将消息打包的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Publish time&lt;/code&gt;: producer发送到broker并写入到leader副本log的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Commit time&lt;/code&gt;: follower副本备份消息的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Catch-up time&lt;/code&gt;: 消费者追赶消费进度，消费到该消息位移值前所花费的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Fetch time&lt;/code&gt;: 从broker读取该消息的时间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2l82tu4nj30nd0dz40n.jpg&#34; alt=&#34;kafka端到端的延迟&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在接下来的内容中，我们将分别解释这五个延迟阶段的具体含义，特定的客户端配置或应用逻辑设计通常会极大地影响端到端延时，因此我们有必要精准定位哪个因素对延时的影响最大。&lt;/p&gt;

&lt;h4 id=&#34;produce-time&#34;&gt;Produce time&lt;/h4&gt;

&lt;p&gt;Produce time 指的是从应用程序通过&lt;code&gt;KafkaProducer.send()&lt;/code&gt;生产一条记录到包含该消息的生产者请求被发往leader副本所在的broker之间的时间。(因此，生产者所处的网络环境以及对应topic分区leader副本所在的broker的网络可能会影响到produce time的延迟)&lt;/p&gt;

&lt;p&gt;Kafka producer会将&lt;code&gt;相同topic分区&lt;/code&gt;下的一组消息打包在一起形成一个批次（batch）以提升网络I/O性能。(在必要情况下，我们可以对生产者的batch size进行一定的调整)&lt;/p&gt;

&lt;p&gt;默认情况下，producer会立即发送batch，这样一个batch中通常不会包含太多的消息。为了提高batch的效率，生产者通常会对&lt;code&gt;linger.ms&lt;/code&gt;来人为设置一个较小的延迟来保证有足够多的消息记录能封装在一个batch中。一旦过了&lt;code&gt;linger.ms&lt;/code&gt;设置的事件，或者batch size已经达到最大值(&lt;code&gt;batch.size&lt;/code&gt;的参数值)，这个batch将被认为已经完成。&lt;/p&gt;

&lt;p&gt;如果生产者也开启了压缩(&lt;code&gt;compression.type&lt;/code&gt;)，kafka的生产者会将已完成的batch进行压缩。在batch完成之前，它的大小时根据生产者指定的压缩类型和之前观测到的压缩比率估算出来的。&lt;/p&gt;

&lt;p&gt;如果发送给leader副本的未确认的生产者请求数量已经达到最大(&lt;code&gt;max.inflight.requests.per.connection=5&lt;/code&gt;)，则在生产者的批处理可能需要等待更长的时间。因此，broker响应生产者请求越快，生产者的等待时间也将会变得更小。&lt;/p&gt;

&lt;h4 id=&#34;publish-time&#34;&gt;Publish time&lt;/h4&gt;

&lt;p&gt;Publish time是指内部kafka生产者发送生产者请求到一个broker节点，并且对应的消息到达leader副本日志之间的时间。当请求到达Broker节点时，负责连接的网络线程将获取该请求并将其放入请求队列中。其中一个请求处理程序线程从队列中获取请求并处理它们。(对应broker节点的num.thread 和num.io.thread两个相关参数)&lt;/p&gt;

&lt;p&gt;因此，Publish time包含生产者请求的网络时间，broker上的排队时间，以及将消息追加到日志所消耗的时间(通常也是page cache 的访问时间)。当Broker端负载比较低，网络和日志的追加写入时间会影响publish time，随着broker负载变高，队列延迟的增加
将会更多的影响publish time。&lt;/p&gt;

&lt;h4 id=&#34;commit-time&#34;&gt;Commit time&lt;/h4&gt;

&lt;p&gt;Commit time是指从leader副本中复制消息到全部的同步副本(all in-sync replicas)中所消耗的时间。kafka只会将已提交(committed)的消息暴露给consumer，也就是该消息必须在全部的ISR中包含。follower副本中的消息会从leader副本中并行的拉取，在一个正常的集群中，我们通常不希望副本处于不同步状态(当然有的业务场景可能会导致短暂的不同步现象)。这意味着消息被提交的时间等于ISR中最慢的follower副本所在broker去从ledaer broker节点获取记录并写入到follower副本日志的时间。&lt;/p&gt;

&lt;p&gt;为了复制数据，follower所在的broker会想leader节点发送fetch请求，准确的来讲消费者也是使用fetch请求来获取消息。但是，官方在副本复制的fetch请求中，broker端优化了默认配置: leader副本会尽早的发送请求，只要有一个字节可用，就会发起fetch请求(由&lt;code&gt;replica.fetch.min.bytes&lt;/code&gt;参数控制)或者当&lt;code&gt;replica.fetch.wait.max.ms&lt;/code&gt;满足条件。Commit time主要受副本因此配置参数的影响以及集群的当前负载情况。&lt;/p&gt;

&lt;h4 id=&#34;catch-up-time&#34;&gt;Catch-up time&lt;/h4&gt;

&lt;p&gt;Kafka中消息是按照其生产的顺序被消费的，除非显示的声明了一个新的offset或者有一个新的消费者从最新的offset进行消费。同一个分区下，consumer必须要消费完之前发布的消息后才能读取后面的消息。假设在提交消息时，消费者的偏移量是提交消息后面的N条消息，那么，Catch-up time就是消费者消费者N条消息的总时间.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2mnjafg2j30rs0723z1.jpg&#34; alt=&#34;Catch-up time&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当我们在构建实时处理应用的时候，最好让catch-up时间为0，即一旦消息被提交，消费者可以立马读取到消息。如果消费者总是落后，端到端延迟可能会变得无限大。因此，catch-up 时间通常依赖于消费者的能力是否能够追赶上生产者的吞吐量。&lt;/p&gt;

&lt;h4 id=&#34;fetch-time&#34;&gt;Fetch time&lt;/h4&gt;

&lt;p&gt;订阅主题分区的消费者会不断轮询去从leader副本中获取更多的数据，Fetch time是从leader副本所在broker节点获取消息记录的s时间，可能需要等待足够的数据来形成对fetch请求的响应，并从&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;的响应中返回记录。在默认的配置下，已经对于消费者的fetch延迟做了优化(&lt;code&gt;fetch.min.bytes&lt;/code&gt;=1)，即及时只有一个字节可用的时候，fetch请求也会响应数据，或者在一个短暂超时之后&lt;code&gt;fetch.max.wait.ms&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;end-to-end-latency-vs-producer-and-consumer-latencies&#34;&gt;End-to-end latency VS producer and consumer latencies&lt;/h4&gt;

&lt;p&gt;下图显示了Kafka客户端观察到的延迟(通常称为生产者延迟和消费者延迟)与端到端延迟之间的关系。&lt;/p&gt;

&lt;p&gt;生产者延迟是指&lt;code&gt;KafkaProducer.send()&lt;/code&gt;发送和生产的消息被确认间的事件。消息的确认依赖于&lt;code&gt;acks&lt;/code&gt;的配置，该参数可以控制消息的持久性(durability):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当&lt;code&gt;acks=0&lt;/code&gt;，立即确认，不等待broker的返回&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;acks=1&lt;/code&gt;，消息被追加到leader副本所在分区后再确认&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;acks=all&lt;/code&gt;，在所有的ISR(同步副本)都接收到消息时才确认&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，生产者延迟包含&lt;code&gt;produce time&lt;/code&gt;,&lt;code&gt;publich time(如果acks &amp;gt;= 1)&lt;/code&gt;,&lt;code&gt;commit time(如果acks=all)&lt;/code&gt; 以及生产者响应从broker返回到生产者的时间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2n8dbz3bj30rs08a75c.jpg&#34; alt=&#34;end-to-end-latency and producer time&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图清晰的向我们展示了为何改变&lt;code&gt;acks&lt;/code&gt;参数能够减少生产者延迟(其实是通过从生产者延迟中移除几个延迟概念来减少的&lt;code&gt;publish和commit&lt;/code&gt;)。不过，无论我们如何配置生产者的&lt;code&gt;acks&lt;/code&gt;参数，publish和commit 时间总是端到端延迟的一部分。&lt;/p&gt;

&lt;p&gt;消费者延迟(Consumer latency)是指消费者发起一个fetch请求到broker节点，以及broker节点向consumer返回响应的时间。计算方法是&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;返回的时间。Consumer的延迟主要包含了上图中的fetch time&lt;/p&gt;

&lt;h4 id=&#34;控制end-to-end-latency&#34;&gt;控制end-to-end latency&lt;/h4&gt;

&lt;p&gt;如果我们思考一条消息的生命周期，控制端到端延时其实就是控制消息在系统中流转的时间总和。很多Kafka clients端和broker端参数的默认值已然对延时做了优化：比如减少人为等待时间来提高批处理的能力(通过&lt;code&gt;linger.ms&lt;/code&gt;,&lt;code&gt;fetch.min.bytes&lt;/code&gt;,&lt;code&gt;replica.fetch.min.bytes&lt;/code&gt;参数来适当调优)。其他的延时可能来自于broker端上的队列等候时间，控制这种延时就要涉及控制broker的负载（CPU或吞吐量），通常情况下我们要时刻关注broker节点的各项基础监控指标。&lt;/p&gt;

&lt;p&gt;如果我们将系统视为一个整体，那么整个端到端的延迟还要求系统中的每一个部分(生产者,broker,消费者)都能够可靠的维持应用程序逻辑所需的吞吐量。&lt;/p&gt;

&lt;p&gt;例如，如果您的应用程序逻辑以100 MB/s发送数据，但是由于某种原因，您的Kafka消费者吞吐量在几秒钟内下降到10 MB/s，那么在此之前产生的大多数消息都需要在系统中等待更长的时间，直到消费者赶上了。此时，你需要一种高效的方式来扩展你的Kafka clients程序以提升吞吐量——高效地利用broker端资源来减少队列等候时间和偶发的网络拥塞。&lt;/p&gt;

&lt;p&gt;理想情况下，限制延迟意味着确保所有延迟都低于目标。但实际生产环境中，由于意外故障和峰值负载，这种严格的保证是不可能的。不过，可以设计应用程序并对系统进行调优，以实现95%的延迟目标，控制所有的消息延迟在95~99%低于目标延迟时间。高百分位延迟也称为尾部延迟，因为它们是延迟频谱的尾部。&lt;/p&gt;

&lt;p&gt;目标延时所用的百分位越大，你需要降低或容忍应用最差表现所做的努力就越多。比如，偶尔的大请求可能会阻塞全部的请求，从而增加整体的延迟，这也就是所谓的&lt;code&gt;head-of-line&lt;/code&gt;队首阻塞。同时，大量低速率客户端可能偶尔会同时向kafka发送生产或消费请求，或全部刷新集群元数据，也会导致请求队列比平常更长，从而引发比平时更严重的尾延迟。这种行为就是所谓的&lt;code&gt;micro-bursting&lt;/code&gt;(微型冲击，可能就是水滴石穿的意思吧)&lt;/p&gt;

&lt;h4 id=&#34;不同客户端配置的延迟测试&#34;&gt;不同客户端配置的延迟测试&lt;/h4&gt;

&lt;p&gt;在这接下来的内容中，我们使用实验结果来说明Kafka客户端配置和吞吐量扩展技术对性能的影响。我们使用kafka内置的&lt;a href=&#34;https://github.com/apache/kafka/tree/trunk/tools/src/main/java/org/apache/kafka/trogdor&#34;&gt;Trogdor&lt;/a&gt;测试框架以及生产者和消费者的基准测试，&lt;code&gt;ProduceBench&lt;/code&gt;和&lt;code&gt;ConsumeBench&lt;/code&gt;来进行我们的生产者和消费者实验测试。&lt;/p&gt;

&lt;p&gt;我们所有的测试都在一个包含9个代理的Kafka集群上运行，该集群的复制因子为3，这保证了在出现最多两个同时发生的节点故障时不会丢失消息。&lt;/p&gt;

&lt;p&gt;Kafka集群运行在AWS的&lt;code&gt;r5.xlarge&lt;/code&gt;实例上，使用有2T的EBS(弹性块存储)。Kafka的broker节点分布在同一区域内的三个可用性区域(AZ)，以获得更强的容错性，其中每个主题分区副本被放置在一个不同的AZ上，并且kafka客户端配置使用SASL认证和SSL加密，Broker之间使用&lt;code&gt;PLAINTEXT&lt;/code&gt;进行通信。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;主题:&lt;/code&gt;需要注意的是，分布式集群中节点如果在不同可用区也可能导致延迟的增加，当然这要在延迟和容错性角度进行权衡，也需要考虑到云厂商的可用区之间本身的延迟。&lt;/p&gt;

&lt;p&gt;我们的实验使用了以下非默认客户端配置和其他规范:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数项&lt;/th&gt;
&lt;th&gt;参数值&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;副本数&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;topic的分区数&lt;/td&gt;
&lt;td&gt;108&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;security.protocol&lt;/td&gt;
&lt;td&gt;SASL_SSL&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;sasl.mechanism&lt;/td&gt;
&lt;td&gt;PLAIN&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;acks&lt;/td&gt;
&lt;td&gt;all&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;linger.ms&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;compression.type&lt;/td&gt;
&lt;td&gt;lz4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Producer record size&lt;/td&gt;
&lt;td&gt;value=521bytes/key=4bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Trogdor record value generator&lt;/td&gt;
&lt;td&gt;uniformRandom&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Trogdor record key generator&lt;/td&gt;
&lt;td&gt;sequential&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Number of Trogdor agents&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这个测试场景会产生额外的延迟: 多可用区可能增加commit时间，由于是跨可用区的副本。无论是clients端还是broker端，SSL加密也是有开销的。同时由于SSL无法利用Zero Copy特性进行数据传输，因为consumer获取消息时也会增加额外的开销。&lt;/p&gt;

&lt;p&gt;虽然这些因素都会影响延迟，但是通常情况下企业内部可能还是需要这种架构上的考虑，因此采用该部署结构进行测试。&lt;/p&gt;

&lt;h4 id=&#34;持久性设置对延迟的影响&#34;&gt;持久性设置对延迟的影响&lt;/h4&gt;

&lt;p&gt;当将延迟目标与其他需求叠加在一起时，首先考虑持久性需求是很有用的。由于数据的重要性，通常需要一定程度的持久性。&lt;/p&gt;

&lt;p&gt;优化持久性会增加端到端延迟，因为这会增加延迟的复制开销(提交时间)，并向Broker添加复制负载，从而增加排队延迟。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Replication factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Replication factor 是Kafka持久化保证的核心，它定义了Kafka集群上保存的topic副本数。Replication factor = N 表示我们最多能够容忍N-1台broker宕机而不必数据丢失。N=1能够令端到端延时最小化，但却是最低的持久化保证。&lt;/p&gt;

&lt;p&gt;增加副本数会增加备份开销并给broker额外增加负载。如果clients端带宽在broker端均匀分布，那么每个broker都会使用&lt;code&gt;N * w写带宽&lt;/code&gt;和&lt;code&gt;r + (N - 1) * w读带宽&lt;/code&gt;，其中w是clients端在broker上的写入带宽占用，r是读带宽占用。&lt;/p&gt;

&lt;p&gt;由此，降低N 对端到端延时影响的最佳方法就是确保每个broker上的负载是均匀的。这会降低commit time，因为commit time是由最慢的那个follower副本决定的。&lt;/p&gt;

&lt;p&gt;如果你的Kafka broker使用了过多的磁盘带宽或CPU，follower就会开始出现追不上leader的情况从而推高了commit time。(其实还需要注意的是，当最小的ISR默认为副本的数量个数时，在出现follower和leader不同步时恰巧leader节点宕机，会导致topic本身不可用)&lt;/p&gt;

&lt;p&gt;我们建议为副本同步消息流量设置成使用不同的listener来减少与正常clients流量的干扰。你也可以在follower broker上增加I/O并行度，并增加副本拉取线程数量&lt;code&gt;number.replica.fetchers&lt;/code&gt;来改善备份性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;纵然我们配置了多个副本，producer还是必须通过acks参数来配置可靠性水平。设置acks=all能够提供最强的可靠性保证，但同时也会增加broker应答PRODUCE请求的时间，就像我们之前讨论的那样。&lt;/p&gt;

&lt;p&gt;Broker端应答的速度变慢通常会降低单个producer的吞吐量，进而增加producer的等待时间。这是因为producer端会限制未应答请求的数量(&lt;code&gt;max.inflight.requests.per.connection&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;举个例子，在我们的环境中acks=1，我们启动了9个producer（同时也跑了9个consumer），吞吐量达到了195MB/秒。当acks切换成all时，吞吐量下降到161MB/秒。设置更高级别的acks通常要求我们扩展producer程序才能维持之前的吞吐量水平以及最小化producer内部的等待时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Min.insync.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;是一个重要的持久化参数，因为它定义了broker端ISR副本中最少要有多少个副本写入消息才算PRODUCE请求成功。这个参数会影响可用性，但是不会影响端到端的延时。因此，选择一个小一点的值并不能减少commit time并减少延迟。&lt;/p&gt;

&lt;h4 id=&#34;在满足延迟目标的前提下扩展吞吐&#34;&gt;在满足延迟目标的前提下扩展吞吐&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;延迟和吞吐的权衡&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;优化Kafka clients端吞吐量意味着优化batching的效果。Kafka producer内部会执行一类batching，即收集多条消息到一个batch中。&lt;/p&gt;

&lt;p&gt;每个batch被统一压缩然后作为一个整体被写入日志或从日志中读取。这说明消息备份也是以batch为单位进行的。&lt;/p&gt;

&lt;p&gt;Batching会减少每条消息的成本，因为它将这些成本摊还到clients端和broker端。通常来说，batch越大这种开销降低的效果就越高，减少的网络和磁盘I/O就越多。&lt;/p&gt;

&lt;p&gt;另一类batching就是在单个网络请求/响应中收集多个batch以减少网络数据传输量。这能降低clients端和broker端的请求处理开销。这类batching能够提升吞吐量和降低延时，因为batch越大，网络传输I/O量越小，CPU和磁盘使用率越低，故最终能够优化吞吐量。另外batch越大还能减低端到端延时，因为每条消息的成本降低了，使得系统处理相同数量消息的总时间变少了。&lt;/p&gt;

&lt;p&gt;这里的延时-吞吐量权衡是指通过人为增加等待时间来提升打包消息的能力。但过了某个程度，人为等待时间的增加可能会抵消或覆盖你从打包机制获得的延时收益。因此你的延时目标有可能会限制你能实施打包化的水平，进而减少所能达到的吞吐量并增加延时。如果拉低了本能达到的吞吐量或端到端延时水平，你可以通过扩展集群来换取或“购买”更多的吞吐量或处理能力。&lt;/p&gt;

&lt;h4 id=&#34;配置kafka的生产者和消费者以实现batching&#34;&gt;配置kafka的生产者和消费者以实现batching&lt;/h4&gt;

&lt;p&gt;对于producer而言，batching由两个参数进行控制: &lt;code&gt;batch.size(16KB)&lt;/code&gt;和&lt;code&gt;linger.ms(0)&lt;/code&gt;，前者控制batch的大小，后者限制延迟量。如果使用场景中，应用会频繁的像kafka集群发送数据，及时设置了&lt;code&gt;linger.ms=0&lt;/code&gt;，整个batch也会被尽快填满。如果应用生产数据的频率较低，可以通过增加&lt;code&gt;linger.ms&lt;/code&gt;来增加batch。&lt;/p&gt;

&lt;p&gt;对于consumer而言，可以调整&lt;code&gt;fetch.min.bytes(1)&lt;/code&gt;来限制每个消费者在每个fetch响应中接收的数据量，该参数指定了broker应该在一个fetch响应中返回的最小数据，以及&lt;code&gt;fetch.max.wait.ms(500)&lt;/code&gt;来设置等待数据的超时时间。在fetch响应中的数据越多，就会有更少的fetch请求。&lt;/p&gt;

&lt;p&gt;在生产者端的batching也会间接影响produce和fetch的请求数量，因为batch定义了数据能够被获取的最小数据量。&lt;/p&gt;

&lt;p&gt;值得注意的是，默认情况下，Kafka producer和consumer设置的是无人为等待时间，这么做的目的是为了降低延时。但是，即使你的目标就是了使延时最小化，我们依然推荐你设置一个不为0的linger.ms值，比如5~10ms。当然，这么做是有前提的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你扩展了你的producer程序，平均下来使得每个producer实例的发送速率变得很低，那么你的batch只会包含很少的几条消息。如果你整体的吞吐量已然很高了，那么你可能会直接把你的Kafka集群压挂，导致超高的队列等候时间从而推高延时。此时，设置一个较小的&lt;code&gt;linger.ms&lt;/code&gt;值确实能够改善延时。&lt;/li&gt;
&lt;li&gt;如果你在意尾延时，那么增加&lt;code&gt;linger.ms&lt;/code&gt;可能会降低请求速率以及同时到达broker端的瞬时冲击流量。这种冲击越大，请求在尾部的延时就越高。这些瞬时冲击流量决定了你的尾延时水平。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面这个实验说明了以上两种场景。我们启动了90个producer，向一个有108个分区的topic发送消息。生产端整体的吞吐量峰值在90MB/秒。我们跑了3次测试，每一次对应一种不同的producer配置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2squjyvij30rs0fzaaz.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因为在给定的总吞吐下，我们有相对大量的生产者，因此&lt;code&gt;linger.ms = 0&lt;/code&gt;导致在生产者端机会没有batch操作。将&lt;code&gt;linger.ms&lt;/code&gt;从0调整到5可以增加batching能力: 向kafka发起的生产者请求从2800降低到了1100。这减少了50%和99%的生产者延迟。&lt;/p&gt;

&lt;p&gt;增加&lt;code&gt;batch.size&lt;/code&gt;不会直接影响生产者的等待时间，因为生产者在填满batch的时间不会超过&lt;code&gt;linger.ms&lt;/code&gt;的限制。在我们的实验中，增加&lt;code&gt;batch.size&lt;/code&gt;从16KB到128KB没有增加bacth的效果，因为每个生产者的吞吐量非常低。正如预期的那样，生产者延迟在两种配置之间没有变化。&lt;/p&gt;

&lt;p&gt;总之，如果您的目标是最小化延迟，我们建议保留默认的客户端批处理配置，并尽可能增加&lt;code&gt;linger.ms&lt;/code&gt;。如果你在意尾延时，最好调优下打包水平来减少请求发送率以及大请求冲击的概率。&lt;/p&gt;

&lt;h4 id=&#34;不增加人为延迟以提高batching效率&#34;&gt;不增加人为延迟以提高batching效率&lt;/h4&gt;

&lt;p&gt;batching效果不好的另一个原因是producer发送消息给大量分区。&lt;code&gt;如果消息不是发往同一个分区的，它们就无法聚集在一个batch下&lt;/code&gt;。因此，通常最好设计成让每个producer都只向有限的几个分区发送消息。&lt;/p&gt;

&lt;p&gt;另外，可以考虑升级到Kafka 2.4 producer。这个版本引入了一个全新的Sticky分区器。该分区器能够改善non-keyed topic的打包效果，同时还无需引入人为等待。&lt;/p&gt;

&lt;h4 id=&#34;clients的数量对尾延迟-tail-latency-的影响&#34;&gt;clients的数量对尾延迟(tail-latency)的影响&lt;/h4&gt;

&lt;p&gt;即使整体的生产和消费的吞吐量保持不变，通常也是Clients数越多，broker上负载越大。这是因为clients数量多会导致更多的METADATA请求发到Kafka，继而要维护更多的连接，故给broker带来更大的开销。&lt;/p&gt;

&lt;p&gt;相对于50%或平均延时的影响，Clients数量增加对尾延时的影响更大。&lt;/p&gt;

&lt;p&gt;每个producer最多发送&lt;code&gt;max.inflight.requests.per.connection&lt;/code&gt;个PRODUCE请求给单个broker，而每个consumer一次最多只会给一个broker发送FETCH请求。Clients越多，同一时刻发送到broker的PRODUCE和FETCH请求也就越多，这就增加了形成请求瞬时冲击的概率，进而推高了尾延时。&lt;/p&gt;

&lt;p&gt;Consumer数量通常由topic分区数量以及期望consumer没有较大lag的目标共同决定。但是，我们却很容易为了扩展吞吐量而引入大量的producer。&lt;/p&gt;

&lt;p&gt;基于吞吐量的考量增加producer实例数可能有相反的效果，因为producer会导致更少的消息被打包，毕竟每个producer处理了更少的消息，因而发送速率会变慢。同时producer还必须等待更长的时间来积累相同数量的消息进到batch里面。&lt;/p&gt;

&lt;p&gt;在我们的实验中，我们将producer的数量从90增加到900，发现吞吐量没有他打变化：90MB/秒。&lt;/p&gt;

&lt;p&gt;我们使用&lt;code&gt;batch.size=16KB&lt;/code&gt;,&lt;code&gt;linger.ms=5&lt;/code&gt;,&lt;code&gt;acks=all&lt;/code&gt;的生产者配置，实验结果如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2s85pax9j30rs0f60tm.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结果显示增加producer数量(90-&amp;gt;900)增加了60%的中位数延时值，而99%延时值几乎增加了3倍。&lt;/p&gt;

&lt;p&gt;延时的增加是因为producer端打包效果变差导致的。&lt;/p&gt;

&lt;p&gt;尾延时的增加是因为更大的请求瞬时冲击，这会拉升broker端延时，同时producer端会等待更长的时间来接收应答。&lt;/p&gt;

&lt;p&gt;在900个producer的测试中，broker完全被PRODUCE请求压垮了。用于处理请求的时间几乎占到了broker端CPU使用率的100%。另外由于我们使用了SSL，它也会进一步引入请求级的开销。&lt;/p&gt;

&lt;p&gt;如果你通过添加producer来提升吞吐量，那么可以考虑增加单个proudcer的吞吐量，即&lt;code&gt;改善batching的效果&lt;/code&gt;。不管怎样，你最终可能会有很多producer实例。比如，大公司收集设备上的统计指标，而设备数可能有成千上万。此时，你可以考虑使用一个Broker收集来自多个clieints的请求，然后把它们转换成更高效的PRODUCE请求再发给Kafka。你也可以增加broker数来降低单个broker上的请求负载。&lt;/p&gt;

&lt;h4 id=&#34;关于增加消费者数量的说明&#34;&gt;关于增加消费者数量的说明&lt;/h4&gt;

&lt;p&gt;当扩展消费者时需要注意，在同一个消费者组的消费者会提交offset信息和心跳到broker节点上(controller节点)。如果按时间间隔执行偏移提交(&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;)，则消费者组中的更多消费者者会增加偏移提交率。偏移量提交本质上是向内部&lt;code&gt;__consumer_offsets&lt;/code&gt;产生请求，因此增加consumer数量会导致broker上的请求负载增加，特别是&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;值很小的时候。&lt;/p&gt;

&lt;h4 id=&#34;压缩配置的影响&#34;&gt;压缩配置的影响&lt;/h4&gt;

&lt;p&gt;默认情况下，Kafka producer不做压缩。&lt;code&gt;compression.type&lt;/code&gt;参数可以决定要不要做压缩。&lt;/p&gt;

&lt;p&gt;压缩会在producer端引入额外的开销来压缩消息，在broker端做校验时解压缩从而引入额外的开销，另外在consumer端解压缩也是开销。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;:通常情况下broker端的压缩参数需要设置成&lt;code&gt;producer&lt;/code&gt;，以避免压缩方式冲突导致数据无法正常消费，这样broker只需要直接将压缩后的日志写入&lt;/p&gt;

&lt;p&gt;虽然压缩会增加CPU开销，但它还是可能减少端到端延时的，因为它能显著地降低处理数据所需的带宽占用，进而减少broker端的负载。压缩是在batch级别上完成的，故打包效果越好，压缩效果也就越好。&lt;/p&gt;

&lt;h4 id=&#34;更多的分区可能增加延迟&#34;&gt;更多的分区可能增加延迟&lt;/h4&gt;

&lt;p&gt;一个主题的分区是kafka中的并行单元。发送到不同分区的消息可以由生产者并行发送，由不同的Broker并行写入，并可以由不同的消费者并行读取。因此，更多的分区通常会导致更高的吞吐量，不过单从吞吐量的角度来看，我们能够从每个Broker有10个分区的kafka集群，就已经能够达到最大的吞吐量了。您可能需要更多的主题分区来支持您的应用程序逻辑。&lt;/p&gt;

&lt;p&gt;但是，太多的分区可能导致更多的端到端的延迟。每个主题的分区越多，对生产者的批处理就越少。每个Broker的主题分区越多，每个follow副本获取请求的开销就越大。每个fetch请求必须去枚举自己感兴趣的分区，并且每个leader副本必须去检查状态，同时从请求的每个分区中去fetch数据，这通常会导致较小的磁盘I/O。因此，越多的分区，可能会导致更长的commit time和更高的cpu使用，最终导致较长的排队延迟。&lt;/p&gt;

&lt;p&gt;提交时间的增加和更高的CPU负载会导致所有共享同一个Kafka集群的客户端端到端延迟的增加，即使是那些只生产和使用少量主题分区的客户端来说，也是如此。&lt;/p&gt;

&lt;p&gt;我们使用两个topic来做此次测试。一个Topic有9个生产者生产5MB/s的数据，然后有一个对应9个消费者的消费者组。这个实验持续了几天，我们将这个主题中的分区数量从108个逐步增加到7200个(每个Broker8000个)，每个步骤运行一个小时。第二个主题在整个实验运行期间有9个分区和9个生产者，每个生产者向一个分区和一个对应的消费者组(每个分区一个)生产消息，该主题每秒生产一个512bytes的数据。&lt;/p&gt;

&lt;p&gt;下图显示了分区数量对客户端访问9分区主题的99%的端到端延迟的影响，随着每个broker上分区数的增加，clients的端到端延时大致呈线性增加趋势。分区数的增加会推高broker上的CPU负载同时拖慢所有clients的备份，即使是对那些只与固定分区数量交互的clients而言，也会抬高端到端延迟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2rwiufyuj30rs0eh0ty.jpg&#34; alt=&#34;mutli-partition-latency&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了减少延时，最好还是限制每个broker上的分区数，方法是减少总的分区数或扩展集群。你还可以通过增加fetcher线程数量的方式来改善commit time。&lt;/p&gt;

&lt;h4 id=&#34;broker节点负载对延迟的影响&#34;&gt;broker节点负载对延迟的影响&lt;/h4&gt;

&lt;p&gt;我们已经讨论了Broker上的负载导致增加排队延迟，从而增加了端到端的延迟，很容易看出为什么请求速率的增加会加剧排队延迟，因为更多的请求会导致更大的队列。&lt;/p&gt;

&lt;p&gt;broker节点上高资源利用率(磁盘或cpu)可能导致更高的队列的延迟，并且延迟的增长会随着资源利用率的增长呈指数级增长。这是一个可以有排队理论解释的已知属性: Kingman公式证明等待某种资源的时间正比于资源繁忙程度/资源空闲程度&lt;code&gt;(% of time resource is busy)/(% of time resource is idle)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2r3oe03wj30rs0gb0tp.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于延迟随资源利用率呈指数增长，如果broker中的任何资源的利用率接近100%，您可能会看到很高的延迟。通过减少每个Broker的资源使用(比如减少每个broker的链接数，请求以及分区数)或扩展集群来整体降低每个broker节点的资源使用率，在这种情况可以显著降低延迟。保持负载在broker之间平均通常情况下是非常有用的，同时也可以&lt;code&gt;均匀地或基于负载分布分区副本&lt;/code&gt;也能降低尾部延迟。&lt;/p&gt;

&lt;p&gt;因此，通常情况下，负责kafka集群的SRE团队需要自动检测Broker节点上的高资源利用率(磁盘和CPU)，然后重新平衡集群上的分区，以便更均匀地在Broker之间重新分配负载，或者在需要时扩展集群。而如果使用云厂商提供的kafka服务，则可以适当避免这类事情的发生，因为云服务会去做相关的事情。&lt;/p&gt;

&lt;h4 id=&#34;总结&#34;&gt;总结&lt;/h4&gt;

&lt;p&gt;我们已经演示了，在为吞吐量扩展客户机和分区时的边界延迟要求时可以通过限制每个broker的连接数、分区数和请求速率来限制每个broker的使用。&lt;/p&gt;

&lt;p&gt;边界尾延迟需要额外注意减少来自客户机的任何突发(连接和请求)或应用程序行为中的差异。&lt;/p&gt;

&lt;p&gt;均匀加载的broker节点对于最小化尾部延迟也很重要，因为它受到最慢broker的影响。&lt;/p&gt;

&lt;p&gt;如下是一些相关扩展的文章，可能有助于我们控制整体延迟:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/white-paper/optimizing-your-apache-kafka-deployment/&#34;&gt;Optimizing Your Apache Kafka Deployment&lt;/a&gt;提供配置Kafka部署的指导方针，以优化各种目标:吞吐量、延迟、持久性和可用性(公众号回复:&lt;code&gt;kafka&lt;/code&gt;可获取资料)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster&#34;&gt;How to Choose the Number of Topics/Partitions in a Kafka Cluster?&lt;/a&gt;(2016) 和&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster&#34;&gt;follow-updates&lt;/a&gt;有一些kafka 2.0版本的优化&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner&#34;&gt;Improving batching with the new sticky partitioner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-345%3A+Introduce+static+membership+protocol+to+reduce+consumer+rebalances&#34;&gt;KIP-345&lt;/a&gt;: 引入静态成员协议来减少消费者的再平衡&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka如何合理规划分区数量</title>
      <link>https://bgbiao.top/post/kafka%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E8%A7%84%E5%88%92%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E8%A7%84%E5%88%92%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 如同其他分布式系统一样，在kafka集群中，单Topic的partition也并不是越多越好，但通常对于业务方来说，可能会简单的根据生产者或消费者的处理能力来提出扩partition的需求，此时就需要根据具体的场景进行分析以确定partition的数量。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于Kafka集群承载的业务Topic来说，分区的数量，可以体现出整个业务的量级同时能够尽可能的提供更高的吞吐，但并不是越多的分区就意味着越高的吞吐和处理能力，通常情况下需要业务方和基础服务方一起来进行分析。&lt;/p&gt;

&lt;p&gt;以下为多分区Topic的优缺点，可以适当根据需求和场景进行规划分区数量。&lt;/p&gt;

&lt;h3 id=&#34;目录&#34;&gt;目录&lt;/h3&gt;

&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h3 id=&#34;多分区可以提高吞吐-higher-throughput&#34;&gt;多分区可以提高吞吐(Higher Throughput)&lt;/h3&gt;

&lt;p&gt;首先，我们需要理解的是，在kafka集群中，topic分区&lt;code&gt;partition&lt;/code&gt;是一个并行单位。&lt;/p&gt;

&lt;p&gt;在生产者和broker端，可以完全并行完成对不同分区的写入操作。一些昂贵的操作，比如压缩(compression)，需要消耗更多的硬件资源。&lt;/p&gt;

&lt;p&gt;在消费者端，kafka总是会给每个消费者线程一个单分区的数据，因此当分区的数量其实也就限制了消费者线程的最大数据量，如果消费者不足以在最短时间消费数据，可以通过优化客户端程序或增加partition数量的方式(同时增加消费者线程)来缓解，但后者需要topic级别的调整，同时需要确认生产者是否有分区绑定相关操作。&lt;/p&gt;

&lt;p&gt;因此，一般而言，kafka集群的拥有越多的分区也意味着可以获取更高的吞吐。&lt;/p&gt;

&lt;p&gt;选择分区的数量一般可用基于吞吐来进行简单计算。&lt;/p&gt;

&lt;p&gt;您可以在单个分区上对生产(称为p)和消费(称为c)所能实现的所有性能进行度量。假如我们的目标吞吐是&lt;code&gt;t&lt;/code&gt;，然后我们可以设置分区数量为&lt;code&gt;max(t/p, t/c)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在生产者端，可以通过设置&lt;code&gt;batch size&lt;/code&gt;,&lt;code&gt;compression&lt;/code&gt;,&lt;code&gt;ack&lt;/code&gt;,&lt;code&gt;replication factor&lt;/code&gt;等参数来计算单个分区的吞吐。
不过如&lt;a href=&#34;https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines&#34;&gt;LinkedIn-Benchmarking&lt;/a&gt;中显示，通常单个分区可以承载每秒10 Million调数据的写入。&lt;/p&gt;

&lt;p&gt;在消费者端吞吐量通常依赖于应用程序，因为它对应于使用者逻辑处理每个消息的速度，因此得实际进行测量。&lt;/p&gt;

&lt;p&gt;尽管在topic创建后期，可以根据需求进行扩容分区，但是对于有&lt;code&gt;keys&lt;/code&gt;的消息需要注意。&lt;/p&gt;

&lt;p&gt;因为当生产者写入一个带&lt;code&gt;key&lt;/code&gt;的消息后，kafka将依据该&lt;code&gt;key&lt;/code&gt;的hash来决定数据映射到具体的分区，这样就可以保证具有相同&lt;code&gt;key&lt;/code&gt;的消息会被路由到同一个分区，从而保证了一类消息的有序性。&lt;/p&gt;

&lt;p&gt;如果此时分区数量突然增加，将可能导致数据的无序性，为了避免未来这种问题的出现，一般而言会在业务接入初期进行分区的过度分配&lt;code&gt;over-partition&lt;/code&gt;，即在topic创建时尽量多创建一些，但基本上在接入之前需要预估未来的吞吐量以确定一个合理的分区数量，这样即使当前集群规模较小，可以对topic进行提前规划，待后期集群规模大之后进行迁移即可，否则刚开始因为集群规模小，而对分区数量没有合理规划，后期会比较麻烦，而且这样当生产者使用带&lt;code&gt;key&lt;/code&gt;的消息时，您可以跟上吞吐量的增长，而不会破坏应用程序中的语义。&lt;/p&gt;

&lt;p&gt;除了吞吐量之外，在规划分区数时还需要考虑一些其他的因素，因为在吞吐增加的同时可能会增加一些其他影响。&lt;/p&gt;

&lt;h3 id=&#34;需要更多的open-file-handles&#34;&gt;需要更多的Open File Handles&lt;/h3&gt;

&lt;p&gt;每个分区会映射到broker机器的其中一个目录，在每个日志目录每个日志段(segment)包含四个文件:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;00000000000029487197.index: 索引文件&lt;/li&gt;
&lt;li&gt;00000000000029487197.log: 真正的日志文件&lt;/li&gt;
&lt;li&gt;00000000000029487197.snapshot: 快照&lt;/li&gt;
&lt;li&gt;00000000000029487197.timeindex: 时间索引&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在kafka中，broker会为每个segment打开一个file handle ，不过这仅是一个配置问题，通常在生产集群可以配置OS层面的打开文件数为&lt;code&gt;30 thousand&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;多分区可能增加整体不可用性&#34;&gt;多分区可能增加整体不可用性&lt;/h3&gt;

&lt;p&gt;整体可用性的降低是因为在异常时有更多的分区需要进行恢复数据，此时多分区之间的数据同步可能在网络上需要消耗。&lt;/p&gt;

&lt;p&gt;kafka集群内部的副本机制，可以提供比较高的可用性和持久性。一个分区如果有多个副本，每个副本将会存储到不同的broker上，副本被设计为leader和follow副本。&lt;/p&gt;

&lt;p&gt;在内部，Kafka自动管理所有这些副本，并确保它们保持同步，生产者和消费者对分区的请求都将由leader副本来响应，当broker宕机后，该节点上的leader副本将暂时不可用，kafka内部的controller角色将自动将分区的leader副本切换到其他满足条件的副本上，以尽快提供读写请求(是否能尽快切换到其他副本上取决于数据的一致性和可靠性要求)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;leader副本的切换动作会涉及到controller从zookeeper中去获取对应分区的相关副本元数据，在controller内部，操作zookeeper是串行的。&lt;/p&gt;

&lt;p&gt;在通常情况下，当一个Broker被优雅地关闭时，控制器会主动地将leader从关闭的代理中移开，每次只关闭一个，一个leader的切换通常仅会需要消耗几毫秒，因此，对于客户端而言，当使用优雅重启时，仅有一个很小的不可用窗口。&lt;/p&gt;

&lt;p&gt;然而，当broker被异常关闭时(&lt;code&gt;kill -9&lt;/code&gt;)，观测到的不可用性可能与分区的数量成正比。假设每个broker共2000个分区，每个分区共2个副本，基本每个broker将负责1000个分区，当该broker异常关闭时，所有1000个分区将在同一时间不可用。假设为单个分区选主的时间需要消耗5ms，选举1000个分区将消耗5s。&lt;/p&gt;

&lt;p&gt;因此，对于某些分区，其观察到的不可用性可能是5秒加上检测故障所需的时间。&lt;/p&gt;

&lt;p&gt;如果不行的是，异常关闭的broker节点刚好是controller角色，在这种情况下，分区选leader的操作将不会立即进行，知道controller本身转移到正常的broker节点上。&lt;/p&gt;

&lt;p&gt;controller控制器自动发生故障转移，但需要新控制器在初始化期间从ZooKeeper读取每个分区的一些元数据。&lt;/p&gt;

&lt;p&gt;例如，如果Kafka集群中有10,000个分区，并且每个分区初始化来自ZooKeeper的元数据需要2 ms时间，这可能会给不可用窗口增加20秒。&lt;/p&gt;

&lt;p&gt;一般来说，异常的关闭是罕见的。但是，如果关心在这些罕见情况下的可用性，那么最好将每个Broker的分区数量限制在&lt;code&gt;2到4000&lt;/code&gt;个，集群中的分区总数限制在数万个以内。&lt;/p&gt;

&lt;h3 id=&#34;可能增加端到端的延迟-end-to-end-latency&#34;&gt;可能增加端到端的延迟(End-to-end Latency)&lt;/h3&gt;

&lt;p&gt;Kafka中的端到端延迟是由&lt;code&gt;生产者发布消息到消费者读取消息&lt;/code&gt;的时间定义的。&lt;/p&gt;

&lt;p&gt;Kafka只在&lt;code&gt;提交消息之后&lt;/code&gt;才向使用者公开消息(commited log)，即当消息被复制到所有同步副本时。因此，提交消息的时间可能是端到端延迟的重要部分。&lt;/p&gt;

&lt;p&gt;默认情况下，Kafka的broker节点仅使用一个线程来复制来自另一个Broker的数据，用于在两个Broker之间共享副本的所有分区。(可以设置适当大参数来调整同步线程数)&lt;/p&gt;

&lt;p&gt;实验表明，将1000个分区从一个Broker复制到另一个Broker可以增加大约20 ms延迟，这意味着端到端延迟至少是20 ms，这对于某些实时计算类的应用来说，整体的延迟其实有点高，当然如果整个集群比较大时，分区分布在不同的broker上，该问题可以适当缓解(其余的broker可以从这一个broker上平均fetch消息)&lt;/p&gt;

&lt;p&gt;因此，由于提交消息而增加的延迟将只有几ms，而不是几十ms。&lt;/p&gt;

&lt;p&gt;如果关系延迟指标，可以参照如下方式来计算分区:&lt;/p&gt;

&lt;p&gt;将每个Broker的分区数量限制在&lt;code&gt;100 * b * r&lt;/code&gt;可能是一个好主意，其中b是Kafka集群中的Broker数量，r是复制因子。&lt;/p&gt;

&lt;h3 id=&#34;更多的分区可能在客户端需要更多的内存&#34;&gt;更多的分区可能在客户端需要更多的内存&lt;/h3&gt;

&lt;p&gt;在客户端在内部，生产者缓冲每个分区的消息。在积累了足够的数据或经过了足够的时间之后，将从缓冲区中删除累积的消息并将其发送给Broker。&lt;/p&gt;

&lt;p&gt;如果增加分区的数量，消息将在客户端区域中的更多分区中累积。所使用的内存总量现在可能超过了配置的内存限制。&lt;/p&gt;

&lt;p&gt;当发生这种情况时，生产者必须阻止或删除任何新消息，这两种方法都不理想。为了防止这种情况发生，需要重新配置生成器，使其具有更大的内存大小。&lt;/p&gt;

&lt;p&gt;根据经验，要获得良好的吞吐量，应该为生产者中生成的每个分区分配至少几十KB的内存，如果分区数量显著增加，还应该调整内存总量。&lt;/p&gt;

&lt;p&gt;消费者也存在类似的问题。消费者为每个分区获取一批消息。消费者使用的分区越多，所需的内存就越多。然而，这通常只是一个针对非实时用户的问题。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;通常，Kafka集群中的分区越多，吞吐量就越高。但是，必须意识到总分区或每个Broker拥有太多分区对可用性和延迟等方面的潜在影响，通常这部分需要业务方和基础服务方进行合理规划和调整。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相关文档&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster/&#34;&gt;kafka-supports-200k-partitions-per-cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/&#34;&gt;kafka-topic-partition-numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka常用运维操作</title>
      <link>https://bgbiao.top/post/kafka%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 在kafka的集群运维操作过程中，我们需要通过一些工具来实现集群的高可用以及负载的平均操作，而对于kafka集群的SRE来说，需要掌握好如下几点，才能更好的维护和保证kafka集群服务的稳定性，可靠性和整体性能。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;要想kafka跑的好，如下几点要知晓。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Graceful shutdown&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;建议开启如下参数:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;controlled.shutdown.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 只有在broker上承载的分区都具有副本时(副本大于1，且副本存活)，controller节点才会成功关闭&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Balancing leadership&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每当Broker停止或崩溃时，该broker的分区的领导权就转移到其他副本。&lt;/p&gt;

&lt;p&gt;这意味着，默认情况下，当broker重新启动时，它将只是所有分区的关注者，这意味着它不会用于客户端读写，这对于整个集群来说吞吐会受到1/N的降低(N表示集群节点数)&lt;/p&gt;

&lt;p&gt;为了避免这种不平衡，kafka提供了一种优先副本的概念&lt;code&gt;preferred replicas&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;如果一个分区的副本列表是1、5、9，那么节点1比节点5或节点9更适合作为leader，因为它位于副本列表的前面。&lt;/p&gt;

&lt;p&gt;可以使用如下命令来恢复已恢复副本的领导权:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 老版本工具
bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot

# 新版本工具&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当然每次在服务器启动后执行该操作，可能很无聊，因此可以设置如下参数来自动执行:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;auto.leader.rebalance.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Balancing Replicas Across Racks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;机架层面的副本均衡。&lt;/p&gt;

&lt;p&gt;机架感知特性将相同分区的副本分散到不同的机架上，这扩展了Kafka为broker失败提供的覆盖机架失败的保证，如果机架上的所有broker同时失败，就限制了数据丢失的风险。&lt;/p&gt;

&lt;p&gt;该特性还可以应用于其他broker分组，如EC2中的可用性区域。&lt;/p&gt;

&lt;p&gt;您可以通过向broker配置添加属性来指定broker属于特定的机架：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;broker.rack=my-rack-id&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当创建、修改或重新分发一个主题时，将遵循机架约束，确保副本尽可能多地跨越多个机架(一个分区将跨越最小(#机架，复制因子)不同的机架)。&lt;/p&gt;

&lt;p&gt;用于将副本副本分配给broker的算法，会确保每个broker的leader数量是恒定的，而不管broker是如何分布在机架上的。这确保了平衡的吞吐量。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 明智的做法是为每个机架配置相同数量的broker&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mirroring data between clusters&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们将在Kafka集群之间复制数据的过程称为“镜像”，以避免与单个集群中节点之间的复制混淆。&lt;/p&gt;

&lt;p&gt;Kafka附带一个用于在Kafka集群之间镜像数据的工具，即&lt;code&gt;MirrorMaker&lt;/code&gt;，该工具可以从源集群进行消费，并生产到目标集群。&lt;/p&gt;

&lt;p&gt;常用的场景就是在另外一个数据中心提供副本。&lt;/p&gt;

&lt;p&gt;您可以运行许多这样的镜像进程来提高吞吐量和容错能力。&lt;/p&gt;

&lt;p&gt;使用mirrormaker进行迁移topic到另外的集群:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-mirror-maker.sh
      --consumer.config consumer.properties
      --producer.config producer.properties --whitelist my-topic&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;需要注意，我们必须使用&lt;code&gt;--whitelist&lt;/code&gt;参数指定topic，该参数支持java的正则表达式结构，比如&lt;code&gt;--whitelist &#39;A|B&#39;&lt;/code&gt;，或者&lt;code&gt;--whitelist &#39;*&#39;&lt;/code&gt; .&lt;/p&gt;

&lt;p&gt;通常在使用kafka-mirror-maker时，建议配合&lt;code&gt;auto.create.topics.enable=true&lt;/code&gt;使用，可以大批量的进行topic迁移。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Checking consumer position&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查消费者的位移，有时候了解消费者当前的位置时很有必要的。&lt;/p&gt;

&lt;p&gt;kafka有一个工具，它将显示所有消费者在一个消费者组中的位置，以及他们与日志结束的距离&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 在my-group的消费者上消费my-topic的主题
# 可以查看整个消费者组的消费情况
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Managing Consumer Groups&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ConsumerGroupCommand工具可以&lt;code&gt;list, describe, or delete&lt;/code&gt;一个消费组，消费者组可以手动删除，也可以在该组最后提交的偏移量过期时自动删除。&lt;/p&gt;

&lt;p&gt;只有在组中没有任何活动成员时，手动删除才有效。&lt;/p&gt;

&lt;p&gt;如下命令可以列出所有主题的所有消费者组:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;查看指定消费者组&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当然可用试用一些额外的参数来查看更多的消费者信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ndash;members: 查看消费者组中活跃的消费者&lt;/li&gt;
&lt;li&gt;&amp;ndash;members &amp;ndash;verbose: 该参数还可以查看分配给每个成员的分区&lt;/li&gt;
&lt;li&gt;&amp;ndash;offsets: 该参数实际上可以被&lt;code&gt;--describe&lt;/code&gt;参数中的内容覆盖掉&lt;/li&gt;
&lt;li&gt;&amp;ndash;state: 该参数可以提供组级别的信息&lt;/li&gt;
&lt;li&gt;&amp;ndash;delete: 该参数可以手动删除一个或多个消费者组&lt;/li&gt;

&lt;li&gt;&lt;p&gt;-reset-offsets: 该参数用于重置消费者组的偏移量，此选项在同一时间支持一个消费者组，同时需要使用&lt;code&gt;--all-topics或--topic&lt;/code&gt;指定范围&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看消费者组成员
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --members

CONSUMER-ID                                    HOST            CLIENT-ID       #PARTITIONS
consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1       2
consumer4-117fe4d3-c6c1-4178-8ee9-eb4a3954bee0 /127.0.0.1      consumer4       1
consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2       3
consumer3-ecea43e4-1f01-479f-8349-f9130b75d8ee /127.0.0.1      consumer3       0

# 查看消费者组成员详细信息(分区)
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --members --verbose

CONSUMER-ID                                    HOST            CLIENT-ID       #PARTITIONS     ASSIGNMENT
consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1       2               topic1(0), topic2(0)
consumer4-117fe4d3-c6c1-4178-8ee9-eb4a3954bee0 /127.0.0.1      consumer4       1               topic3(2)
consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2       3               topic2(1), topic3(0,1)
consumer3-ecea43e4-1f01-479f-8349-f9130b75d8ee /127.0.0.1      consumer3       0               -

# --state参数

$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --state

COORDINATOR (ID)          ASSIGNMENT-STRATEGY       STATE                #MEMBERS
localhost:9092 (0)        range                     Stable               4

# 删除消费者组
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group my-group --group my-other-group

Deletion of requested consumer groups (&amp;#39;my-group&amp;#39;, &amp;#39;my-other-group&amp;#39;) was successful.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; &lt;code&gt;--reset-offsets&lt;/code&gt;选项支持如下三个执行选项:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;显示要重置的偏移量&lt;/li&gt;
&lt;li&gt;&amp;ndash;execute: 执行&lt;code&gt;--reset-offsets&lt;/code&gt;进程&lt;/li&gt;
&lt;li&gt;&amp;ndash;export: 以csv格式导出执行结果&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;--reset-offsets&lt;/code&gt;参数还有如下方案可供选择:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ndash;to-datetime: 重置offset到另外一个offset (format:YYYY-MM-DDTHH:mm:SS.sss)&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-earliest: 重置offset到最早的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-latest: 重置为最新的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;shift-by: 重置offset为n&lt;/li&gt;
&lt;li&gt;&amp;ndash;from-file: 重置到csv中定义的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-current: 重置offset到当前&lt;/li&gt;
&lt;li&gt;&amp;ndash;by-duration: 重置offset为当前时间( Format: &amp;lsquo;PnDTnHnMnS&amp;rsquo;)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;to-offset: 重置offset为指定的值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 设置消费者组的offset为最新
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --reset-offsets --group consumergroup1 --topic topic1 --to-latest

TOPIC                          PARTITION  NEW-OFFSET
topic1                         0          0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果你还是使用老的&lt;code&gt;high-level&lt;/code&gt;消费者，并且将组的元数据存储在zk中(&lt;code&gt;offsets.storage=zookeeper&lt;/code&gt;)，可以使用&lt;code&gt;--zookeeper&lt;/code&gt;来代替&lt;code&gt;bootstrap-server&lt;/code&gt;参数:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --zookeeper localhost:2181 --list&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Expanding your cluster&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;集群的扩展.&lt;/p&gt;

&lt;p&gt;将服务器添加到Kafka集群很容易，只需为它们分配一个惟一的brokerid，并在新服务器上启动Kafka.&lt;/p&gt;

&lt;p&gt;然而，这些新服务器不会自动分配任何数据分区，因此，除非将分区移动到它们，否则在创建新主题之前，它们不会做任何工作。&lt;/p&gt;

&lt;p&gt;因此，通常在向集群中添加机器时，您会希望将一些现有数据迁移到这些机器上。&lt;/p&gt;

&lt;p&gt;迁移数据的过程是手动启动的，但是完全自动化。&lt;/p&gt;

&lt;p&gt;实际上，Kafka将添加新服务器作为它正在迁移的分区的追随者，并允许它完全复制该分区中的现有数据。&lt;/p&gt;

&lt;p&gt;当新服务器完全复制了该分区的内容并加入同步副本时，现有副本中的一个将删除其分区的数据。&lt;/p&gt;

&lt;p&gt;可以使用分区重新分配工具在broker之间移动分区。&lt;/p&gt;

&lt;p&gt;理想的分区分布应该确保所有broker之间的数据负载和分区大小是一致的。&lt;/p&gt;

&lt;p&gt;分区重新分配工具不具备自动研究Kafka集群中的数据分布并移动分区以获得均匀的负载分布的能力，因此，管理员必须确定应该移动哪些主题或分区。&lt;/p&gt;

&lt;p&gt;分区迁移工具可以运行在三种互斥模式下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--generate&lt;/code&gt;: 给定主题列表和broker列表，该工具生成一个候选重新分配，将指定主题的所有分区移动到新的broker，该参数仅帮助管理员方便的来生成给定主题和目标broker列表的分区重新分配计划&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 该工具根据用户提供的重新分配计划开始重新分配分区(使用&lt;code&gt;--reassignment-json-file&lt;/code&gt;指定生成的迁移配置)，- &lt;code&gt;--verify&lt;/code&gt;: 该工具将验证列出的所有分区的重新分配状态，可以是成功完成、失败或正在进行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;1.自动迁移数据到新的服务器&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;分区重新分配工具可用于将某些主题从当前broker集移到新添加的broker。 这在扩展现有集群时通常很有用，因为与一次移动一个分区相比，将整个主题移至新的broker集更容易。 用于执行此操作时，用户应提供应移至新的一组broker的主题列表和新broker的目标列表。 然后，该工具将给定主题列表中的所有分区平均分配到新的一组broker中。 在此过程中，主题的复制因子保持不变。 有效地，将输入主题列表的所有分区的副本从旧的broker集移至新添加的broker。&lt;/p&gt;

&lt;p&gt;如下示例(topic:foo1和foo2的全部分区移动到broker 5和6上，迁移完成后，该topic的全部分区将在Broker5和6上):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat topics-to-move.json
{&amp;#34;topics&amp;#34;: [{&amp;#34;topic&amp;#34;: &amp;#34;foo1&amp;#34;},
            {&amp;#34;topic&amp;#34;: &amp;#34;foo2&amp;#34;}],
&amp;#34;version&amp;#34;:1
}

# 准备好json文件之后，使用分区重新分配工具生成一个候选分配
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --topics-to-move-json-file topics-to-move.json --broker-list &amp;#34;5,6&amp;#34; --generate
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

Proposed partition reassignment configuration

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]}]
}

# 该工具生成一个将移动所有分区的候选分配(分配到哪些broker上)，此时分区移动还没有开始，它只告诉您当前的分配和建议的新分配。
# 应该保存当前的赋值，以防您想要回滚到它.
# 使用生成的迁移计划进行迁移
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file expand-cluster-reassignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]}]
}

# 最后使用--verify选项验证迁移状态
# 注意:使用相同的迁移计划任务expand-cluster-reassignment.json
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file expand-cluster-reassignment.json --verify
Status of partition reassignment:
Reassignment of partition [foo1,0] completed successfully
Reassignment of partition [foo1,1] is in progress
Reassignment of partition [foo1,2] is in progress
Reassignment of partition [foo2,0] completed successfully
Reassignment of partition [foo2,1] completed successfully
Reassignment of partition [foo2,2] completed successfully&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;2.自定义分区分配和迁移&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;分区重分配工具还可以用于有选择地将分区的副本移动到一组特定的broker。&lt;/p&gt;

&lt;p&gt;当我们以这种方式使用时，假设用户知道重新分配计划，并且不需要该工具来生成候选的重新分配，即直接使用用户的分配策略进行数据迁移。&lt;/p&gt;

&lt;p&gt;示例: 迁移topic&lt;code&gt;foo1&lt;/code&gt;的partition-0到broker5和6，partition-1到broker2和3&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义迁移计划
$ cat custom-reassignment.json
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},{&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]}

# 使用--execute选项执行上述的迁移计划
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file custom-reassignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[3,4]}]
}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

# --verify来验证迁移状态

$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file custom-reassignment.json --verify
Status of partition reassignment:
Reassignment of partition [foo1,0] completed successfully
Reassignment of partition [foo2,1] completed successfully&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Decommissioning brokers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;分区重新分配工具还不能自动生成用于退役broker的重新分配计划，因此，管理员必须制定一个重新分配计划，将托管在代理上的所有分区的副本迁移到代理的其余部分。&lt;/p&gt;

&lt;p&gt;这可能比较繁琐，因为重新分配需要确保所有副本不会从已退役的代理移动到另一个代理。为了简化这个过程，我们计划在将来为退役代理添加工具支持。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Increasing replication factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;增加现有分区的复制因子很容易，只需在定制的重新分配json文件中指定额外的副本，并使用—execute选项来增加指定分区的复制因子。&lt;/p&gt;

&lt;p&gt;示例: 将主题foo的partition-0的副本从1增加到3。在增加复制因子之前，代理5上只存在分区的副本，作为增加复制因子的一部分，我们将在代理6和代理7上添加更多的副本。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义迁移配置
$ cat increase-replication-factor.json
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6,7]}]}

# 执行
bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6,7]}]}

# 验证
bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --verify
Status of partition reassignment:
Reassignment of partition [foo,0] completed successfully

# 查看副本数
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic foo --describe
Topic:foo   PartitionCount:1    ReplicationFactor:3 Configs:
  Topic: foo    Partition: 0    Leader: 5   Replicas: 5,6,7 Isr: 5,6,7&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Limiting Bandwidth Usage during Data Migration&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kafka允许您对复制流量施加限制，设置用于将副本从一台机器移动到另一台机器的带宽上限。&lt;/p&gt;

&lt;p&gt;这在重新平衡集群、引导新代理或添加或删除代理时非常有用，因为它限制了这些数据密集型操作对用户的影响&lt;/p&gt;

&lt;p&gt;最简单的方式就是在使用&lt;code&gt;kafka-reassign-partitions.sh&lt;/code&gt;脚本时，使用限流功能，不过&lt;code&gt;kafka-configs.sh&lt;/code&gt;脚本也具有该功能。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 限制在执行重平衡时，迁移速度不能超过50MB/s.
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --execute --reassignment-json-file bigger-cluster.json —throttle 50000000

# 当然，如果要改变速率的限制，可以重新运行
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181  --execute --reassignment-json-file bigger-cluster.json --throttle 700000000
  There is an existing assignment running.
  The throttle limit was set to 700000000 B/s

# 一旦完成重平衡后，就可以再次验证
# 需要注意:当冲平衡完成后，使用--verify验证时需要删除限流，否则会影响正常复制
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181  --verify --reassignment-json-file bigger-cluster.json
Status of partition reassignment:
Reassignment of partition [my-topic,1] completed successfully
Reassignment of partition [mytopic,0] completed successfully
Throttle was removed.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;查看broker的限流配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type brokers
Configs for brokers &amp;#39;2&amp;#39; are leader.replication.throttled.rate=700000000,follower.replication.throttled.rate=700000000
Configs for brokers &amp;#39;1&amp;#39; are leader.replication.throttled.rate=700000000,follower.replication.throttled.rate=700000000&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;这显示了应用于复制协议的leader和follower端上的节流。默认情况下，两边分配相同的节流吞吐量值。&lt;/p&gt;

&lt;p&gt;查看限流的副本:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type topics
Configs for topic &amp;#39;my-topic&amp;#39; are leader.replication.throttled.replicas=1:102,0:101,
    follower.replication.throttled.replicas=1:101,0:102&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Setting quotas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配额设置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 为user=user1, client-id=clientA配置自定义配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1 --entity-type clients --entity-name clientA
Updated config for entity: user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39;.

# 为user=user1配置配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1
Updated config for entity: user-principal &amp;#39;user1&amp;#39;.

# 为client-id=clientA配置配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type clients --entity-name clientA
Updated config for entity: client-id &amp;#39;clientA&amp;#39;.

# 为user=userA配置默认的配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1 --entity-type clients --entity-default
Updated config for entity: user-principal &amp;#39;user1&amp;#39;, default client-id.

# 为user配置默认配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-default
Updated config for entity: default user-principal.

# 为client-id配置默认配额
$  bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type clients --entity-default
Updated config for entity: default client-id.

# 查看配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-name user1 --entity-type clients --entity-name clientA
Configs for user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-name user1
Configs for user-principal &amp;#39;user1&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type clients --entity-name clientA
Configs for client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

# 如果不指定entity name ，将显示所有的entity-type的配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users
Configs for user-principal &amp;#39;user1&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200
Configs for default user-principal are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-type clients
Configs for user-principal &amp;#39;user1&amp;#39;, default client-id are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200
Configs for user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 在broker的配置中增加如下配置，会默认为全部的生产者和消费者进行配额限制.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 生产者和消费者10MB/s
quota.producer.default=10485760
quota.consumer.default=10485760&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#operations&#34;&gt;kafka-operations&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gehf9xu0tzj30p00angou.jpg&#34; alt=&#34;交流群&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka生产规划和运维</title>
      <link>https://bgbiao.top/post/kafka%E7%94%9F%E4%BA%A7%E8%A7%84%E5%88%92%E5%92%8C%E8%BF%90%E7%BB%B4/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%94%9F%E4%BA%A7%E8%A7%84%E5%88%92%E5%92%8C%E8%BF%90%E7%BB%B4/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 通常对于初创企业或者初创业务团队来说，对于开源组件的使用都会显的比较随意，而这种情况会随着业务量级的增长或时间的推移导致开源服务的滥用，进而造成的结果就是服务整体的稳定性和可靠性相对较差，且是边际效应递减的，如果此时不对整体业务以及开源服务进行规划和改造，那么风险和成本将是同比增长的。在我过去的工作经历中，经历过类似服务的有&lt;code&gt;Redis集群&lt;/code&gt;，&lt;code&gt;ElasticSearch&lt;/code&gt;集群，虽然整体改造后并不一定将成本降到最低，但是可以将服务的可用性和可靠性提高很多，而且根据业务场景以及使用方式来规划集群后会使得整体的边际成本呈递减状态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;笔者目前所处的团队所管理的kafka集群也处于该种状态，集群当前规模大约为20+ECS，总数据量大约400T，其中承接的Topic服务主要分为&lt;code&gt;日志收集&lt;/code&gt;、&lt;code&gt;数据管道&lt;/code&gt;、&lt;code&gt;流式计算&lt;/code&gt;、&lt;code&gt;业务事件存储&lt;/code&gt;几种大场景，我们需要知道，以上几种使用场景对于kafka集群的的&lt;code&gt;可用性&lt;/code&gt;，&lt;code&gt;可靠性&lt;/code&gt;，&lt;code&gt;数据一致性&lt;/code&gt;要求其实是不同的，如果将所有场景耦合到同一个集群，在数据量较大的情况下，任何的小异常点都可能造成整体服务受到影响，并且整个集群的恢复周期会很长，如果业务没有及时的降级策略很可能影响核心业务的处理。&lt;/p&gt;

&lt;p&gt;鉴于以前对开源分布式服务的规划和改造经验，本篇文章将根据官方文档以及经验来分享一些关于Kafka生产集群规划和运维管理相关的知识.&lt;/p&gt;

&lt;h2 id=&#34;一-kafka集群运维和规划&#34;&gt;一、Kafka集群运维和规划&lt;/h2&gt;

&lt;p&gt;其实任何开源的分布式系统在开始规划时，就需要考虑到业务场景，以及生产环境的周边可观测系统，比如如下几个方面:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;规划和部署生产级别的集群(包含官方最佳实践以及一些针对不停场景推荐的配置项变更)&lt;/li&gt;
&lt;li&gt;执行一些部署后的操作(比如滚动重启集群，集群备份，数据迁移等等)&lt;/li&gt;
&lt;li&gt;集群的可观测性(监控重要统计数据，理解kafka内部行为的具体含义以及是否需要报警通知)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;二-集群规划&#34;&gt;二、集群规划&lt;/h2&gt;

&lt;p&gt;本节主要介绍，kafka集群在生产环境部署前的一些规划，包含硬件配置选择，网络以及文件系统和其他考虑的选型.&lt;/p&gt;

&lt;h3 id=&#34;1-硬件和os&#34;&gt;1.硬件和OS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;通常对于分布式的开源服务来将对于硬件本身没有太高的要求，但当需要承载一定量级的业务时，我们需要考虑一些硬件是否能够支撑对应的业务场景，并且通常来讲针对不同的业务场景选择不同的硬件(如果可选择)，也许会适当降低资源成本。&lt;/p&gt;

&lt;h4 id=&#34;1-0-os&#34;&gt;1.0 OS&lt;/h4&gt;

&lt;p&gt;一般来说，对于运行Linux中的kafka集群不需要过多的OS以及kernel参数调整，但如下几种情况可以根据具体情况进行参考:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;文件描述符(fd)&lt;/code&gt;: broker节点上fd限制可以参考&lt;code&gt;(number_of_partitions)*(partition_size/segment_size)&lt;/code&gt;公式&lt;/li&gt;
&lt;li&gt;&lt;code&gt;套接字缓冲区(socket buffer)&lt;/code&gt;: 该参数可以增加多数据中心之间的数据传输(一般异地集群备份建议调整以增加吞吐)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;最大内存映射区域数(vm.max_map_count)&lt;/code&gt;: 当kafka broker节点拥有太多分区时应该密切关注系统级别的该参数，默认为65535。每一个日志段，分配的分区，都需要一对&lt;code&gt;index/timeindex&lt;/code&gt;文件，而每个文件都会消耗一个内存区域(一个日志段使用2个内存映射区域)，因此一个分区至少需要2个内存区域，一个broker上拥有50000分区时，将会消耗100000个内存区域，此时默认的参数就会导致broker 以&lt;code&gt;OutOfMemoryError&lt;/code&gt;方式crash掉。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;每个分区的日志段的数量取决于段(segment)的大小，负载，以及保留策略&lt;/p&gt;

&lt;p&gt;kafka使用大量的文件以及socket和客户端进行通讯，我们都知道，在Linux下，一切皆文件，因此系统需要设置更多的可用文件描述符&amp;gt;。&lt;/p&gt;

&lt;p&gt;在大多数的默认系统配置中，单个进程可用使用1024个文件描述符，对于kafka来说太小了，建议调整到至少&lt;code&gt;100000&lt;/code&gt;，但是通常和操作
系统以及发行版本有关系，需要根据具体的OS进行调整。&lt;/p&gt;

&lt;p&gt;可用通过计算Kafka数据目录中的&lt;code&gt;.index&lt;/code&gt;文件来计算当前的mmap编号。&lt;code&gt;.index&lt;/code&gt;文件大多数代表了内存映射文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 1.统计.index文件个数
$ find . -name &amp;#39;*index&amp;#39; | wc -l

# 2.为每个session设置vm.max_map_count参数，这将计算当前内存映射文件的数量，mmap限制的最小值就是打开文件的ulimit限制
# 该值要远大于index的数量
$ sysctl -w vm.max_map_count=262144

# 3.持久化mmap参数
$ echo &amp;#39;vm.max_map_count=262144&amp;#39; &amp;gt;&amp;gt; /etc/sysctl.conf
$ sysctl -p&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;1-1-内存&#34;&gt;1.1 内存&lt;/h4&gt;

&lt;p&gt;Kafka严重依赖文件系统来存储和缓存消息。&lt;/p&gt;

&lt;p&gt;所有数据都会立即写入文件系统上的持久日志中，而不必刷新到磁盘。实际上，这仅意味着将其转移到内核的页面缓存&lt;code&gt;pagecache&lt;/code&gt;中。 当回收内存时，操作系统会将可用内存转移到磁盘缓存中，而对性能的影响很小。&lt;/p&gt;

&lt;p&gt;同时，Kafka非常小心地使用堆空间&lt;code&gt;heap space&lt;/code&gt;，不需要将堆大小设置为超过6 GB，这样将会在32G内存的机器上缓存28-30G的数据到文件系统。&lt;/p&gt;

&lt;p&gt;因此，生产集群需要足够的内存来缓存活动的reader和writer。在Confluent的使用建议中，提出了对内存需求的粗略估计方式，比如需要缓冲30s，那么内存需求大概为&lt;code&gt;write_throughput * 30&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通常来讲&lt;code&gt;64G&lt;/code&gt;内存配置的机器是一个不错的选择.&lt;/p&gt;

&lt;h4 id=&#34;1-2-cpu&#34;&gt;1.2 CPU&lt;/h4&gt;

&lt;p&gt;大多数的kafka集群对于cpu的要求不是那么高，因此对于CPU的配置没有像其他资源那么重要(但是通常同等资源都是由一定比例配比的)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果开启了SSL，那么可能对集群的整体性能有一定影响，且对cpu有一定要求，具体需要考虑到cpu的类型以及具体的JVM实现细节(通常来讲内部服务均不会开启SSL，因为管理成本很高，且性能上略有损失，安全上可以通过整体的IT安全进行要求和管控)&lt;/p&gt;

&lt;p&gt;通常情况下建议使用较新的多核处理器，通用集群可以设置为&lt;code&gt;24&lt;/code&gt;核心。&lt;/p&gt;

&lt;p&gt;如果需要在更快的CPU或更多的内核之间进行选择，请选择更多的内核，因为多核提供的额外并发性将远远超过稍快的时钟速度。&lt;/p&gt;

&lt;h4 id=&#34;1-3-disk&#34;&gt;1.3 Disk&lt;/h4&gt;

&lt;p&gt;生产集群建议使用多块磁盘来最大化整体的吞吐，不要与应用程序日志或其他OS文件系统活动共享用于Kafka数据的相同驱动器，以确保良好的延迟。&lt;/p&gt;

&lt;p&gt;在官方的最佳实践中建议，可以将&lt;code&gt;多块磁盘构建成RAID&lt;/code&gt;，或者直接将独立的&lt;code&gt;多块磁盘&lt;/code&gt;作为kafka的数据存储，也就是JBOD方案(Just Bunch Of Disks)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注:&lt;/code&gt;如果软RAID的话其实会在存储方面增加一层数据均衡，增加了集群的复杂度，因此一般可用选择后者，而且RAID主要用于提供冗余，对于开源分布式服务来讲，在软件层面上基本都会保证数据的冗余。&lt;/p&gt;

&lt;p&gt;不过在实际的场景中，具体选择使用多块盘做RAID还是直接使用多块盘挂载，以下有几种场景可以考虑:&lt;/p&gt;

&lt;p&gt;如果配置多个数据目录，则Broker将在路径中放置一个新分区，该分区中当前存储的分区数最少。每个分区将完全位于数据目录之一中，如果&lt;code&gt;分区之间的数据不平衡，就会导致磁盘之间的负载不平衡&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;RAID在平衡磁盘之间的负载方面做得更好，它能在较低的水平上平衡负载。RAID的主要缺点是减少了可用的磁盘空间(RAID0除外)，好处是可以容忍磁盘故障(RAID1，RAID5等)。&lt;/p&gt;

&lt;p&gt;在生产中强烈不建议使用RAID 5 or RAID 6 ,会严重影响到写吞吐的性能，并且在磁盘故障时会有重建阵列的I/O成本(&lt;code&gt;RAID0下也存在重建I/O的成本&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;如果额外的成本可以接受，建议使用RAID10(容量减半，多一份冗余)，否则，建议Kafka服务器配置多个日志目录，每个目录都安装在单独的驱动器上。&lt;/p&gt;

&lt;p&gt;linked使用8x7200转的sata磁盘，一般来说，磁盘吞吐量是性能瓶颈，磁盘越多越好。&lt;/p&gt;

&lt;p&gt;kafka官方文档中其实建议使用多个驱动器以获得良好的吞吐量，因为每个路径都独立挂载在不同的磁盘上，这使得多块物理磁盘磁头同时执行物理I/O写操作，可以极大地加速Kafka消息生产的速度。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 通常在使用本地盘时，容量可能会比较大，当磁盘容量超过2T时，Linux下默认的MBR分区就不能满足容量的要求了，此时需要在分区时进行GPT分区，否则等线上业务真正上线后会发现超过2T的空间就被浪费了。&lt;/p&gt;

&lt;p&gt;另外一个问题就是，磁盘容量规划的问题，虽然kafka默认为全部的日志数据设置了7天保留时间，但是往往在海量的数据消费场景中，单天的数据量也可能达到好几个T，这就导致了需要提前对业务的场景和使用方式进行提前规划，并提前计算最少的存储量。&lt;/p&gt;

&lt;p&gt;但一般对于磁盘空间的规划可以根据消息量大概估算，比如一天7亿条消息，单条1kb，消息副本为3(可保证2节点同时挂)，那么大概的存储空间为&lt;code&gt;7亿*3*1KB/1000/1000=2100G&lt;/code&gt;，也就是这种规模下的数据，一天产生2T的数据，实际使用数据为700G，1400G数据为冗余数据，此时我们在规划磁盘容量时就需要考虑到单天数据量的大小，以及数据的保留时间。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果客户端开启了消息压缩，整体的数据能再相对小一些，可以根据具体情况来考虑&lt;/p&gt;

&lt;h4 id=&#34;1-4-network&#34;&gt;1.4 Network&lt;/h4&gt;

&lt;p&gt;在分布式系统中，快速可靠的网络是性能的一个重要组成部分(&lt;code&gt;因此通常分布式系统中建议在同机房&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;低延迟确保节点可以轻松通信，而高带宽有助于集群节点之前的副本移动和恢复(&lt;code&gt;往往在kafka集群中优先瓶颈点都是带宽&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;目前大多数的数据中心基本都是千兆(1 GbE)或万兆网络(10 GbE)，对于大多数集群通常都是足够的。&lt;/p&gt;

&lt;p&gt;应该尽量避免集群跨越多个数据中心，即使数据中心在很近的距离同地区，也要避免跨越巨大地理距离的集群。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注:&lt;/code&gt;实际上在分布式系统中分区是肯定会发生的，通过避免跨机房部署能够降低分区的概率&lt;/p&gt;

&lt;p&gt;Kafka集群假设所有节点都是相等的，较大的延迟可能会加剧分布式系统中的问题，并使调试和解决变得更加困难。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果业务上需要异地进行数据读写，推荐的方法是在每个数据中心中部署一个本地Kafka集群，每个数据中心中的应用程序实例只与它们的本地集群交互，并在集群之间进行镜像(kafka提供了mirror-maker工具)。&lt;/p&gt;

&lt;h4 id=&#34;1-5-filesystem&#34;&gt;1.5 Filesystem&lt;/h4&gt;

&lt;p&gt;现在操作系统中，大部分的系统应该都使用了&lt;code&gt;Ext4&lt;/code&gt;或&lt;code&gt;XFS&lt;/code&gt;系统，官方也推荐使用这两种文件系统，但是对于具体的文件系统的选择，官方提供了如下几种场景和需要注意的点。&lt;/p&gt;

&lt;p&gt;使用各种文件系统创建和挂载选项，在具有大量消息负载的集群上执行了比较测试，XFS带来了更好的本地时间(最好的EXT4配置是160ms vs. 250ms+)，以及更低的平均等待时间。XFS性能在磁盘性能方面的可变性也较小。&lt;/p&gt;

&lt;p&gt;不论是使用哪种文件系统，推荐修改默认的挂载参数:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;noatime&lt;/code&gt;: 此选项禁止在读取文件时更新文件的atime(最后访问时间)属性,这可以消除大量的文件系统写操作，特别是在引导消费者的情况下,Kafka完全不依赖于atime属性，所以禁用它是安全的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat /etc/fstab
UUID=&amp;#34;4231b126-7e67-45c4-b8bf-554006291d35&amp;#34;  /export1    xfs    defaults,noatime         0 2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;XFS文件系统挂载参数优化:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;largeio&lt;/code&gt;: 这会影响stat调用报告的首选I/O大小，尽管这可以在较大的磁盘写入上实现更高的性能，但实际上对性能的影响很小或没有影响&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nobarrier&lt;/code&gt;: 于具有电池后备缓存的基础设备，此选项可以通过禁用定期写刷新来提供更高的性能。 但是，如果基础设备的行为良&amp;gt;好，它将向文件系统报告它不需要刷新，并且此选项将无效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EXT文件系统挂载参数优化:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在ext4文件系统下，要获得最佳性能，则需要调整几个参数。这些选项在故障情况下通常是不安全的，并且将导致更多的数据丢失和损坏，对于单个broker故障，可以擦除磁盘并从群集重建副本，在多数情况下，多broker异常意味着潜在的文件系统损坏，无法轻易恢复。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data=writeback&lt;/code&gt;: Ext4默认为data = ordered，这使某些写入操作具有很强的顺序，在Kafka场景下其实不需要该参数，此设置消除了排序约束，并且似乎大大减少了延迟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Disabling journaling&lt;/code&gt;: 日志记录是一个折衷:它使服务器崩溃后重新引导更快，但它引入了大量额外的锁定，增加了写入性能的差异&lt;/li&gt;
&lt;li&gt;&lt;code&gt;commit=num_secs&lt;/code&gt;: 这调整了ext4提交到其元数据日志的频率。 将此值设置为较低的值可以减少崩溃期间未刷新数据的丢失。 将此值设置为较高的值将提高吞吐量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nobh&lt;/code&gt;: 此设置控制在使用data=writeback模式时附加的排序保证，可以提高吞吐量和延迟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delalloc&lt;/code&gt;: 延迟分配意味着文件系统避免在物理写入发生之前分配任何块，此功能非常适合吞吐量&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-6-application-vs-os-flush-management&#34;&gt;1.6 Application vs. OS Flush Management&lt;/h4&gt;

&lt;p&gt;Kafka始终会立即将所有数据写入文件系统，并支持配置刷新策略的功能，该策略控制何时使用刷新将数据从OS缓存中强制出到磁盘上。&lt;/p&gt;

&lt;p&gt;可以控制此刷新策略，以在一段时间后或在写入一定数量的消息之后将数据强制到磁盘。 在此配置中有几种选择。&lt;/p&gt;

&lt;p&gt;Kafka必须最终调用fsync才能知道数据已刷新。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;当从崩溃中恢复任何未知的日志段时，Kafka将通过检查其消息的CRC来检查每条消息的完整性，并在启动时执行的恢复过程中重建附带的偏移索引文件&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;请注意，Kafka中的持久性不需要将数据同步到磁盘，因为发生故障的节点将始终从其副本中恢复。&lt;/p&gt;

&lt;p&gt;我们建议使用默认刷新设置，该设置将完全禁用应用程序的fsync。&lt;/p&gt;

&lt;p&gt;这意味着依靠操作系统和Kafka自己的后台刷新来完成后台刷新。&lt;/p&gt;

&lt;p&gt;这为所有用途提供了最佳的解决方案：无需调节配置，提高吞吐量和延迟，并提供完全恢复保证。&lt;/p&gt;

&lt;p&gt;通常，我们认为&lt;code&gt;复制&lt;/code&gt;提供的保证要强于&lt;code&gt;同步到本地磁盘&lt;/code&gt;，但是偏执狂仍然更愿意同时拥有两者，并且仍然支持应用程序级fsync策略。&lt;/p&gt;

&lt;p&gt;使用应用程序级刷新设置的缺点是，其磁盘使用模式效率较低（它给操作系统减少了重新排序写操作的余地），并且由于大多数Linux文件系统中的fsync阻止了文件写入，因此它会引入延迟。 后台刷新进行更精细的页面级锁定。&lt;/p&gt;

&lt;h4 id=&#34;1-7-理解linux操作系统的flush行为&#34;&gt;1.7 理解Linux操作系统的Flush行为&lt;/h4&gt;

&lt;p&gt;在Linux中，写入文件系统的数据将保留在页面缓存中，直到必须将其写出到磁盘为止（由于应用程序级fsync或操作系统自身的刷新策略）。&lt;/p&gt;

&lt;p&gt;数据刷新是通过一组称为pdflush的后台线程完成的（或在2.6.32版的内核“冲洗线程”中）。&lt;/p&gt;

&lt;p&gt;Pdflush具有可配置的策略，该策略控制可以在缓存中维护多少脏数据以及必须将多脏数据写回到磁盘的时间.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://web.archive.org/web/20160518040713/http://www.westnet.com/~gsmith/content/linux-pdflush.htm&#34;&gt;pdflush刷新策略&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当Pdflush无法跟上写入数据的速度时，它将最终导致写入过程阻塞写入中的延迟，从而减慢数据的累积。&lt;/p&gt;

&lt;p&gt;与进程内缓存相比，使用pagecache存储将写入磁盘的数据有几个优点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I/O调度将连续的小写批量写到更大的物理写中，从而提高吞吐量&lt;/li&gt;
&lt;li&gt;I/O调度尝试重新排序写操作，以最小化磁盘头的移动，从而提高吞吐量&lt;/li&gt;
&lt;li&gt;它会自动使用机器上所有的空闲内存&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-节点配置&#34;&gt;2.节点配置&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1.避免使用太小的节点配置，因为这样整个集群的节点数可能会特别多，在这种机器上运行kafka将会有更多的开销&lt;/li&gt;
&lt;li&gt;2.避免使用太高配计算机，因为它们经常导致资源使用不平衡，比如内存优先不够了，但cpu还剩余很多。如果在每个高配机器上运行多个broker节点，将会增加整体的复杂度&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-jvm配置&#34;&gt;3.JVM配置&lt;/h3&gt;

&lt;p&gt;在当前大多数Java类应用下，基本都在使用JDK8(建议使用最新的jdk8)，在此环境下默认使用的是&lt;code&gt;G1&lt;/code&gt;的垃圾回收器，因此一般情况下仅需要修改如下参数即可:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MaxGCPauseMillis&lt;/code&gt;: 指定每次垃圾回收默认的停顿时间，默认值200ms&lt;/li&gt;
&lt;li&gt;&lt;code&gt;InitiatingHeapOccupancyPercent&lt;/code&gt;: G1 启动新一轮垃圾回收之前可以使用的堆内存百分比，默认值是45&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;官方推荐的GC参数如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20
       -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M
       -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;作为参考，LinkedIn最繁忙的集群当前是如下情况:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;60 brokers&lt;/li&gt;
&lt;li&gt;50k partitions (replication factor 2)&lt;/li&gt;
&lt;li&gt;800k messages/sec in&lt;/li&gt;
&lt;li&gt;300 MBps inbound, 1 GBps + outbound&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面的GC调优看起来比较激进，但集群中的所有broker都会有90%的gc中止时间，大概21ms，它们做不到每秒一个young GC&lt;/p&gt;

&lt;p&gt;作为同样是图片社交的&lt;code&gt;Pinterest&lt;/code&gt;来讲，他们采用如下的JVM参数:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/how-pinterest-runs-kafka-at-scale-ff9c6f735be&#34;&gt;Pinterest的大规模kafka实践&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 61G的内存
-Xms8g -Xmx8g -XX:NewSize=512m -XX:MaxNewSize=512m -XX:MetaspaceSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=25
       -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=25 
       -XX:MaxMetaspaceFreeRatio=75
       -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:PrintTenuringDistribution 
       -Xloggc:/var/log/kafka/gc.log -XX:UseGCLogFileRotation -XX:NumberOfGCLogFiles=40
       -XX:GCLogFileSize=50M&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;-Xmx10G -Xms10G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xloggc:/opt/app/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;4-kafka核心配置&#34;&gt;4.kafka核心配置&lt;/h3&gt;

&lt;p&gt;Kafka默认设置在大多数情况下都能工作，特别是与性能相关的设置和选项，但是考虑到集群的规划以及场景用途，有一些补充的配置参数可以对生产环境进行调优。&lt;/p&gt;

&lt;p&gt;通常配置上来讲会分为&lt;code&gt;broker端配置&lt;/code&gt;、&lt;code&gt;produser端配置&lt;/code&gt;、&lt;code&gt;consumer端配置&lt;/code&gt;，由于各个业务方当前均使用开源客户端，因此对于客户端的配置无法做到严格管控(如果有内部的sdk封装可能会比较好)。&lt;/p&gt;

&lt;h4 id=&#34;4-1-重要的客户端配置&#34;&gt;4.1 重要的客户端配置&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks&lt;/code&gt;: 消息一致性保证(0:投递即成功,1:副本同步即成功,all/-1:全部ISR同步即成功)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression&lt;/code&gt;: 压缩类型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch size&lt;/code&gt;: 批处理大小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 对于消费者来说，最重要的参数为&lt;code&gt;fetch size&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;鉴于集群的整体可用性可靠性其实很大一部分和客户端的使用方式有关，后面会列举一些常见的生产者和消费者端的核心参数&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#configuration&#34;&gt;kafka详细参数列表&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-2-broker核心配置&#34;&gt;4.2 broker核心配置&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;zookeeper.connect&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;zk连接串，建议写全部的zk节点地址。&lt;/p&gt;

&lt;p&gt;brokers链接的zk集群地址，该值默认采用&lt;code&gt;host:ip/path&lt;/code&gt;来指定一个zk中的znode节点，通常情况下用来隔离环境. kafka的zk路径中使
用了&lt;code&gt;chroot&lt;/code&gt;环境，如果不指定使用默认的&lt;code&gt;/&lt;/code&gt;来作为存储路径。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;broker.id&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker唯一标识，该值可以任意设定(int类型)。默认&lt;code&gt;reserved.broker.max&lt;/code&gt;开始，每次+1&lt;/p&gt;

&lt;p&gt;在分布式集群中，可以手动指定每个broker的节点信息，同时也可以使用如下方式来自动生成每个broker的id&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;#broker.id
broker.id.generation.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;log.dirs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;kafka存储的日志消息都是保存在该参数指定的日志路径下，该值可以指定多个磁盘路径，通常我们会绑定到多个磁盘上。比如&lt;code&gt;log.dirs=/exoprt/kafka1,/export/kafka2,/export/kafka3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;对应的另外一个默认参数为&lt;code&gt;log.dir&lt;/code&gt;，默认值为&lt;code&gt;/tmp/kafka-logs&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;listeners&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker监听列表，默认将为&lt;code&gt;PLAINTEXT://myhost:9092&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;advertised.listeners&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;监听器发布到zk集群中的地址，供客户端使用，默认采用&lt;code&gt;listeners&lt;/code&gt;参数值&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.recovery.threads.per.data.dir&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每个数据目录用于在启动时进行日志恢复和在关闭时进行刷新的线程数，默认值为: &lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;生产环境下，该值可以适当的调整大一些，用来增加正常关闭时数据flush的速度，以及启动时日志恢复的速度，可以提高broker节点的整体可用性。&lt;/p&gt;

&lt;p&gt;对于如下几种情况，kafka会使用&lt;code&gt;可配置的线程池&lt;/code&gt;来处理日志片段.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器正常启动: 用于打开每个分区的日志片段&lt;/li&gt;
&lt;li&gt;服务器崩溃后重启: 用于检查和截断每个分区的日志片段&lt;/li&gt;
&lt;li&gt;服务器正常关闭: 用于关闭日志片段&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;默认情况下，每个日志目录采用一个线程，因为这些线程仅有在启动和关闭时才用到，所以可以适当设置大一点，并不会影响到整体服务的性能，特别是对于包含大量分区的服务器来说，一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。&lt;/p&gt;

&lt;p&gt;需要注意的是，该值是每个日志目录的线程数，因此总线程数需要考虑到&lt;code&gt;log.dirs&lt;/code&gt;的配置&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注&lt;/code&gt;: 这也是在使用RAID和JBOD两种磁盘方案的另外一个考虑点&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;delete.topic.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否允许删除topic，默认为: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果为false，通过管理工具删除topic仅为标记删除，此时使用&lt;code&gt;describe&lt;/code&gt;命令可以查看到topic的详情信息，但是无法写入，可以通过删除&lt;code&gt;zk&lt;/code&gt;中的节点来删除&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注&lt;/code&gt;: 生产环境建议设置为&lt;code&gt;false&lt;/code&gt;，由集群管理员定期统一的进行删除和管理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.create.topics.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;默认情况下，kafka会使用如下三种方式创建topic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当一个生产者开始往主题写入消息时&lt;/li&gt;
&lt;li&gt;当一个消费者开始从主题读取消息时&lt;/li&gt;
&lt;li&gt;当任意一个客户端向主题发送元数据请求时&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推荐是设置成&lt;code&gt;false&lt;/code&gt;，不允许客户端直接创建topic，否则topic会无法管理。默认值为&lt;code&gt;true&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.leader.rebalance.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否开启&lt;code&gt;leader&lt;/code&gt;自动平衡，默认值为&lt;code&gt;true&lt;/code&gt;。后台会有线程进行定期检查leader的分布情况&lt;/p&gt;

&lt;p&gt;kafka中有一个被称为优先副本（preferred replicas）的概念(通常分区会有主分区和副本分区的概念，主分区先写入，然后push到其他副本分区)。&lt;/p&gt;

&lt;p&gt;如果一个分区有3个副本，且这3个副本的优先级别分别为0,1,2，根据优先副本的概念，0会作为leader 。&lt;/p&gt;

&lt;p&gt;当0节点的broker挂掉时，会启动1这个节点broker当做leader。&lt;/p&gt;

&lt;p&gt;当0节点的broker再次启动后，会自动恢复为此partition的leader。不会导致负载不均衡和资源浪费，这就是leader的均衡机制(前提是第一次partition在分配的时候，它本身就是一个相对平均的分配)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;auto.leader.rebalance.enable=true
# 对应影响的其他两个参数
# leader.imbalance.per.broker.percentage : 每个broker允许leader不平衡比例(如果每个broker上超过了这个值，controller将会&amp;gt;执行分区再平衡)，默认值10.
# leader.imbalance.check.interval.seconds: 主分区再平衡的频率，默认值为300s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;其实，在重要业务的场景中，需要将&lt;code&gt;leader.imbalance.per.broker.percentage&lt;/code&gt;参数适当调整小一些，以避免broker中leader不平衡率导致节点的吞吐不均匀&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动创建topic的默认分区数，默认为1，通常生产集群不建议打开topic自动创建，一方面是不便于管理和追溯，另外一方面因为自动创建默认分区时1，且无法动态变更，造成的风险可能会比较大。&lt;/p&gt;

&lt;p&gt;多分区的topic有这更好的数据平衡能力，并且可以帮助消费者进行并行化消费。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 对于有key的数据，避免改变分区的数量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;default.replication.factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;适用于自动创建的主题的默认复制因子，推荐至少设置为2，默认为1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.insync.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当使用&lt;code&gt;required.acks=-1(all)&lt;/code&gt;提交到生产请求所需的ISR中的最小副本数，默认为1，建议在数据一致性要求较高的topic中设置至少为2&lt;/p&gt;

&lt;p&gt;指定&lt;code&gt;ISR&lt;/code&gt;的最小数量。当producer设置&lt;code&gt;ack=all(-1)&lt;/code&gt;时，该值指定的副本必须全部写成功，才认为消息写入成功，否则生产者将抛异常(&lt;code&gt;either NotEnoughReplicas or NotEnoughReplicasAfterAppend&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: &lt;code&gt;min.insync.replicas&lt;/code&gt;参数和生产者&lt;code&gt;ack&lt;/code&gt;参数一起使用，可以加强整个消息的持久性&lt;/p&gt;

&lt;p&gt;示例:(3副本的topic,可以设置该值为2,同时生产者ack设置为all，这将确保大多数副本没有收到写操作时，生产者直接异常)&lt;/p&gt;

&lt;p&gt;默认值为:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;unclean.leader.election.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否启用不在ISR集中的副本以选作领导者，即使这样做可能会导致数据丢失。该参数可以提高整体Topic的可用性，但是可能会造成数据的整体不一致性(部分数据的丢失)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#topicconfigs&#34;&gt;kafka可用性和可靠性保证&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;默认值为:&lt;code&gt;false&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;为false，就只从ISR中获取leader保证了数据的可靠性，但是partition就失效了，&lt;code&gt;true&lt;/code&gt;则从replica中获取，则可用性增强，但是数&amp;gt;据可能存在丢失情况&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;  该参数实际上在设置的时候也有一定的争议性，比如，我们知道副本是有&lt;code&gt;ISR&lt;/code&gt;的，即正在同步的副本，如果当前的broker宕&amp;gt;机导致需要选举leader partition，此时如果ISR内除了leader之外还有其他副本(但谁又能保证一定有呢)，那直接从ISR中选举leader&amp;gt;即可，如果没有的话，当&lt;code&gt;auto.leader.rebalance.enable=true&lt;/code&gt;时，就会去其他存活的副本中选举leader，此时可以增强整体的可用性，但是如果存活的副本不在ISR中，即意味着数据可能有一定的丢失了。但是如果该参数为false的话，ISR中没有，就直接异常了，为了保证数据的一致性。&lt;/p&gt;

&lt;p&gt;该参数的存在其实是在可用性和可靠性之间做了一个权衡，为true时保证了可用性AP，为false时保证了一致性CP&lt;/p&gt;

&lt;p&gt;&lt;code&gt;数据一致性保证&lt;/code&gt;: ISR就保存了kafka认为可靠的副本，它们具备这样的条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;落后leader的消息条数在一定阈值内&lt;/li&gt;
&lt;li&gt;或者落后在一定时间内；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;num.replica.fetchers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数指定了fetch线程的数量(从源broker中复制消息的fetch线程)，默认值: &lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其实可以适当的调整大一些，可以增强副本之前的同步效率，设置为2可以满足大多数的场景&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.io.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker处理请求的 IO 线程数，需要考虑到磁盘的IO状况。默认值为:&lt;code&gt;8&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该值通常情况下在生产环境也可以适当的调整大一些，但是通常情况下需要考虑到所使用的的磁盘的整体情况，可以尝试设置为&lt;code&gt;num.network.threads&lt;/code&gt;的两倍，比如&lt;code&gt;d1ne.4xlarge&lt;/code&gt;的规格其实可以设置为20&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.network.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定broker用来接收来自网络的请求和发送网络的响应的线程数，默认值为: &lt;code&gt;3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在生产环境中，可以根据网络的情况以及cpu和内存的使用情况将该值默认调大一些，基本上可以为逻辑cpu核心的2/3都是可以的，比如我们生产环境采用&lt;code&gt;d1ne.4xlarge&lt;/code&gt;规格的实例，可以设置该值为10&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;background.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;后台任务处理线程数(例如过期消息删除等)。默认值为:&lt;code&gt;10&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;socket相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;socket.send.buffer.bytes: (socket发送缓冲区:SO_SNDBUFF) 默认值:&lt;code&gt;102400&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;socket.receive.buffer.bytes: (socket接收缓冲区:SO_RCVBUFF) 默认值:&lt;code&gt;102400&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;socket.request.max.bytes: (请求最大值，message.max.bytes要小于该值较好) 默认值:&lt;code&gt;104857600&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在生产环境中如果涉及到多可用区，或多机房环境时，socket缓冲区的默认值也是有点小的，因此尝试可以尝试将该值设置为&lt;code&gt;1M&lt;/code&gt;或者&lt;code&gt;2M&lt;/code&gt;，即&lt;code&gt;socket.send.buffer.bytes=2097152/1048576&lt;/code&gt;，生产环境推荐优化该参数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.max.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该值表示kafka允许的最大的batch大小(不是单个message的大小)，默认值为&lt;code&gt;1000012&lt;/code&gt;，即1MB.&lt;/p&gt;

&lt;p&gt;在最新的消息格式版本中，为了提高效率，一般消息的提交都是采用batch的方式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在以前的消息格式版本中，未压缩的记录不会分组成批，在这种情况下，此限制仅适用于单个记录。&lt;/p&gt;

&lt;p&gt;在每个topic级别可以使用&lt;code&gt;max.message.bytes&lt;/code&gt;设置&lt;/p&gt;

&lt;p&gt;通常情况下，如果是一个集群承担多种业务场景，通常需要将该值设置为可以满足大多数场景的配置，比如&lt;code&gt;4194304&lt;/code&gt;即&lt;code&gt;4MB&lt;/code&gt;，&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;log相关(具体到topic级别)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;log.segment.bytes: 单个日志段(segment)的大小，默认为&lt;code&gt;1073741824&lt;/code&gt;,即1GB&lt;/li&gt;
&lt;li&gt;log.segment.delete.delay.ms: 日志段从文件系统中删除前等待的时间，默认为&lt;code&gt;60000&lt;/code&gt;，即1min&lt;/li&gt;
&lt;li&gt;log.cleanup.policy: 保留窗口之外的日志清理策略可同时指定多个策略如: [&lt;code&gt;delete&lt;/code&gt;,compact]&lt;/li&gt;
&lt;li&gt;log.cleaner.enable: 启用日志清除器进程，和&lt;code&gt;cleanup.policy = compact&lt;/code&gt;参数结合使用，默认为&lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.cleaner.threads: 日志清理的后台线程数量，默认为&lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.cleaner.delete.retention.ms: 删除的日志保留的时间，默认为&lt;code&gt;86400000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.retention.bytes: 删除日志前，日志最大的大小，超过该值即删除，默认&lt;code&gt;-1&lt;/code&gt;，作用在每个partition，会影响整个topic的容量&lt;/li&gt;
&lt;li&gt;log.retention.minutes(hours|ms): 日志保留时间，如果没指定，默认使用hours参数&lt;/li&gt;
&lt;li&gt;log.retention.check.interval.ms: 日志清理器检查日志是否符合删除条件的频率，默认为&lt;code&gt;300000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.interval.messages: 将消息刷新到磁盘之前在日志分区上累积的消息数，默认为&lt;code&gt;9223372036854775807&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.interval.ms: 主题中的消息在刷新到磁盘之前保存在内存中的最大时间，默认为&lt;code&gt;null&lt;/code&gt;(log.flush.scheduler.interval.ms参数的值)&lt;/li&gt;
&lt;li&gt;log.flush.scheduler.interval.ms: 日志刷新器检查是否需要将日志刷新到磁盘的频率，默认&lt;code&gt;9223372036854775807&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.offset.checkpoint.interval.ms: 更新最后一次刷新的持久记录(被作为恢复点)的频率，默认为&lt;code&gt;60000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.start.offset.checkpoint.interval.ms: 更新日志起始偏移量的持久记录的频率，默认&lt;code&gt;60000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.roll.hours: 新日志段(segment)被创建前的最大时间，默认&lt;code&gt;168&lt;/code&gt;，如果没设置优先使用&lt;code&gt;log.roll.ms&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;offsets相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;offsets.commit.required.acks: offset提交之前是否需要ack确认,默认值:&lt;code&gt;-1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.commit.timeout.ms: 当偏移量注意&lt;code&gt;_offset&lt;/code&gt;的所有副本接收到提交或超时达到该时间时，offset提交将延迟. 默认值:&lt;code&gt;5000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.load.buffer.size: 偏移量加载到缓存中时从偏移量段读取的批处理大小. 默认值:&lt;code&gt;5242880&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.retention.check.interval.ms: 历史offset检查的频率，默认值:&lt;code&gt;600000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.retention.minutes: 在消费者组的消费者全部异常之后，offset保留的时间，默认值:&lt;code&gt;10080&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.topic.compression.codec: 偏移量主题的压缩解码器，默认:&lt;code&gt;0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.topic.num.partitions: offset提交主题的分区数量，默认:&lt;code&gt;50&lt;/code&gt;(&lt;code&gt;注意:&lt;/code&gt;集群部署后不要改变)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;offsets.topic.replication.factor&lt;/code&gt;: offset提交主题的副本数，默认:&lt;code&gt;3&lt;/code&gt; (在集群大小满足此复制因子要求之前，内部主题创建将&amp;gt;失败,该主题非常重要，需要要求强一致性)&lt;/li&gt;
&lt;li&gt;offsets.topic.segment.bytes: offset提交主题的段大小，设置相对较小，以便更快地实现日志压缩和缓存负载，默认值:&lt;code&gt;104857600&lt;/code&gt;，即1Mb&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;queue相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;queued.max.requests: 在网络阻塞线程前，数据平面允许的排队请求数，默认值:&lt;code&gt;500&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;replica相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;replica.fetch.min.bytes:每个fetch响应所需的最小字节数，默认值:&lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.wait.max.ms: 由follow副本发起的每个fetch请求的最大等待时间，该值应小于&lt;code&gt;replica.lag.time.max.ms&lt;/code&gt;，以避免
为低吞吐量的主题频繁地收缩ISR，默认值:&lt;code&gt;500&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.lag.time.max.ms: follow副本在该时间内没有和leader副本同步，或没有发送任何同步请求，将会被leader副本从ISR中删&amp;gt;除. 默认值:&lt;code&gt;10000&lt;/code&gt;，即10s&lt;/li&gt;
&lt;li&gt;replica.socket.receive.buffer.bytes: 副本接收请求的网络缓冲区，默认值:&lt;code&gt;65535&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.socket.timeout.ms: 网络请求的超时时间，默认值:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.backoff.ms: 发生获取分区错误时要休眠的时间，参数不是很重要，默认值:&lt;code&gt;1000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.max.bytes: 尝试为每个分区获取的消息字节数，参数不是很重要，默认值:&lt;code&gt;1048576&lt;/code&gt;,即1M&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;broker.rack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker所在的机架，用来感知机架的变化，通常多个分区不会放在同一个机架上&lt;/p&gt;

&lt;p&gt;示例: &lt;code&gt;RACK1&lt;/code&gt;, &lt;code&gt;us-east-1d&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;controller控制器相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;controlled.shutdown.enable&lt;/code&gt;: 启用控制器关闭，默认:&lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;controlled.shutdown.max.retries: 控制器会因为各种原因而宕机，该值表示控制器的重试次数，默认:&lt;code&gt;3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;controlled.shutdown.retry.backoff.ms: 在每次重试之前，系统从前一次故障(控制器fail over或副本延迟)的状态中恢复过来的时
间，默认:&lt;code&gt;5000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;controller.socket.timeout.ms&lt;/code&gt;: 控制器到broker角色转换的socket超时时间，默认:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;group相关(消费组)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;group.max.size: 消费组中最大消费者数量&lt;/li&gt;
&lt;li&gt;group.initial.rebalance.delay.ms:注册消费者允许的最小会话超时，默认:&lt;code&gt;6000&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 很多参数是有不同级别的生效范围的，比如:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;read-only&lt;/code&gt;: 仅在broker重启后才能生效&lt;/li&gt;
&lt;li&gt;&lt;code&gt;per-broker&lt;/code&gt;: 可以为每个broker动态更新&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster-wide&lt;/code&gt;: 可作为集群范围内的值动态更新，也可以在每个broker上更新进行测试&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#brokerconfigs&#34;&gt;broker配置作用范围&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;示例配置&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# ZooKeeper地址
zookeeper.connect=[list of ZooKeeper servers]

# kafka log相关配置
num.partitions=8
default.replication.factor=3
log.dirs=[List of directories. Kafka should have its own dedicated disk(s) or SSD(s).]

# 其他配置核心配置
broker.id=[An integer. Start with 0 and increment by 1 for each new broker.]
listeners=[list of listeners]
auto.create.topics.enable=false
# 最小的isr数量，可以在topic级别设置
min.insync.replicas=2
queued.max.requests=[number of concurrent requests]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在kafka集群中，当broker集群参数确定后，还有一些针对topic的参数是可以进行动态调整的，以提高kafka服务的灵活性。&lt;/p&gt;

&lt;h4 id=&#34;4-3-topic级别的动态参数调整&#34;&gt;4.3 Topic级别的动态参数调整&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#topicconfigs&#34;&gt;Topic级别的配置&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 如下topic的参数可以在使用过程中进行动态调整，使用&lt;code&gt;kafka-topic.sh&lt;/code&gt;工具中的&lt;code&gt;alter&lt;/code&gt;参数来直接修改topic相关的参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cleanup.policy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个字符串是“删除”或“压缩”或两者兼而有之. 默认值: &lt;code&gt;[compact, delete]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;compression.type&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;日志压缩类型，默认值为&lt;code&gt;producer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;delete.retention.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用于日志压缩主题的删除保留时间。默认值:&lt;code&gt;86400000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.message.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每个topic可发送的最大消息(batch size)字节数.(区别于全局的&lt;code&gt;message.max.bytes&lt;/code&gt;参数)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定创建topic的默认分区数量，该值默认为1，建议根据具体的情况进行设定，越多的分区对于海量数据来说可以提高吞吐，但是对于少量数据来说，也可能增加网络消耗.&lt;/p&gt;

&lt;p&gt;一般情况下，我们会对默认的topic的分区进行过度分配，以防止后期带key的message扩容分区导致的问题，一般建议初始值设置为5-10&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;分区数一旦指定，只能增加，不能减少&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;default.replication.factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定kafka副本数，默认每个主题分区均有一个副本，当该副本所在主机异常，可能造成数据的丢失，建议在适当场景将副本至少设置成
2个，以尽快保证数据的一致性。默认值:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;自动创建主题的副本因子&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retention.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;kafka的log保留时间，也可以使用&lt;code&gt;log.retention.hours&lt;/code&gt;参数来配置保留时间，默认168小时，即一周。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retention.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定log保留的大小，作用在每一个partition上，加入一个topic有3个partition，设置了&lt;code&gt;log.retention.bytes&lt;/code&gt;为1GB，则表示整个topic仅可以存储3GB的数据，超过该容量的数据会被进行自动删除。&lt;/p&gt;

&lt;p&gt;此时，临时增加该topic的容量的方法就是调整该参数，或调整topic的partition个数。&lt;/p&gt;

&lt;p&gt;-1表示不限制&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;segment.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每个日志段的大小，通常在消息到达broker时，会被追加到分区的当前日志段上(segment)，当日志段大小超过该参数指定的值(默认1GB)，当前日志段就会被关闭，一个新的日志段被打开。&lt;/p&gt;

&lt;p&gt;如果一个日志片段被关闭，就开始等待过期，该值不建议设置太小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;segment.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面会指定日志段的分割，该参数会指定历史的日志段的过期时间。该参数会和&lt;code&gt;log.retention.bytes&lt;/code&gt;一起校验，谁先满足就生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.max.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该值用来限制单个消息的大小，默认值为&lt;code&gt;1000 000&lt;/code&gt;即&lt;code&gt;1MB&lt;/code&gt;，如果超过该大小，broker不会接受，而且会抛出相关异常&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;该参数指的是消息被压缩后的大小，通常生产中的消息生产会使用gzip或snappy来进行压缩&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;消息的大小对于性能有比较显著的影响，越大负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求，还会增加磁
盘写入块的大小，从而影响 IO 吞吐量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;file.delete.delay.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在从文件系统中删除一个文件前的等待时间&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flush.messages&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数允许我们指定一个间隔来强制同步数据到本地磁盘，比如设置为1，表示每条消息后都会执行同步磁盘，如果设置为5表示，每5个消息同步一次。&lt;/p&gt;

&lt;p&gt;一般情况下，管法定不建议修改该参数，可以使用副本机制来保证持久性和开启操作系统的后台flush功能，会更加有效率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flush.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;同上，但是指定的是时间间隔。比如设置1000，表示1000ms后执行一次同步操作.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;follower.replication.throttled.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对日志复制的副本列表应该被在follow侧进行限流。&lt;/p&gt;

&lt;p&gt;副本列表应该为&lt;code&gt;[PartitionId]:[BrokerId],[PartitionId]:[BrokerId]&lt;/code&gt;格式，或者使用通配符&lt;code&gt;*&lt;/code&gt;来表示给topic的所有副本进行限流。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;leader.replication.throttled.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;同上，在leader侧进行限流&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;index.interval.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来控制多久kafka会增加一个index实体数据到它的offset的index上。默认设置确保我们大约每4096字节索引一条消息。索引越多，读取越接近日志中的确切位置，但索引越大。通常不需要修改该参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.message.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;被kafka允许的最大记录的batch size。&lt;/p&gt;

&lt;p&gt;如果增加了该值，并且有消费者版本老于&lt;code&gt;0.10.2&lt;/code&gt;，消费者的&lt;code&gt;fetch size&lt;/code&gt;也必须增加，这样就能获取到该批次大小的数据。&lt;/p&gt;

&lt;p&gt;在高版本的消息格式(message format)中，为了效率，记录总是会被分组成batch；而在之前的消息格式版本中，未被压缩的消息不会被分组成batch，在这种情况下，该参数仅在单条记录上生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.downconversion.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此配置用于控制是否启用消息格式的向下兼容以满足消费者请求。&lt;/p&gt;

&lt;p&gt;当设置成&lt;code&gt;false&lt;/code&gt;，对于希望使用较旧消息格式的消费者来说，broker将不会执行向下转换。来自旧客户端的消费者请求，broker将会返回&lt;code&gt;UNSUPPORTED_VERSION&lt;/code&gt;错误码。&lt;/p&gt;

&lt;p&gt;此配置不适用于可能需要复制到follower的消息格式转换。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.format.version&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定消息格式版本，broker将使用&lt;code&gt;append&lt;/code&gt;方式追加message到log里。该值必须是一个可用的ApiVersion，比如&lt;code&gt;0.8.2, 0.9.0.0, 0.10.0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过设置特定的消息格式版本，用户可以验证已存在磁盘上的消息是否小于或者等于指定的版本。&lt;/p&gt;

&lt;p&gt;错误地设置此值将导致使用较旧版本的使用者中断，因为他们将收到他们不理解的格式的消息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.timestamp.difference.max.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker接收到消息的时间戳和在消息体内部的时间戳的最大时间差距。如果&lt;code&gt;message.timestamp.type=CreateTime&lt;/code&gt;，当时间戳的差值大于该值，一个message将被拒绝。如果&lt;code&gt;message.timestamp.type=LogAppendTime&lt;/code&gt;，该参数将被忽略。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.timestamp.type&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定message中时间戳的类型。&lt;code&gt;CreateTime&lt;/code&gt;或&lt;code&gt;LogAppendTime&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.cleanable.dirty.ratio&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用于控制，日志压缩器(log compactor)将尝试清除日志的频率。默认情况下，我们将避免清除已压缩超过50％的日志的日志。这个比率限制了最大空间浪费(日志中的重复,50%或50%以上的日志重复)。&lt;/p&gt;

&lt;p&gt;比率越高，意味着越少，更有效的清理，但是也意味着更多的日志空间浪费。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.compaction.lag.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一条消息保持未压缩的最小时间。仅适用于正在压缩的日志。&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;4-3-producer核心参数&#34;&gt;4.3 Producer核心参数&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;bootstrap.servers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定broker地址&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;key.serializer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker 需要接收到序列化之后的&lt;code&gt;k/v&lt;/code&gt;值，所以生产者需要将序列化后的值发送过来。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;org.apache.kafka.common.serialization.Serializer&lt;/code&gt;该类表示把键对象序列化为字节数组&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ByteArraySerializer: 默认的序列化方式&lt;/li&gt;
&lt;li&gt;StringSerializer:&lt;/li&gt;
&lt;li&gt;IntegerSerializer:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;value.serializer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定序列化后的value，需要实现&lt;code&gt;org.apache.kafka.common.serialization.Serializer&lt;/code&gt;接口&lt;/p&gt;

&lt;p&gt;&lt;code&gt;org.apache.kafka.common.serialization.StringSerializer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;compression.type&lt;/strong&gt;
指定消息压缩类型:gzip,snappy等，&lt;/p&gt;

&lt;p&gt;broker端也有该参数，默认值为:&lt;code&gt;producer&lt;/code&gt;，表示遵循生产者的压缩方式&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;生产者使用何种压缩方式，消费者将必须使用该方式进行解压缩&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;acks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来声明要有多少个分区副本接收消息后，生产者才认为消息写入成功，也就是数据一致性衡量，该参数对消息的丢失的影响较&amp;gt;大. 默认值为:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt;: 表示生产者不知道消息是否被broker成功接收被处理，反正自己发出去了就认为是成功了，该种清理增加了吞吐，但是也&amp;gt;增加的数据丢失的风险，因为程序的稳定性，网络的稳定性都可能会影响到消息的生产&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt;: 只要集群中leader接收到消息并成功处理，就返回给生产者写入成功的消息。该种情况，如果发送过程中网络出现问题或&amp;gt;者kafka集群异常导致leader没工作而导致消息写入失败，生产者会受到写入失败相关的异常，此时生产者可进行重试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all/-1&lt;/code&gt;: 表示所有参与复制的节点都收到消息时，生产者才会接收到来自服务器端写入成功的消息，该种情况下，整体的消息
确认延迟会更高一些，但是数据的一致性也更强一些&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 消息的发送其实也分&lt;code&gt;sync&lt;/code&gt;和&lt;code&gt;async&lt;/code&gt;，即同步和异步，kafka为了保证消息高效传输会决定是同步发送还是异步发送。如果让&amp;gt;客户端等待服务器的响应(通过调用get()方法)也会增加延迟，如果采用客户端回调方式，延迟问题可能会有好转。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;buffer.memory&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来设置生产者内存缓冲区的大小，生产者会用它来缓冲要发送到服务器的消息，以此来提供消息传递的效率。默认值:&lt;code&gt;33554432&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足，此时&lt;code&gt;send()&lt;/code&gt;方法就会阻塞或者直接异常，取
决于&lt;code&gt;block.on.buffer.null&lt;/code&gt;参数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retries&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;生产者从服务器收到的错误有可能是临时性的错误，比如暂时找不到&lt;code&gt;leader&lt;/code&gt;或者当前partition正在迁移无法找到相关的partition，&amp;gt;这种情况下，该参数可以决定生产者的行为，如果重试次数超过之后，生产者就会放弃重试，并返回错误。&lt;/p&gt;

&lt;p&gt;默认情况下，生产者在每次重试之间等待100ms，这个等待参数可以通过&lt;code&gt;retry.backoff.ms&lt;/code&gt;来修改&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;batch.size&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每次提交的batch大小，默认值:&lt;code&gt;16384&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当有多个消息需要被发送&lt;code&gt;同一个分区&lt;/code&gt;(如何决定是发送到同一个分区?)时，生产者会把他们发送到同一个批次里.&lt;/p&gt;

&lt;p&gt;该参数用来指定一个批次提交的大小，当达到该batch的大小，所有的消息会被统一发送至broker&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;client.id&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来指定客户端的id，不过可以不用指定，注册后为每个客户端生成64为的id&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.in.flight.requests.per.connection&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此参数指定了生产者在收到服务器响应之前可以发送多少消息，它的值越高，就会占用越多的内存，不过也会提高吞吐量&lt;/p&gt;

&lt;p&gt;把它设为1 可以保证消息是&lt;code&gt;按照发送的顺序&lt;/code&gt;写入服务器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;timeout相关参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;request.timeout.ms&lt;/code&gt;: 生产者在发送数据时等待服务器返回的响应时间，默认值:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;metadata.fetch.timeout.ms&lt;/code&gt;: 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout.ms&lt;/code&gt;: 指定了 broker 等待同步副本返回消息确认的时间，与 asks 的配置相匹配&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;max.block.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此参数指定了在调用 send() 方法或使用 partitionFor() 方法获取元数据时生产者的阻塞时间.&lt;/p&gt;

&lt;p&gt;当生产者的发送缓冲区已捕，或者没有可用的元数据时，这些方法就会阻塞，阻塞时间超过该参数值时，生产者抛出异常&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.request.size&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用于控制生产者发送的&lt;code&gt;请求大小&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息的总大小&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;receive.buffer.bytes和send.buffer.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了保证可靠的消息传输，这两个参数分别指定了 TCP Socket &lt;code&gt;接收和发送数据包的缓冲区&lt;/code&gt;的大小，默认为-1，表示使用操作系统的&amp;gt;默认值。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果生产者或消费者与broker所处的数据中心不同，该值可以适当调大&lt;/p&gt;

&lt;h4 id=&#34;4-4-consumer核心参数&#34;&gt;4.4 Consumer核心参数&lt;/h4&gt;

&lt;p&gt;在消费者组中的消费者重平衡期间，消费者无法读取消息，造成整个消费者组在重平衡的期间都不可用&lt;/p&gt;

&lt;p&gt;消费者通过向组织协调者（Kafka Broker）发送心跳来维护自己是消费者组的一员并确认其拥有的分区。&lt;/p&gt;

&lt;p&gt;对于不同步的消费群体来说，其组织协调者可以是不同的。&lt;/p&gt;

&lt;p&gt;只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心&amp;gt;跳。&lt;/p&gt;

&lt;p&gt;如果一段时间，消费者不发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡
。&lt;/p&gt;

&lt;p&gt;如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在这段时间里，组里的消费者将不处理消息(STW)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_consumer_offset&lt;/code&gt;主题就主要是用来记录相关消费者的偏移量以及消费者分区分配的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;fetch.min.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者从服务器获取记录的最小字节数，默认:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它&amp;gt;返回给消费者。&lt;/p&gt;

&lt;p&gt;这样可以降低消费者和 broker 的工作负载，因为它们在主题使用频率不是很高的时候就不用来回处理消息。&lt;/p&gt;

&lt;p&gt;如果没有很多可用数据，但消费者的 CPU 使用率很高，那么就需要把该属性的值设得比默认值大。&lt;/p&gt;

&lt;p&gt;如果消费者的数量比较多，把该属性的值调大可以降低 broker 的工作负载。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;fetch.max.wait.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面参数用来控制每次fetch时的最小数据量，但也不能一直等待数据的容量满足要求，因此还有另外一个参数，即&lt;code&gt;fetch.max.wait.ms&lt;/code&gt;，指定多长时间还没满足数据容量就进行fetch数据，默认是&lt;code&gt;500ms&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.partition.fetch.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了服务器从每个分区里返回给消费者的&lt;code&gt;最大字节数&lt;/code&gt;，默认值为&lt;code&gt;1MB&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;即&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;方法从每个分区返回的记录最多不超过该值指定的大小。&lt;/p&gt;

&lt;p&gt;加入一个20分区的主题，拥有5个消费者，那么每个消费者必须至少&lt;code&gt;4MB&lt;/code&gt;的内存来接收消息(每个消费者消费4个分区，每个分区返回消&amp;gt;费者的最大字节数1MB)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 该参数的设置要适当的设置大一些，防止单个消费者异常后，整体内存受限。&lt;/p&gt;

&lt;p&gt;至少，该参数的值要大于&lt;code&gt;max.message.size&lt;/code&gt;(broker接收消息的最大字节数)，否则消费者无法读取这些消息，导致消费者一直重试并&amp;gt;挂起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;session.timeout.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s，在这个时间内没有发送心跳就会直接认为消费者死亡，此时
协调器就会进行触发consumer rebalance.&lt;/p&gt;

&lt;p&gt;此参数与&lt;code&gt;heartbeat.interval.ms&lt;/code&gt;(poll() 方法向群组协调器发送心跳的频率)强相关。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.offset.reset&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下的该如何处理，默认值为&lt;code&gt;latest&lt;/code&gt;，意思是在偏移量无效的情况下&amp;gt;，默认从最新的记录下开始读取数据。可选值为&lt;code&gt;earliest&lt;/code&gt;，表示从最开始位置进行读取.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;enable.auto.commit&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者是否自动提交偏移量，默认值是 true，对应&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;参数来保证每次提交偏移量的频率&lt;/p&gt;

&lt;p&gt;为了避免数据重复和丢失，消费者可以设置为false，由自己决定自己的消费位置(客户端保证数据消费的一致性)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;partition.assignment.strategy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PartitionAssignor&lt;/code&gt;(分区分配器)会根据给定的消费者和主题，决定哪些分区应该被分配到哪个消费者，默认有两个策略:&lt;code&gt;Range&lt;/code&gt;和&lt;code&gt;RoundRobin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.poll.records&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用于控制&lt;code&gt;单次调用call()&lt;/code&gt; 方法能够返回的记录数量，可以帮你控制在轮询中需要处理的数据量.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;heartbeat.interval.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在消费组中，消费者心跳到消费者协调器的频率，默认值:&lt;code&gt;3000ms&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;三-集群管理&#34;&gt;三、集群管理&lt;/h2&gt;

&lt;p&gt;任何一款优秀的开源软件，都会提供比较丰富的集群管理工具来帮助使用者(管理员和实际使用者)来对集群进行操作，记下来从三个角度来大概讲解集群管理相关的操作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方提供的操作脚本&lt;/li&gt;
&lt;li&gt;kafka-manager&lt;/li&gt;
&lt;li&gt;kafkacat&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-官方工具&#34;&gt;1. 官方工具&lt;/h3&gt;

&lt;p&gt;在kafka的发行包中，默认包含了如下管理工具脚本:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ ls
connect-distributed.sh        kafka-delete-records.sh              kafka-server-stop.sh
connect-mirror-maker.sh       kafka-dump-log.sh                    kafka-streams-application-reset.sh
connect-standalone.sh         kafka-leader-election.sh             kafka-topics.sh
kafka-acls.sh                 kafka-log-dirs.sh                    kafka-verifiable-consumer.sh
kafka-broker-api-versions.sh  kafka-mirror-maker.sh                kafka-verifiable-producer.sh
kafka-configs.sh              kafka-preferred-replica-election.sh  trogdor.sh
kafka-console-consumer.sh     kafka-producer-perf-test.sh          windows
kafka-console-producer.sh     kafka-reassign-partitions.sh         zookeeper-security-migration.sh
kafka-consumer-groups.sh      kafka-replica-verification.sh        zookeeper-server-start.sh
kafka-consumer-perf-test.sh   kafka-run-class.sh                   zookeeper-server-stop.sh
kafka-delegation-tokens.sh    kafka-server-start.sh                zookeeper-shell.sh&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;这里主要介绍几个常用的工具脚本:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运维管理类&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-topics.sh&lt;/code&gt;: 用来创建，删除，查看，改变一个topic参数的工具&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-reassign-partitions.sh&lt;/code&gt;: 用来对partition进行重新分配(管理员会较多使用)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-log-dirs.sh&lt;/code&gt;: 用来查看指定broker下日志目录的使用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-leader-election.sh&lt;/code&gt;: 用于一组Topic分区的leader重新分配，可以支持优先副本和非同步副本(不在ISR中)，老版本中的kafka-preferred-replica-election.sh脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-replica-verification.sh&lt;/code&gt;: 该工具可以用来检查topic的一组副本的数据是否一致&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-broker-api-versions.sh&lt;/code&gt;: 用来查看指定broker当前支持的各个接口的版本(kafka高版本已经保证了向下兼容)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-configs.sh&lt;/code&gt;: 用来操作和查看topic, client, user or broker的实体配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;kafka操作类&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-console-consumer.sh&lt;/code&gt;: 通过终端来启动消费者&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-console-producer.sh&lt;/code&gt;: 通过终端来启动生产者&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-consumer-groups.sh&lt;/code&gt;: 用来查看，删除或者重置消费者组offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-consumer-perf-test.sh&lt;/code&gt;: 用来进行消费者压力测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-producer-perf-test.sh&lt;/code&gt;: 用来进行生产者压力测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-delete-records.sh&lt;/code&gt;: 删除指定分区的记录，直到指定的offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-mirror-maker.sh&lt;/code&gt;: 用于多集群之间同步topic数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-server-start.sh&lt;/code&gt;: broker启动脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-server-stop.sh&lt;/code&gt;: broker关闭脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-streams-application-reset.sh&lt;/code&gt;: 流式应用工具&lt;/li&gt;
&lt;li&gt;&lt;code&gt;zookeeper-shell.sh&lt;/code&gt;: kafka工具中也默认提供了zookeeper管理工具(不太好用)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-1-kafka-topics-sh&#34;&gt;1.1 kafka-topics.sh&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;topic创建&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--create&lt;/code&gt;: 创建topic&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--topic&lt;/code&gt;: 指定topic名称&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--partitions&lt;/code&gt;: 指定分区数量&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--replication-factor&lt;/code&gt;: 指定副本数量(仅在创建时可用)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--config&lt;/code&gt;: 指定topic级别的参数(动态参数，可修改)&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--replica-assignment&lt;/code&gt;: 手动指定partition到broker的分配&lt;part1_replica1:part1_replica2,part2_replica1:part2_replica2&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建topic
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --create --topic bgbiao.top
Created topic bgbiao.top.

# 查看默认创建topic的参数详情(由broker配置决定)
# 默认3个分区，1个副本
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 1	Leader: 2	Replicas: 2	Isr: 2
	Topic: bgbiao.top	Partition: 2	Leader: 3	Replicas: 3	Isr: 3

# 指定参数创建topic
# 指定分区为5，副本为3，topic数据保留2分钟
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --create --topic bgbiao.top-1 --partitions 5 --replication-factor 3 --config retention.ms=120000

# 分区，副本和指定参数都改变了
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top-1
Topic: bgbiao.top-1	PartitionCount: 5	ReplicationFactor: 3	Configs: min.insync.replicas=1,segment.bytes=1073741824,retention.ms=120000
	Topic: bgbiao.top-1	Partition: 0	Leader: 2	Replicas: 2,3,1	Isr: 2,3,1
	Topic: bgbiao.top-1	Partition: 1	Leader: 3	Replicas: 3,1,2	Isr: 3,1,2
	Topic: bgbiao.top-1	Partition: 2	Leader: 1	Replicas: 1,2,3	Isr: 1,2,3
	Topic: bgbiao.top-1	Partition: 3	Leader: 2	Replicas: 2,1,3	Isr: 2,1,3
	Topic: bgbiao.top-1	Partition: 4	Leader: 3	Replicas: 3,2,1	Isr: 3,2,1&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;topic更改&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; topic的分区(partitions)可以根据需要进行调整(只能调整大，不能调整小)，而且在调整分区的过程中，对于一个有&lt;code&gt;key&lt;/code&gt;的主题来说，一条消息的分区逻辑和顺序性可能会受到影响。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 副本数一旦topic创建之后，就不能再修改了，除非进行重分配(副本数不能超过broker数量哦)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--alter&lt;/code&gt;: 修改分区数量，replica分配，或者topic的动态配置项(结合&amp;ndash;topic参数)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--partitions&lt;/code&gt;: 修改指定Topic的分区数量&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--replica-assignment&lt;/code&gt;: 手动指定part到broker的分配&lt;a href=&#34;p1-r1:p1-r2,p2-r1:p2-r2&#34;&gt;p1-r1:p1-r2,p2-r1:p2-r2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--config&lt;/code&gt;: 修改topic的指定参数(动态参数调整:key=value)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--delete-config&lt;/code&gt;: 删除topipc的指定参数()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 通常情况下&lt;code&gt;--replica-assignment&lt;/code&gt;参数需要和&lt;code&gt;--partitions&lt;/code&gt;一同使用才可以指定分区下的副本到broker节点上的分配，相当于手动扩容迁移&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 上面我们刚开始创建的bgbiao.top的topic是1个分区1个副本，这里采用alter参数进行修改基本配置
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --alter  --topic bgbiao.top --replica-assignment 1,2,3,1,2 --partitions 5

# 因为bgbiao.top 这个topic再创建时只有一个replication，因此--replica-assignment参数只能指定副本分配在那个broker上，无法指定多个副本的关系
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 5	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 1	Leader: 2	Replicas: 2	Isr: 2
	Topic: bgbiao.top	Partition: 2	Leader: 3	Replicas: 3	Isr: 3
	Topic: bgbiao.top	Partition: 3	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 4	Leader: 2	Replicas: 2	Isr: 2

 &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;topic相关信息查看&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--list&lt;/code&gt;: 列出topic&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看topic详情信息&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--topic&lt;/code&gt;: 指定topic查看详情信息&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--exclude-internal&lt;/code&gt;: 排除内部topic(consumer_offset_topic)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--unavailable-partitions&lt;/code&gt;: 仅显示leader不可用的分区(在集群异常时快速排查受影响的分区)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--under-min-isr-partitions&lt;/code&gt;: 仅显示isr小于配置的min-isr-partitions的分区&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--under-replicated-partitions&lt;/code&gt;: 仅显示不同步的分区&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在低版本的kafka中使用&amp;ndash;zookeeper来链接集群，高版本中基本都通过&amp;ndash;bootstrap-server指定broker来连接集群&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 列出集群topic
# --list参数列出可用的topic
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --list
__consumer_offsets
....
....

# 也可以使用--topic指定topic
# 如果指定topic不存在，将返回空
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --list --topic __consumer_offsets
__consumer_offsets

# 列出topic详情信息
# --describe参数(同时可以使用--topic指定topic查看)
# --exclude-internal参数可以排除内部的topic(__consumer_offsets)
# --unavailable-partitions参数可以列出leader不可用的topic，在集群故障时快速查看受影响的topic
# 
# 可以查看某个topic的分区和副本分布，以及topic级别的相关配置
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic __consumer_offsets
Topic: __consumer_offsets	PartitionCount: 50	ReplicationFactor: 1	Configs: compression.type=producer,min.insync.replicas=1,cleanup.policy=compact,segment.bytes=104857600
	Topic: __consumer_offsets	Partition: 0	Leader: 3	Replicas: 3	Isr: 3
	Topic: __consumer_offsets	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
....
....

# 查看集群leader不可用的分区
# 可以发现leader都为-1，是因为副本和isr的id是4，而broker4其实已经光荣阵亡了
$ /opt/app/kafka_2.11-1.0.1/bin/kafka-topics.sh --zookeeper 172.16.217.38:2181/log-kafka --describe --unavailable-partitions
...
	Topic: realtime_kafka.post_alg_real	Partition: 2	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 11	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 20	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 29	Leader: -1	Replicas: 4	Isr: 4
	Topic: rm-bp1d3u2p9v3l4da7c632	Partition: 1	Leader: -1	Replicas: 4	Isr: 4
	Topic: rm-bp1udb05091x11q5x	Partition: 1	Leader: -1	Replicas: 4	Isr: 4

# 查看副本不同步的分区详情
# 可以发现副本中有不同步的情况，是因为有副本所在的节点已经挂了，通常有一部分是因为资源或者网络原因未同步，还有就是如上述broker阵亡的情况
# 如果说--unavailable-partitions可以直接查看到受影响的topic，那么--under-replicated-partitions就可以查看可用性受影响的topic，因为当副本为2时，此时broker4阵亡的前提下，topic下的分区是无法保证高可用的
$ /opt/app/kafka_2.11-1.0.1/bin/kafka-topics.sh --zookeeper 172.16.217.38:2181/log-kafka --describe --under-replicated-partitions
...
...
	Topic: androidregister	Partition: 1	Leader: 2	Replicas: 4,2	Isr: 2
	Topic: eventjsonlog	Partition: 11	Leader: 2	Replicas: 4,2	Isr: 2
	Topic: eventjsonlog	Partition: 27	Leader: 2	Replicas: 2,4	Isr: 2
	Topic: eventjsonlog	Partition: 38	Leader: 13	Replicas: 13,4	Isr: 13
	Topic: eventjsonlog	Partition: 44	Leader: 10	Replicas: 4,10	Isr: 10
	Topic: eventjsonlog	Partition: 52	Leader: 12	Replicas: 12,4	Isr: 12
	Topic: eventjsonlog	Partition: 59	Leader: 11	Replicas: 4,11	Isr: 11
	Topic: eventlog	Partition: 8	Leader: 16	Replicas: 16,4	Isr: 16
	Topic: eventlog	Partition: 23	Leader: 3	Replicas: 4,3	Isr: 3
	Topic: eventlog	Partition: 38	Leader: 13	Replicas: 13,4	Isr: 13
	Topic: eventlog	Partition: 44	Leader: 10	Replicas: 4,10	Isr: 10
	Topic: eventlog	Partition: 52	Leader: 12	Replicas: 12,4	Isr: 12
	Topic: eventlog	Partition: 59	Leader: 11	Replicas: 4,11	Isr: 11
	Topic: pusheventlog	Partition: 9	Leader: 1	Replicas: 1,4	Isr: 1
	Topic: pusheventlog	Partition: 12	Leader: 7	Replicas: 4,7	Isr: 7&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;删除&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--delete&lt;/code&gt;: 指定topic删除&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在删除Topic时会受&lt;code&gt;delete.topic.enable&lt;/code&gt;参数的影响，如果为true，则topic直接删除，如果为false，删除仅是标记删除，即在topic的config中增加一个删除标记&lt;code&gt;MarkedForDeletion:true&lt;/code&gt;，待broker重启后完全删除(也可通过zk中的数据删除)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 如果delete.topic.enable=true，则直接删除掉
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --delete   --topic bgbiao.top&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;topic真正的元数据结构: &lt;code&gt;/brokers/topics/topic-name&lt;/code&gt;,删除这个即删除&lt;/li&gt;
&lt;li&gt;标记删除的topic元数据: &lt;code&gt;/admin/delete_topics/topic-name&lt;/code&gt;,删除这个才算数据清理完成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-2-kafka-reassign-partitions-sh&#34;&gt;1.2 kafka-reassign-partitions.sh&lt;/h4&gt;

&lt;p&gt;该脚本用于在副本之间移动topic的分区，也就是对副本进行重新分配，也是SRE在日常操作中会比较常用的脚本，需要注意的是，在做迁移时需要注意到当前集群的整体情况，毕竟在移动副本时，需要设计到新副本的数据同步，也会占用一定资源。&lt;/p&gt;

&lt;p&gt;通常，将服务器添加到Kafka集群很容易，只需为它们分配一个惟一的brokerid，并在新服务器上启动Kafka。然而，这些新服务器不会自动分配任何数据分区，因此，除非将分区移动到它们，否则在创建新主题之前，它们不会做任何工作。因此，向集群中添加机器时，您会希望将一些现有数据迁移到这些机器上。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--broker-list&lt;/code&gt;: 指定分区需要重新分配到的broker节点，如果&lt;code&gt;--topics-to-move-json-file&lt;/code&gt;参数被指定用来生成重分配配置时，必须制定该参数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--topics-to-move-json-file&lt;/code&gt;: 生成一个移动指定topic的分区到指定broker(&lt;code&gt;--broker-list&lt;/code&gt;)的配置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--generate&lt;/code&gt;: 生成候选分区分配的配置，该参数仅会生成候选的分配方案，不会进行执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reassignment-json-file&lt;/code&gt;: 分区手动分配的配置参数，该参数可由&lt;code&gt;generate&lt;/code&gt;参数生成，通常一般会进行微调&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--replica-alter-log-dirs-throttle&lt;/code&gt;: 在相同的broker上日志目录之间的副本移动将被限流为该值bytes/sec，限流应该至少设置为1 KB/s，默认是-1表示不限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--throttle&lt;/code&gt;: broker之间的分区移动可以使用该值进行限流(bytes/sec)，同上&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 通过指定&lt;code&gt;--reassignment-json-file&lt;/code&gt;参数来执行重新分配&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--verify&lt;/code&gt;: 如果一个重分配完成了，可以指定&lt;code&gt;--reassignment-json-file&lt;/code&gt;参数来查看重分配的进度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;topics-to-move-json-file文件示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;{&amp;#34;topics&amp;#34;:
[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;},{&amp;#34;topic&amp;#34;: &amp;#34;foo1&amp;#34;}],
&amp;#34;version&amp;#34;:1
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;reassignment-json-file文件示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 注意:log_dirs是可选参数，需要指定绝对路径，也可以指定为any，当指定后需要和replicas的长度相等
  {&amp;#34;partitions&amp;#34;:
  	[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;,
  	  &amp;#34;partition&amp;#34;: 1,
  	  &amp;#34;replicas&amp;#34;: [1,2,3],
  	  &amp;#34;log_dirs&amp;#34;: [&amp;#34;dir1&amp;#34;,&amp;#34;dir2&amp;#34;,&amp;#34;dir3&amp;#34;]
    }],
  &amp;#34;version&amp;#34;:1
  }&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;分区重分配示例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看当前topic详情
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 3	Replicas: 3	Isr: 3
	Topic: bgbiao.top	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 2	Leader: 2	Replicas: 2	Isr: 2

# 1.编辑move.json配置
$ cat move.json
{&amp;#34;topics&amp;#34;: [{&amp;#34;topic&amp;#34;: &amp;#34;bgbiao.top&amp;#34;}],
&amp;#34;version&amp;#34;:1
}

# 2.生成迁移配置
# 指定正确的zookeeper地址来获取分区的分布状态以及待迁移的状态
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --topics-to-move-json-file move.json --broker-list &amp;#34;1,2,3&amp;#34; --generate
Current partition replica assignment
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

Proposed partition reassignment configuration
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

# 编辑迁移配置
# 当前分区状态为:bgbiao.top-2的副本在broker2,bgbiao.top-1的副本在broker1,bgbiao.top-0的副本在broker3
# 迁移后的分区状态:bgbiao.top-2的副本在broker3,bgbiao.top-1的副本在broker2,bgbiao.top-0的副本在broker1
# 然后将期望的迁移配置保存下来做相关修改即可.
# 我们是想给某个分区增加副本，因此可以修改成如下配置
$ cat assignment.json
{
    &amp;#34;partitions&amp;#34;: [
        {
            &amp;#34;partition&amp;#34;: 0,
            &amp;#34;replicas&amp;#34;: [
                3,1,2
            ],
            &amp;#34;topic&amp;#34;: &amp;#34;bgbiao.top&amp;#34;
        }
    ],
    &amp;#34;version&amp;#34;: 1
}

# 3.根据上述的迁移配置执行迁移
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --reassignment-json-file ./assignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.

# 4.查看上述迁移的进度(将--execute参数改为--verify参数)
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --reassignment-json-file ./assignment.json --verify
Status of partition reassignment:
Reassignment of partition bgbiao.top-0 completed successfully

# 再次查看topix详情
# 如期望，partition-1增加了两个副本,该副本的整体可用性提高了3倍
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 3	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 3	Replicas: 3,1,2	Isr: 3,1,2
	Topic: bgbiao.top	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 2	Leader: 2	Replicas: 2	Isr: 2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 该工具可以让集群部分节点故障后，及时将新部分的partition进行调整，以恢复partition的高可用性。同时能够让集群在扩展后，快速将已有topic的数据均衡的分布在新节点上，以实现整体负载的均衡。&lt;/p&gt;

&lt;h4 id=&#34;1-3-kafka-log-dirs-sh&#34;&gt;1.3 kafka-log-dirs.sh&lt;/h4&gt;

&lt;p&gt;该脚本参数用于查看kafka各个broker节点以及topic的磁盘使用率情况&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看topic和broker的磁盘使用情况&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--broker-list&lt;/code&gt;: 指定查看的broker列表&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--topic-list&lt;/code&gt;: 指定需要查看的topic列表&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 当指定topic后会从全部的broker中进行查找
$ sh /opt/app/kafka/bin/kafka-log-dirs.sh --bootstrap-server 172.29.203.62:9092 --describe --topic-list myapp-yum-log,myapp
Querying brokers for log directories information
Received log directory information from brokers 1,2,3
{&amp;#34;version&amp;#34;:1,&amp;#34;brokers&amp;#34;:[{&amp;#34;broker&amp;#34;:1,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-2&amp;#34;,&amp;#34;size&amp;#34;:13291235,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-0&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]},{&amp;#34;broker&amp;#34;:2,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-1&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-0&amp;#34;,&amp;#34;size&amp;#34;:13258726,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]},{&amp;#34;broker&amp;#34;:3,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-2&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-1&amp;#34;,&amp;#34;size&amp;#34;:13264869,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]}]}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结果是json串，可以看到&lt;code&gt;myapp-yum-log-2&lt;/code&gt;在broker-1上占用了&lt;code&gt;13291235&lt;/code&gt;字节，也就是&lt;code&gt;12M&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;1-4-kafka-leader-election-sh&#34;&gt;1.4 kafka-leader-election.sh&lt;/h4&gt;

&lt;p&gt;用于一组 Topic 分区的 leader 重新分配，可以支持优先副本和非同步副本。一般用于指定topic的分区存在非预选副本或非同步副本的情况，对整个leader进行适当调整&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--admin.config&lt;/code&gt;: 传给admin客户端的配置文件&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--all-topic-partitions&lt;/code&gt;: 基于选举类型&lt;code&gt;--election-type&lt;/code&gt;来对符合条件的topic进行选举&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--bootstrap-server&lt;/code&gt;: 指定broker地址&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--election-type&lt;/code&gt;: 指定选举类型&lt;code&gt;[preferred,unclean]&lt;/code&gt;，对优先副本进行选举或非同步副本进行选举&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--partition&lt;/code&gt;: 指定需要选举的指定topic分区的id(和&amp;ndash;topic一起使用)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;--path-to-json-file&lt;/code&gt;: 使用json配置文件来保存重分配信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 比如我们发现topic的partition-1当前的leader不是优先副本(broker相对倾斜),可以使用如下配置进行leader重新选举
$ sh kafka-leader-election.sh --bootstrap-server 172.29.203.62:9092 --topic test-bgbiao-1 --partition 0 --election-type preferred
Valid replica already elected for partitions


{&amp;#34;partitions&amp;#34;:
[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;, &amp;#34;partition&amp;#34;: 1},
{&amp;#34;topic&amp;#34;: &amp;#34;foobar&amp;#34;, &amp;#34;partition&amp;#34;: 2}]
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-5-kafka-configs-sh&#34;&gt;1.5 kafka-configs.sh&lt;/h4&gt;

&lt;p&gt;用来查看和修改kafka相关的配置信息，包含集群的动态配置，topic级别的动态配置等等&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--all&lt;/code&gt;: 列出给定实体的全部配置文件(默认已经生效的全部参数，如果没有all仅对动态参数生效)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--entity-type&lt;/code&gt;: 实体类型[topics/clients/users/brokers/broker-loggers]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--entity-name&lt;/code&gt;: 实体名称[topic名称/client-id/user-name/broker-id]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 列出给定实体的配置文件&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--force&lt;/code&gt;: 强制生效&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--topic&lt;/code&gt;: 指定topic名称&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--alter&lt;/code&gt;: 修改指定实体的配置文件 &lt;code&gt;注意:当使用delete-config和add-config时必须使用--alter&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete-config&lt;/code&gt;: 删除指定的配置&amp;rdquo;k1,k2&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add-config&lt;/code&gt;: 给指定的实体增加配置(k=v,k2=[v1,v2,v3],k3=v3)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;topic级别的动态参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cleanup.policy&lt;/code&gt;: 清理策略&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression.type&lt;/code&gt;: 压缩类型(通常建议在produce端控制)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delete.retention.ms&lt;/code&gt;: 压缩日志的保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flush.messages&lt;/code&gt;: 持久化message限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flush.ms&lt;/code&gt;: 持久化频率&lt;/li&gt;
&lt;li&gt;&lt;code&gt;follower.replication.throttled.replicas&lt;/code&gt;: follower副本限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leader.replication.throttled.replicas&lt;/code&gt;: leader副本限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.message.bytes&lt;/code&gt;: 最大的batch的message大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.downconversion.enable&lt;/code&gt;: message向下兼容&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.format.version&lt;/code&gt;: message格式版本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;: 最小的ISR&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retention.ms&lt;/code&gt;: 日志保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retention.bytes&lt;/code&gt;: 日志保留大小(通常按照时间限制)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segment.bytes&lt;/code&gt;: segment的大小限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segment.ms&lt;/code&gt;: segment的切割时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unclean.leader.election.enable&lt;/code&gt;: 是否允许非同步副本选主(针对可用性设置的一个参数)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;broker级别的动态参数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker级别的动态参数比较多，这里只列举常用的几个&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;log.retention.ms&lt;/code&gt;: 日志保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.connections&lt;/code&gt;: 最大连接数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.connections.per.ip&lt;/code&gt;: 每个ip的最大连接数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.max.bytes&lt;/code&gt;: batch的message的最大限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;: 最小的ISR&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.io.threads&lt;/code&gt;: IO线程数(网络线程数的两倍)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.network.threads&lt;/code&gt;: 网络线程数(cpu的2/3较好)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.recovery.threads.per.data.dir&lt;/code&gt;: 每个数据目录的恢复线程&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.replica.fetchers&lt;/code&gt;: 副本的fetchers数量(默认为1,可适当调大)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;user级别的参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SCRAM-SHA-256&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SCRAM-SHA-512&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consumer_byte_rate&lt;/code&gt;: 针对消费者user进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;producer_byte_rate&lt;/code&gt;: 针对生产者进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;request_percentage&lt;/code&gt;: 请求百分比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;clients级别参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;consumer_byte_rate&lt;/code&gt;: 针对消费者user进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;producer_byte_rate&lt;/code&gt;: 针对生产者进行限流&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;request_percentage&lt;/code&gt;: 请求百分比&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 修改topic的数据保留时间
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --add-config retention.ms=10000000 --alter

# 查看topic的动态参数配置
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --describe
Dynamic configs for topic push-test are:
retention.ms=10000000 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:retention.ms=10000000}

# 删除topic动态参数
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --alter --delete-config retention.ms
Completed updating config for topic push-test.

# 查看broker全部的参数(--all会获取全部的参数)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --all --broker-defaults  --describe
Default configs for brokers in the cluster are:

# 也可以使用如下参数查看broker的全部参数(动态的和默认的参数)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --all --entity-type brokers --entity-name  1  --describe
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --all --broker 1  --describe

# broker的动态参数(去除了--all之后，会发现列出的是动态的配置，默认broker是没有动态参数调整的)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --broker 1  --describe
Dynamic configs for broker 1 are:

# user和client也是类似的&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-6-kafka-broker-api-versions-sh&#34;&gt;1.6 kafka-broker-api-versions.sh&lt;/h4&gt;

&lt;p&gt;查看kafka对外的各个api版本.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看当前kafka版本
$ sh kafka-broker-api-versions.sh --bootstrap-server 172.29.203.62:9092 --version
2.5.0 (Commit:66563e712b0b9f84)

# 查看集群所有节点的api版本
$ sh kafka-broker-api-versions.sh --bootstrap-server 172.29.203.62:9092
172.29.203.106:9092 (id: 2 rack: null) -&amp;gt; (
	Produce(0): 0 to 8 [usable: 8],
	Fetch(1): 0 to 11 [usable: 11],
	ListOffsets(2): 0 to 5 [usable: 5],
	Metadata(3): 0 to 9 [usable: 9],
	LeaderAndIsr(4): 0 to 4 [usable: 4],
	StopReplica(5): 0 to 2 [usable: 2],
	UpdateMetadata(6): 0 to 6 [usable: 6],
	ControlledShutdown(7): 0 to 3 [usable: 3],
	OffsetCommit(8): 0 to 8 [usable: 8],
	OffsetFetch(9): 0 to 7 [usable: 7],
	FindCoordinator(10): 0 to 3 [usable: 3],
	JoinGroup(11): 0 to 7 [usable: 7],
	Heartbeat(12): 0 to 4 [usable: 4],
	LeaveGroup(13): 0 to 4 [usable: 4],
	SyncGroup(14): 0 to 5 [usable: 5],
	DescribeGroups(15): 0 to 5 [usable: 5],
	ListGroups(16): 0 to 3 [usable: 3],
	SaslHandshake(17): 0 to 1 [usable: 1],
	ApiVersions(18): 0 to 3 [usable: 3],
	CreateTopics(19): 0 to 5 [usable: 5],
	DeleteTopics(20): 0 to 4 [usable: 4],
	DeleteRecords(21): 0 to 1 [usable: 1],
	InitProducerId(22): 0 to 3 [usable: 3],
	OffsetForLeaderEpoch(23): 0 to 3 [usable: 3],
	AddPartitionsToTxn(24): 0 to 1 [usable: 1],
	AddOffsetsToTxn(25): 0 to 1 [usable: 1],
	EndTxn(26): 0 to 1 [usable: 1],
	WriteTxnMarkers(27): 0 [usable: 0],
	TxnOffsetCommit(28): 0 to 3 [usable: 3],
	DescribeAcls(29): 0 to 2 [usable: 2],
	CreateAcls(30): 0 to 2 [usable: 2],
	DeleteAcls(31): 0 to 2 [usable: 2],
	DescribeConfigs(32): 0 to 2 [usable: 2],
	AlterConfigs(33): 0 to 1 [usable: 1],
	AlterReplicaLogDirs(34): 0 to 1 [usable: 1],
	DescribeLogDirs(35): 0 to 1 [usable: 1],
	SaslAuthenticate(36): 0 to 2 [usable: 2],
	CreatePartitions(37): 0 to 2 [usable: 2],
	CreateDelegationToken(38): 0 to 2 [usable: 2],
	RenewDelegationToken(39): 0 to 2 [usable: 2],
	ExpireDelegationToken(40): 0 to 2 [usable: 2],
	DescribeDelegationToken(41): 0 to 2 [usable: 2],
	DeleteGroups(42): 0 to 2 [usable: 2],
	ElectLeaders(43): 0 to 2 [usable: 2],
	IncrementalAlterConfigs(44): 0 to 1 [usable: 1],
	AlterPartitionReassignments(45): 0 [usable: 0],
	ListPartitionReassignments(46): 0 [usable: 0],
	OffsetDelete(47): 0 [usable: 0]
)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;1-7-生产者和消费者工具&#34;&gt;1.7 生产者和消费者工具&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-console-consumer.sh&lt;/code&gt;: 终端消费者工具&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;kafka-console-producer.sh&lt;/code&gt;: 终端生产者工具&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 指定topic从终端写入数据
$ sh /opt/app/kafka/bin/kafka-console-producer.sh --bootstrap-server 172.29.203.62:9092 --topic test-push
&amp;gt;hello xxb
&amp;gt;BGBiao
&amp;gt;My website is https://bgbiao.top.
&amp;gt;And
&amp;gt;公众号: BGBiao


# 指定消费者组对topic进行消费
# --from-beginning表示从头开始消费
# 因为开始生产者刚开始生产并生产topic，导致topic无leader会有警告信息
# 可以看到client-id就是consumer-test-bgbiao-1,即consumer的前缀加消费组加数字后缀
$ sh kafka-console-consumer.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --group test-bgbiao
[2020-05-31 19:52:13,472] WARN [Consumer clientId=consumer-test-bgbiao-1, groupId=test-bgbiao] Error while fetching metadata with correlation id 2 : {test-push=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
hello xxb
BGBiao
My website is https://bgbiao.top.

公众号: BGBiao&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-8-kafka-consumer-groups-sh&#34;&gt;1.8 kafka-consumer-groups.sh&lt;/h4&gt;

&lt;p&gt;消费组管理工具，可以列出所有的消费组，查看消费组详情，删除消费组信息以及重置消费组的offset&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--all-groups&lt;/code&gt;: 应用到所有的消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--all-topics&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete&lt;/code&gt;: 删除topic分区的offset,以及拥有者和消费组信息(&amp;ndash;group g1 &amp;ndash;group g2)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete-offsets&lt;/code&gt;: 删除消费组的offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看消费组信息以及消费者的offset lag&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 指定操作，支持&lt;code&gt;reset-offsets&lt;/code&gt;操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--export&lt;/code&gt;: 导出操作执行到csv，支持&lt;code&gt;reset-offsets&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--from-file&lt;/code&gt;: 指定文件中指定的值重置offset (csv文件)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--group&lt;/code&gt;: 指定消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--list&lt;/code&gt;: 列出所有的消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--members&lt;/code&gt;: 查看消费组中的成员&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--state&lt;/code&gt;: 查看消费组的状态&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--offsets&lt;/code&gt;: 查看消费组并且列出每个消费组所有topic的分区以及消息的offset lag&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reset-offsets&lt;/code&gt;: 重置消费组的offset (需要指定如下一个参数)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-datetime&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--by-period&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-earliest&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-latest&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--shift-by&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--from-file&lt;/code&gt;:&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--to-current&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看全部的消费者组
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --all-grou  --list
KMOffsetCache-daf27df49ede
test-bgbiao

# 查看消费者详情
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --describe

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
test-bgbiao     test-push       0          1               1               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       1          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       2          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1

# 查看消费组的成员
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --members --describe

GROUP           CONSUMER-ID                                                 HOST            CLIENT-ID              #PARTITIONS
test-bgbiao     consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1 3

# 查看消费组状态
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --state --describe

GROUP                     COORDINATOR (ID)          ASSIGNMENT-STRATEGY  STATE           #MEMBERS
test-bgbiao               172.29.203.62:9092 (1)    range                Stable          1


# 查看消费组的offset信息
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --offsets --describe
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
test-bgbiao     test-push       0          1               1               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       1          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       2          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-full-push    2          61392           61430           38              -                                                           -               -
test-bgbiao     test-full-push    1          61056           61088           32              -                                                           -               -
test-bgbiao     test-full-push    0          61299           61337           38              -&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-kafka-manager&#34;&gt;2. kafka-manager&lt;/h3&gt;

&lt;h2 id=&#34;四-集群监控&#34;&gt;四、集群监控&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#monitoring&#34;&gt;kafka-doc-monitor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>你还记得你JVM的的初始堆大小吗</title>
      <link>https://bgbiao.top/post/jvm%E7%9A%84%E5%88%9D%E5%A7%8B%E5%A0%86/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/jvm%E7%9A%84%E5%88%9D%E5%A7%8B%E5%A0%86/</guid>
      
        <description>&lt;p&gt;通常对于很多java应用来说，当打成jar包后会下意识的使用&lt;code&gt;java -jar xxx.jar&lt;/code&gt;来运行应用，而不是根据自己业务或实际debug的一些需求来增加一些JVM的辅助参数，这样导致的问题就是，后续出了问题之后不容易进行管理以及相关故障追踪和排查。&lt;/p&gt;

&lt;p&gt;那么问题来了，当你在&lt;code&gt;jar -jar&lt;/code&gt;的时候，默认的JVM堆内存是多少呢?&lt;/p&gt;

&lt;p&gt;其实，JVM在不同架构(配置)的OS下回体现出不同的JVM配置，比如在一个&lt;code&gt;8c16g&lt;/code&gt;的ECS上，默认的Heap值如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ java -XX:+PrintFlagsFinal -version | grep HeapSize
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 264241152                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 4206886912                          {product}
java version &amp;#34;1.8.0_141&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由上述的输出可知，初始的堆内存为&lt;code&gt;264241152/1024/1024=252M&lt;/code&gt;，而堆内存最大为&lt;code&gt;4206886912/1024/1024/1024=3G&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个时候可能就会有一个问题就是，该ECS上跑多少个&lt;code&gt;java -jar xxx.jar&lt;/code&gt;这类的服务会比较好呢？如果按照每个服务都能使用3G的堆内存来算，该机器上做多跑4个这类的服务是一个比较合理的规划，但是考虑实际的业务使用需求，单纯这样考虑可能会有点唐突了，因此还是建议每个应用在部署时指定一些基础的参数，比如初始堆和最大堆，并且这两个参数一般建议设置成一致，以免在运行过程中堆的扩容造成的损耗。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>分布式对象存储Minio的可观测性方案</title>
      <link>https://bgbiao.top/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8minio%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8minio%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;背景: 对于初创企业来说，在很长一段时间一些基础的开源服务基本都是&amp;rdquo;裸奔&amp;rdquo;上线的，除了一些传统的主机级别的监控之外，很难有一些额外的性能指标来描述该服务的整体性能情况。因此，在我们的&lt;a href=&#34;https://bgbiao.top/post/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/&#34;&gt;Minio对象存储服务&lt;/a&gt;上线到最近一直也是裸奔的，虽然暂时也没出现过故障，但是作为一名专业搞笑的SRE来讲，服务的可观测性一定得跟上，不然后期铁锅是妥妥的背定了，这篇文章就主要介绍下&lt;code&gt;Minio&lt;/code&gt;的可观测性方案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;开源组件的可观测性现状&#34;&gt;开源组件的可观测性现状&lt;/h3&gt;

&lt;p&gt;在开头提到了，初创企业的开源服务初期大多都是裸奔上线的，出现这种情况我认为一般分为内因和外因:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;内因是开源的基础中间件性能指标通常很多，不容易抽象，因此这些服务的性能指标数据通常可以通过内部的api或cli来获取，不太容易直接和开源的监控系统进行集成;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;外因是对于初创企业来说，人力有限并且对于众多开源组件的理解不够深入导致前面说的&amp;rdquo;裸奔&amp;rdquo;上线的现象。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不过随着以&lt;code&gt;Kubernetes&lt;/code&gt;，&lt;code&gt;Prometheus&lt;/code&gt;为代表的CloudNative理念不断发展，越来越多的开源中间件也支持了兼容&lt;code&gt;Prometheus Metrics&lt;/code&gt;格式的性能指标，这对于初创企业的技术团队来说可谓是一个福音。&lt;/p&gt;

&lt;p&gt;截止目前，我们所熟知的很多开源软件已经内置了兼容&lt;code&gt;Prometheus Metrics&lt;/code&gt;的API接口，不再需要第三方的&lt;code&gt;exporter&lt;/code&gt;来导出一些性能指标数据。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[内置Metrics接口的开源软件](https://prometheus.io/docs/instrumenting/exporters/#software-exposing-prometheus-metrics)&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ceph.com/docs/master/mgr/prometheus/&#34;&gt;Ceph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-metrics&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/operations/admin.html#get--stats?format=prometheus&#34;&gt;Envoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;Etcd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/flink&#34;&gt;Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.grafana.org/administration/metrics/&#34;&gt;Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kong/kong-plugin-prometheus&#34;&gt;Kong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/BuoyantIO/linkerd&#34;&gt;Linkerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/minio/minio&#34;&gt;Minio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rabbitmq.com/prometheus.html&#34;&gt;RabbitMQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client&#34;&gt;Telegraf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik&#34;&gt;Traefik&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openzipkin/zipkin/tree/master/zipkin-server#metrics&#34;&gt;Zipkin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;minio集群的可观测性&#34;&gt;Minio集群的可观测性&lt;/h3&gt;

&lt;p&gt;得益于&lt;code&gt;Minio&lt;/code&gt;的云原生化，这款分布式的对象存储服务天然的支持了&lt;code&gt;Prometheus Metrics&lt;/code&gt;格式的指标数据以及服务端点(API)，因此，如果想要在已有的Minio集群中增加性能指标的监控，将是一件很容易的事情。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.min.io/docs/how-to-monitor-minio-using-prometheus.html&#34;&gt;使用Prometheus监控Minio服务&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Minio服务通过内置的服务端点暴露监控数据，用来监控服务整体的健康状态以及性能指标:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Healthcheck 探针: 提供两个服务探活接口，一个用于检测服务是否启动，另外一个用于检测服务是否可以正常对外提供服务(服务就绪)&lt;/li&gt;
&lt;li&gt;- 探活接口: &lt;code&gt;/minio/health/live&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;- 就绪接口: &lt;code&gt;/minio/health/ready&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Prometheus 探针: 提供了prometheus metrics格式的性能指标数据&lt;/li&gt;
&lt;li&gt;- Metrics接口: &lt;code&gt;/minio/prometheus/metrics&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Healthcheck相关的探针默认是非认证的接口，服务启动后可直接访问; Prometheus探针的接口默认是基于&lt;code&gt;JWT认证&lt;/code&gt;的接口，需要额外设置来访问其Metrics数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Minio的Metrics数据暴露&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;管理员可通过下述方式获取Metrics端点的jwt token:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 获取token
$ mc admin prometheus generate  minio
scrape_configs:
- job_name: minio-job
  bearer_token: eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjQ3NDAwMzM4MjAsImlzcyI6InByb21ldGhldXMiLCJzdWIiOiJNaW5pb1NvdWwifQ.1QiANgXVCpAPWCdF9EejhH608rZbdCRcHe3RtalC2XnScWtYMk_OG0ih-Z3t4ADb1cnYREdTrQwWscFw6Xvk3Q
  metrics_path: /minio/prometheus/metrics
  scheme: http
  static_configs:
  - targets: [minio.bgbiao.top]

# 在配置prometheus的scrape时配置如上相关参数&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;通常对于内部系统间的调用来说，权限可能没那么重要，可以增加如下环境变量来开启metrics的非认证方式:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;MINIO_PROMETHEUS_AUTH_TYPE=&amp;#34;public&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;此时，直接访问接口可以获取到如下的Metrics数据:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ curl -s  minio.bgbiao.top/minio/prometheus/metrics | head -10
# HELP disk_storage_available Total available space left on the disk
# TYPE disk_storage_available gauge
disk_storage_available{disk=&amp;#34;/data/minio&amp;#34;} 2.78376280064e+11
# HELP disk_storage_total Total space on the disk
# TYPE disk_storage_total gauge
disk_storage_total{disk=&amp;#34;/data/minio&amp;#34;} 3.00809048064e+11
# HELP disk_storage_used Total disk storage used on the disk
# TYPE disk_storage_used gauge
disk_storage_used{disk=&amp;#34;/data/minio&amp;#34;} 2.2432768e+10
# HELP go_gc_duration_seconds A summary of the GC invocation durations.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;minio-metrics相关定义&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;标准的运行时指标使用以&lt;code&gt;go_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;进程级别的指标以&lt;code&gt;process_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;prometheus暴露的指标&lt;code&gt;promhttp_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_used&lt;/code&gt;: 磁盘使用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_available&lt;/code&gt;: 磁盘可用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_total&lt;/code&gt;: 磁盘总空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minio_disks_offline&lt;/code&gt;: 当前minio实例中处于下线状态的个数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minio_disks_total&lt;/code&gt;: 当前minio实例的磁盘总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_requests_total&lt;/code&gt;: 当前minio实例中s3接口总请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_errors_total&lt;/code&gt;: s3接口错误请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_requests_current&lt;/code&gt;: 活动状态的s3请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;internode_rx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例接收的节点间字节的总数(bytes)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;internode_tx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例发送到其他节点的字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_rx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例接收的s3字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_tx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例发送的s3字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_ttfb_seconds_&lt;/code&gt;: 统计s3请求的延迟信息&lt;/li&gt;
&lt;li&gt;- bucket: bucket操作相关的延迟&lt;/li&gt;
&lt;li&gt;- count: 延迟统计&lt;/li&gt;
&lt;li&gt;- sum: 总延迟&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Minio不同的版本的Metrics数据有区别，需要查看具体暴露的数据指标&lt;/p&gt;

&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 打开文件数
process_open_fds{job=&amp;#34;minio-metrics&amp;#34;}

# 启动时间(时间戳)
process_start_time_seconds{job=&amp;#34;minio-metrics&amp;#34;}

# 虚拟内存使用
process_virtual_memory_bytes{job=&amp;#34;minio-metrics&amp;#34;}

# cpu占用时间
process_cpu_seconds_total{job=&amp;#34;minio-metrics&amp;#34;}

# minio对外的http接口状态
promhttp_metric_handler_requests_total{job=&amp;#34;minio-metrics&amp;#34;}

# 链接中的http请求
promhttp_metric_handler_requests_in_flight{job=&amp;#34;minio-metrics&amp;#34;}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;配置prometheus数据抓取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 我们的Prometheus是使用CRD方式部署在Kubernetes集群中的，因此抓取外部Metrics数据需要做如下的操作.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 暴露minio服务
$ cat endpoint-minio.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: minio-metrics
  namespace: monitoring
  labels:
    app: minio-metrics
subsets:
- addresses:
  - ip: 192.168.0.148
  - ip: 192.168.0.149
  - ip: 192.168.0.150
  - ip: 192.168.0.151
  ports:
  - port: 9000
    name: http-metrics
    protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  name: minio-metrics
  labels:
    app: minio-metrics
spec:
  ports:
  - name: http-metrics
    port: 9000
    targetPort: 9000
    protocol: TCP

# prometheus servicemonitor
$ cat prometheus-minio.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: minio-metrics
  name: minio-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
  # 可以定义两个采集端点，一个是minio服务本身的监控，一个是minio节点的基础监控
  - interval: 30s
    port: http-metrics
    path: /minio/prometheus/metrics
  jobLabel: app
  # 匹配monitoring命名空间的app=minio-metrics的svc
  namespaceSelector:
    matchNames:
    - monitoring
  selector:
    matchLabels:
      app: minio-metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;查看prometheus监控的minio相关数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prometheus成功抓取minio metrics数据后，即可在prometheus中查看到先关数据:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdnrt82rfpj324a0t47at.jpg&#34; alt=&#34;minio-prometheus-metrics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在Grafana中配置关心的指标以及相关图表:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdofcrk9bbj31gr0u04a4.jpg&#34; alt=&#34;minio-grafana监控&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了方便其他运维小伙伴们，我将Minio的Grafana模板开源出来，有需求的可以直接使用如下模板:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/12063&#34;&gt;minio-grafana模板&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Traefik的可观测性方案</title>
      <link>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>&lt;h2 id=&#34;traefik的可观测性支持&#34;&gt;Traefik的可观测性支持&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.traefik.io/observability/logs/&#34;&gt;traefik-observability&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在Traefik-2.X的生态里，将可观测性分为了如下几个部分，并提升到了专门的功能说明中&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务日志: Traefik进程本身相关的操作日志&lt;/li&gt;
&lt;li&gt;访问日志: 由Traefik接管的代理服务的访问日志(access.log)&lt;/li&gt;
&lt;li&gt;Metrics: Traefik提供的自身详细的metrics数据&lt;/li&gt;
&lt;li&gt;Tracing: Traefik也提供了追踪相关的接口，用来可视化分布式或微服务中的调用情况&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;服务日志&#34;&gt;服务日志&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;默认的环境中,Traefik会将日志以&lt;code&gt;text&lt;/code&gt;格式写入到stdout中，如果使用docker的方式部署的话，想要查看日志需要使用&lt;code&gt;docker logs container_name&lt;/code&gt;方式来查看日志。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;相关配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[log]
  filePath = &amp;#34;/path/to/traefik.log&amp;#34;   # 配置traefik的进程日志路径
  format = &amp;#34;json&amp;#34;                     # 配置日志文件的格式[text(text|json)]
  level = &amp;#34;DEBUG&amp;#34;                     # 指定日志输出的级别[ERROR(ERROR|DEBUG|INFO|PANIC|FATAL|WARN)]

# cli 配置
--log.filePath=/path/to/traefik.log
--log.format=json
--log.level=DEBUG&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 具体的日志配置参数需要和当前环境中的traefik大版本兼容，否则可能会出现意想不到的问题。&lt;/p&gt;

&lt;h3 id=&#34;访问日志&#34;&gt;访问日志&lt;/h3&gt;

&lt;p&gt;访问日志用来记录通过traefik进来的各个请求的访问详情，包含HTTP请求的各个header以及响应时间等数据，类似于Nginx中的&lt;code&gt;access.log&lt;/code&gt;，通常情况，我们可以使用访问日志来分析整个traefik的整体流量以及各个服务流量以及状态详情。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 访问日志默认也是以&lt;code&gt;text&lt;/code&gt;格式被写到标准输出的&lt;/p&gt;

&lt;p&gt;&lt;code&gt;相关配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[accessLog]
  filePath = &amp;#34;/path/to/traefik.log&amp;#34;
  format = &amp;#34;&amp;#34;                       # 指定访问日志的格式，默认使用CLF(Common Log Format)，可以指定为json格式
  bufferingSize = 100               # 以异步方式写入日志需要指定该参数，表示写入到指定输出设备前保留在内存中的日志行数
  [accessLog.filters]               # 指定一组逻辑上是Or的过滤连接器,指定多个过滤器将比只指定一个过滤器保留更多的访问日志
    statusCodes = [&amp;#34;200&amp;#34;, &amp;#34;300-302&amp;#34;] # 过滤指定状态码范围的请求日志
    retryAttempts = true             # 当有重试时保留日志
    minDuration = &amp;#34;10ms&amp;#34;             # 当请求花费的时间超过指定的持续时间时，保留访问日志
    
  [accessLog.fields]                # 限制访问日志中的字段(可以使用fields.names和fields.header选项来决定字段的输出)
    defaultMode = &amp;#34;keep&amp;#34;            # 每种字段可以设置成如下字段(keep:保留字段,drop:丢弃,redact:使用redacted替换值)
    [accessLog.fields.names]        # 指定限制的字段名称
      &amp;#34;ClientUsername&amp;#34; = &amp;#34;drop&amp;#34;     # 设置ClientUsername字段为丢弃
    [accessLog.fields.headers]      # 设置headers相关字段
      defaultMode = &amp;#34;keep&amp;#34;          # 对全部的header进行默认保留
      [accessLog.fields.headers.names] # 对指定的header字段设置保留规则
        &amp;#34;User-Agent&amp;#34; = &amp;#34;redact&amp;#34;
        &amp;#34;Authorization&amp;#34; = &amp;#34;drop&amp;#34;
        &amp;#34;Content-Type&amp;#34; = &amp;#34;keep&amp;#34;

# cli 配置
--accesslog=true
--accesslog.filepath=/path/to/access.log
--accesslog.format=json
--accesslog.bufferingsize=100
--accesslog.filters.statuscodes=200,300-302
--accesslog.filters.retryattempts
--accesslog.filters.minduration=10ms
--accesslog.fields.defaultmode=keep
--accesslog.fields.names.ClientUsername=drop
--accesslog.fields.headers.defaultmode=keep
--accesslog.fields.headers.names.User-Agent=redact
--accesslog.fields.headers.names.Authorization=drop
--accesslog.fields.headers.names.Content-Type=keep&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 由于我们是将Traefik当做Kubernetes集群中的边缘节点，去代理内部HTTP服务的，因此Traefik部署在集群内部,将进程日志和访问日志都以volume的方式挂载到边缘节点的数据目录中。&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;DaemonSet&lt;/code&gt;方式将Traefik部署在k8s集群内部，具体的配置如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;97
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat traefik-ds.yml
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      affinity:
        # 定义node的亲和性，不允许调度到master节点
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      containers:
      - image: traefik:v1.7.16
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8080
        securityContext:
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
        - --traefikLog.filePath=/logdata/traefik.log
        - --configfile=/config/traefik.toml
        - --accesslog.filepath=/logdata/access.log
        - --accesslog.bufferingsize=100
        volumeMounts:
        - mountPath: /config
          name: config
        - mountPath: /logdata
          name: access-log
      volumes:
      - configMap:
          name: traefik-config
        name: config
      - name: access-log
        hostPath:
          path: /opt/logs/ingress/

# 查看traefik 的状态
$ kubectl  get pods -n kube-system  | grep traefik
traefik-ingress-controller-2dx7k   1/1     Running   0          5h28m
...
...

$ kubectl  get svc -n kube-system  | grep traefik
traefik-ingress-service   ClusterIP   10.253.132.216   &amp;lt;none&amp;gt;        80/TCP,8080/TCP          123d
traefik-web-ui            ClusterIP   10.253.54.184    &amp;lt;none&amp;gt;        80/TCP                   172d


# 可以通过节点的ping接口和admin接口来查看traefik服务是否正常
$ curl 10.253.132.216/ping
OK

$ curl 10.253.132.216:8080
&amp;lt;a href=&amp;#34;/dashboard/&amp;#34;&amp;gt;Found&amp;lt;/a&amp;gt;.


# 在调度到treafik的节点上查看进程日志和访问日志
$ tree -L 2 /opt/logs/ingress/
/opt/logs/ingress/
├── access.log
└── traefik.log

$ tail -n 10 /opt/logs/ingress/traefik.log
time=&amp;#34;2020-04-07T08:53:38Z&amp;#34; level=warning msg=&amp;#34;Endpoints not available for my-data/my-data-selfaccess-dev&amp;#34;
time=&amp;#34;2020-04-07T08:53:38Z&amp;#34; level=warning msg=&amp;#34;Endpoints not available for my-data/my-data-metadata-prod1&amp;#34;


$ tail -n 10 /opt/logs/ingress/access.log
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;POST /.kibana/_search?ignore_unavailable=true&amp;amp;filter_path=aggregations.types.buckets HTTP/1.1&amp;#34; 503 161 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491674 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.41.10:9200&amp;#34; 1ms
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;POST /.kibana/_search?ignore_unavailable=true&amp;amp;filter_path=aggregations.types.buckets HTTP/1.1&amp;#34; 503 161 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491671 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.26.20:9200&amp;#34; 1ms
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;GET /.kibana/doc/config%3A6.4.0 HTTP/1.1&amp;#34; 503 301 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491675 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.14.6:9200&amp;#34; 1ms&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;从访问日志的输出格式中，我们可以看到，traefik的访问日志和Nginx的访问日志会比较相似，有了这份日志后，我们可以通过一些ELK之类的日志分析方案来分期网站的整体状态，比如UV,PV,区域分布，状态分布以及响应时间等等。&lt;/p&gt;

&lt;p&gt;另外，我们是将访问日志直接持久化输出到node节点上，后面可以通过node主机上的日志采集插件，将日志发送到ELK Stack中，进行分析，当然也可以直接将ELK Stack的日志采集端部署到traefik的pod中，也是可以的。&lt;/p&gt;

&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;

&lt;p&gt;Traefik默认支持四种Metrics的后端实现:
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/datadog/&#34;&gt;Datadog&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/influxdb/&#34;&gt;Influxdb&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/prometheus/&#34;&gt;Prometheus&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/statsd/&#34;&gt;StatsD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;想要开启&lt;code&gt;metrics&lt;/code&gt;的支持，只需要做如下配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
    [metrics]
      [metrics.prometheus]
      buckets=[0.1,0.3,1.2,5.0]
      entryPoint = &amp;#34;traefik&amp;#34;

# yaml 配置文件
metrics: {}

# cli 配置
--metrics=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Datadog后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置文件
[metrics]
  [metrics.datadog]
    address = &amp;#34;127.0.0.1:8125&amp;#34;
    addEntryPointsLabels = true   #在入口处增加metrics标签[true]
    addServicesLabels = true      #在service中启用meirtcs[true]
    pushInterval = 10s            #push metrics到datalog的间隔时间[10s]

# cli 配置
--metrics.datadog=true
--metrics.datadog.address=127.0.0.1:8125
--metrics.datadog.addEntryPointsLabels=true
--metrics.datadog.addServicesLabels=true
--metrics.datadog.pushInterval=10s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;InfluxDB后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置
[metrics]
  [metrics.influxDB]
    address = &amp;#34;localhost:8089&amp;#34;     #指定influxdb地址 [localhost:8089]
    protocol = &amp;#34;udp&amp;#34;               #influxdb的传输协议 [udp(udp|http)]
    database = &amp;#34;db&amp;#34;                #指定metrics写入的库[&amp;#34;&amp;#34;]
    retentionPolicy = &amp;#34;two_hours&amp;#34;  #metrics在influxdb中的保留策略 [&amp;#34;&amp;#34;]
    username = &amp;#34;&amp;#34;                  #influxdb用户名
    password = &amp;#34;&amp;#34;                  #influxdb密码
    addEntryPointsLabels = true    #入口处增加metrics标签[true]
    addServicesLabels = true       #在service中启用meirtcs[true]
    pushInterval = 10s             #push metrics到datalog的间隔时间[10s]

# cli 配置
--metrics.influxdb=true
--metrics.influxdb.address=localhost:8089
--metrics.influxdb.protocol=udp
--metrics.influxdb.database=db
--metrics.influxdb.retentionPolicy=two_hours
--metrics.influxdb.username=john
--metrics.influxdb.password=secret
--metrics.influxdb.addEntryPointsLabels=true
--metrics.influxdb.addServicesLabels=true
--metrics.influxdb.pushInterval=10s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Prometheus后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置
[metrics]
  [metrics.prometheus]
    buckets = [0.1,0.3,1.2,5.0]      #延迟的metrics的bucket存储[0.100000, 0.300000, 1.200000, 5.000000]
    addEntryPointsLabels = true      #入口处增加metrics标签[true]
    addServicesLabels = true         #在service中启用meirtcs[true]
    entryPoint = &amp;#34;traefik&amp;#34;           #指定metrics的端点[traefik(默认是管理端口8080/metrics)],也可以自定义
    manualRouting = true             #是否禁用内部路由[false]

# cli配置
--metrics.prometheus=true
--metrics.prometheus.buckets=0.100000, 0.300000, 1.200000, 5.000000
--metrics.prometheus.addEntryPointsLabels=true
--metrics.prometheus.addServicesLabels=true
## 自定义了一个metrics端点，并指定了端口
--metrics.prometheus.entryPoint=metrics
--entryPoints.metrics.address=:8082
--metrics.prometheus.manualrouting=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;和其他两种方式不同的是，prometheus仅会暴露metrics，是需要使用prometheus-server定期进行&lt;code&gt;pull&lt;/code&gt;来收集数据的。&lt;/p&gt;

&lt;p&gt;配置生效后，可以访问如下端口进行测试:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义了metrics端点
$ curl localhost:8082/metrics

# 使用默认的traefik端点(用的是admin的端口)
$ curl localhost:8080/metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;StatsD后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;详细配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置
[metrics]
  [metrics.statsD]
    address = &amp;#34;localhost:8125&amp;#34;          # 指定statsD服务地址
    addEntryPointsLabels = true         # 入口处增加metrics标签[true] 
    addServicesLabels = true            # 在service中启用meirtcs[true]
    pushInterval = 10s                  # push间隔
    prefix = &amp;#34;traefik&amp;#34;                  # 定义metrics收集的前缀[traefik]

# cli 配置
--metrics.statsd=true
--metrics.statsd.address=localhost:8125
--metrics.statsd.addEntryPointsLabels=true
--metrics.statsd.addServicesLabels=true
--metrics.statsd.pushInterval=10s
--metrics.statsd.prefix=&amp;#34;traefik&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Prometheus后端的Metrics示例&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 由于在生产环境使用的是traefik-1.7.6版本，因此上述的一些配置参数可能并不适用于该版本，详细的参数需要查看具体版本的支持参数，同时我们将traefik当做kubernetes集群中的ingress方案，因此如下操作在一个可用的k8s集群内部。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.traefik.io/v1.7/configuration/metrics/&#34;&gt;traefik-1.7-metrics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;1.traefik的metrics配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# traefik metrics 配置
$ cat traefik-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: traefik-config
  namespace: kube-system
data:
  traefik.toml: |
    defaultEntryPoints = [&amp;#34;http&amp;#34;,&amp;#34;https&amp;#34;]
    debug = false
    logLevel = &amp;#34;INFO&amp;#34;

    InsecureSkipVerify = true
    [entryPoints]
      [entryPoints.http]
      address = &amp;#34;:80&amp;#34;
      compress = true
      [entryPoints.https]
      address = &amp;#34;:443&amp;#34;
        [entryPoints.https.tls]
    [web]
      address = &amp;#34;:8080&amp;#34;
    [kubernetes]
    # 定义metrics相关参数
    [metrics]
      [metrics.prometheus]
      buckets=[0.1,0.3,1.2,5.0]
      entryPoint = &amp;#34;traefik&amp;#34;
    [ping]
    entryPoint = &amp;#34;http&amp;#34;

# 重新调度pod后，即可查看暴露的endpoint

$ kubectl  get ep -A | grep traefik
kube-system            traefik-ingress-service                    172.16.171.163:80,172.16.21.26:80,172.16.21.27:80 + 11 more...            122d
kube-system            traefik-web-ui                             172.16.171.163:8080,172.16.21.26:8080,172.16.21.27:8080 + 4 more...       171d

$ kubectl  get svc -n kube-system | grep traefik
traefik-ingress-service   ClusterIP   10.253.132.216   &amp;lt;none&amp;gt;        80/TCP,8080/TCP          122d
traefik-web-ui            ClusterIP   10.253.54.184    &amp;lt;none&amp;gt;        80/TCP                   171d

# 测试访问metrics服务(因为和traefik相关的两个service均路由到了traefil-ingress的pod上,下面两个效果是一致的)
$ curl -s  10.253.132.216:8080/metrics  | head -10
....
....
$ curl -s  10.253.54.184/metrics | head -10&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 推荐使用traefik-web-ui暴露的svc地址&lt;/p&gt;

&lt;p&gt;指标以及相关含义:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标项&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;process_max_fds&lt;/td&gt;
&lt;td&gt;traefik进程最大的fd&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_open_fds&lt;/td&gt;
&lt;td&gt;进程打开的fd&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_resident_memory_bytes&lt;/td&gt;
&lt;td&gt;进程占用内存&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_start_time_seconds&lt;/td&gt;
&lt;td&gt;进程启动时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_virtual_memory_bytes&lt;/td&gt;
&lt;td&gt;进程占用虚拟内存&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_open_connections&lt;/td&gt;
&lt;td&gt;traefik后端打开链接&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_bucket&lt;/td&gt;
&lt;td&gt;traefik后端请求处理时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_sum&lt;/td&gt;
&lt;td&gt;总时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_count&lt;/td&gt;
&lt;td&gt;总请求时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_requests_total&lt;/td&gt;
&lt;td&gt;一个后端处理的总请求数(按status code, protocol, and method划分)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_server_up&lt;/td&gt;
&lt;td&gt;后端是否up(0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_last_reload_failure&lt;/td&gt;
&lt;td&gt;traefik上次失败reload的时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_last_reload_success&lt;/td&gt;
&lt;td&gt;上次成功reload的时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_reloads_failure_total&lt;/td&gt;
&lt;td&gt;失败次数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_reloads_total&lt;/td&gt;
&lt;td&gt;成功次数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_open_connections&lt;/td&gt;
&lt;td&gt;入口点存在打开链接的数量(method and protocol划分)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_request_duration_seconds_bucket&lt;/td&gt;
&lt;td&gt;在入口点处理请求花费的时间(status code, protocol, and method.)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_requests_total&lt;/td&gt;
&lt;td&gt;一个入口点处理的总请求数(状态码分布)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code&gt;2.配置prometheus-server&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意，此时我们需要配置prometheus-server来对traefik暴露的metrics进行定期的pull采集。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 在k8s中创建一个prometheus monitor service
$ cat prometheus-traefik.yml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    k8s-app: traefik-ingress-lb
  name: traefik-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
    # 定义endpoint采集的时间
  - interval: 30s
    port: admin
    path: /metrics
  jobLabel: k8s-app
  # 匹配monitoring命名空间的app=gpu-metrics的svc
  namespaceSelector:
    matchNames:
    - kube-system
  selector:
    matchLabels:
      k8s-app: traefik-ingress-lb

$ kubectl apply -f prometheus-traefik.yml&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;配置完成后，即可在prometheus中查看相关的metrics数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdl4lcmvwsj32620o0ah5.jpg&#34; alt=&#34;prometheus-traefik-metrics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;3.根据指标配置Grafana&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/12041&#34;&gt;grafana模板&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdl6drdnotj31kw0u0gxk.jpg&#34; alt=&#34;Traefik-全局监控详情&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有了Merics的可视化后，针对于HTTP服务来说做各种滚动升级以及切流发布时，就很容易能够看到整个流量的变化。&lt;/p&gt;

&lt;h3 id=&#34;tracing&#34;&gt;Tracing&lt;/h3&gt;

&lt;p&gt;追踪系统可以开发人员可视化其基础架构中的调用流程.&lt;/p&gt;

&lt;p&gt;Traefik遵循OpenTracing规范(一个为分布式跟踪而设计的开放标准)&lt;/p&gt;

&lt;p&gt;Traefik支持五种追踪系统后端:
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/jaeger/&#34;&gt;Jaeger&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/zipkin/&#34;&gt;Zipkin&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/datadog/&#34;&gt;Datadog&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/instana/&#34;&gt;Instana&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/haystack/&#34;&gt;Haystack&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/elastic/&#34;&gt;Elastic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Datadog,Instana,Haystack为商业解决方案，以下不做介绍&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.配置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 默认情况下，traefik使用&lt;code&gt;Jaeger&lt;/code&gt;来最为追踪系统的后端实现.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  serviceName = &amp;#34;traefik&amp;#34;			# 选择追踪系统的后端实现[traefik(表示使用jaeger)]
  spanNameLimit = 150					# 限制长名称的名称阶段(这可以防止某些跟踪提供程序删除超过其长度限制的跟踪)

# cli 配置
--tracing=true
--tracing.serviceName=traefik
--tracing.spanNameLimit=150&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.Jaeger&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  [tracing.jaeger]					# 开启jaeger的追踪支持
    samplingServerURL = &amp;#34;http://localhost:5778/sampling&amp;#34; 		# 指定jaeger-agent的http采样地址
    samplingType = &amp;#34;const&amp;#34;	# 指定采样类型[const(const|probabilistic|rateLimiting)]
    samplingParam = 1.0			# 采样参数的值[1.0(const:0|1,probabilistic:0-1,rateLimiting:每秒的span数)]
    localAgentHostPort = &amp;#34;127.0.0.1:6831&amp;#34;										# 本地agent主机和端口(会发送到jaeger-agent)
    gen128Bit = true				# 生成128位的traceId,兼容OpenCensus
    propagation = &amp;#34;jaeger&amp;#34;  # 设置数据传输的header类型[jaeger(jaeger|b3兼容OpenZipkin)]
    traceContextHeaderName = &amp;#34;uber-trace-id&amp;#34;  # 跟踪上下文的header,用于传输跟踪上下文的http头名
  [tracing.jaeger.collector]  # 指定jaeger的collector服务
    endpoint = &amp;#34;http://127.0.0.1:14268/api/traces?format=jaeger.thrift&amp;#34;
    user = &amp;#34;my-user&amp;#34;          # 向collector提交时的http认证用户[&amp;#34;&amp;#34;]
    password = &amp;#34;my-password&amp;#34;  # 向collector提交时的http认证密码[&amp;#34;&amp;#34;]


# cli 配置
--tracing.jaeger=true
--tracing.jaeger.samplingServerURL=http://localhost:5778/sampling
--tracing.jaeger.samplingType=const
--tracing.jaeger.samplingParam=1.0
--tracing.jaeger.localAgentHostPort=127.0.0.1:6831
--tracing.jaeger.gen128Bit
--tracing.jaeger.propagation=jaeger
--tracing.jaeger.traceContextHeaderName=uber-trace-id
--tracing.jaeger.collector.endpoint=http://127.0.0.1:14268/api/traces?format=jaeger.thrift
--tracing.jaeger.collector.user=my-user
--tracing.jaeger.collector.password=my-password&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3.Zipkin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
[tracing]
  [tracing.zipkin]                  # 指定使用zipkin追踪系统
    httpEndpoint = &amp;#34;http://localhost:9411/api/v2/spans&amp;#34;   # 指定zipkip收集数据的http端点
    sameSpan = true                 # 使用Zipkin SameSpan RPC 类型追踪方式
    id128Bit = true                 # 使用Zipkin 128 bit的追踪id(true)
    sampleRate = 0.2                # 指定请求trace系统的频率[1.0(0.1-1.0)]

# cli 配置
--tracing.zipkin=true
--tracing.zipkin.httpEndpoint=http://localhost:9411/api/v2/spans
--tracing.zipkin.sameSpan=true
--tracing.zipkin.id128Bit=false
--tracing.zipkin.sampleRate=0.2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.Elastic&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  [tracing.elastic]
    serverURL = &amp;#34;http://apm:8200&amp;#34;     # 指定Elastic APM服务地址
    secretToken = &amp;#34;&amp;#34;                  # 指定Elastic APM服务的安全token
    serviceEnvironment = &amp;#34;&amp;#34;           # 指定APM Server的环境

# cli 配置
--tracing.elastic=true
--tracing.elastic.serverurl=&amp;#34;http://apm:8200&amp;#34;
--tracing.elastic.secrettoken=&amp;#34;mytoken&amp;#34;
--tracing.elastic.serviceenvironment=&amp;#34;production&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>基于DCGM和Prometheus的GPU监控方案</title>
      <link>https://bgbiao.top/post/%E5%9F%BA%E4%BA%8Edcgm%E5%92%8Cprometheus%E7%9A%84gpu%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%9F%BA%E4%BA%8Edcgm%E5%92%8Cprometheus%E7%9A%84gpu%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>&lt;h2 id=&#34;基于dcgm和prometheus的gpu监控方案&#34;&gt;基于DCGM和Prometheus的GPU监控方案&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;背景: 在早期的GPU监控中我们会使用一些NVML工具来对GPU卡的基本信息进行采集，并持久化到监控系统的数据存储层。因为我们知道，其实通过&lt;code&gt;nvidia-smi&lt;/code&gt;这样的命令也是可以获取到GPU的基本信息的，但随着整个AI市场的发展和成熟，对于GPU的监控也越来越需要一套标准化的工具体系，也就是本篇文章讲的关于&lt;a href=&#34;https://developer.nvidia.com/dcgm&#34;&gt;DCGM&lt;/a&gt;相关的监控解决方案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;DCGM(Data Center GPU Manager)即数据中心GPU管理器，是一套用于在集群环境中管理和监视&lt;code&gt;Tesla™&lt;/code&gt;GPU的工具。&lt;/p&gt;

&lt;p&gt;它包括主动健康监控，全面诊断，系统警报以及包括电源和时钟管理在内的治理策略。&lt;/p&gt;

&lt;p&gt;它可以由系统管理员独立使用，并且可以轻松地集成到NVIDIA合作伙伴的集群管理，资源调度和监视产品中。&lt;/p&gt;

&lt;p&gt;DCGM简化了数据中心中的GPU管理，提高了资源可靠性和正常运行时间，自动化了管理任务，并有助于提高整体基础架构效率。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 虽然可以通过&lt;code&gt;nvidia-smi&lt;/code&gt;命令将相关的信息采集，并定期汇报到数据存储进行数据分析计算和展现，但是涉及到一整套的监控体系的整合，仍然需要使用方进行一些列的改造。因此这里，我们采用NVIDIA官方提供的DCGM方案来进行GPU数据采集，并通过声称下一代监控系统的Prometheus进行整个监控和告警的集成。&lt;/p&gt;

&lt;h3 id=&#34;dcgm工具部署&#34;&gt;DCGM工具部署&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ git clone https://github.com/NVIDIA/gpu-monitoring-tools.git

# 构建dcgm-exporter工具，其实就是nvidia官方对于nvidia-docker2.x推出的用于gpu数据监控的工具
# 最终会将gpu卡的metrics基本信息存储以metrics的数据格式存储到文件中
$ cd dcgm-exporter
# nvidia/dcgm-exporter:latest
$ make 

$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter nvidia/dcgm-exporter

# 查看dcgm-exporter收集到的gpu metrics数据
$ docker exec -it nvidia-dcgm-exporter tail -n 10  /run/prometheus/dcgm.prom
dcgm_ecc_dbe_aggregate_total{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_sbe Total number of retired pages due to single-bit errors.
# TYPE dcgm_retired_pages_sbe counter
dcgm_retired_pages_sbe{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_dbe Total number of retired pages due to double-bit errors.
# TYPE dcgm_retired_pages_dbe counter
dcgm_retired_pages_dbe{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_pending Total number of pages pending retirement.
# TYPE dcgm_retired_pages_pending counter
dcgm_retired_pages_pending{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;dcgm-exporter采集指标项以及含义:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dcgm_fan_speed_percent&lt;/td&gt;
&lt;td&gt;GPU 风扇转速占比（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_sm_clock&lt;/td&gt;
&lt;td&gt;GPU sm 时钟(MHz)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_memory_clock&lt;/td&gt;
&lt;td&gt;GPU 内存时钟(MHz)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_gpu_temp&lt;/td&gt;
&lt;td&gt;GPU 运行的温度(℃)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_power_usage&lt;/td&gt;
&lt;td&gt;GPU 的功率（w）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_tx_throughput&lt;/td&gt;
&lt;td&gt;GPU PCIe TX传输的字节总数 （kb）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_rx_throughput&lt;/td&gt;
&lt;td&gt;GPU PCIe RX接收的字节总数   （kb）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_replay_counter&lt;/td&gt;
&lt;td&gt;GPU PCIe重试的总数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_gpu_utilization&lt;/td&gt;
&lt;td&gt;GPU 利用率（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_mem_copy_utilization&lt;/td&gt;
&lt;td&gt;GPU 内存利用率（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_enc_utilization&lt;/td&gt;
&lt;td&gt;GPU 编码器利用率 （%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_dec_utilization&lt;/td&gt;
&lt;td&gt;GPU 解码器利用率 (%)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_xid_errors&lt;/td&gt;
&lt;td&gt;GPU 上一个xid错误的值&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_power_violation&lt;/td&gt;
&lt;td&gt;GPU 功率限制导致的节流持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_thermal_violation&lt;/td&gt;
&lt;td&gt;GPU 热约束节流持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_sync_boost_violation&lt;/td&gt;
&lt;td&gt;GPU 同步增强限制，限制持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_fb_free&lt;/td&gt;
&lt;td&gt;GPU fb（帧缓存）的剩余（MiB）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_fb_used&lt;/td&gt;
&lt;td&gt;GPU fb （帧缓存）的使用 （MiB）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;其实到这，dcgm已经完整的将我们需要的gpu的metrics数据采集出来了，并且是符合prometheus的数据格式和标准的，此时，我们可以根据实际的情况编写一个简单的api程序，将采集到的数据以api的形式暴露出去，就可以让整个prometheus server对各个gpu主机的metrics进行采集和监控。&lt;/p&gt;

&lt;p&gt;不过官方提供了基于kubernetes集群中pod方式的api接口，采用golang语言开发，具体使用情况可参考如下文档。&lt;/p&gt;

&lt;h3 id=&#34;prometheus-gpu-metrics-exporter&#34;&gt;prometheus gpu metrics exporter&lt;/h3&gt;

&lt;p&gt;在&lt;code&gt;gpu-monitoring-tools&lt;/code&gt;项目中，默认提供了一个&lt;code&gt;pod-gpu-metrics-exporter&lt;/code&gt;模块，用于在kubernetes集群中的gpu-metrics的部署，官方的示例步骤如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nvidia-k8s-device-plugin&lt;/li&gt;
&lt;li&gt;Deploy GPU Pods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在使kubernetes集群中部署的前提是你的GPU要托管在k8s集群内部，这也就意味着你得先成功将带GPU的主机成功托管到集群中，并且能够调度GPU资源&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建一个监控的命名空间
# Create the monitoring namespace
$ kubectl create namespace monitoring

# Add gpu metrics endpoint to prometheus
$ kubectl create -f prometheus/prometheus-configmap.yaml

# Deploy prometheus
$ kubectl create -f prometheus/prometheus-deployment.yaml

$ kubectl create -f pod-gpu-metrics-exporter-daemonset.yaml

# Open in browser: localhost:9090

# 具体的docker镜像构建和运行
# 依然是gpu-monitoring-tools项目
$ cd  pod-gpu-metrics-exporter
$ docker build -t pod-gpu-metrics-exporter .

# 运行dcgm-exporter
$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter nvidia/dcgm-exporter

# 运行gpu-metrics-exporter
$ docker run -d --privileged --rm -p 9400:9400 -v /var/lib/kubelet/pod-resources:/var/lib/kubelet/pod-resources --volumes-from nvidia-dcgm-exporter:ro nvidia/pod-gpu-metrics-exporter:v1.0.0-alpha

# 此时就将上述的那个dcgm-exporter中采集到数据成功暴露到对外的接口了
$ curl -s localhost:9400/gpu/metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;需要注意的是，在&lt;code&gt;gpu-metrics-exporter&lt;/code&gt;的程序中，是针对pod的方式来采集gpu的metrics的信息，并且附带了pod本身的基本信息，因此如果你的&lt;code&gt;gpu&lt;/code&gt;主机还未在kubernetes集群中托管，官方提供的镜像可能并不能使用，需要对&lt;code&gt;src/http.go&lt;/code&gt;文件中采集的路径进行改变，将默认的&lt;code&gt;gpuPodMetrics&lt;/code&gt;改成&lt;code&gt;gpuMetrics&lt;/code&gt;即可，两者会去读取不同的dcgm-exporter暴露出来的metrics文件，否则访问api接口时会发现无法找到metrics文件.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;func getGPUmetrics(resp http.ResponseWriter, req *http.Request) {
	//metrics, err := ioutil.ReadFile(gpuPodMetrics)
	metrics, err := ioutil.ReadFile(gpuMetrics)
	if err != nil {
		http.Error(resp, err.Error(), http.StatusInternalServerError)
		glog.Errorf(&amp;#34;error responding to %v%v: %v&amp;#34;, req.Host, req.URL, err.Error())
		return
	}
	resp.Write(metrics)
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;参考&lt;a href=&#34;https://github.com/BGBiao/gpu-monitoring-tools/tree/master/gpu-metrics-exporter&#34;&gt;gpu-metrics-exporter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;图省事的，可以直接下载如下两个镜像，在已经work 的GPU主机上直接运行.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dcgm-exporter: &lt;code&gt;docker pull bgbiao/dcgm-exporter:latest&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;gpu-metrics-exporter: &lt;code&gt;docker pull bgbiao/gpu-metrics-exporter:latest&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 确定dcgm-exporter是运行的
$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter bgbiao/dcgm-exporter

$ docker run -d --privileged --rm -p 9400:9400  --volumes-from nvidia-dcgm-exporter:ro bgbiao/gpu-metrics-exporter

# 检查gpu暴露出来的基础信息
$ curl -s localhost:9400/gpu/metrics
dcgm_ecc_dbe_aggregate_total{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
....
....&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;prometheus采集&#34;&gt;prometheus采集&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 有了上述的gpu-metrics-exporter之后，我们的gpu相关的运行数据就可以以premetheus兼容的方式获取了，此时在prometheus-server上配置，去定期pull 数据即可，我们的prometheus-server目前部署在kubernetes集群内部，因此这里分享将gpu的数据采集到kubernetes集群内部的prometheus中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建endpoint以及对应的service&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# gpu-metrics的endpoint和service配置

$ cat endpoint-gpus.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: gpu-metrics
  namespace: monitoring
  labels:
    app: gpu-metrics
subsets:
- addresses:
  - ip: 172.16.65.234
  ports:
  - port: 9400
    name: http-metrics
    protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  name: gpu-metrics
  labels:
    app: gpu-metrics
spec:
  ports:
  - name: http-metrics
    port: 19400
    targetPort: 9400
    protocol: TCP

$ kubectl  apply -f endpoint-gpus.yaml

# 查看创建的相关资源
$ kubectl  get ep,svc -n monitoring  -l app=gpu-metrics
NAME                    ENDPOINTS            AGE
endpoints/gpu-metrics   172.16.65.234:9400   5m24s

NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
service/gpu-metrics   ClusterIP   10.253.138.97   &amp;lt;none&amp;gt;        19400/TCP   5m24s

# 测试service暴露的端点
# 确保集群内部可以访问service暴露出来的endpoint即可

$ curl 10.253.138.97:19400/gpu/metrics
# HELP dcgm_sm_clock SM clock frequency (in MHz).
# TYPE dcgm_sm_clock gauge
dcgm_sm_clock{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 1328
# HELP dcgm_memory_clock Memory clock frequency (in MHz).
# TYPE dcgm_memory_clock gauge
dcgm_memory_clock{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 715&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;创建prometheus抓取数据的规则&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat prometheus-gpus.yml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: gpu-metrics
  name: gpu-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
    # 定义endpoint采集的时间和采集的URI
  - interval: 30s
    port: http-metrics
    path: /gpu/metrics
  jobLabel: app
  # 匹配monitoring命名空间的app=gpu-metrics的svc
  namespaceSelector:
    matchNames:
    - monitoring
  selector:
    matchLabels:
      app: gpu-metrics

$ kubectl  apply -f prometheus-gpus.yml
servicemonitor.monitoring.coreos.com/gpu-metrics created

$ kubectl  get servicemonitor  -n monitoring gpu-metrics
NAME          AGE
gpu-metrics   69s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当上述资源创建完成后，在集群内部的prometheus-server中就可以找到对应的target，确认状态为up即表示prometheus已正常采集集群外gpu的metrics数据了，接下来数据就会以30s为间隔，源源不断的将数据采集到prometheus存储中.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdiuxv5l47j31pk0aegon.jpg&#34; alt=&#34;prometheus-gpu-targets&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;gpu监控信息的展示&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;到这里，我们已经到万里长征的最后一步了，就是把prometheus中gpu的监控数据用grafana展示出来，以实时去分析一些gpu的基本数据。&lt;/p&gt;

&lt;p&gt;在grafana官网中，已经有大佬制作了gpu监控的相关模板，比如&lt;code&gt;[GPU-Nodes-Metrics](https://grafana.com/grafana/dashboards/12027)&lt;/code&gt;,因此，对于我们使用者来说，在grafana的面板中，将该模板导入即可使用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdiv4s5t9nj30ec0ek0tc.jpg&#34; alt=&#34;选择导入方式创建&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0dzwdmjj31ly0u041p.jpg&#34; alt=&#34;指定模板(dashboard id或json)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0ftc6d8j31nd0u0djg.jpg&#34; alt=&#34;注意:确认prometheus库正确后即可导入&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0h15tp5j31oi0u0n5x.jpg&#34; alt=&#34;最终的GPU监控图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考项目&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/gpu-monitoring-tools&#34;&gt;gpu-monitor-tools&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/11752&#34;&gt;gpu-metrics-grafana&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>构建更小Docker镜像的一些建议</title>
      <link>https://bgbiao.top/post/%E6%9E%84%E5%BB%BA%E6%9B%B4%E5%B0%8Fdocker%E9%95%9C%E5%83%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E6%9E%84%E5%BB%BA%E6%9B%B4%E5%B0%8Fdocker%E9%95%9C%E5%83%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 前两天在群里看到有人提到说，自己构建了一个镜像，明明就只往base镜像中增加了tomcat，但是构建好的镜像大小最终却是两倍的tomcat包的大小，最后看到Dockerfile后才发现作者在把tomcat包拷贝进去之后，又使用&lt;code&gt;RUN&lt;/code&gt;指令，执行了一次&lt;code&gt;chmod a+x tomcat&lt;/code&gt;，我想说，这么搞镜像不大那是不可能的。另外一件事就是前段时间，同事说让搞一个公司级别的base镜像，要稳定并且尽量小，借着这两个事，和大家分享几点Docker镜像相关的事情。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先，镜像的大小最终取决于如下几点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.业务需求和debug的便利性(比如科学计算和普通的java或者golang程序)&lt;/li&gt;
&lt;li&gt;2.业务镜像构建的依赖特性(构建过程和交付物的依赖关系)&lt;/li&gt;
&lt;li&gt;3.交付物的定义过程(Dockerfile分层过程中的变更层)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来，从三个点来谈谈我个人的想法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、单从镜像大小的角度考虑&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果仅从镜像的大小角度来讲，为了镜像尽可能的小，有如下的base镜像可供选择:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;alpine: 专为容器而生的基础镜像，缺点是默认使用的&lt;code&gt;musl libc&lt;/code&gt;，但是大多数运行在Linux下的程序几乎都是&lt;code&gt;glibc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scratch: 没有任何&lt;code&gt;杂念&lt;/code&gt;的基础镜像，优点就是没有杂念，缺点也明显就是各种动态链接库，shell等等都没有(所以对应静态依赖的程序还是可以的)&lt;/li&gt;
&lt;li&gt;busybox: 基本也是一个没有太多&lt;code&gt;杂念&lt;/code&gt;的基础镜像，不过生态里包含了很多依赖镜像，比如&lt;code&gt;busybox:glibc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;centos: centos发行版的mini镜像，基础的库和工具包基本都有，base稍微大了点(200M左右吧,不过也可以精简)&lt;/li&gt;
&lt;li&gt;ubuntu: ubuntu发现版的mini镜像，同上，base大概在120M左右，不过两者的稳定性和包的管理有差异&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但以上几种的base均有利弊，而且企业内部通常业务场景也会有一定的变化，因此我们在维护内部的基础base镜像时一般不会为了&lt;code&gt;镜像小&lt;/code&gt;这个伪目标而使用多种base来构建不同镜像，主要是考虑到后期的维护成本较高(稳定性，可操作性).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、考虑业务的需求和debug的便利性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;java: 程序依赖基本包含在程序中，仅对java依赖&lt;/li&gt;
&lt;li&gt;c: 可能需要指定的libc库以及动态链接库的依赖&lt;/li&gt;
&lt;li&gt;golang: 编译好的程序几乎不需要依赖&lt;/li&gt;
&lt;li&gt;python: 需要依赖python以及各个库的支持，同时库可能依赖系统的动态链接库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通常在企业环境中，系统不可能长期只有一种语言来开发，因此不同语言生态下也就诞生了不同的需求。&lt;/p&gt;

&lt;p&gt;比如，当下不论是&lt;code&gt;DL(Deep Learning)&lt;/code&gt;还是&lt;code&gt;ML(Machine Learning)&lt;/code&gt;大部分对外的库基本都是使用Python开发的，因此在这种场景下，通常业务所需要的基础库是相当大，几个G的竟像也是司空见惯的。&lt;/p&gt;

&lt;p&gt;同时，还有一个比较常见的情况，就是我们的技术人员都有可能去容器内部进行简单的debug操作(比如使用curl,netstat等工具)，此时不同的base镜像会包含不同的生态工具，无疑也会增加大家的学习成本，如果对外推广可能会遭遇一定障碍。&lt;/p&gt;

&lt;p&gt;最后，还有一个点就是业务上层的base竟像的精简化。&lt;/p&gt;

&lt;p&gt;很多时候base环境内部可能存在一些基本工具，仅是程序构建时需要的工具，比如c程序的gcc,golang程序的go,java程序的jdk(其实仅jre就可以)，因此为了进一步减少空间，可以将构建过程相关的工具阉割掉。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三、交付物的定义过程&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在传统的CI/CD流水线中，交付物通常是一个静态的压缩包，而在引入以Docker为代表的容器技术之后，交付物就是包含业务代码和其运行时环境的镜像，因此在交付物的定义过程中也可以做一些镜像精简的优化。&lt;/p&gt;

&lt;p&gt;这里主要是Docker的分层思想，在开源的容器市场中，基于&lt;code&gt;overlay&lt;/code&gt;的存储引擎已经是不争的事实，所以，我们可以在分层过程中进行一些优化，对overlay不太了解的可以阅读以前的一篇文章&lt;a href=&#34;https://www.jianshu.com/p/959e8e3da4b2&#34;&gt;overlayfs的探究以及在docker的使用&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;FROM golang as golang-build
WORKDIR /
COPY hello.go .
RUN go build -ldflags &amp;#34;-s -w&amp;#34; -o hello hello.go

FROM alpine
COPY --from=golang-build hello .
RUN chmod a-x hello &amp;amp;&amp;amp; chmod a+x hello
CMD [&amp;#34;./hello&amp;#34;]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;我们知道，在分层的思想中，每一层都是上一层的可写叠加，而在最新层变更的文件才是整个镜像或者容器增加的数据，所以如上的Dockerfile中，我们在&lt;code&gt;RUN&lt;/code&gt;指令中增加了权限的操作(仅用来说明问题)，你会发现，最终的镜像会比不加&lt;code&gt;RUN&lt;/code&gt;指令整整大了一个&lt;code&gt;hello&lt;/code&gt;程序的空间，这其实就是镜像分层中的一个优化点。&lt;/p&gt;

&lt;p&gt;所以，在企业内部进行容器化改造和上线时，除了需要考虑各个适用方的场景问题和操作便利性，同时在构建过程中也需要进行一定的把控。&lt;/p&gt;

&lt;p&gt;当然啦，尽可能的将镜像压缩到最小，不仅可以减少磁盘的使用，同时在大规模分发镜像时也会表现的相对有效率，但在实际使用过程中，并不是所有的镜像越小越好，同时我们需要在镜像的通用性和可维护性上进行一定权重的考量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>使用jwt-go验证API</title>
      <link>https://bgbiao.top/post/golang-jwt%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang-jwt%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;背景: 在如今前后端分离开发的大环境中，我们需要解决一些登陆，后期身份认证以及鉴权相关的事情，通常的方案就是采用请求头携带token的方式进行实现。本篇文章主要分享下在Golang语言下使用&lt;a href=&#34;https://github.com/dgrijalva/jwt-go&#34;&gt;jwt-go&lt;/a&gt;来实现后端的token认证逻辑。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;JSON Web Token(JWT)&lt;/code&gt;是一个常用语HTTP的客户端和服务端间进行身份认证和鉴权的标准规范，使用JWT可以允许我们在用户和服务器之间传递安全可靠的信息。&lt;/p&gt;

&lt;p&gt;在开始学习&lt;a href=&#34;https://jwt.io/&#34;&gt;JWT&lt;/a&gt;之前，我们可以先了解下早期的几种方案。&lt;/p&gt;

&lt;h3 id=&#34;token-cookie-session的区别&#34;&gt;token、cookie、session的区别&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Cookie&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cookie总是保存在客户端中，按在客户端中的存储位置，可分为&lt;code&gt;内存Cookie&lt;/code&gt;和&lt;code&gt;硬盘Cookie&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;内存Cookie由浏览器维护，保存在内存中，浏览器关闭后就消失了，其存在时间是短暂的。硬盘Cookie保存在硬盘里，有一个过期时间，除非用户手工清理或到了过期时间，硬盘Cookie不会被删除，其存在时间是长期的。所以，按存在时间，可分为&lt;code&gt;非持久Cookie和持久Cookie&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;cookie 是一个非常具体的东西，指的就是浏览器里面能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cookie由服务器生成，发送给浏览器&lt;/code&gt;，浏览器把cookie以key-value形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在客户端上的，所以浏览器加入了一些限制确保cookie不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的cookie数量是有限的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Session&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Session字面意思是会话，主要用来标识自己的身份。比如在无状态的api服务在多次请求数据库时，如何知道是同一个用户，这个就可以通过session的机制，服务器要知道当前发请求给自己的是谁&lt;/p&gt;

&lt;p&gt;为了区分客户端请求，&lt;code&gt;服务端会给具体的客户端生成身份标识session&lt;/code&gt;，然后客户端每次向服务器发请求的时候，都带上这个“身份标识”，服务器就知道这个请求来自于谁了。&lt;/p&gt;

&lt;p&gt;至于客户端如何保存该标识，可以有很多方式，对于浏览器而言，一般都是使用&lt;code&gt;cookie&lt;/code&gt;的方式&lt;/p&gt;

&lt;p&gt;服务器使用session把用户信息临时保存了服务器上，用户离开网站就会销毁，这种凭证存储方式相对于cookie来说更加安全，但是session会有一个缺陷: 如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。&lt;/p&gt;

&lt;p&gt;因此，通常企业里会使用&lt;code&gt;redis,memcached&lt;/code&gt;缓存中间件来实现session的共享，此时web服务器就是一个完全无状态的存在，所有的用户凭证可以通过共享session的方式存取，当前session的过期和销毁机制需要用户做控制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Token&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;token的意思是“令牌”，是用户身份的验证方式，最简单的token组成: &lt;code&gt;uid(用户唯一标识)&lt;/code&gt;+&lt;code&gt;time(当前时间戳)&lt;/code&gt;+&lt;code&gt;sign(签名,由token的前几位+盐以哈希算法压缩成一定长度的十六进制字符串)&lt;/code&gt;，同时还可以将不变的参数也放进token&lt;/p&gt;

&lt;p&gt;这里我们主要想讲的就是&lt;code&gt;Json Web Token&lt;/code&gt;，也就是本篇的主题:JWT&lt;/p&gt;

&lt;h3 id=&#34;json-web-token-jwt-介绍&#34;&gt;Json-Web-Token(JWT)介绍&lt;/h3&gt;

&lt;p&gt;一般而言，用户注册登陆后会生成一个jwt token返回给浏览器，浏览器向服务端请求数据时携带&lt;code&gt;token&lt;/code&gt;，服务器端使用&lt;code&gt;signature&lt;/code&gt;中定义的方式进行解码，进而对token进行解析和验证。&lt;/p&gt;

&lt;h4 id=&#34;jwt-token组成部分&#34;&gt;JWT Token组成部分&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcpwngvonhj30hx03xwf0.jpg&#34; alt=&#34;JWT-Token组成部分&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;header: 用来指定使用的算法(HMAC SHA256 RSA)和token类型(如JWT)&lt;/li&gt;
&lt;li&gt;payload: 包含声明(要求)，声明通常是用户信息或其他数据的声明，比如用户id，名称，邮箱等. 声明可分为三种: registered,public,private&lt;/li&gt;
&lt;li&gt;signature: 用来保证JWT的真实性，可以使用不同的算法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;header&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;{
    &amp;#34;alg&amp;#34;: &amp;#34;HS256&amp;#34;,
    &amp;#34;typ&amp;#34;: &amp;#34;JWT&amp;#34;
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;对上面的json进行base64编码即可得到JWT的第一个部分&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;payload&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;registered claims: 预定义的声明，通常会放置一些预定义字段，比如过期时间，主题等(iss:issuer,exp:expiration time,sub:subject,aud:audience)&lt;/li&gt;
&lt;li&gt;public claims: 可以设置公开定义的字段&lt;/li&gt;

&lt;li&gt;&lt;p&gt;private claims: 用于统一使用他们的各方之间的共享信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;{
&amp;#34;sub&amp;#34;: &amp;#34;xxx-api&amp;#34;,
&amp;#34;name&amp;#34;: &amp;#34;bgbiao.top&amp;#34;,
&amp;#34;admin&amp;#34;: true
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对payload部分的json进行base64编码后即可得到JWT的第二个部分&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 不要在header和payload中放置敏感信息，除非信息本身已经做过脱敏处理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;signature&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了得到签名部分，必须有编码过的header和payload，以及一个秘钥，签名算法使用header中指定的那个，然后对其进行签名即可&lt;/p&gt;

&lt;p&gt;&lt;code&gt;HMACSHA256(base64UrlEncode(header)+&amp;quot;.&amp;quot;+base64UrlEncode(payload),secret)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;签名是&lt;code&gt;用于验证消息在传递过程中有没有被更改&lt;/code&gt;，并且，对于使用私钥签名的token，它还可以验证JWT的发送方是否为它所称的发送方。&lt;/p&gt;

&lt;p&gt;在&lt;a href=&#34;https://jwt.io&#34;&gt;jwt.io&lt;/a&gt;网站中，提供了一些JWT token的编码，验证以及生成jwt的工具。&lt;/p&gt;

&lt;p&gt;下图就是一个典型的jwt-token的组成部分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcpxe1ungej30wq0mygo8.jpg&#34; alt=&#34;jwt官方签名结构&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;什么时候用jwt&#34;&gt;什么时候用JWT&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Authorization(授权): 典型场景，用户请求的token中包含了该令牌允许的路由，服务和资源。单点登录其实就是现在广泛使用JWT的一个特性&lt;/li&gt;
&lt;li&gt;Information Exchange(信息交换):  对于安全的在各方之间传输信息而言，JSON Web Tokens无疑是一种很好的方式.因为JWTs可以被签名，例如，用公钥/私钥对，你可以确定发送人就是它们所说的那个人。另外，由于签名是使用头和有效负载计算的，您还可以验证内容没有被篡改&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;jwt-json-web-tokens-是如何工作的&#34;&gt;JWT(Json Web Tokens)是如何工作的&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcptxpqcrxj30ct0bsq3h.jpg&#34; alt=&#34;JWT认证过程&#34; /&gt;&lt;/p&gt;

&lt;p&gt;所以，基本上整个过程分为两个阶段，第一个阶段，客户端向服务端获取token，第二阶段，客户端带着该token去请求相关的资源.&lt;/p&gt;

&lt;p&gt;通常比较重要的是，服务端如何根据指定的规则进行token的生成。&lt;/p&gt;

&lt;p&gt;在认证的时候，当用户用他们的凭证成功登录以后，一个JSON Web Token将会被返回。&lt;/p&gt;

&lt;p&gt;此后，token就是用户凭证了，你必须非常小心以防止出现安全问题。&lt;/p&gt;

&lt;p&gt;一般而言，你保存令牌的时候不应该超过你所需要它的时间。&lt;/p&gt;

&lt;p&gt;无论何时用户想要访问受保护的路由或者资源的时候，用户代理（通常是浏览器）都应该带上JWT，典型的，通常放在Authorization header中，用Bearer schema:
&lt;code&gt;Authorization: Bearer &amp;lt;token&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;服务器上的受保护的路由将会检查Authorization header中的JWT是否有效，如果有效，则用户可以访问受保护的资源。如果JWT包含足够多的必需的数据，那么就可以减少对某些操作的数据库查询的需要，尽管可能并不总是如此。&lt;/p&gt;

&lt;p&gt;如果token是在授权头（Authorization header）中发送的，那么跨源资源共享(CORS)将不会成为问题，因为它不使用cookie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcpxi6z1dmj315o0fvab0.jpg&#34; alt=&#34;获取JWT以及访问APIs以及资源&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;客户端向授权接口请求授权&lt;/li&gt;
&lt;li&gt;服务端授权后返回一个access token给客户端&lt;/li&gt;
&lt;li&gt;客户端使用access token访问受保护的资源&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;基于token的身份认证和基于服务器的身份认证&#34;&gt;基于Token的身份认证和基于服务器的身份认证&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;1.基于服务器的认证&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;前面说到过session，cookie以及token的区别，在之前传统的做法就是基于存储在服务器上的session来做用户的身份认证，但是通常会有如下问题:
- Sessions: 认证通过后需要将用户的session数据保存在内存中，随着认证用户的增加，内存开销会大
- 扩展性: 由于session存储在内存中，扩展性会受限，虽然后期可以使用redis,memcached来缓存数据
- CORS: 当多个终端访问同一份数据时，可能会遇到禁止请求的问题
- CSRF: 用户容易受到CSRF攻击&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.Session和JWT Token的异同&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;都可以存储用户相关信息，但是session存储在服务端，JWT存储在客户端&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcpxunv5qcj30dd0gfgmp.jpg&#34; alt=&#34;session和jwt数据存储位置&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.基于Token的身份认证如何工作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于Token的身份认证是无状态的，服务器或者session中不会存储任何用户信息.(很好的解决了共享session的问题)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用户携带用户名和密码请求获取token(接口数据中可使用appId,appKey)&lt;/li&gt;
&lt;li&gt;服务端校验用户凭证，并返回用户或客户端一个Token&lt;/li&gt;
&lt;li&gt;客户端存储token,并在请求头中携带Token&lt;/li&gt;
&lt;li&gt;服务端校验token并返回数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;
- 随后客户端的每次请求都需要使用token
- token应该放在header中
- 需要将服务器设置为接收所有域的请求: &lt;code&gt;Access-Control-Allow-Origin: *&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.用Token的好处&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无状态和可扩展性&lt;/li&gt;
&lt;li&gt;安全: 防止CSRF攻击;token过期重新认证&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;5.JWT和OAuth的区别&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.OAuth2是一种授权框架 ，JWT是一种认证协议&lt;/li&gt;
&lt;li&gt;2.无论使用哪种方式切记用HTTPS来保证数据的安全性&lt;/li&gt;
&lt;li&gt;3.OAuth2用在&lt;code&gt;使用第三方账号登录的情况&lt;/code&gt;(比如使用weibo, qq, github登录某个app)，而&lt;code&gt;JWT是用在前后端分离&lt;/code&gt;, 需要简单的对后台API进行保护时使用&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;使用gin框架集成jwt&#34;&gt;使用Gin框架集成JWT&lt;/h3&gt;

&lt;p&gt;在Golang语言中，&lt;a href=&#34;https://github.com/dgrijalva/jwt-go&#34;&gt;jwt-go&lt;/a&gt;库提供了一些jwt编码和验证的工具，因此我们很容易使用该库来实现token认证。&lt;/p&gt;

&lt;p&gt;另外，我们也知道&lt;a href=&#34;https://github.com/gin-gonic/gin&#34;&gt;gin&lt;/a&gt;框架中支持用户自定义middleware，我们可以很好的将jwt相关的逻辑封装在middleware中，然后对具体的接口进行认证。&lt;/p&gt;

&lt;h4 id=&#34;自定义中间件&#34;&gt;自定义中间件&lt;/h4&gt;

&lt;p&gt;在gin框架中，自定义中间件比较容易，只要返回一个&lt;code&gt;gin.HandlerFunc&lt;/code&gt;即完成一个中间件定义。&lt;/p&gt;

&lt;p&gt;接下来，我们先定义一个用于jwt认证的中间件.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 定义一个JWTAuth的中间件
func JWTAuth() gin.HandlerFunc {
	return func(c *gin.Context) {
		// 通过http header中的token解析来认证
		token := c.Request.Header.Get(&amp;#34;token&amp;#34;)
		if token == &amp;#34;&amp;#34; {
			c.JSON(http.StatusOK, gin.H{
				&amp;#34;status&amp;#34;: -1,
				&amp;#34;msg&amp;#34;:    &amp;#34;请求未携带token，无权限访问&amp;#34;,
				&amp;#34;data&amp;#34;:   nil,
			})
			c.Abort()
			return
		}

		log.Print(&amp;#34;get token: &amp;#34;, token)

		// 初始化一个JWT对象实例，并根据结构体方法来解析token
		j := NewJWT()
		// 解析token中包含的相关信息(有效载荷)
		claims, err := j.ParserToken(token)

		if err != nil {
			// token过期
			if err == TokenExpired {
				c.JSON(http.StatusOK, gin.H{
					&amp;#34;status&amp;#34;: -1,
					&amp;#34;msg&amp;#34;:    &amp;#34;token授权已过期，请重新申请授权&amp;#34;,
					&amp;#34;data&amp;#34;:   nil,
				})
				c.Abort()
				return
			}
			// 其他错误
			c.JSON(http.StatusOK, gin.H{
				&amp;#34;status&amp;#34;: -1,
				&amp;#34;msg&amp;#34;:    err.Error(),
				&amp;#34;data&amp;#34;:   nil,
			})
			c.Abort()
			return
		}

		// 将解析后的有效载荷claims重新写入gin.Context引用对象中
		c.Set(&amp;#34;claims&amp;#34;, claims)

	}
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;定义jwt编码和解码逻辑&#34;&gt;定义jwt编码和解码逻辑&lt;/h4&gt;

&lt;p&gt;根据前面提到的jwt-token的组成部分，以及&lt;code&gt;jwt-go&lt;/code&gt;中相关的定义，我们可以使用如下方法进行生成token.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 定义一个jwt对象
type JWT struct {
	// 声明签名信息
	SigningKey []byte
}

// 初始化jwt对象
func NewJWT() *JWT {
	return &amp;amp;JWT{
		[]byte(&amp;#34;bgbiao.top&amp;#34;),
	}
}

// 自定义有效载荷(这里采用自定义的Name和Email作为有效载荷的一部分)
type CustomClaims struct {
	Name  string `json:&amp;#34;name&amp;#34;`
	Email string `json:&amp;#34;email&amp;#34;`
	// StandardClaims结构体实现了Claims接口(Valid()函数)
	jwt.StandardClaims
}


// 调用jwt-go库生成token
// 指定编码的算法为jwt.SigningMethodHS256
func (j *JWT) CreateToken(claims CustomClaims) (string, error) {
	// https://gowalker.org/github.com/dgrijalva/jwt-go#Token
	// 返回一个token的结构体指针
	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString(j.SigningKey)
}


// token解码
func (j *JWT) ParserToken(tokenString string) (*CustomClaims, error) {
	// https://gowalker.org/github.com/dgrijalva/jwt-go#ParseWithClaims
	// 输入用户自定义的Claims结构体对象,token,以及自定义函数来解析token字符串为jwt的Token结构体指针
	// Keyfunc是匿名函数类型: type Keyfunc func(*Token) (interface{}, error)
	// func ParseWithClaims(tokenString string, claims Claims, keyFunc Keyfunc) (*Token, error) {}
	token, err := jwt.ParseWithClaims(tokenString, &amp;amp;CustomClaims{}, func(token *jwt.Token) (interface{}, error) {
		return j.SigningKey, nil
	})

	if err != nil {
		// https://gowalker.org/github.com/dgrijalva/jwt-go#ValidationError
		// jwt.ValidationError 是一个无效token的错误结构
		if ve, ok := err.(*jwt.ValidationError); ok {
			// ValidationErrorMalformed是一个uint常量，表示token不可用
			if ve.Errors&amp;amp;jwt.ValidationErrorMalformed != 0 {
				return nil, fmt.Errorf(&amp;#34;token不可用&amp;#34;)
				// ValidationErrorExpired表示Token过期
			} else if ve.Errors&amp;amp;jwt.ValidationErrorExpired != 0 {
				return nil, fmt.Errorf(&amp;#34;token过期&amp;#34;)
				// ValidationErrorNotValidYet表示无效token
			} else if ve.Errors&amp;amp;jwt.ValidationErrorNotValidYet != 0 {
				return nil, fmt.Errorf(&amp;#34;无效的token&amp;#34;)
			} else {
				return nil, fmt.Errorf(&amp;#34;token不可用&amp;#34;)
			}

		}
	}

	// 将token中的claims信息解析出来并断言成用户自定义的有效载荷结构
	if claims, ok := token.Claims.(*CustomClaims); ok &amp;amp;&amp;amp; token.Valid {
		return claims, nil
	}

	return nil, fmt.Errorf(&amp;#34;token无效&amp;#34;)

}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;定义登陆验证逻辑&#34;&gt;定义登陆验证逻辑&lt;/h4&gt;

&lt;p&gt;接下来的部分就是普通api的具体逻辑了，比如可以在登陆时进行用户校验，成功后未该次认证请求生成token。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 定义登陆逻辑
// model.LoginReq中定义了登陆的请求体(name,passwd)
func Login(c *gin.Context) {
	var loginReq model.LoginReq
	if c.BindJSON(&amp;amp;loginReq) == nil {
		// 登陆逻辑校验(查库，验证用户是否存在以及登陆信息是否正确)
		isPass, user, err := model.LoginCheck(loginReq)
		// 验证通过后为该次请求生成token
		if isPass {
			generateToken(c, user)
		} else {
			c.JSON(http.StatusOK, gin.H{
				&amp;#34;status&amp;#34;: -1,
				&amp;#34;msg&amp;#34;:    &amp;#34;验证失败&amp;#34; + err.Error(),
				&amp;#34;data&amp;#34;:   nil,
			})
		}

	} else {
		c.JSON(http.StatusOK, gin.H{
			&amp;#34;status&amp;#34;: -1,
			&amp;#34;msg&amp;#34;:    &amp;#34;用户数据解析失败&amp;#34;,
			&amp;#34;data&amp;#34;:   nil,
		})
	}
}

// token生成器
// md 为上面定义好的middleware中间件
func generateToken(c *gin.Context, user model.User) {
	// 构造SignKey: 签名和解签名需要使用一个值
	j := md.NewJWT()

	// 构造用户claims信息(负荷)
	claims := md.CustomClaims{
		user.Name,
		user.Email,
		jwtgo.StandardClaims{
			NotBefore: int64(time.Now().Unix() - 1000), // 签名生效时间
			ExpiresAt: int64(time.Now().Unix() + 3600), // 签名过期时间
			Issuer:    &amp;#34;bgbiao.top&amp;#34;,                    // 签名颁发者
		},
	}

	// 根据claims生成token对象
	token, err := j.CreateToken(claims)

	if err != nil {
		c.JSON(http.StatusOK, gin.H{
			&amp;#34;status&amp;#34;: -1,
			&amp;#34;msg&amp;#34;:    err.Error(),
			&amp;#34;data&amp;#34;:   nil,
		})
	}

	log.Println(token)
	// 封装一个响应数据,返回用户名和token
	data := LoginResult{
		Name:  user.Name,
		Token: token,
	}

	c.JSON(http.StatusOK, gin.H{
		&amp;#34;status&amp;#34;: 0,
		&amp;#34;msg&amp;#34;:    &amp;#34;登陆成功&amp;#34;,
		&amp;#34;data&amp;#34;:   data,
	})
	return

}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;定义普通待验证接口&#34;&gt;定义普通待验证接口&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 定义一个普通controller函数，作为一个验证接口逻辑
func GetDataByTime(c *gin.Context) {
	// 上面我们在JWTAuth()中间中将&amp;#39;claims&amp;#39;写入到gin.Context的指针对象中，因此在这里可以将之解析出来
	claims := c.MustGet(&amp;#34;claims&amp;#34;).(*md.CustomClaims)
	if claims != nil {
		c.JSON(http.StatusOK, gin.H{
			&amp;#34;status&amp;#34;: 0,
			&amp;#34;msg&amp;#34;:    &amp;#34;token有效&amp;#34;,
			&amp;#34;data&amp;#34;:   claims,
		})
	}
}


// 在主函数中定义路由规则
	router := gin.Default()
	v1 := router.Group(&amp;#34;/apis/v1/&amp;#34;)
	{
		v1.POST(&amp;#34;/register&amp;#34;, controller.RegisterUser)
		v1.POST(&amp;#34;/login&amp;#34;, controller.Login)
	}

	// secure v1
	sv1 := router.Group(&amp;#34;/apis/v1/auth/&amp;#34;)
	// 加载自定义的JWTAuth()中间件,在整个sv1的路由组中都生效
	sv1.Use(md.JWTAuth())
	{
		sv1.GET(&amp;#34;/time&amp;#34;, controller.GetDataByTime)

	}
	router.Run(&amp;#34;:8081&amp;#34;)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;验证使用jwt后的接口&#34;&gt;验证使用JWT后的接口&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 运行项目
$ go run main.go
127.0.0.1
13306
root:bgbiao.top@tcp(127.0.0.1:13306)/test_api?charset=utf8mb4&amp;amp;parseTime=True&amp;amp;loc=Local
[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &amp;#34;debug&amp;#34; mode. Switch to &amp;#34;release&amp;#34; mode in production.
 - using env:	export GIN_MODE=release
 - using code:	gin.SetMode(gin.ReleaseMode)

[GIN-debug] POST   /apis/v1/register         --&amp;gt; warnning-trigger/controller.RegisterUser (3 handlers)
[GIN-debug] POST   /apis/v1/login            --&amp;gt; warnning-trigger/controller.Login (3 handlers)
[GIN-debug] GET    /apis/v1/auth/time        --&amp;gt; warnning-trigger/controller.GetDataByTime (4 handlers)
[GIN-debug] Listening and serving HTTP on :8081

# 注册用户
$ curl -i -X POST \
   -H &amp;#34;Content-Type:application/json&amp;#34; \
   -d \
&amp;#39;{
  &amp;#34;name&amp;#34;: &amp;#34;hahaha1&amp;#34;,
  &amp;#34;password&amp;#34;: &amp;#34;hahaha1&amp;#34;,
  &amp;#34;email&amp;#34;: &amp;#34;hahaha1@bgbiao.top&amp;#34;,
  &amp;#34;phone&amp;#34;: 10000000000
}&amp;#39; \
 &amp;#39;http://localhost:8081/apis/v1/register&amp;#39;
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Date: Sun, 15 Mar 2020 07:09:28 GMT
Content-Length: 41

{&amp;#34;data&amp;#34;:null,&amp;#34;msg&amp;#34;:&amp;#34;success &amp;#34;,&amp;#34;status&amp;#34;:0}%


# 登陆用户以获取token
$ curl -i -X POST \
   -H &amp;#34;Content-Type:application/json&amp;#34; \
   -d \
&amp;#39;{
  &amp;#34;name&amp;#34;:&amp;#34;hahaha1&amp;#34;,
  &amp;#34;password&amp;#34;:&amp;#34;hahaha1&amp;#34;
}&amp;#39; \
 &amp;#39;http://localhost:8081/apis/v1/login&amp;#39;
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Date: Sun, 15 Mar 2020 07:10:41 GMT
Content-Length: 290

{&amp;#34;data&amp;#34;:{&amp;#34;token&amp;#34;:&amp;#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyTmFtZSI6ImhhaGFoYTEiLCJlbWFpbCI6ImhhaGFoYTFAYmdiaWFvLnRvcCIsImV4cCI6MTU4NDI1OTg0MSwiaXNzIjoiYmdiaWFvLnRvcCIsIm5iZiI6MTU4NDI1NTI0MX0.HNXSKISZTqzjKd705BOSARmgI8FGGe4Sv-Ma3_iK1Xw&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;hahaha1&amp;#34;},&amp;#34;msg&amp;#34;:&amp;#34;登陆成功&amp;#34;,&amp;#34;status&amp;#34;:0}


# 访问需要认证的接口
# 因为我们对/apis/v1/auth/的分组路由中加载了jwt的middleware，因此该分组下的api都需要使用jwt-token认证
$ curl http://localhost:8081/apis/v1/auth/time
{&amp;#34;data&amp;#34;:null,&amp;#34;msg&amp;#34;:&amp;#34;请求未携带token，无权限访问&amp;#34;,&amp;#34;status&amp;#34;:-1}%

# 使用token认证
$ curl http://localhost:8081/apis/v1/auth/time -H &amp;#39;token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyTmFtZSI6ImhhaGFoYTEiLCJlbWFpbCI6ImhhaGFoYTFAYmdiaWFvLnRvcCIsImV4cCI6MTU4NDI1OTg0MSwiaXNzIjoiYmdiaWFvLnRvcCIsIm5iZiI6MTU4NDI1NTI0MX0.HNXSKISZTqzjKd705BOSARmgI8FGGe4Sv-Ma3_iK1Xw&amp;#39;
{&amp;#34;data&amp;#34;:{&amp;#34;userName&amp;#34;:&amp;#34;hahaha1&amp;#34;,&amp;#34;email&amp;#34;:&amp;#34;hahaha1@bgbiao.top&amp;#34;,&amp;#34;exp&amp;#34;:1584259841,&amp;#34;iss&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;nbf&amp;#34;:1584255241},&amp;#34;msg&amp;#34;:&amp;#34;token有效&amp;#34;,&amp;#34;status&amp;#34;:0}%&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/BGBiao/gin-jwt-token&#34;&gt;gin-jwt-go源码&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Golang语言中的ORM框架之gorm</title>
      <link>https://bgbiao.top/post/golang-gorm%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang-gorm%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;前言:&lt;a href=&#34;https://github.com/jinzhu/gorm&#34;&gt;gorm&lt;/a&gt;是Golang语言中一款性能极好的ORM库，对开发人员相对是比较友好的。当然还有另外一个&lt;a href=&#34;https://github.com/go-xorm/xorm&#34;&gt;xorm&lt;/a&gt;库也是比较出名的，感兴趣的也可以看看这个库，接下来主要介绍下&lt;code&gt;gorm&lt;/code&gt;库的一些基本使用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;gorm介绍和快速入门&#34;&gt;GORM介绍和快速入门&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;功能概览&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;全功能ORM(无限接近)&lt;/li&gt;
&lt;li&gt;关联(Has One, Has Many, Belongs To, Many To Many, 多态)&lt;/li&gt;
&lt;li&gt;钩子函数Hook(在创建/保存/更新/删除/查找之前或之后)&lt;/li&gt;
&lt;li&gt;预加载&lt;/li&gt;
&lt;li&gt;事务&lt;/li&gt;
&lt;li&gt;复合主键&lt;/li&gt;
&lt;li&gt;SQL 生成器&lt;/li&gt;
&lt;li&gt;数据库自动迁移&lt;/li&gt;
&lt;li&gt;自定义日志&lt;/li&gt;
&lt;li&gt;可扩展性, 可基于 GORM 回调编写插件&lt;/li&gt;
&lt;li&gt;所有功能都被测试覆盖&lt;/li&gt;
&lt;li&gt;开发者友好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们都知道，在golang中需要使用一些驱动包来对指定数据库进行操作，比如MySQL需要使用&lt;code&gt;github.com/go-sql-driver/mysql&lt;/code&gt;库，而Sqlite需要使用&lt;code&gt;github.com/mattn/go-sqlite3&lt;/code&gt;库来支持，不过好在gorm框架中对各个驱动包进行了简单包装，可以让我们在写程序时可以更方便的管理驱动库.&lt;/p&gt;

&lt;p&gt;支持的数据库以及导入路径如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mysql: github.com/jinzhu/gorm/dialects/mysql&lt;/li&gt;
&lt;li&gt;postgres: github.com/jinzhu/gorm/dialects/postgres&lt;/li&gt;
&lt;li&gt;sqlite: github.com/jinzhu/gorm/dialects/sqlite&lt;/li&gt;
&lt;li&gt;sqlserver: github.com/jinzhu/gorm/dialects/mssql&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;gorm框架只是简单封装了数据库的驱动包，在安装时仍需要下载原始的驱动包&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 由于在项目中使用mysql比较多，这里使用mysql进行数据存储
$ go get -u github.com/jinzhu/gorm
$ go get -u github.com/go-sql-driver/mysql&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;快速入门&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;使用docker快速创建一个本地可连接的mysql实例&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;itd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;MYSQL_ROOT_PASSWORD&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;orm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;13306&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3306&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;5.6&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;登陆mysql并创建一个测试库&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;it&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;orm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;uroot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pbgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;database&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test_api&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Query&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;OK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;row&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;affected&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.00&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;show&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;databases&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;+--------------------+&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Database&lt;/span&gt;           &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;+--------------------+&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;information_schema&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;              &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;performance_schema&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test_api&lt;/span&gt;           &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;+--------------------+&lt;/span&gt;
&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;rows&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;set&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.00&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;sec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;运行一个简单示例&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;gorm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;s&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;

    &lt;span class=&#34;s&#34;&gt;&amp;#34;github.com/jinzhu/gorm&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;github.com/jinzhu/gorm/dialects/mysql&amp;#34;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;


&lt;span class=&#34;c1&#34;&gt;// 定义一个数据模型(user表)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 列名是字段名的蛇形小写(PassWd-&amp;gt;pass_word)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;Id&lt;/span&gt;          &lt;span class=&#34;kt&#34;&gt;uint&lt;/span&gt;        &lt;span class=&#34;s&#34;&gt;`gorm:&amp;#34;AUTO_INCREMENT&amp;#34;`&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;        &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;      &lt;span class=&#34;s&#34;&gt;`gorm:&amp;#34;size:50&amp;#34;`&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;Age&lt;/span&gt;         &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;         &lt;span class=&#34;s&#34;&gt;`gorm:&amp;#34;size:3&amp;#34;`&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;Birthday&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Time&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;Email&lt;/span&gt;       &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;      &lt;span class=&#34;s&#34;&gt;`gorm:&amp;#34;type:varchar(50);unique_index&amp;#34;`&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;PassWord&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;      &lt;span class=&#34;s&#34;&gt;`gorm:&amp;#34;type:varchar(25)&amp;#34;`&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;gorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;DB&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;gorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;mysql&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;root:bgbiao.top@(127.0.0.1:13306)/test_api?charset=utf8&amp;amp;parseTime=True&amp;amp;loc=Local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Errorf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;创建数据库连接失败:%v&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;defer&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 自动迁移数据结构(table schema)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// 注意:在gorm中，默认的表名都是结构体名称的复数形式，比如User结构体默认创建的表为users
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;c1&#34;&gt;// db.SingularTable(true) 可以取消表名的复数形式，使得表名和结构体名称一致
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;AutoMigrate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{})&lt;/span&gt;


    &lt;span class=&#34;c1&#34;&gt;// 添加唯一索引
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}).&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;AddUniqueIndex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name_email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 插入记录
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bgbiao&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Email&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bgbiao@bgbiao.top&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;xxb&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Email&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;xxb@bgbiao.top&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;

    &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;users&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;// 查看插入后的全部元素
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;插入后元素:\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;users&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;users&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 查询一条记录
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;First&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name = ?&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bgbiao&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;查看查询记录:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 更新记录(基于查出来的数据进行更新)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Update&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;biaoge&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;更新后的记录:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 删除记录
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Delete&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;c1&#34;&gt;// 查看全部记录
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;查看全部记录:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;db&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;users&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;users&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;运行gorm实例&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;gorm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;example&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;插入后元素&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;xxb&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;xxb&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}]&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;查看查询记录&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;更新后的记录&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;biaoge&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;查看全部记录&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;xxb&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;xxb&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bgbiao&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}]&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;gorm常用的功能函数&#34;&gt;GORM常用的功能函数&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;自动迁移&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 使用自动迁移模式将保持表的更新，但是不会更新索引以及现有列的类型或删除未使用的列&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 同时迁移多个模型
db.AutoMigrate(&amp;amp;User{}, &amp;amp;Product{}, &amp;amp;Order{})

// 创建表时增加相关参数
// 比如修改表的字符类型CHARSET=utf8
db.Set(&amp;#34;gorm:table_options&amp;#34;, &amp;#34;ENGINE=InnoDB&amp;#34;).AutoMigrate(&amp;amp;User{})&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;检查表&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 检查模型是否存在
db.HasTable(&amp;amp;User{})

// 检查表是否存在
db.HasTable(&amp;#34;users&amp;#34;)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;增、删、改表结构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;在实际企业的生产环境中，通常数据库级别的变更操作，都需要转换成sql交由DBA兄弟帮忙进行线上库表变更，因此不论使用自动迁移，还是手动创建表，都是在开发环境阶段的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 使用模型创建
db.CreateTable(&amp;amp;User{})

// 增加参数创建
db.Set(&amp;#34;gorm:table_options&amp;#34;, &amp;#34;ENGINE=InnoDB&amp;#34;).CreateTable(&amp;amp;User{}) 

// 删除表
db.DropTable(&amp;amp;User{})
db.DropTable(&amp;#34;users&amp;#34;)

// 模型和表名的混搭
db.DropTableIfExists(&amp;amp;User{}, &amp;#34;products&amp;#34;)


// 修改列(修改字段类型)
db.Model(&amp;amp;User{}).ModifyColumn(&amp;#34;description&amp;#34;, &amp;#34;text&amp;#34;)

// 删除列
db.Model(&amp;amp;User{}).DropColumn(&amp;#34;description&amp;#34;)

// 指定表名创建表
db.Table(&amp;#34;deleted_users&amp;#34;).CreateTable(&amp;amp;User{})

// 指定表名查询
var deleted_users []User
db.Table(&amp;#34;deleted_users&amp;#34;).Find(&amp;amp;deleted_users)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;索引和约束&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 添加外键
// 1st param : 外键字段
// 2nd param : 外键表(字段)
// 3rd param : ONDELETE
// 4th param : ONUPDATE
db.Model(&amp;amp;User{}).AddForeignKey(&amp;#34;city_id&amp;#34;, &amp;#34;cities(id)&amp;#34;, &amp;#34;RESTRICT&amp;#34;, &amp;#34;RESTRICT&amp;#34;)

// 单个索引
db.Model(&amp;amp;User{}).AddIndex(&amp;#34;idx_user_name&amp;#34;, &amp;#34;name&amp;#34;)

// 多字段索引
db.Model(&amp;amp;User{}).AddIndex(&amp;#34;idx_user_name_age&amp;#34;, &amp;#34;name&amp;#34;, &amp;#34;age&amp;#34;)

// 添加唯一索引(通常使用多个字段来唯一标识一条记录)
db.Model(&amp;amp;User{}).AddUniqueIndex(&amp;#34;idx_user_name&amp;#34;, &amp;#34;name&amp;#34;)
db.Model(&amp;amp;User{}).AddUniqueIndex(&amp;#34;idx_user_name_age&amp;#34;, &amp;#34;name&amp;#34;, &amp;#34;id&amp;#34;,&amp;#34;email&amp;#34;)


// 删除索引
db.Model(&amp;amp;User{}).RemoveIndex(&amp;#34;idx_user_name&amp;#34;)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;gorm模型注意事项&#34;&gt;GORM模型注意事项&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;gorm.Model结构体&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其实在&lt;code&gt;gorm&lt;/code&gt;官方文档的示例中，会默认在模型的属性中增加一个&lt;a href=&#34;https://pkg.go.dev/github.com/jinzhu/gorm?tab=doc#Model&#34;&gt;gorm.Model&lt;/a&gt;的属性，该属性的原始结构如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 官方示例模型
type User struct {
  gorm.Model
  Name         string
	.....
}

// gorm.Model结构体
type Model struct {
	ID        uint `gorm:&amp;#34;primary_key&amp;#34;`
	CreatedAt time.Time
	UpdatedAt time.Time
	DeletedAt *time.Time `sql:&amp;#34;index&amp;#34;`
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;很明显，当我们在用户自定义的模型中增加&lt;code&gt;gorm.Model&lt;/code&gt;时，会自动为我们的表增加&lt;code&gt;id,created_at,updated_at,deleted_at&lt;/code&gt;四个字段。&lt;/p&gt;

&lt;p&gt;同时需要注意的是，当我们的模型中有&lt;code&gt;CreatedAt&lt;/code&gt;,&lt;code&gt;UpdatedAt&lt;/code&gt;,&lt;code&gt;DeletedAt&lt;/code&gt;属性并且类型为&lt;code&gt;time.Time&lt;/code&gt;或者&lt;code&gt;*time.Time&lt;/code&gt;类型时，当有数据操作时，会自动更新对应的时间。&lt;/p&gt;

&lt;p&gt;所以，在定义模型时，可以根据实际的需求来决定是否引入&lt;code&gt;gorm.Model&lt;/code&gt;结构&lt;/p&gt;

&lt;p&gt;另外需要注意的是: 所有字段的零值, 比如&lt;code&gt;0, &#39;&#39;, false 或者其它零值&lt;/code&gt;都不会保存到数据库内，但会使用他们的默认值，因此一些非必须字段，可以使用&lt;code&gt;DEFAULT&lt;/code&gt;的tag字段来声明列的默认值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;gorm模型支持的tags&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;gorm支持一些常见的tags来自定义模型字段的扩展信息&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;结构体标记&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;column&lt;/td&gt;
&lt;td&gt;列明(默认是字段的蛇形小写)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;type&lt;/td&gt;
&lt;td&gt;数据类型&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;size&lt;/td&gt;
&lt;td&gt;列长度&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PRIMARY_KEY&lt;/td&gt;
&lt;td&gt;声明主键&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;UNIQUE&lt;/td&gt;
&lt;td&gt;声明唯一&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DEFAULT&lt;/td&gt;
&lt;td&gt;指定默认值&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PRECISION&lt;/td&gt;
&lt;td&gt;声明列精度&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;NOT NULL&lt;/td&gt;
&lt;td&gt;将列指定为非 NULL&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AUTO_INCREMENT&lt;/td&gt;
&lt;td&gt;声明自增列&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;INDEX&lt;/td&gt;
&lt;td&gt;创建具有或不带名称的索引, 如果多个索引同名则创建复合索引&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;UNIQUE_INDEX&lt;/td&gt;
&lt;td&gt;创建唯一索引&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;EMBEDDED&lt;/td&gt;
&lt;td&gt;将结构设置为嵌入&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;EMBEDDED_PREFIX&lt;/td&gt;
&lt;td&gt;设置嵌入结构的前缀&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;忽略此字段&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; gorm也支持一些关联的结构体标签，比如外键，关联外键，等操作，通常在复杂的企业环境中，建议在库表设计时将相关表都设计成孤立表，具体的关联逻辑由业务层去实现(可能增加了开发的成本，不过当业务发展比较复杂时，这样做无疑是方便后期做扩展和优化的)&lt;/p&gt;

&lt;h3 id=&#34;详细的crud接口&#34;&gt;详细的CRUD接口&lt;/h3&gt;

&lt;h4 id=&#34;创建&#34;&gt;创建&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;插入记录&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 相当于insert into users(name,age,brithday) values(&amp;#34;BGBiao&amp;#34;,18,time.Now())
user := User{Name: &amp;#34;BGBiao&amp;#34;, Age: 18, Birthday: time.Now()}
// 主键为空返回`true`
db.NewRecord(user)
db.Create(&amp;amp;user)
// 创建`user`后返回`false`
db.NewRecord(user) &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;在Hooks中设置字段值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 通常我们在设计模型时，有一些原始字段，希望在初始化模型后就拥有记录，此时可以使用hooks来插入初始记录&lt;/p&gt;

&lt;p&gt;如果想再&lt;code&gt;BeforeCreate&lt;/code&gt;hook中修改字段的值，可以使用&lt;code&gt;scope.SetColumn&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;func (user *User) BeforeCreate(scope *gorm.Scope) error {
  scope.SetColumn(&amp;#34;ID&amp;#34;, uuid.New())
  return nil
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;创建扩展选项&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 为Instert语句添加扩展SQL选项
// insert into produce(name,code) values(&amp;#34;name&amp;#34;,&amp;#34;code&amp;#34;) on conflict;
db.Set(&amp;#34;gorm:insert_option&amp;#34;, &amp;#34;ON CONFLICT&amp;#34;).Create(&amp;amp;product)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;查询&#34;&gt;查询&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;基本查询&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 根据主键查询第一条记录
// SELECT * FROM users ORDER BY id LIMIT 1;
db.First(&amp;amp;user)


// 随机获取一条记录
// SELECT * FROM users LIMIT 1;
db.Take(&amp;amp;user)


// 根据主键查询最后一条记录
// SELECT * FROM users ORDER BY id DESC LIMIT 1;
db.Last(&amp;amp;user)


// 查询所有的记录
// SELECT * FROM users;
db.Find(&amp;amp;users)


// 查询指定的某条记录(仅当主键为整型时可用)
// SELECT * FROM users WHERE id = 10;
db.First(&amp;amp;user, 10)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;结构体方式查询&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 结构体方式
// select * from users where name = &amp;#39;bgbiao.top&amp;#39;
db.Where(&amp;amp;User{Name: &amp;#34;bgbiao.top&amp;#34;, Age: 20}).First(&amp;amp;user)

// Map方式
// select * from users where name = &amp;#39;bgbiao.top&amp;#39; and age = 20;
db.Where(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;bgbiao.top&amp;#34;, &amp;#34;age&amp;#34;: 20}).Find(&amp;amp;users)

// 主键的切片
// select * from users where id in (20,21,22);
db.Where([]int64{20, 21, 22}).Find(&amp;amp;users)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Where条件查询&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 使用了Where()方法，基本上就是基本的sql语法&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 使用条件获取一条记录 First()方法
db.Where(&amp;#34;name = ?&amp;#34;, &amp;#34;bgbiao.top&amp;#34;).First(&amp;amp;user)

// 获取全部记录 Find()方法
db.Where(&amp;#34;name = ?&amp;#34;, &amp;#34;jinzhu&amp;#34;).Find(&amp;amp;users)

// 不等于
db.Where(&amp;#34;name &amp;lt;&amp;gt; ?&amp;#34;, &amp;#34;jinzhu&amp;#34;).Find(&amp;amp;users)

// IN
db.Where(&amp;#34;name IN (?)&amp;#34;, []string{&amp;#34;jinzhu&amp;#34;, &amp;#34;bgbiao.top&amp;#34;}).Find(&amp;amp;users)

// LIKE
db.Where(&amp;#34;name LIKE ?&amp;#34;, &amp;#34;%jin%&amp;#34;).Find(&amp;amp;users)

// AND
db.Where(&amp;#34;name = ? AND age &amp;gt;= ?&amp;#34;, &amp;#34;jinzhu&amp;#34;, &amp;#34;22&amp;#34;).Find(&amp;amp;users)

// Time
// select * from users where updated_at &amp;gt; &amp;#39;2020-03-06 00:00:00&amp;#39;
db.Where(&amp;#34;updated_at &amp;gt; ?&amp;#34;, lastWeek).Find(&amp;amp;users)

// BETWEEN
// select * from users where created_at between &amp;#39;2020-03-06 00:00:00&amp;#39; and &amp;#39;2020-03-14 00:00:00&amp;#39;
db.Where(&amp;#34;created_at BETWEEN ? AND ?&amp;#34;, lastWeek, today).Find(&amp;amp;users)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Not条件&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// select * from users where name != &amp;#39;bgbiao.top&amp;#39;;
db.Not(&amp;#34;name&amp;#34;, &amp;#34;jinzhu&amp;#34;).First(&amp;amp;user)

// Not In
// select * from users where name not in (&amp;#34;jinzhu&amp;#34;,&amp;#34;bgbiao.top&amp;#34;);
db.Not(&amp;#34;name&amp;#34;, []string{&amp;#34;jinzhu&amp;#34;, &amp;#34;bgbiao.top&amp;#34;}).Find(&amp;amp;users)

// 主键不在slice中的查询
// select * from users where id not in (1,2,3)
db.Not([]int64{1,2,3}).First(&amp;amp;user)

// select * from users;
db.Not([]int64{}).First(&amp;amp;user)

// 原生SQL
// select * from users where not(name = &amp;#39;bgbiao.top&amp;#39;);
db.Not(&amp;#34;name = ?&amp;#34;, &amp;#34;bgbiao.top&amp;#34;).First(&amp;amp;user)

// struct方式查询
// select * from users where name != &amp;#39;bgbiao.top&amp;#39;
db.Not(User{Name: &amp;#34;bgbiao.top&amp;#34;}).First(&amp;amp;user)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Or条件&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT * FROM users WHERE role = &amp;#39;admin&amp;#39; OR role = &amp;#39;super_admin&amp;#39;;
db.Where(&amp;#34;role = ?&amp;#34;, &amp;#34;admin&amp;#34;).Or(&amp;#34;role = ?&amp;#34;, &amp;#34;super_admin&amp;#34;).Find(&amp;amp;users)

// Struct 方式
// SELECT * FROM users WHERE name = &amp;#39;jinzhu&amp;#39; OR name = &amp;#39;bgbiao.top&amp;#39;;
db.Where(&amp;#34;name = &amp;#39;jinzhu&amp;#39;&amp;#34;).Or(User{Name: &amp;#34;bgbiao.top&amp;#34;}).Find(&amp;amp;users)

// Map 方式
// SELECT * FROM users WHERE name = &amp;#39;jinzhu&amp;#39; OR name = &amp;#39;bgbiao.top&amp;#39;;
db.Where(&amp;#34;name = &amp;#39;jinzhu&amp;#39;&amp;#34;).Or(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;bgbiao.top&amp;#34;}).Find(&amp;amp;users)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;FirstOrCreate&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获取匹配的第一条记录, 否则根据给定的条件创建一个新的记录(仅支持 struct 和 map 条件)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 未找到,就插入记录
if select * from users where name = &amp;#39;non_existing&amp;#39;) is null; insert into users(name) values(&amp;#34;non_existing&amp;#34;)
db.FirstOrCreate(&amp;amp;user, User{Name: &amp;#34;non_existing&amp;#34;})

// 找到
// select * from users where name = &amp;#39;bgbiao.top&amp;#39; 
db.Where(User{Name: &amp;#34;bgbiao.top&amp;#34;}).FirstOrCreate(&amp;amp;user)

## attrs参数:如果记录未找到，将使用参数创建 struct 和记录.
// 未找到(将条件前置，并将拆入数据填充到Attrs方法中)
db.Where(User{Name: &amp;#34;non_existing&amp;#34;}).Attrs(User{Age: 20}).FirstOrCreate(&amp;amp;user)

// 找到
db.Where(User{Name: &amp;#34;bgbiao.top&amp;#34;}).Attrs(User{Age: 30}).FirstOrCreate(&amp;amp;user)

## assgin参数: 不管记录是否找到，都将参数赋值给 struct 并保存至数据库
db.Where(User{Name: &amp;#34;non_existing&amp;#34;}).Assign(User{Age: 20}).FirstOrCreate(&amp;amp;user)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;子查询&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;*gorm.expr&lt;/code&gt; 子查询&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT * FROM &amp;#34;orders&amp;#34;  WHERE &amp;#34;orders&amp;#34;.&amp;#34;deleted_at&amp;#34; IS NULL AND (amount &amp;gt; (SELECT AVG(amount) FROM &amp;#34;orders&amp;#34;  WHERE (state = &amp;#39;paid&amp;#39;)));
db.Where(&amp;#34;amount &amp;gt; ?&amp;#34;, DB.Table(&amp;#34;orders&amp;#34;).Select(&amp;#34;AVG(amount)&amp;#34;).Where(&amp;#34;state = ?&amp;#34;, &amp;#34;paid&amp;#34;).QueryExpr()).Find(&amp;amp;orders)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;字段查询&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通常情况下，我们只想选择几个字段进行查询，指定你想从数据库中检索出的字段，默认会选择全部字段。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT name, age FROM users;
db.Select(&amp;#34;name, age&amp;#34;).Find(&amp;amp;users)

// SELECT name, age FROM users;
db.Select([]string{&amp;#34;name&amp;#34;, &amp;#34;age&amp;#34;}).Find(&amp;amp;users)

// SELECT COALESCE(age,&amp;#39;42&amp;#39;) FROM users; 
db.Table(&amp;#34;users&amp;#34;).Select(&amp;#34;COALESCE(age,?)&amp;#34;, 42).Rows()&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;排序(Order)&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT * FROM users ORDER BY age desc, name;
db.Order(&amp;#34;age desc, name&amp;#34;).Find(&amp;amp;users)

// 多字段排序
// SELECT * FROM users ORDER BY age desc, name;
db.Order(&amp;#34;age desc&amp;#34;).Order(&amp;#34;name&amp;#34;).Find(&amp;amp;users)

// 覆盖排序
// 
db.Order(&amp;#34;age desc&amp;#34;).Find(&amp;amp;users1).Order(&amp;#34;age&amp;#34;, true).Find(&amp;amp;users2)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;限制输出&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT * FROM users LIMIT 3;
db.Limit(3).Find(&amp;amp;users)

// -1 取消 Limit 条件
// SELECT * FROM users LIMIT 10;
// SELECT * FROM users;
db.Limit(10).Find(&amp;amp;users1).Limit(-1).Find(&amp;amp;users2)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;统计count&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// SELECT count(*) from USERS WHERE name = &amp;#39;jinzhu&amp;#39; OR name = &amp;#39;bgbiao.top&amp;#39;;
db.Where(&amp;#34;name = ?&amp;#34;, &amp;#34;jinzhu&amp;#34;).Or(&amp;#34;name = ?&amp;#34;, &amp;#34;bgbiao.top&amp;#34;).Find(&amp;amp;users).Count(&amp;amp;count)

// select count(*) from users where name = &amp;#39;bgbiao.top&amp;#39;
db.Model(&amp;amp;User{}).Where(&amp;#34;name = ?&amp;#34;, &amp;#34;bgbiao.top&amp;#34;).Count(&amp;amp;count)

// SELECT count(*) FROM deleted_users;
db.Table(&amp;#34;deleted_users&amp;#34;).Count(&amp;amp;count)

// SELECT count( distinct(name) ) FROM deleted_users;
db.Table(&amp;#34;deleted_users&amp;#34;).Select(&amp;#34;count(distinct(name))&amp;#34;).Count(&amp;amp;count)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;分组(grouo&amp;amp;having)&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;rows, err := db.Table(&amp;#34;orders&amp;#34;).Select(&amp;#34;date(created_at) as date, sum(amount) as total&amp;#34;).Group(&amp;#34;date(created_at)&amp;#34;).Rows()
for rows.Next() {
  ...
}

rows, err := db.Table(&amp;#34;orders&amp;#34;).Select(&amp;#34;date(created_at) as date, sum(amount) as total&amp;#34;).Group(&amp;#34;date(created_at)&amp;#34;).Having(&amp;#34;sum(amount) &amp;gt; ?&amp;#34;, 100).Rows()
for rows.Next() {
  ...
}

type Result struct {
  Date  time.Time
  Total int64
}
db.Table(&amp;#34;orders&amp;#34;).Select(&amp;#34;date(created_at) as date, sum(amount) as total&amp;#34;).Group(&amp;#34;date(created_at)&amp;#34;).Having(&amp;#34;sum(amount) &amp;gt; ?&amp;#34;, 100).Scan(&amp;amp;results)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;连接查询&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;rows, err := db.Table(&amp;#34;users&amp;#34;).Select(&amp;#34;users.name, emails.email&amp;#34;).Joins(&amp;#34;left join emails on emails.user_id = users.id&amp;#34;).Rows()
for rows.Next() {
  ...
}

db.Table(&amp;#34;users&amp;#34;).Select(&amp;#34;users.name, emails.email&amp;#34;).Joins(&amp;#34;left join emails on emails.user_id = users.id&amp;#34;).Scan(&amp;amp;results)

// 多连接及参数
db.Joins(&amp;#34;JOIN emails ON emails.user_id = users.id AND emails.email = ?&amp;#34;, &amp;#34;jinzhu@example.org&amp;#34;).Joins(&amp;#34;JOIN credit_cards ON credit_cards.user_id = users.id&amp;#34;).Where(&amp;#34;credit_cards.number = ?&amp;#34;, &amp;#34;411111111111&amp;#34;).Find(&amp;amp;user)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;pluck查询&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Pluck，查询 model 中的一个列作为&lt;code&gt;切片&lt;/code&gt;，如果您想要查询多个列，您应该使用&lt;code&gt;Scan&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;var ages []int64
db.Find(&amp;amp;users).Pluck(&amp;#34;age&amp;#34;, &amp;amp;ages)

var names []string
db.Model(&amp;amp;User{}).Pluck(&amp;#34;name&amp;#34;, &amp;amp;names)

db.Table(&amp;#34;deleted_users&amp;#34;).Pluck(&amp;#34;name&amp;#34;, &amp;amp;names)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;scan扫描&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;type Result struct {
  Name string
  Age  int
}

var result Result
db.Table(&amp;#34;users&amp;#34;).Select(&amp;#34;name, age&amp;#34;).Where(&amp;#34;name = ?&amp;#34;, &amp;#34;Antonio&amp;#34;).Scan(&amp;amp;result)

// 原生 SQL
db.Raw(&amp;#34;SELECT name, age FROM users WHERE name = ?&amp;#34;, &amp;#34;Antonio&amp;#34;).Scan(&amp;amp;result)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;更新&#34;&gt;更新&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;更新所有字段&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;save会更新所有字段，及时没有赋值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;db.First(&amp;amp;user)

user.Name = &amp;#34;bgbiao.top&amp;#34;
user.Age = 100
// update users set name = &amp;#39;bgbiao.top&amp;#39;,age=100 where id = user.id
db.Save(&amp;amp;user)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;更新修改字段&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;Update&lt;/code&gt;和&lt;code&gt;Updates&lt;/code&gt;方法&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 更新单个属性，如果它有变化
// update users set name = &amp;#39;hello&amp;#39; where id = user.id
db.Model(&amp;amp;user).Update(&amp;#34;name&amp;#34;, &amp;#34;hello&amp;#34;)

// 根据给定的条件更新单个属性
// update users set name = &amp;#39;hello&amp;#39; where active = true
db.Model(&amp;amp;user).Where(&amp;#34;active = ?&amp;#34;, true).Update(&amp;#34;name&amp;#34;, &amp;#34;hello&amp;#34;)

// 使用 map 更新多个属性，只会更新其中有变化的属性
// update users set name = &amp;#39;hello&amp;#39;,age=18,actived=false where id = user.id
db.Model(&amp;amp;user).Updates(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;hello&amp;#34;, &amp;#34;age&amp;#34;: 18, &amp;#34;actived&amp;#34;: false})

// 使用 struct 更新多个属性，只会更新其中有变化且为非零值的字段
db.Model(&amp;amp;user).Updates(User{Name: &amp;#34;hello&amp;#34;, Age: 18})

// 警告：当使用 struct 更新时，GORM只会更新那些非零值的字段
// 对于下面的操作，不会发生任何更新，&amp;#34;&amp;#34;, 0, false 都是其类型的零值
db.Model(&amp;amp;user).Updates(User{Name: &amp;#34;&amp;#34;, Age: 0, Actived: false})&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;更新选定字段&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果想要更新或者忽略某些字段，可以先使用&lt;code&gt;Select&lt;/code&gt;或&lt;code&gt;Omit&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// update users set name = &amp;#39;hello&amp;#39; where id = user.id;
db.Model(&amp;amp;user).Select(&amp;#34;name&amp;#34;).Updates(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;hello&amp;#34;, &amp;#34;age&amp;#34;: 18, &amp;#34;actived&amp;#34;: false})

// Omit()方法用来忽略字段
// update users set age=18,actived=false where id = user.id
db.Model(&amp;amp;user).Omit(&amp;#34;name&amp;#34;).Updates(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;hello&amp;#34;, &amp;#34;age&amp;#34;: 18, &amp;#34;actived&amp;#34;: false})&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;无hook更新&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面的更新操作会会自动运行 model 的&lt;code&gt;BeforeUpdate&lt;/code&gt;,&lt;code&gt;AfterUpdate&lt;/code&gt;方法，来更新一些类似&lt;code&gt;UpdatedAt&lt;/code&gt;的字段在更新时保存其 &lt;code&gt;Associations&lt;/code&gt;, 如果你不想调用这些方法，你可以使用&lt;code&gt;UpdateColumn&lt;/code&gt;,&lt;code&gt;UpdateColumns&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 更新单个属性，类似于 `Update`
// update users set name = &amp;#39;hello&amp;#39; where id = user.id;
db.Model(&amp;amp;user).UpdateColumn(&amp;#34;name&amp;#34;, &amp;#34;hello&amp;#34;)

// 更新多个属性，类似于 `Updates`
// update users set name = &amp;#39;hello&amp;#39;,age=18 where id = user.id;
db.Model(&amp;amp;user).UpdateColumns(User{Name: &amp;#34;hello&amp;#34;, Age: 18})&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;批量更新&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 使用struct实例更新时，只会更新非零值字段，弱项更新全部字段，建议使用map&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// update users set name = &amp;#39;hello&amp;#39;,age=18 where id in (10,11)
db.Table(&amp;#34;users&amp;#34;).Where(&amp;#34;id IN (?)&amp;#34;, []int{10, 11}).Updates(map[string]interface{}{&amp;#34;name&amp;#34;: &amp;#34;hello&amp;#34;, &amp;#34;age&amp;#34;: 18})

// 使用 struct 更新时，只会更新非零值字段，若想更新所有字段，请使用map[string]interface{}
db.Model(User{}).Updates(User{Name: &amp;#34;hello&amp;#34;, Age: 18})

// 使用 `RowsAffected` 获取更新记录总数
db.Model(User{}).Updates(User{Name: &amp;#34;hello&amp;#34;, Age: 18}).RowsAffected&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;使用SQL计算表达式&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// update products set price = price*2+100 where id = product.id
DB.Model(&amp;amp;product).Update(&amp;#34;price&amp;#34;, gorm.Expr(&amp;#34;price * ? + ?&amp;#34;, 2, 100))

// update products set price = price*2+100 where id = product.id;
DB.Model(&amp;amp;product).Updates(map[string]interface{}{&amp;#34;price&amp;#34;: gorm.Expr(&amp;#34;price * ? + ?&amp;#34;, 2, 100)})

// update products set quantity = quantity-1 where id = product.id;
DB.Model(&amp;amp;product).UpdateColumn(&amp;#34;quantity&amp;#34;, gorm.Expr(&amp;#34;quantity - ?&amp;#34;, 1))

// update products set quantity = quantity -1 where id = product.id and quantity &amp;gt; 1
DB.Model(&amp;amp;product).Where(&amp;#34;quantity &amp;gt; 1&amp;#34;).UpdateColumn(&amp;#34;quantity&amp;#34;, gorm.Expr(&amp;#34;quantity - ?&amp;#34;, 1))&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;删除&#34;&gt;删除&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;删除记录&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 删除记录时，请确保主键字段有值，GORM 会通过主键去删除记录，如果主键为空，GORM 会删除该 model 的所有记录。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 删除现有记录
// delete from emails where id = email.id;
db.Delete(&amp;amp;email)

// 为删除 SQL 添加额外的 SQL 操作
// delete from emails where id = email.id OPTION (OPTIMIZE FOR UNKNOWN)
db.Set(&amp;#34;gorm:delete_option&amp;#34;, &amp;#34;OPTION (OPTIMIZE FOR UNKNOWN)&amp;#34;).Delete(&amp;amp;email)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;批量删除&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// delete from emails where email like &amp;#39;%jinzhu%&amp;#39;
db.Where(&amp;#34;email LIKE ?&amp;#34;, &amp;#34;%jinzhu%&amp;#34;).Delete(Email{})

// 同上
db.Delete(Email{}, &amp;#34;email LIKE ?&amp;#34;, &amp;#34;%jinzhu%&amp;#34;)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;软删除&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果一个model有&lt;code&gt;DeletedAt&lt;/code&gt;字段，他将自动获得软删除的功能！&lt;/p&gt;

&lt;p&gt;当调用&lt;code&gt;Delete&lt;/code&gt;方法时， 记录不会真正的从数据库中被删除，只会将&lt;code&gt;DeletedAt&lt;/code&gt;字段的值会被设置为当前时间。&lt;/p&gt;

&lt;p&gt;在之前，我们可能会使用&lt;code&gt;isDelete&lt;/code&gt;之类的字段来标记记录删除，不过在gorm中内置了&lt;code&gt;DeletedAt&lt;/code&gt;字段，并且有相关hook来保证软删除。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// UPDATE users SET deleted_at=&amp;#34;2020-03-13 10:23&amp;#34; WHERE id = user.id;
db.Delete(&amp;amp;user)

// 批量删除
// 软删除的批量删除其实就是把deleted_at改成当前时间,并且在查询时无法查到,所以底层用的是update的sql
db.Where(&amp;#34;age = ?&amp;#34;, 20).Delete(&amp;amp;User{})

// 查询记录时会忽略被软删除的记录
// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL;
db.Where(&amp;#34;age = 20&amp;#34;).Find(&amp;amp;user)

// Unscoped 方法可以查询被软删除的记录
// SELECT * FROM users WHERE age = 20;
db.Unscoped().Where(&amp;#34;age = 20&amp;#34;).Find(&amp;amp;users)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;物理删除&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 使用&lt;code&gt;Unscoped().Delete()&lt;/code&gt;方法才是真正执行sql中的&lt;code&gt;delete&lt;/code&gt;语句.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// Unscoped 方法可以物理删除记录
// DELETE FROM orders WHERE id=10;
db.Unscoped().Delete(&amp;amp;order)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>过去这一个月的所思所想</title>
      <link>https://bgbiao.top/post/%E7%96%AB%E6%83%85%E5%9C%A8%E5%AE%B6%E8%BF%99%E4%B8%AA%E6%9C%88/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E7%96%AB%E6%83%85%E5%9C%A8%E5%AE%B6%E8%BF%99%E4%B8%AA%E6%9C%88/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gceh0gxrolj313y0u07wl.jpg&#34; alt=&#34;可乐葱三结义&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这一个月以来，受疫情的影响，一直在家办公，可能对外人而言，觉得在家办公会相对比较轻松，能够除工作外做更多的事情，但这一个月下来，我却有颇多的不爽和不适，也因此把公众号的更新耽误了许久。本来计划3月2号全员复工的我们，在2月的尾巴突然通知延迟到3月16号上班，这让我顿时有了紧迫感，2020年的规划和计划得赶紧抓紧执行了，公号也得更起来。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;先说说在家办公吧。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在春节期间，由于疫情的爆发，国家将法定的春节延长至2月2日(正月初九)，所以我们正式的远程办公是在2月3日开始执行的，截止2月底，相当于已经整整在家办公四周了。&lt;/p&gt;

&lt;p&gt;在家的办公的这四周里，虽然对于个人实际的工作内容没有太大的变化，但整个工作形式、工作状态以及工作效能却是有很大的变化的。(&lt;code&gt;注意:这里说的是在家办公而非远程办公&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;在工作形式上可谓是百花齐放。相关的协作和协同工具也基本上处于头部几家互联网大厂，首当其冲的肯定属于阿里旗下的&lt;code&gt;钉钉&lt;/code&gt;,由于其早已在TOB领域深耕多年，在这次特殊情况下也就自然发挥了其作用，不过在以直播方式应用在中小学教学领域时也是遭遇&lt;code&gt;1分好评&lt;/code&gt;的尴尬场面。其次是企业微信和头条旗下的&lt;code&gt;飞书&lt;/code&gt;，前者由于存在个人版，所以没做尝试，而飞书前两天在&lt;code&gt;姜胡说&lt;/code&gt;作者胡子老师的直播会议时有幸做了尝试，只能说用过了钉钉，基本很难去转向飞书，毕竟作为TOB产品，以及协作工具，后者的功能更全，生态更广。&lt;/p&gt;

&lt;p&gt;为什么在家办公一个月我会有很多不适？我总结了几个点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;早中午的打卡(每天按点进行团队视频打卡)&lt;/li&gt;
&lt;li&gt;网络的限制&lt;/li&gt;
&lt;li&gt;家庭办公中的生活干扰&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在家办公后公司采取了一系列措施来保证员工的安全和&amp;rdquo;到岗&amp;rdquo;，而钉钉则解决了团队以及项目的沟通和协作问题，看起来似乎即使因为疫情的影响，对于互联网业务的技术岗位来说，也基本不会影响业务进度。事实上也的确是这个样子的。&lt;/p&gt;

&lt;p&gt;但是，对于员工个人(其实是我自己)而言，需要克服的是更多的困难。&lt;/p&gt;

&lt;p&gt;比如家庭网络对于远程办公场景的支撑如何，又如家庭场景的多样性对办公场景的干扰性如何，因为疫情是突然爆发的，所以大部分人在这两方面应该没有足够的准备，也因此可以确定的是，在目标导向或者结果导向的情况下，在家办公的工作内容可能会花费更多的时间。&lt;/p&gt;

&lt;p&gt;我不知道其他小伙伴们如何，但事实上，在北漂出租屋办公一个月的日子里，我好像每天都要加班到晚上十点，才能勉强将当日的计划做完，并且办公环境的限制会使得身体各种不舒服。&lt;/p&gt;

&lt;p&gt;说了这么多我的在家办公情况，其实并未想表明什么，只是希望疫情能够快速过去，企业能早日复工，而我也能去公司去做工作上的事情。&lt;/p&gt;

&lt;p&gt;不过上周五，收到这个通知，感觉又要痛苦两周。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gcepuaum3fj30ks0axt9k.jpg&#34; alt=&#34;延期办公&#34; /&gt;&lt;/p&gt;

&lt;p&gt;但其实，如果在家办公久了，也许以后会成为常态，那对于技术工作者而言是不是也会不再受地域的限制，会不会未来北上广深的技术人员在家办公即可，如此以来不是企业降负，员工自由么，那个时候就可以在家置办个高速网络和工作台，真正实现SOHO了(容我自己YY会儿)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;蜗居生活&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在家办公这一周可以算得上是真正的蜗居生活了，对于我这种天生好动的人来说，一周出门两三次，活动空间不超过40平，这种情况下，也很难会有比较好的心情(主要是我也不咋喜欢宅的娱乐活动)。&lt;/p&gt;

&lt;p&gt;所以，偶然在一次做饭中，想起来将菜根留下来做水培，也就有了题图的&amp;rdquo;可乐葱三结义&amp;rdquo;，一方面是因为实在没事干，想用这种小葱根水培来见证蜗居的日子，另外一方面是因为从假期开始也一直在看电视剧《三国》，每每看到刘备取得一定成绩时，就会想起这桃园三兄弟，三人有勇有谋，且情同手足。&lt;/p&gt;

&lt;p&gt;可叹刘备的胸襟，关羽的忠义，张飞的粗狂。&lt;/p&gt;

&lt;p&gt;话说，活动空间有限，又不能出门，对于运动细胞发达的我更是煎熬，为了不使自己在疫情过后丢掉了矫健的步伐，开始了每晚的Keep运动，每晚10点开始一天的简单运动放松，项目是: 李现HIT全身燃脂。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关于成长&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其实当人越是处于一个封闭的物理环境时，越容易有焦虑感，这种焦虑感一方面源自于个人成长多样性，另外一方面也源于缺乏与真实环境的正面反馈。&lt;/p&gt;

&lt;p&gt;在家办公的一个月(加上环境的限制)，的确在个人成长方面受限了很多，比如没有足够时间和经历去学习一些新技术，也很难抽出一小段时间来专注读技术之外的书籍(不过还是读完了两本)，这对于整个人的体系化成长会有很大的影响。&lt;/p&gt;

&lt;p&gt;所以，虽然突然又多出来两周的在家办公时间，但是我已经调整了整个生活和工作计划，打算充分利用在家办工的这段时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其他，就没有什么了，我打算趁着现在还没复工，好好梳理梳理我的运维知识体系和个人价值体系以及财富体系，毕竟整个2月一个月的时间整个收益曲线变化很大，现在刚好是可以整理自己思绪的时候，加油吧，baby！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gceh0txnrhj313y0u01l9.jpg&#34; alt=&#34;坚定的眼神&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>开源分布式对象存储服务-MinIO</title>
      <link>https://bgbiao.top/post/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景:通常在企业中我们会将一些图片，视频，文档等相关数据存储在对象存储中，以便于数据的存储和快速获取。在过去的一段时间，我们将这部分数据存储在公有云的对象存储服务上，但随着业务的快速发展，我们需要存储一些身份信息用于审核和实名相关的数据，这部分数据较为敏感，因此对于敏感数据的存储我们选择了使用兼容S3协议的开源分布式对象存储-&lt;a href=&#34;https://github.com/minio/minio&#34;&gt;Minio&lt;/a&gt;来进行自建服务。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Minio可能在国内知道和用的人不是很多，我第一次接触Minio是也是当时我们需要使用Spinnaker集群来管理和维护内部的Kubernetes集群，而Spinnaker的中的持久化存储就使用的是Minio &lt;a href=&#34;https://mp.weixin.qq.com/s/uN0RoGtcK1jT4QXlzkf4Bg&#34;&gt;Spinnaker集群搭建&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;但其实，Minio这款开源的分布式对象存储服务在国外已经相当受欢迎，并且国内也有多中小型互联网公司使用它来作为对象存储服务。&lt;/p&gt;

&lt;p&gt;有意思的是当年在开源的分布式存储方案中，比较有名的就是&lt;code&gt;GlusterFS&lt;/code&gt;和&lt;code&gt;Ceph&lt;/code&gt;。前者虽然也提供了块存储和对象存储的接口，但对于企业来说更多用于了分布式文件系统存储，其实就是一种高可用版本的NAS解决方案(通常用于替换NFS)，而后者则针对多种存储场景设计了不同的产品，针对分布式文件系统存储有&lt;code&gt;CephFS&lt;/code&gt;，针对分布式块存储有&lt;code&gt;Ceph RBD&lt;/code&gt;，针对分布式对象存储有&lt;code&gt;Ceph Radosgw&lt;/code&gt;，基本上可以做到开箱即用。&lt;/p&gt;

&lt;p&gt;所以，在后来GlusterFS后来被收购后，据说创始团队又开源了一个分布式存储软件，就是这个用Golang编写的小而美的对象存储&lt;a href=&#34;https://min.io/&#34;&gt;Minio&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;minio介绍&#34;&gt;Minio介绍&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;MinIO&lt;/code&gt;是一个用&lt;code&gt;Golang&lt;/code&gt;开发的基于&lt;code&gt;Apache License v2.0&lt;/code&gt;开源协议的&lt;code&gt;对象存储服务&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。&lt;/p&gt;

&lt;p&gt;Minio使用纠删码&lt;code&gt;erasure code&lt;/code&gt;和校验和&lt;code&gt;checksum&lt;/code&gt;来保护数据免受硬件故障和数据损坏。&lt;/p&gt;

&lt;p&gt;因此，即便您丢失一半数量（N/2）的硬盘，您仍然可以恢复数据。&lt;/p&gt;

&lt;h4 id=&#34;纠错码介绍-erasure-code&#34;&gt;纠错码介绍(erasure code)&lt;/h4&gt;

&lt;p&gt;纠删码是一种恢复丢失和损坏数据的数学算法， Minio采用&lt;code&gt;Reed-Solomon code&lt;/code&gt;将对象拆分成&lt;code&gt;可变数据块&lt;/code&gt;和&lt;code&gt;奇偶校验块&lt;/code&gt;。 比如12块盘(driver)，一个对象可以被切分到所有驱动器上的可变数量的数据和奇偶校验块—从6个数据和6个奇偶校验块到10个数据和2个奇偶校验块。&lt;/p&gt;

&lt;p&gt;但是，默认情况下，MinIO在&lt;code&gt;N/2&lt;/code&gt;个数据块和&lt;code&gt;N/2&lt;/code&gt;个奇偶校验驱动器上分片对象，当然用户可以通过&lt;a href=&#34;https://github.com/minio/minio/tree/master/docs/erasure/storage-class&#34;&gt;storage classes&lt;/a&gt;来自定义配置，不过官方还是建议采用使用N/2个节点来分配数据块和奇偶校验块，这样能够以最佳的方式保护防止驱动器(driver)故障.&lt;/p&gt;

&lt;p&gt;在上面的12个驱动器示例(使用默认配置)中，您可以丢失6个驱动器中的任何一个，但仍然可以从其余驱动器可靠地重构和恢复数据。&lt;/p&gt;

&lt;h4 id=&#34;为什么纠错码有用&#34;&gt;为什么纠错码有用&lt;/h4&gt;

&lt;p&gt;与RAID或复制不同，纠错码可以保护数据不受多个驱动器故障的影响。&lt;/p&gt;

&lt;p&gt;比如，在经典的&lt;code&gt;RAID6&lt;/code&gt;中可以在损失两块盘的情况下不丢数据，然而在Minio中纠错码可以保证当一般的盘故障时依然不会影响到数据。此外，纠错码在在对象级别，并且每次就可以修复一个对象。对于&lt;code&gt;RAID&lt;/code&gt;而言，数据的修复在卷(volume)级别，这就意味比较高的修复时间。由于MinIO对每个对象单独编码，所以它可以逐步的对对象进行修复。一旦部署了存储服务器，就不需要在服务器的生命周期内更换或修复驱动器。MinIO的纠错码后端是为提高操作效率而设计的，它可以更加高效的利用硬件而达到加速的效果。&lt;/p&gt;

&lt;h4 id=&#34;什么是-bit-rot-保护&#34;&gt;什么是&lt;code&gt;Bit Rot&lt;/code&gt;保护&lt;/h4&gt;

&lt;p&gt;Bit Rot，也称为Data Rot或静默数据损坏，是当今磁盘驱动器面临的数据丢失问题。驱动器上的数据可能在不发出错误信号的情况下被损坏，这使得比特损坏比永久的硬盘驱动器故障更危险。而在Minio内部的设计中采用了高速的&lt;a href=&#34;https://github.com/minio/highwayhash&#34;&gt;HighwayHash&lt;/a&gt;校验和来保护&lt;code&gt;Bit Bot&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;drivers是如何使用纠错码的&#34;&gt;Drivers是如何使用纠错码的&lt;/h4&gt;

&lt;p&gt;MinIO将您提供的驱动器分为4、6、8、10、12、14或16个驱动器的纠错码集，因此，在你构建一个Minio集群时，需要确保提供的驱动器的数量是这些数据之一的倍数，然后每个对象都会被写入一个单一的纠错码集中。&lt;/p&gt;

&lt;p&gt;Minio会使用尽可能大的EC集(除以给定驱动器的数量)，比如，18个驱动器可以配置为3组6个驱动器，但是24个驱动器最大只能分配2组12个驱动器。&lt;/p&gt;

&lt;p&gt;驱动器的大小应该大致相同。&lt;/p&gt;

&lt;h3 id=&#34;minio集群实操&#34;&gt;Minio集群实操&lt;/h3&gt;

&lt;h4 id=&#34;使用纠错码模式运行minio服务&#34;&gt;使用纠错码模式运行minio服务&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 使用二进制方式运行有12个驱动器的minio服务
$ minio server /data1 /data2 /data3 /data4 /data5 /data6 /data7 /data8 /data9 /data10 /data11 /data12

# 使用docker方式运行有8驱动器的minio服务
$ docker run -p 9000:9000 --name minio \
  -v /mnt/data1:/data1 \
  -v /mnt/data2:/data2 \
  -v /mnt/data3:/data3 \
  -v /mnt/data4:/data4 \
  -v /mnt/data5:/data5 \
  -v /mnt/data6:/data6 \
  -v /mnt/data7:/data7 \
  -v /mnt/data8:/data8 \
  minio/minio server /data1 /data2 /data3 /data4 /data5 /data6 /data7 /data8&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;以纠错码方式运行服务后，你就可以尝试将任意一半盘毁坏，依然不会影响整个系统的IO。但是&lt;code&gt;如果要求不影响写，处于正常的的驱动器个数必须大于N/2&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;分布式minio集群&#34;&gt;分布式MinIO集群&lt;/h4&gt;

&lt;p&gt;通常情况下，为了成本和效率的考虑开发同学可能会使用上述方式快速创建一个minio服务，但是从稳定性和可用性的角度来考虑，上述方式均无法保证，因此MinIO也提供了分布式的模式。&lt;/p&gt;

&lt;p&gt;分布式Minio可以让你将多块硬盘（甚至在不同的机器上）组成一个对象存储服务。由于硬盘分布在不同的节点上，分布式Minio避免了单点故障。&lt;/p&gt;

&lt;p&gt;分布式的Minio的优势:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;数据保护&lt;/code&gt;: 采用纠错码&lt;code&gt;erasure code&lt;/code&gt;防止多节点或者驱动器异常，采用&lt;code&gt;bit rot&lt;/code&gt;来进行数据保护。一个分布式的Minio集群最小需要4块盘(其实是纠错码要求最小4块)来驱动整个集群，当我们启动分布式集群后，纠错码会自动启动&lt;/li&gt;
&lt;li&gt;&lt;code&gt;高可用&lt;/code&gt;: 多节点组成的分布式minio可保证服务的高可用(一个N节点的分布式Minio,只要有N/2节点在线，你的数据就是安全的。不过你需要至少有N/2+1个节点才能创建新的对象。)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;一致性保障&lt;/code&gt;: MinIO在所有的IO操作中都严格遵循&lt;code&gt;read-after-write&lt;/code&gt;和&lt;code&gt;list-after-write&lt;/code&gt;一致性模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;运行分布式minio集群&#34;&gt;运行分布式MinIO集群&lt;/h4&gt;

&lt;p&gt;想要运行一个分布式的MinIO集群，你只需要将驱动器的位置参数传给minio指令即可，然后需要在全部节点运行相同的命令。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意事项&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;所有的节点需要有相同的access key 和 secret key，推荐在启动之前使用&lt;code&gt;MINIO_ACCESS_KEY&lt;/code&gt;和&lt;code&gt;MINIO_SECRET_KEY&lt;/code&gt;变量来共享key&lt;/li&gt;
&lt;li&gt;MinIO创建一组4, 6, 8, 10, 12, 14 or 16个驱动器的纠错码，因此提供的驱动数量必须是前面数字的倍数&lt;/li&gt;
&lt;li&gt;MinIO会选择给定驱动中，较大的一个EC集合，比如8个驱动将会使用一个大小为8的EC集，而不是两个大小为4的EC集&lt;/li&gt;
&lt;li&gt;每一个对象都会写到一个EC集中，因此对象的分布不可能超过16个驱动&lt;/li&gt;
&lt;li&gt;MinIO集群中的所有节点应该是同构的(比如:相同的OS,相同的磁盘和相同的网络架构)&lt;/li&gt;
&lt;li&gt;MinIO分布式模式需要&lt;code&gt;fresh directories&lt;/code&gt;(即干净的目录)，如果需要可以和其他应用程序共享驱动器(使用子目录的方式)&lt;/li&gt;
&lt;li&gt;运行分布式MinIO实例的服务器之间的间隔应该小于15分钟，你可以使用&lt;code&gt;NTP&lt;/code&gt;服务来保证服务器时间同步&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MINIO_DOMAIN&lt;/code&gt;环境变量应该被定义成&lt;code&gt;bucket DNS&lt;/code&gt;样式的支持(可以给每个bucket设置子域名)&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;Windows&lt;/code&gt;上的分布式集群是实验性的，需要谨慎&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gb4fbrthg2j30qo0f0myz.jpg&#34; alt=&#34;官方提供的有32个驱动器的32节点的分布式集群&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;一个EC Set 上包含多少个Drive是由系统自动根据集群规模算出来的，当然你可以自己去配置.&lt;/p&gt;

&lt;p&gt;我们以1个驱动器的4节点来组成集群:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# tree -L 1 /opt/app/
/opt/app/
├── minio
├── minio.conf

$ cat minio.conf
MINIO_ACCESS_KEY=BGBiao
MINIO_SECRET_KEY=BGBiao
ENDPOINTS=&amp;#34;http://10.0.0.148:9000/data/minio http://172.16.62.149:9000/data/minio http://172.16.62.150:9000/data/minio http://172.16.62.151:9000/data/minio&amp;#34;

$ cat /usr/lib/systemd/system/minio.service
[Unit]
Description=Minio
Documentation=https://docs.minio.io
Wants=network-online.target
After=network-online.target
AssertFileIsExecutable=/opt/app/minio

[Service]
EnvironmentFile=-/opt/app/minio.conf
ExecStart=/opt/app/minio server $ENDPOINTS

# Let systemd restart this service always
Restart=always
# Specifies the maximum file descriptor number that can be opened by this process
LimitNOFILE=65536
# Disable timeout logic and wait until process is stopped
TimeoutStopSec=infinity
SendSIGKILL=no
[Install]
WantedBy=multi-user.target


# 将上述配置同步到4个节点，并启动，minio实例之间会自行发现各个节点
$ systemctl restart minio&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;minio分布式对象存储服务使用&#34;&gt;Minio分布式对象存储服务使用&lt;/h3&gt;

&lt;p&gt;当使用前面的方式成功运行minio的对象服务后，我们就可以使用以下几种方式进行访问:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;web&lt;/code&gt;: 默认我们可以访问实例的9000端口，通过access key和secret key进行访问实例&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mc&lt;/code&gt;: 使用minio官方提供的兼容s3的客户端&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aws-cli&lt;/code&gt;: 使用aws的客户端命令&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3cmd&lt;/code&gt;: 使用3s的开源客户端执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minio-go&lt;/code&gt;: 使用minio的golang客户端操作集群&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 当我们成功运行minio服务后，默认会提供一个简单的web管理页面.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gb5hep7kazj31zm0u0aer.jpg&#34; alt=&#34;web管理页面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里我们使用&lt;code&gt;mc&lt;/code&gt;客户端命令进行操作(&lt;code&gt;值得一提的是，有了mc客户端之后操作oss就如同本地操作一样方便快捷&lt;/code&gt;)&lt;/p&gt;

&lt;h4 id=&#34;minio客户端mc的使用&#34;&gt;minio客户端mc的使用&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;客户端配置管理&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 添加minio云存储服务(会将数据存入~/.mc/config.json)
# mc config host add &amp;lt;ALIAS&amp;gt; &amp;lt;YOUR-S3-ENDPOINT&amp;gt; &amp;lt;YOUR-ACCESS-KEY&amp;gt; &amp;lt;YOUR-SECRET-KEY&amp;gt; &amp;lt;API-SIGNATURE&amp;gt;
$ mc config host add minio http://bgbiao.top:9000 BGBiao BGBiao S3v4&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;查看bucket&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看minio集群中的bucket
$ mc ls minio
[2020-01-10 20:54:19 CST]      0B test11/
[2019-07-08 19:51:02 CST]      0B test23/
[2019-07-08 20:10:58 CST]      0B test4/

# 查看bucket的内容
$ mc ls minio/test11
[2019-07-05 21:22:34 CST]   88KiB 111
[2019-07-07 11:03:21 CST]   88KiB 112
[2019-07-08 10:50:51 CST]   88KiB 113
[2019-07-08 18:17:17 CST]   88KiB 114
[2019-07-09 11:51:30 CST]   66KiB 116
[2019-07-09 14:24:23 CST]   66KiB 117.jpg
[2019-07-09 14:33:17 CST]   66KiB 118.jpg
[2019-07-09 14:52:36 CST]   66KiB 119.jpg
[2020-01-10 20:52:28 CST]  7.4KiB server.xml&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;bucket管理&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建一个bucket
$ mc mb minio/bgbiao
Bucket created successfully `minio/bgbiao`.
$ mc ls minio/ | grep bgbiao
[2020-01-22 16:32:43 CST]      0B bgbiao/

# rb可以直接删除指定的bucket
$ mc rb minio/bgbiao
Removed `minio/bgbiao` successfully.

# tree可以打印出来bucket组织的文件系统树形结构
$ mc tree --depth 2 --files minio/bgbiao
minio/bgbiao
└─ hostname.txt

# du可以查看某个bucket或者object的大小
$ mc du minio/bgbiao
10B bgbiao
$ mc du minio/
9.1GiB&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;对象管理&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 将本地文件拷贝到minio的oss服务
# 并直接使用cat命令访问
$ hostname &amp;gt; hostname.txt
$ mc cp hostname.txt minio/bgbiao/
hostname.txt:         10 B / 10 B  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  132 B/s 0s%
$ mc ls minio/bgbiao/
[2020-01-22 16:33:52 CST]     10B hostname.txt
$ mc cat  minio/bgbiao/hostname.txt
localhost

# 使用pipe命令可以将标准输入的数据直接写入到minio的存储中
$ echo ${PATH} | mc pipe minio/bgbiao/path.txt
$ mc ls minio/bgbiao/
[2020-01-22 16:33:52 CST]     10B hostname.txt
[2020-01-22 16:43:43 CST]    111B path.txt
$ mc cat minio/bgbiao/path.txt
/Users/BGBiao/.cargo/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/go/bin:/usr/local/soul/bin


# 受用share命令生成可供外部匿名下载的临时链接地址
# 生成后我们就可以使用共享链接在4小时内随意下载
$ mc share download --expire 4h minio/bgbiao/hostname.txt
URL: http://bgbiao.top:9000/bgbiao/hostname.txt
Expire: 4 hours 0 minutes 0 seconds
Share: http://bgbiao.top:9000/bgbiao/hostname.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=BGBiao%2F20200122%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20200122T083619Z&amp;amp;X-Amz-Expires=14400&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=ec49806b7c249bbeb140af759afeff907672ebd97637b759efd11d4f9b1a20b3

# 使用mirror指令对bucket内容进行镜像(最实用的一个指令)
# 将minio这个对象服务下的bgbiao的整个bucket的对象镜像到本地
# 使用minio的mc客户端可以在多个minio服务之间进行数据镜像
$ mc mirror minio/bgbiao .
...iao/hostname.txt:  10 B / 10 B  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  39 B/s 0s %

# 使用find指令来直接查找内容(相对比较实用,find指令支持很多方便快捷的参数，和Linux本地的find命令内容相似)
# 查找名称为*.txt的文件并打印临时url下载地址
$ mc find minio/bgbiao/ --name &amp;#34;*.txt&amp;#34; --print {url}
http://bgbiao.top:9000/bgbiao/hostname.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=BGBiao%2F20200122%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20200122T084926Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=a02a370575cae5d5cf92c565d02918e20d734f80afed3e5eebf5fe1433aa348a
http://bgbiao.top:9000/bgbiao/path.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=BGBiao%2F20200122%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20200122T084926Z&amp;amp;X-Amz-Expires=604800&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=d7d87f6a4f9d406ae02a6844574f02f6e1479215bee8401feea58e95e98b8b36
 
# diff命令可以列出两个bucket之间对象的大小，名字，时间的不同
$ mc diff . minio/bgbiao/
&amp;gt; http://bgbiao.top:9000/bgbiao/path.txt
&amp;lt; readme.md

# rm可以直接删除指定的对象(--force --recursive就相当于我们linux中的rm -rf)
$ mc rm --force --recursive   minio/bgbiao
Removing `minio/bgbiao/hostname.txt`.
Removing `minio/bgbiao/path.txt`.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;minio运维管理&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;90
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# stat可以查看minio服务的元数据信息
$ mc stat minio/bgbiao
Name      : bgbiao/
Date      : 1970-01-01 08:00:00 CST
Size      : 0 B
Type      : folder
$ mc stat minio/bgbiao/hostname.txt
Name      : hostname.txt
Date      : 2020-01-22 17:04:27 CST
Size      : 10 B
ETag      : 902f570940ba8d4b74743a3a97f5aff6-1
Type      : file
Metadata  :
  Content-Type         : text/plain
  X-Minio-Deployment-Id: 80525c40-fec3-459e-8080-6f5210548647


# retention指令可以设置指定前缀的对象的保留时间

# events指令可以查看和添加对象的事件

# watch可以实时监听对象的events

# policy用来管理匿名用户对bucket和object的访问
# 设置bgbiao这个bucket匿名用户仅可以下载(download/public/upload)
$ mc policy set download minio/bgbiao
$ mc policy list minio/bgbiao 

# admin用来管理minio服务
# mc admin info 查看minio服务基本信息
# mc admin service 重启和停止minio服务
# mc admin config  管理minio服务的配置信息
$ mc admin info minio
●  10.0.0.149:9000
   Uptime: 1 day
   Version: 2020-01-16T22:40:29Z
   Network: 4/4 OK
   Drives: 1/1 OK

●  10.0.0.150:9000
   Uptime: 1 day
   Version: 2020-01-16T22:40:29Z
   Network: 4/4 OK
   Drives: 1/1 OK

●  10.0.0.151:9000
   Uptime: 1 day
   Version: 2020-01-16T22:40:29Z
   Network: 4/4 OK
   Drives: 1/1 OK

●  10.0.0.148:9000
   Uptime: 1 day
   Version: 2020-01-16T22:40:29Z
   Network: 4/4 OK
   Drives: 1/1 OK

13 GiB Used, 2 Buckets, 166,580 Objects
4 drives online, 0 drives offline
 
# config 用来管理客户端的配置文件(还记得我们刚开始配置本地环境的时候吗)
# minio默认帮我们配置了一些公共的对象存储服务，同时也配置了一个本地的oss服务
$ mc config host list
gcs
  URL       : https://storage.googleapis.com
  AccessKey : YOUR-ACCESS-KEY-HERE
  SecretKey : YOUR-SECRET-KEY-HERE
  API       : S3v2
  Lookup    : dns

local
  URL       : http://localhost:9000
  AccessKey :
  SecretKey :
  API       :
  Lookup    : auto

minio
  URL       : http://bgbiao.top:9000
  AccessKey : BGBiao
  SecretKey : BGBiao
  API       : s3v4
  Lookup    : auto

play
  URL       : https://play.min.io
  AccessKey : Q3AM3UQ867SPQQA43P2F
  SecretKey : zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG
  API       : S3v4
  Lookup    : auto&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>思考自己的价值系统</title>
      <link>https://bgbiao.top/post/2020-%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BB%B7%E5%80%BC%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/2020-%E6%80%9D%E8%80%83%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BB%B7%E5%80%BC%E7%B3%BB%E7%BB%9F/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwgy1gazzkqu1bqj31970u0b2a.jpg&#34; alt=&#34;~美丽的布达拉宫~&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;文末有彩蛋&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;批判(&lt;code&gt;胡&lt;/code&gt;)性(&lt;code&gt;思&lt;/code&gt;)思(&lt;code&gt;乱&lt;/code&gt;)考(&lt;code&gt;想&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在过去的几个月里，我又做了一个实验。&lt;/p&gt;

&lt;p&gt;我这个人总是有一个特点，就是当自己内心里突然出现一个比较有意思的想法时，我就会尽自己最大可能去做一个亲身实验，当然我也不知道这个特点对于我个人来说是福是祸，但每当想起能够控制自己去做一件事情的时候，就觉的特别酷。&lt;/p&gt;

&lt;p&gt;我们都知道如今的互联网有几大产品几乎占据了我们全部的生活，对我个人感触最大的就是&lt;code&gt;抖音&lt;/code&gt;和&lt;code&gt;微信&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;17年因为追&lt;code&gt;中国有嘻哈&lt;/code&gt;节目，了解到&lt;code&gt;抖音&lt;/code&gt;这个产品，那个时候抖音还没有19年这么火，但当时它们的内容以及推荐策略足以让我在卫生间的马桶上呆一个多小时(如果不是公共区域可能会更长)。&lt;/p&gt;

&lt;p&gt;你要知道人对一个东西上瘾是一件很恐怖的事情，因为不知不觉一天就会过去，而人生命的长度是有限的，想到这内心不免会有一些愧疚感(应该很多人都会这样的感觉吧)。那个时候我想办法就强制把抖音卸载了，幸亏我是一个自控力还算可以的人，算是没有在这个产品上荒废太多时光(但其实后来才发现，在这个产品里其实可以有很多&lt;code&gt;价值&lt;/code&gt;可以挖掘，不仅可以带货，也可以用来学习专业领域知识)。&lt;/p&gt;

&lt;p&gt;而微信则非常不同，这个伴随移动互联网崛起的社交软件一直在不断的&lt;code&gt;侵蚀&lt;/code&gt;我们，从一开始的&lt;code&gt;即时通讯，语音聊天，微信群，图片聊天，朋友圈，公众号，小程序，支付，搜一搜(再看)，到现在的圈子和朋友圈图文评论&lt;/code&gt;，微信生态几乎可以满足我们一天大部分的工作和生活需求。&lt;/p&gt;

&lt;p&gt;从一般人的角度来讲可能觉得这样挺好的，我们不需要在不同需求之间来回切换软件，整个工作和生活可能都觉得高效了起来，但如果你仔细想想就会发现，其实没有那么简单。&lt;/p&gt;

&lt;p&gt;在没有离开京东数科之前，曾经有段时间我一直处于被微信引导的状态。&lt;/p&gt;

&lt;p&gt;什么意思呢，就是我发现几乎只要有碎片时间就会去刷朋友圈，去看公众号的推送文章。&lt;/p&gt;

&lt;p&gt;当你通过微信这样的方式去学习和涨见识的时候，你会发现你的朋友都是能力圈周边的人，你的朋友圈也因为各种屏蔽功能只能让你看到你想看的东西，而公众号的推送一般都是我们主动关注的领域(&lt;em&gt;但通常一般主动关注公众号有80%对我个人来说是没有价值的，也就是干扰知识，这可能也是微信团队退出&lt;code&gt;搜一搜&lt;/code&gt;和&lt;code&gt;看一看&lt;/code&gt;两个功能的主要原因吧&lt;/em&gt;)。&lt;/p&gt;

&lt;p&gt;这样造成的一个结果就是我们总是会习惯性的打开微信去消耗碎片时间，而几乎很难得到一些真正有价值成体系的知识(&lt;em&gt;所以关注我公众号的兄弟们如果觉得内容没有给自己带来价值我是非常建议取关的，如果给您带来价值了可以点个&lt;code&gt;在看&lt;/code&gt;，因为这样我的推送不会干扰到您，也可以给有需要的同学带来便利&lt;/em&gt;)。&lt;/p&gt;

&lt;p&gt;讲了这么多废话，我做的小实验其实就是&lt;code&gt;关闭朋友圈&lt;/code&gt;和&lt;code&gt;公众号取关&lt;/code&gt;，通过这种主动屏蔽的方式来改变以前被微信生态绑定的习惯和状态。
&lt;em&gt;其实很佩服微信的产品，很多功能其实都是插拔式的，用户完全可以根据自己的需求来关闭某些功能，所以在&lt;code&gt;关闭朋友圈&lt;/code&gt;后丝毫不会影响微信给我们带来的便利&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;可能会有人有很多疑虑，这其实也是我这半年的思考和写该篇文章的原因，因为当我从这些碎片化的内容中剥离出来后，我能够更加聚焦到自己想关注的内容上来，从而满足自己内心的需要。&lt;/p&gt;

&lt;p&gt;写这篇文章主要想通过自己的一些思考，来不断优化自己的成长路径，同时也希望能对大家有一定帮助。&lt;/p&gt;

&lt;p&gt;接下来，我会从&lt;code&gt;工作&lt;/code&gt;,&lt;code&gt;生活&lt;/code&gt;,&lt;code&gt;运动&lt;/code&gt;,&lt;code&gt;理财&lt;/code&gt;几个方面来分享一下我这大半年的一些感悟和思考。&lt;/p&gt;

&lt;h4 id=&#34;工作&#34;&gt;工作&lt;/h4&gt;

&lt;p&gt;我是15年毕业的，去年6月底从老东家(也是第一家公司)出来的，我很幸运在一毕业能够进入一个大企业进行学习和成长，也很幸运能够加入一个比较好的团队和各种优秀的同事一起共事，这让我在整个职业生涯初期得到了飞速的成长，当然这里要非常感谢三位老领导：超哥，郑老板，还有一位可算是我的职业生涯的启蒙老师波哥。&lt;/p&gt;

&lt;p&gt;有的人可能会说，都9012年了，整个经济周期都从十年缩短到3-5年了，还能在一家互联公司呆4年，可真是&amp;rdquo;兄弟&amp;rdquo;啊。&lt;/p&gt;

&lt;p&gt;其实并不是这样的，要知道我们每个人的职业生涯都是螺旋式成长的，在过去的四年中的确会有成长瓶颈点而有想出去的想法，但考虑到自己的职业履历后都打消这种念头了，幸运的是，通常这个时候都会找到新成长途径(也多亏有个好领导)，不至于让自己四年重复了一年的工作。&lt;/p&gt;

&lt;p&gt;所以，就有了在去年中旬离开的这件事。&lt;/p&gt;

&lt;p&gt;其实在当时老板们对我都很好，而且整体待遇也相当不错，只是对于我个人而言，在相对舒适的环境里成长确实受限了些，而且在一个熟悉的环境里很多决策和思考会形成一定的固有模式，这对于一个发散型思维和批判性思维的人来说并不是一个好事。&lt;/p&gt;

&lt;p&gt;认清自己的现状和期望后，便十分果断的离开了。在这之前还有一个小插曲，就是当年在数科时有个要好的小伙伴，后来去了鹅厂，各种怂恿我出去看看，说出来后机会很多，认知也会提升很多，而我的内心其实也是非常认同的，事实也证明早出来其实是非常明智的，甚至有时在想如果我早一年出来的话，又会是怎样的。&lt;/p&gt;

&lt;p&gt;在工作这件事上，前期我的想法是很简单的，因为我主要追求的是个人成长，只需要自己努力工作，自己快速成长，至于钱的事情可能也没怎么考虑(如果遇到好领导，你的努力老板不会看不见的)，并且刚毕业的前几年，我们往往是不那么缺钱的，更缺的是一些技能和经验，毕竟这两者才是未来个人价值的基础。&lt;/p&gt;

&lt;p&gt;但其实在后面的时间，你会发现钱越来越重要了，因为我们不断面临着买房，结婚以及身体上的压力，而此时并不一定是领导或者公司给你的报酬幅度降低了，而可能是你所处的大环境限制了你所拿到的报酬。&lt;/p&gt;

&lt;p&gt;所以，择机选择一个新的环境，新的方向去继续努力也不失为一种良策，这就好比在2018-2019年整体经济形势不景气的大背景下，很多企业依然保持着高速的成长，那我们要是能够选择一个好的企业，努力工作，闷声发大财不也挺香么(&lt;em&gt;不过也需要谨慎，好的企业不一定一直好，也不容易选择&lt;/em&gt;)，毕竟我们这一代人努力工作一方面是为了满足自己的成就感，另外一方面是为了更好的品质生活(这不得是用钱来换么)，前者通常来讲只要个人自驱力强，很容易在工作中找到成就感，而后者在职业生涯中往往需要依靠自身努力和所处的企业大环境，两者缺一都很难实现(当然也不排除那些不怎么努力但是运气绝佳的人)。&lt;/p&gt;

&lt;p&gt;看到这里的人，或许会有些好奇，我换到了什么企业，做什么工作。&lt;/p&gt;

&lt;p&gt;实际上，从数科离开后，我加入了一家创业公司，还是做运维相关的事，但不同的是在创业公司的整个基础设施都是云化的，在未来整个云计算的大背景，做和云相关的东西至少不会掉队，另外整个运维体系化建设还很原始，正好可以将这几年经历过的也都落地一次，从零将整个运维体系闭环走通(实际上在任何工作中，整个生态或商业闭环的能力其实是相当重要的)。&lt;/p&gt;

&lt;p&gt;当然，还有比较重要的一点是，我们公司的产品更多是面向Z世代人群的，整个互联网的发展史告诉我未来的战场是面向年轻人市场的，所以接触接触年轻人们的世界我觉的对于我们这个当叔叔年级的人来说是有一定帮助的，就像一个B站年会会对它的市值造成那么大影响，我们得去学着理解年轻人的世界不是吗？&lt;/p&gt;

&lt;p&gt;在工作这块我的感悟有以下几点:
- 1.如果你是有想法，自驱力较强的人，没必要为了履历呆够3-5年，外面的世界很大(没想的那么好，但也没有大家说的那么差)，并且这个世界正在&lt;code&gt;微服务&lt;/code&gt;化
- 2.选择一个&lt;code&gt;&amp;quot;有未来&amp;quot;&lt;/code&gt;的企业(即坡道够长)
- 3.尽可能选择一个自己喜欢的方向和能让自己有成就感的事情(不要一味追求利益)，并持续下去&lt;/p&gt;

&lt;p&gt;所以，我目前来说还是做着我比较喜欢的运维相关的工作(Ops也好，DevOps也罢，亦或者是SRE)，本质的内容还是帮助业务快速发展，但其实可能会更多的从&lt;code&gt;技术、运营，甚至营销&lt;/code&gt;等多方面来辅助工作执行。&lt;/p&gt;

&lt;h4 id=&#34;生活&#34;&gt;生活&lt;/h4&gt;

&lt;p&gt;生活上我一直是一个不太讲究的人，但也时常会有一些比较喜欢的东西或者想要去体验的事情，虽然很多东西最后都是浅尝辄止，但是不去尝试，又如何知道自己曾经心心念的东西为何般。&lt;/p&gt;

&lt;p&gt;所以说，人嘛，在生活中总得有一个比较喜欢的事情去做。&lt;/p&gt;

&lt;p&gt;比如说曾经的我，工作就是我全部的生活，不仅仅是工作能够带来给我成就感，还有重要一点是，任何我们想象中美好的生活都是需要很多成本的，一切都是为了未来美好的生活。&lt;/p&gt;

&lt;p&gt;而现在我也会在空闲时间适当的去看一些可以引发思考的节目，电视剧，甚至为了想了解年轻人的世界而去关注一些娱乐节目(当然很多都是向女票请教的)。&lt;/p&gt;

&lt;p&gt;女朋友也找到一个自己喜欢的事(她说喜欢做饭😸)，并且在不断的学习和进步。&lt;/p&gt;

&lt;p&gt;同时，我们会在日常生活之外的时间定期去咖啡馆学习，一起共同成长。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;不得不说家附近有咖啡馆真的是相当方便，通常在星巴克之类的咖啡馆长坐的人大部分都是来学习的，我们看到的基本上都是抱着电脑或者书本在做自己的事，点一杯咖啡，戴一个耳机，自己尽情做自己的事就好。虽然可能这样下来整个开销大了，但其实做事的效率却是很高的，这种高效和快速的成长是无法用金钱的成本来衡量的，因为说不定哪天老板就突然给加薪了呢。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;对了，在过去的几个月里我还给自己找了个事，学&lt;code&gt;架子鼓&lt;/code&gt;，这件事情可算得上从小一直心心念的东西了，但迫于经济和地域条件一直未曾尝试，虽然不知道能不能学会，能学多久，但我还是发自内心的比较喜欢摇滚，比较喜欢这个乐器，希望2020年能够有一定的成绩。&lt;/p&gt;

&lt;h3 id=&#34;运动&#34;&gt;运动&lt;/h3&gt;

&lt;p&gt;工作是为了更好的生活，生活的目的又是不断去探知这个世界，所以健康的身体就成为了最基础的保障，所谓身体是革命的本钱嘛。我在大学时期刚开始跑步时也是为了不感冒(每次感冒就会鼻炎)，直到后面真正爱上了跑步，就会开心也跑，痛苦也跑。&lt;/p&gt;

&lt;p&gt;所以在19年年初和跑团的兄弟们定了契约之后，基本在每个月都会去争取完成100km的任务(只有7月差了5km，到新公司第一个月的最后一天加了个夜班)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwgy1gazzcfhzz1j30ku112n06.jpg&#34; alt=&#34;19年单月跑量&#34; /&gt;&lt;/p&gt;

&lt;p&gt;遗憾的是，19年没有参加过马拉松(北马没中签)，而越野跑也仅跑过一个50km和一个打5折的50km。&lt;/p&gt;

&lt;p&gt;不过，令我比较兴奋的是，以前动不动各种腰痛，颈椎痛，基本很少出现了，以前买的电脑桌自从换工作后也没在用过，我想这可能也是坚持定量运动一个最大的好处吧。&lt;/p&gt;

&lt;p&gt;另外，去年给自己定的目标是挑战崇礼168KM的越野跑，不过因为工作的事情无法参赛，今年提前规划了赛事，如果不出意外会跑完TNF100和崇礼130KM两个越野赛事。其他赛事估计看运气和时间吧，日常的运动量打算继续保持至少100km的跑量(不过1月应该不行了，春节要进藏，不能瞎蹦跶)。&lt;/p&gt;

&lt;p&gt;20年会继续坚持运动，如果有可能，会带着女朋友一起运动，毕竟健康的身体，好看的身材大家都想拥有。&lt;/p&gt;

&lt;h3 id=&#34;理财&#34;&gt;理财&lt;/h3&gt;

&lt;p&gt;理财这件事情是我在过去一年都是比较重视的，但也仅限于基金和股票理财。&lt;/p&gt;

&lt;p&gt;大家都说2018-2019是这几年市场最低迷的两年，的确整个经济的波动在金融市场也表现的淋漓尽致，而我所持仓的理财标的物也是有赔有赚，基金整体上来讲还算不错，所以也想在这里和大家分享一些心路历程。&lt;/p&gt;

&lt;p&gt;我是怎么开始有理财意识的呢？&lt;/p&gt;

&lt;p&gt;源于大学时期，由于我就读的是财经院校，并且会学习金融类相关课程(也会学习支付相关的东西)，有老师就教导我们要&lt;code&gt;有才&lt;/code&gt;，也要&lt;code&gt;有财&lt;/code&gt;，基本上从那个时候就慢慢培养了自己的理财意识(老师会让我们去买余额宝之类的产品来辅助学习支付工具)。&lt;/p&gt;

&lt;p&gt;刚开始毕业那会，会选一些类似P2P理财之类的产品，基本上年化可以保持在4%-6%之间，通常情况会把每个月工资的一部分放进去，直到后来P2P产品的不断倒台，才完全从里面抽出来。&lt;/p&gt;

&lt;p&gt;但是抽出来后会发现，那点钱放在银行账户里收益太低，拿出来又不足以去购买其他资产，索性就找到在银行工作的朋友，让帮忙指导下基金理财，后来也就入了基金理财的坑，到目前为止整体的基金理财平均收益可以保持在10%左右，个人觉得还算是可以的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwgy1gazlk45r55j30ku11241x.jpg&#34; alt=&#34;天天基金上的持仓收益&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwgy1gazljvr5oej30ku1120uk.jpg&#34; alt=&#34;支付宝上的持仓收益&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中图1中可以看到我个人的持仓年涨幅为&lt;code&gt;18.77%&lt;/code&gt;，而&lt;code&gt;沪深300的涨幅为36.07%&lt;/code&gt;，由于我买的都是股票型基金，所以也就意味着在去年一年整个A股市场基本是属于稳定上升状态的，这也就是我在&lt;code&gt;工作&lt;/code&gt;总结中说的&lt;code&gt;外面的环境没想像的那么好，但也没有大家说的那么差&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;因为不论市场好坏，总有一些东西是必须品，也总会存在一些持续上升的价值系统。&lt;/p&gt;

&lt;p&gt;在过去大半年基金理财的收益还算不错后，我开始向几位小伙伴推荐，从前几天来看小伙伴们的基金理财收益也基本达到7%-10%左右，这也是促使我想要写这个总结的动力。&lt;/p&gt;

&lt;p&gt;在经历过两年多的基金理财后，我总结了以下几个点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.选一只蓝筹鸡，至于如何选鸡，我之前写过一篇文章&lt;a href=&#34;https://mp.weixin.qq.com/s/swAOiIT-tWkpC0wa24C51Q&#34;&gt;门外汉如何选鸡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.设置每月投资资金的5%-10%到定投中，并坚持下去&lt;/li&gt;
&lt;li&gt;3.以月或周为单位进行复盘，进行适当调仓&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最重要的我认为属于选鸡，因为通常整个基金背后的管理是较为复杂的，一般基金背后的团队和投资物都会相对来说比较稳定，所以前期选好一只基金后，基本上持续定投，只需等待复利效应了。&lt;/p&gt;

&lt;p&gt;股票投资我是投了A股，港股和美股的，基本上各自都有盈亏，美股整体上是亏损的，下面来说说我这一年在股票上学到东西。&lt;/p&gt;

&lt;p&gt;A股我在年初是买了几家公司的，其中包括了&lt;code&gt;京东方A&lt;/code&gt;，&lt;code&gt;苏宁易购&lt;/code&gt;，&lt;code&gt;达华智能&lt;/code&gt;等。&lt;/p&gt;

&lt;p&gt;买这几只股票是因为看好5G，智能时代和新零售市场，结果却发现在不断的跌，后来在合适的点不断清仓，最终基本全部撤离(苏宁易购还剩了点)，后来总结的一点就是虽然整个5G和智能时代可能是未来的方向，但是由于基础设施或者商业化方案不成熟，对应的股票并不能在当时表现出自己的价值，再加上前期自己只是抱着学习的态度去炒股的，希望能在实践中学习并保留资产，所以就做了快速止损的操作。&lt;/p&gt;

&lt;p&gt;不过从现在来看，那几只股票到现在为止都是涨的(也再一次说明2019年市场没有太差).&lt;/p&gt;

&lt;p&gt;港股过去一年买卖过几家，比较出名的有&lt;code&gt;新东方在线&lt;/code&gt;,&lt;code&gt;美团&lt;/code&gt;,&lt;code&gt;小米&lt;/code&gt;,&lt;code&gt;呷哺呷哺&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;新东方在线我看中的是当前的K12领域，并且有母公司新东方已经在美股上市，线下资源较为丰富，在移动互联网+短视频的双重作用下，新东方在线应该不会太差，事实也证明了它非常不错(我当时10港币买的最后11港币卖出，当前是25港币😅)。&lt;/p&gt;

&lt;p&gt;美团是因为属于互联网新股，并且属于占领整个年轻人生活生态的一家公司，在整个懒人时代，美团外卖着实帮助了很多年轻人，想着整体的价值逻辑和我的认知逻辑比较相符，所以也买卖了一波(50港币买入，60港币卖出，当前是111港元😓)。&lt;/p&gt;

&lt;p&gt;现在持仓的还有小米和呷哺呷哺，不要问我为什么那么快就轻易卖了前两只股票，当然和自己的认知有一定关系，但其实更多在于子弹不够吧，还是前面提到的逻辑，我比较看好智能时代，而小米的整个生态规划都是相当符合我的认知的，所以为了能够赶时机重仓小米，在前两只还不赔的情况下作了快速调仓，然而小米却一度让它的股民失望，其实原因还是在于智能时代的基础设施和条件不具备，导致当下的反应比较疲，不过从当前的状态来看，也算是还不错(目前持仓收益40%左右，而且我相信它会继续上涨)。&lt;/p&gt;

&lt;p&gt;呷哺呷哺，想必在北京的小伙伴都比较熟悉，一个时尚小火锅，当年没毕业时，就听一位老师说过呷哺呷哺，后来这几年也经常去吃，在时尚火锅里算是性价比比较高的，后来开始炒股后一直关注该股票，直到后来到达心里认为的底部价格后开始入仓(当前收益30%左右)。&lt;/p&gt;

&lt;p&gt;美股过去一年买卖的比较多，当然也赔的比较多，当前还持有的欧朋、趣店、蔚来、蘑菇街、如涵控股、京东，不过因为过程中的心理问题，现在几乎全部清仓。&lt;/p&gt;

&lt;p&gt;美股是最开始玩的，最早是因为在京东工作(讲真，当时看到京东做的很多事情，觉得都特别有价值)，就开始买卖自家的股票，但后来发生一些列乌龙事件，在去年年初市值暴跌(最低19刀)，不过到现在整个价值也算平稳(40刀)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;蔚来&lt;/code&gt;是看好电动汽车，毕竟属于国产领域的特斯拉，个人觉得在电动车市场，还算是相当不错的。&lt;code&gt;如涵控股&lt;/code&gt;是看好整个网红电商经济，经济的本质是交易，而整个电商经济中除了品牌效益之外通过网红带货也是一个相当不错的模式(这个其实和当前的直播带货我认为是一套逻辑)，而这两只股票都因为曾经跌到太低，心里接受不了而在初涨时出仓，当前价格都远超于当时卖出价格。&lt;/p&gt;

&lt;p&gt;剩下的几只股票均为无脑买入，为啥叫无脑买入呢，就是关注了几天股票，发现跌了很多，个人感觉应该可以抄底了，但往往我们个人投资者是无法判断低点的，所以整个美股市场当前整体还是赔着。&lt;/p&gt;

&lt;p&gt;从过去一年的股票交易经历中，我也总结了几点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;永远不要抄底，因为散户永远不知道低点在哪里&lt;/li&gt;
&lt;li&gt;炒股过程中&lt;code&gt;逻辑&amp;gt;股票指标&amp;gt;股票相关数据&amp;gt;财报结论&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;要努力工作，先要保证有足够的资金池&lt;/li&gt;
&lt;li&gt;普通人炒股还是要关注价值投资&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，一句话总结就是&lt;code&gt;&amp;quot;你赚的前都是你对这个世界认知的变现；你赔的每一分钱，都是因为你还不太了解这个世界&amp;quot;.&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;过去的半年，不论是在工作、生活还是其他方面对我来说都算得上收获颇丰，希望把这些思考和感受写下来来不断鞭策自己，同时希望2020年能够更上一层路。&lt;/p&gt;

&lt;p&gt;也希望有志青年(技术从业者，理财爱好者，跑步爱好者)一起交流，一起学习，共同成长。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwgy1gb01r8pzz7j30u01h9qac.jpg&#34; alt=&#34;看到这了，领个红包再走吧&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang中的逃逸分析</title>
      <link>https://bgbiao.top/post/golang-%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang-%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;背景:说实话，使用Golang来作为日常的cmdline程序开发也有一两年了，之前作为一名Ops来说，会使用Golang去开发一些常用的工具来实现生产环境的各种常规操作以及日常运维管理，而对于整个Golang语言内部的一些细节都不甚了解。但随着对Ops要求的提高，以及向SRE理念转型的需要，我们越来越需要深入理解一些内部底层的原理，这样在我们去管理的我们的Kubernetes集群，或者其他的一些内部系统时才能真正做到游刃有余。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在Golang中，一个对象最终是分配到&lt;code&gt;堆&lt;/code&gt;还是&lt;code&gt;栈&lt;/code&gt;呢，接下来我们就一起通过&lt;code&gt;逃逸分析&lt;/code&gt;来一起学习学习。&lt;/p&gt;

&lt;h3 id=&#34;概念介绍&#34;&gt;概念介绍&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;逃逸分析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;逃逸分析&lt;/code&gt;是编译器用来确定由程序创建的值所处位置的过程。具体来说，&lt;code&gt;编译器执行静态代码分析&lt;/code&gt;，以确定是否可以将值放在构造函数的&lt;code&gt;栈(帧)&lt;/code&gt;上，或者该值是否必须&lt;code&gt;逃逸&lt;/code&gt;到&lt;code&gt;堆&lt;/code&gt;上。&lt;/p&gt;

&lt;p&gt;所以，更通俗一点讲，逃逸分析就是确定一个对象是要放在&lt;code&gt;堆&lt;/code&gt;还是&lt;code&gt;栈&lt;/code&gt;上，一般遵循如下规则:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.是否有非局部调用(对象定义之外的调用).即:如果有可能被&lt;code&gt;引用&lt;/code&gt;，那通常会被分配到堆上，否则就在&lt;code&gt;栈上&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;2.如果对象太大(即使没有被引用),无法放在栈区也是可能放到&lt;code&gt;堆&lt;/code&gt;上的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总结起来就是: &lt;code&gt;如果在函数外部引用，必定在堆中分配;如果没有外部引用，优先在栈中分配;如果一个函数返回的是一个（局部）变量的地址，那么这个变量就发生逃逸&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;避免逃逸的好处:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.减少gc的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要gc标记清除&lt;/li&gt;
&lt;li&gt;2.逃逸分析完后可以确定哪些变量可以分配在栈上，栈的分配比堆快，性能好(系统开销少)&lt;/li&gt;
&lt;li&gt;3.减少动态分配所造成的内存碎片&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;如何进行逃逸分析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Golang程序中是在编译阶段确定逃逸的，而非运行时，因此我们可以使用&lt;code&gt;go build&lt;/code&gt;的相关工具来进行逃逸分析.&lt;/p&gt;

&lt;p&gt;分析工具:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.通过编译工具查看详细的逃逸分析过程(&lt;code&gt;go build -gcflags &#39;-m -l&#39; main.go&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;2.通过反编译命令查看&lt;code&gt;go tool compile -S main.go&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;编译参数介绍(-gcflags):&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-N&lt;/code&gt;: 禁止编译优化&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-l&lt;/code&gt;: 禁止内联(可以有效减少程序大小)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-m&lt;/code&gt;: 逃逸分析(最多可重复四次)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-benchmem&lt;/code&gt;: 压测时打印内存分配统计&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;堆&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;堆是除栈之外的第二个内存区域，用于存储值，&lt;code&gt;全局变量、内存占用大的局部变量、发生了逃逸的局部变量存在的地方就是堆&lt;/code&gt;，这块的内存没有特定的结构，也没有固定大小，可以根据需要进行调整(但也造成管理成本)，因此堆不像栈那样是自清理的，使用这个内存的成本更大(一般各个语言都会有自己的GC机制，在Golang中会使用&lt;code&gt;三色标记法&lt;/code&gt;来进行堆内存的垃圾回收)。&lt;/p&gt;

&lt;p&gt;首先，成本与垃圾收集器(GC)有关，垃圾收集器必须参与进来以保持该区域的清洁。当GC运行时，它将使用25%的可用CPU资源。此外，它可能会产生微秒级的“stop the world”延迟。拥有GC的好处是你不需要担心内存的管理问题，因为内存管理是相当复杂、也容易出错的。&lt;/p&gt;

&lt;p&gt;堆上的值构成Go中的内存分配。这些分配对GC造成压力，因为堆中不再被指针引用的每个值都需要删除。需要检查和删除的值越多，GC每次运行时必须执行的工作就越多。因此，GC算法一直在努力在堆的大小分配和运行速度之间寻求平衡。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;堆是进程级别的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;栈&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在程序中，每个函数块都会有自己的&lt;code&gt;内存区域&lt;/code&gt;用来存自己的&lt;code&gt;局部变量&lt;/code&gt;（内存占用少）、返回&lt;code&gt;地址、返回值&lt;/code&gt;之类的数据，这一块内存区域有特定的结构和寻址方式，&lt;code&gt;大小在编译时已经确定&lt;/code&gt;，寻址起来也十分迅速，开销很少。&lt;/p&gt;

&lt;p&gt;这块内存地址称为&lt;code&gt;栈&lt;/code&gt;，&lt;code&gt;栈是线程级别&lt;/code&gt;的，&lt;code&gt;大小在创建的时候已经确定&lt;/code&gt;，所以当数据太大的时候，就会发生&amp;rdquo;stack overflow&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;在Golang程序中，函数都是运行在&lt;code&gt;栈&lt;/code&gt;上的，在栈上声明临时变量分配内存，函数运行完成后回收该段栈空间，并且每个函数的栈空间都是独立的，其他代码不可访问的。但是在某些场景下，&lt;code&gt;栈上的空间&lt;/code&gt;需要在该函数被释放后依旧能访问到(函数外调用)，这时候就涉及到内存的逃逸了，而逃逸往往会对应对象的内存分配到堆上.&lt;/p&gt;

&lt;h3 id=&#34;逃逸分析示例&#34;&gt;逃逸分析示例&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1.示例-参数泄露&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;测试代码&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;// 定义一个简单的结构体
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;age&lt;/span&gt;     &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;webSite&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;// 获取用户信息
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetUserInfo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;u&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;u&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;// 获取用户名称
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;u&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;// 初始化user结构体的指针对象
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;BGBiao&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;https://bgbiao.top&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;nf&#34;&gt;GetUserInfo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;nf&#34;&gt;GetName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;使用&lt;code&gt;逃逸分析&lt;/code&gt;来进行内存分析&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ go build -gcflags &amp;#39;-m -m  -l&amp;#39; taoyi.go
# command-line-arguments
./taoyi.go:21:18: leaking param: u to result ~r1 level=0
./taoyi.go:25:14: leaking param: u to result ~r1 level=1
./taoyi.go:31:31: main &amp;amp;user literal does not escape&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由上述输出的&lt;code&gt;leaking param&lt;/code&gt;可以看到，在&lt;code&gt;GetUserInfo&lt;/code&gt;和&lt;code&gt;GetName&lt;/code&gt;函数中的&lt;code&gt;指针变量u&lt;/code&gt;是一个泄露参数，在两个函数中均没有对&lt;code&gt;u&lt;/code&gt;进行变量操作，就直接返回了变量内容，因此最后的该变量&lt;code&gt;user&lt;/code&gt;并没有发生逃逸，&lt;code&gt;&amp;amp;user&lt;/code&gt;对象还是作用在了&lt;code&gt;main()&lt;/code&gt;函数中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.示例-未知类型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个时候，我们把上面的代码稍微改动一下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;....
....
func main() {
    user := &amp;amp;user{&amp;#34;BGBiao&amp;#34;,18,&amp;#34;https://bgbiao.top&amp;#34;}
    fmt.Println(GetUserInfo(user))
    fmt.Println(GetName(user))
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;再次进行逃逸分析:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ go build -gcflags &amp;#39;-m -m  -l&amp;#39; taoyi.go
# command-line-arguments
./taoyi.go:21:18: leaking param: u to result ~r1 level=0
./taoyi.go:25:14: leaking param: u to result ~r1 level=1
./taoyi.go:31:31: &amp;amp;user literal escapes to heap
./taoyi.go:32:16: main ... argument does not escape
./taoyi.go:32:28: GetUserInfo(user) escapes to heap
./taoyi.go:33:16: main ... argument does not escape
./taoyi.go:33:24: GetName(user) escapes to heap&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由上可以发现我们的指针对象&lt;code&gt;&amp;amp;user&lt;/code&gt;在该程序中发生了逃逸，具体是在&lt;code&gt;GetUserInfo(user)&lt;/code&gt;和&lt;code&gt;GetName(user)&lt;/code&gt;发生了逃逸.&lt;/p&gt;

&lt;p&gt;这是为什么呢？怎么加了个&lt;code&gt;fmt.Println&lt;/code&gt;之后对象就发生了逃逸呢?&lt;/p&gt;

&lt;p&gt;其实主要原因为&lt;code&gt;fmt.Println&lt;/code&gt;函数的原因:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;func Println(a ...interface{}) (n int, err error)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;我们可以看到&lt;code&gt;fmt.Println(a)&lt;/code&gt;函数中入参为&lt;code&gt;interface{}&lt;/code&gt;类型，在编译阶段编译器无法确定其具体的类型。因此会产生逃逸，最终分配到堆上(最本质的原因是interface{}类型一般情况下底层会进行&lt;code&gt;reflect&lt;/code&gt;，而使用的&lt;code&gt;reflect.TypeOf(arg).Kind()&lt;/code&gt;获取接口类型对象的底层数据类型时发生了堆逃逸，最终就会反映为当入参是空接口类型时发生了逃逸)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.示例-指针&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此时，我们再小改点代码:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;// 返回结构体对象的指针，此时就会产生逃逸
func GetUserInfo(u user) (*user) {
    return &amp;amp;u
}

func main() {
    user := user{&amp;#34;BGBiao&amp;#34;,18,&amp;#34;https://bgbiao.top&amp;#34;}
    GetUserInfo(user)
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;逃逸分析:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ go build -gcflags &amp;#39;-m -m  -l&amp;#39; taoyi.go
# command-line-arguments
./taoyi.go:21:18: moved to heap: u

# 查看汇编代码(可以看到有个CALL	runtime.newobject(SB)的系统调用)
$ go tool compile -S taoyi.go | grep taoyi.go:21
	0x0000 00000 (taoyi.go:21)	TEXT	&amp;#34;&amp;#34;.GetUserInfo(SB), ABIInternal, $40-48
	0x0000 00000 (taoyi.go:21)	MOVQ	(TLS), CX
	0x0009 00009 (taoyi.go:21)	CMPQ	SP, 16(CX)
	0x000d 00013 (taoyi.go:21)	JLS	147
	0x0013 00019 (taoyi.go:21)	SUBQ	$40, SP
	0x0017 00023 (taoyi.go:21)	MOVQ	BP, 32(SP)
	0x001c 00028 (taoyi.go:21)	LEAQ	32(SP), BP
	0x0021 00033 (taoyi.go:21)	FUNCDATA	$0, gclocals·fb57040982f53920ad6a8ad662a1594f(SB)
	0x0021 00033 (taoyi.go:21)	FUNCDATA	$1, gclocals·263043c8f03e3241528dfae4e2812ef4(SB)
	0x0021 00033 (taoyi.go:21)	FUNCDATA	$2, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB)
	0x0021 00033 (taoyi.go:21)	PCDATA	$0, $1
	0x0021 00033 (taoyi.go:21)	PCDATA	$1, $0
	0x0021 00033 (taoyi.go:21)	LEAQ	type.&amp;#34;&amp;#34;.user(SB), AX
	0x0028 00040 (taoyi.go:21)	PCDATA	$0, $0
	0x0028 00040 (taoyi.go:21)	MOVQ	AX, (SP)
	0x002c 00044 (taoyi.go:21)	CALL	runtime.newobject(SB)
	0x0031 00049 (taoyi.go:21)	PCDATA	$0, $1
	0x0031 00049 (taoyi.go:21)	MOVQ	8(SP), AX
	0x0036 00054 (taoyi.go:21)	PCDATA	$0, $-2
	0x0036 00054 (taoyi.go:21)	PCDATA	$1, $-2
	0x0036 00054 (taoyi.go:21)	CMPL	runtime.writeBarrier(SB), $0
	0x003d 00061 (taoyi.go:21)	JNE	104
	0x003f 00063 (taoyi.go:21)	MOVQ	&amp;#34;&amp;#34;.u+48(SP), CX
	0x0044 00068 (taoyi.go:21)	MOVQ	CX, (AX)
	0x0047 00071 (taoyi.go:21)	MOVUPS	&amp;#34;&amp;#34;.u+56(SP), X0
	0x004c 00076 (taoyi.go:21)	MOVUPS	X0, 8(AX)
	0x0050 00080 (taoyi.go:21)	MOVUPS	&amp;#34;&amp;#34;.u+72(SP), X0
	0x0055 00085 (taoyi.go:21)	MOVUPS	X0, 24(AX)
	0x0068 00104 (taoyi.go:21)	PCDATA	$0, $-2
	0x0068 00104 (taoyi.go:21)	PCDATA	$1, $-2
	0x0068 00104 (taoyi.go:21)	MOVQ	AX, &amp;#34;&amp;#34;.&amp;amp;u+24(SP)
	0x006d 00109 (taoyi.go:21)	LEAQ	type.&amp;#34;&amp;#34;.user(SB), CX
	0x0074 00116 (taoyi.go:21)	MOVQ	CX, (SP)
	0x0078 00120 (taoyi.go:21)	MOVQ	AX, 8(SP)
	0x007d 00125 (taoyi.go:21)	LEAQ	&amp;#34;&amp;#34;.u+48(SP), CX
	0x0082 00130 (taoyi.go:21)	MOVQ	CX, 16(SP)
	0x0087 00135 (taoyi.go:21)	CALL	runtime.typedmemmove(SB)
	0x0091 00145 (taoyi.go:21)	JMP	89
	0x0093 00147 (taoyi.go:21)	NOP
	0x0093 00147 (taoyi.go:21)	PCDATA	$1, $-1
	0x0093 00147 (taoyi.go:21)	PCDATA	$0, $-1
	0x0093 00147 (taoyi.go:21)	CALL	runtime.morestack_noctxt(SB)
	0x0098 00152 (taoyi.go:21)	JMP	0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由以上输出可以看到在&lt;code&gt;GetUserInfo(u user)&lt;/code&gt;函数中的对象u已经被移到&lt;code&gt;堆&lt;/code&gt;上了，这是因为该函数返回的是&lt;code&gt;指针对象&lt;/code&gt;，引用对象被返回到方法之外了(此时该引用对象可以在外部被调用和修改)，因此编译器会把该对象分配到堆上(否则方法结束后，局部变量被回收岂不是很惨)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.示例-综合案例&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;BGBiao&amp;#34;&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;build&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;gcflags&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;line&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;arguments&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escape&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;在上面第三个示例中我们提到，当返回对象是&lt;code&gt;指针类型&lt;/code&gt;(引用对象)时，就会发现逃逸，但上面的示例其实告诉我们虽然&lt;code&gt;*name&lt;/code&gt;是一个指针类型，但是并未发生逃逸，这是因为&lt;code&gt;该引用类型未被外部使用&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;但是又如第二个示例中所说，如果我们在上面的示例中增加&lt;code&gt;fmt.Println(name)&lt;/code&gt;后，会发现该实例又会出现逃逸.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;:虽然当使用fmt.Println的时候又会出现逃逸，但是当使用fmt.Println(*name)和fmt.Println(name)，也是不同的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;demo1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;BGBiao&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;build&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;gcflags&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;line&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;arguments&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escape&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;argument&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escape&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escapes&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;heap&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由上述输出可看到，当使用引用类型来获取底层的值时，在&lt;code&gt;fmt.Println&lt;/code&gt;的入参处&lt;code&gt;*name&lt;/code&gt;发生了逃逸.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;demo2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;BGBiao&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;build&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;gcflags&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;line&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;arguments&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escapes&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;heap&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;argument&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;does&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escape&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;taoyi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;demo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;escapes&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;heap&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;而这次我们使用&lt;code&gt;fmt.Println(name)&lt;/code&gt;来输出底层值，就会发现变量&lt;code&gt;name&lt;/code&gt;在初始化的时候就会出现逃逸&lt;code&gt;new(string)&lt;/code&gt;，&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;通过上面的概念和实例分析，我们基本知道了逃逸分析的概念和规则，并且大概知道何时，那种对象会被分配到堆或栈内存中，在实际情况中可能情况会更加复杂，需要具体分析。&lt;/p&gt;

&lt;p&gt;不过，有如下几点可能在我们实际使用过程中要注意下:
- 静态分配到栈上，性能一定比动态分配到堆上好
- 底层分配到堆，还是栈。实际上对你来说是透明的，不需要过度关心
- 每个 Go 版本的逃逸分析都会有所不同（会改变，会优化)
- 直接通过&lt;code&gt;go build -gcflags &#39;-m -l&#39;&lt;/code&gt; 就可以看到逃逸分析的过程和结果
- 到处都用&lt;code&gt;指针传递并不一定是最好的&lt;/code&gt;，要用对
- map &amp;amp; slice 初始化时，预估容量，避免由扩展导致的内存分配。但是如果太大（10000）也会逃逸，因为栈的空间是有限的&lt;/p&gt;

&lt;h3 id=&#34;思考&#34;&gt;思考&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;函数传递指针真的比传值效率高吗？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们知道传递指针可以减少底层值的拷贝，可以提高效率，但是如果拷贝的数据量小，由于指针传递会产生逃逸，可能会使用堆，也可能会增加GC的负担，所以传递指针不一定是高效的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;内存碎片化问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实际项目基本都是通过 &lt;code&gt;c := make([]int, 0, l)&lt;/code&gt; 来申请内存，长度都是不确定的，自然而然这些变量都会申请到堆上面了.&lt;/p&gt;

&lt;p&gt;Golang使用的垃圾回收算法是『标记——清除』.&lt;/p&gt;

&lt;p&gt;简单得说，就是程序要从操作系统申请一块比较大的内存，内存分成小块，通过链表链接。&lt;/p&gt;

&lt;p&gt;每次程序申请内存，就从链表上面遍历每一小块，找到符合的就返回其地址，没有合适的就从操作系统再申请。如果申请内存次数较多，而且申请的大小不固定，就会引起内存碎片化的问题。&lt;/p&gt;

&lt;p&gt;申请的堆内存并没有用完，但是用户申请的内存的时候却没有合适的空间提供。这样会遍历整个链表，还会继续向操作系统申请内存。这就能解释我一开始描述的问题，申请一块内存变成了慢语句。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
