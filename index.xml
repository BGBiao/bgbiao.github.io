<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BGBiao的SRE人生</title>
    <link>https://bgbiao.top/</link>
    <description>Recent content on BGBiao的SRE人生</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 04 Jul 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bgbiao.top/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ElasticSearch容量管理实践</title>
      <link>https://bgbiao.top/post/elasticsearch%E5%AE%B9%E9%87%8F%E7%AE%A1%E7%90%86%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/elasticsearch%E5%AE%B9%E9%87%8F%E7%AE%A1%E7%90%86%E5%AE%9E%E8%B7%B5/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 了解 ES 的索引管理方法有助于扬长避短，更好的利用 ES 的强大功能，特别是当遇到性能问题时，原因通常都可回溯至数据的索引方式以及集群中的分片数量。如果未能在一开始做出最佳选择，随着数据量越来越大，便有可能会引发性能问题。集群中的数据越多，要纠正这一问题就越难，本文旨在帮助大家了解 ES 容量管理的方法，在一开始就管理好索引的容量，避免给后面留坑。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;为什么要做容量管理&#34;&gt;为什么要做容量管理&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;在生产环境使用 ES 要面对的第一个问题通常是索引容量的规划，不合理的分片数，副本数和分片大小会对索引的性能产生直接的影响。&lt;/li&gt;
&lt;li&gt;Elasticsearch 中的每个索引都由一个或多个分片组成的，每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询。&lt;/li&gt;
&lt;li&gt;查询和写入的性能与索引的大小是正相关的，所以要保证高性能，一定要限制索引的大小，具体来说是限制分片数量和单个分片的大小。&lt;/li&gt;
&lt;li&gt;分片和索引的大小太大和太多容易导致性能问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster?nsukey=GabPjf5OZF0QUSaLqrsDSnv0gl3NYrMXkFpMCqgodCTJVDuEWGlFFEpd2M4FL6peUue8SXsLBtSh24jg5sT73xK%2BIMFUQ%2FcrYnpp2fjHbiId72hUU4n6CPs4SW78M0r4sAldN%2BGI%2B2kiYoGJ4G2p%2Br767kWmctAZhBWU99rxb9he%2BAwTBK%2B1lA49grlc7tQ2xU7XHd6xhx%2FCAy%2FneZWNSg%3D%3D&#34;&gt;官方博客建议的分片数量&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt; ES 官方推荐分片的大小是 20G - 40G，最大不能超过 50G。&lt;/p&gt;

&lt;h3 id=&#34;如何管理es的容量&#34;&gt;如何管理ES的容量&lt;/h3&gt;

&lt;p&gt;在介绍了为何要管理ES的容量后，我们接下来需要考虑的是如何进行管理，以下为通常的做法。&lt;/p&gt;

&lt;h4 id=&#34;1-使用在索引名称上带上时间的方法管理索引&#34;&gt;1. 使用在索引名称上带上时间的方法管理索引&lt;/h4&gt;

&lt;p&gt;例如: &lt;logs-{now{yyyyMMddHH|+08:00}}-000001&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是，在使用HTTP接口创建索引时，索引名称要进行urlencode编码:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1写入和查询索引&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建索引
$ PUT /%3Cnginxlogs-%7Bnow%7ByyyyMMddHH%7C%2B08%3A00%7D%7D-000001%3E
{
  &amp;#34;aliases&amp;#34;: {
  &amp;#34;nginxlogs-read-alias&amp;#34;: {}
  }
}
# 返回结果
{
  &amp;#34;acknowledged&amp;#34; : true,
  &amp;#34;shards_acknowledged&amp;#34; : true,
  &amp;#34;index&amp;#34; : &amp;#34;nginxlogs-2020061518-000001&amp;#34;
}

# 写入数据
$ POST /%3Cnginxlogs-%7Bnow%7ByyyyMMddHH%7C%2B08%3A00%7D%7D-000001%3E/_doc
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
{
  &amp;#34;_index&amp;#34; : &amp;#34;nginxlogs-2020061518-000001&amp;#34;,
  &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
  &amp;#34;_id&amp;#34; : &amp;#34;VNZut3IBgpLCCHbxDzDB&amp;#34;,
  &amp;#34;_version&amp;#34; : 1,
  &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
  &amp;#34;_shards&amp;#34; : {
    &amp;#34;total&amp;#34; : 2,
    &amp;#34;successful&amp;#34; : 2,
    &amp;#34;failed&amp;#34; : 0
  },
  &amp;#34;_seq_no&amp;#34; : 0,
  &amp;#34;_primary_term&amp;#34; : 1
}

# 查询数据 
## 使用多索引查询
$ GET /nginxlogs-2020061518-000001,nginxlogs-2020061519-000001/_search
{&amp;#34;query&amp;#34;:{&amp;#34;match_all&amp;#34;:{}}}

## 使用通配符查询多索引
$ GET /nginxlogs-*/_search
{
  &amp;#34;query&amp;#34;: {
    &amp;#34;match_all&amp;#34;: {}
  }
}
{
  &amp;#34;took&amp;#34; : 0,
  &amp;#34;timed_out&amp;#34; : false,
  &amp;#34;_shards&amp;#34; : {
    &amp;#34;total&amp;#34; : 1,
    &amp;#34;successful&amp;#34; : 1,
    &amp;#34;skipped&amp;#34; : 0,
    &amp;#34;failed&amp;#34; : 0
  },
  &amp;#34;hits&amp;#34; : {
    &amp;#34;total&amp;#34; : {
      &amp;#34;value&amp;#34; : 1,
      &amp;#34;relation&amp;#34; : &amp;#34;eq&amp;#34;
    },
    &amp;#34;max_score&amp;#34; : 1.0,
    &amp;#34;hits&amp;#34; : [
      {
        &amp;#34;_index&amp;#34; : &amp;#34;nginxlogs-2020061518-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;VNZut3IBgpLCCHbxDzDB&amp;#34;,
        &amp;#34;_score&amp;#34; : 1.0,
        &amp;#34;_source&amp;#34; : {
          &amp;#34;name&amp;#34; : &amp;#34;xxx&amp;#34;
        }
      }
    ]
  }
}

# 使用别名查询
$ GET /nginxlogs-read-alias/_search
{
  &amp;#34;query&amp;#34;: {
    &amp;#34;match_all&amp;#34;: {}
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.2时间索引的缺点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt; 虽然使用带时间的索引可以带来很多方便，但是在实际过程中使用带时间的索引也有一定的缺陷。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于写入之后需要数据变更的不是用时间索引&lt;/li&gt;
&lt;li&gt;直接使用时间分割也可能存在某段时间数据量集中，导致索引分片超过设计容量的问题，可能影响性能&lt;/li&gt;
&lt;li&gt;索引维护起来比较麻烦(当然可以使用template进行管理，前提是满足业务需求)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2-使用-rollover-管理索引&#34;&gt;2. 使用 Rollover 管理索引&lt;/h4&gt;

&lt;p&gt;Rollover 的原理是使用一个别名指向真正的索引，当指向的索引满足一定条件（&lt;strong&gt;文档数或时间或索引大小&lt;/strong&gt;）更新实际指向的索引。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.1创建索引&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;PUT myro-000001
{
  &amp;#34;aliases&amp;#34;: {
    &amp;#34;myro_write_alias&amp;#34;:{}
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.2通过别名写入数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里使用&lt;code&gt;bulk&lt;/code&gt;接口进行写入数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ POST /myro_write_alias/_bulk?refresh=true
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}

{
  &amp;#34;took&amp;#34; : 37,
  &amp;#34;errors&amp;#34; : false,
  &amp;#34;items&amp;#34; : [
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myro-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;wVvFtnIBUTVfQxRWwXyM&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 0,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    },
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myro-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;wlvFtnIBUTVfQxRWwXyM&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 1,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    },
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myro-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;w1vFtnIBUTVfQxRWwXyM&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 2,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    }
  ]
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.3执行 rollover 操作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;给索引设置具体的&lt;code&gt;rollover&lt;/code&gt;条件，任意一个条件触发都会进行rollover:&lt;/p&gt;

&lt;p&gt;下面我们给索引别名设置rollover规则为&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;最大文档数为3&lt;/li&gt;
&lt;li&gt;分片最大大小为5gb&lt;/li&gt;

&lt;li&gt;&lt;p&gt;文档最长时间7d&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ POST /myro_write_alias/_rollover
{
&amp;#34;conditions&amp;#34;: {
&amp;#34;max_age&amp;#34;:   &amp;#34;7d&amp;#34;,
&amp;#34;max_docs&amp;#34;:  3,
&amp;#34;max_size&amp;#34;: &amp;#34;5gb&amp;#34;
}
}
{
&amp;#34;acknowledged&amp;#34; : true,
&amp;#34;shards_acknowledged&amp;#34; : true,
&amp;#34;old_index&amp;#34; : &amp;#34;myro-000001&amp;#34;,
&amp;#34;new_index&amp;#34; : &amp;#34;myro-000002&amp;#34;,
&amp;#34;rolled_over&amp;#34; : true,
&amp;#34;dry_run&amp;#34; : false,
&amp;#34;conditions&amp;#34; : {
&amp;#34;[max_docs: 3]&amp;#34; : true,
&amp;#34;[max_size: 5gb]&amp;#34; : false,
&amp;#34;[max_age: 7d]&amp;#34; : false
}
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此时，我们已经设置了rollover规则，这个时候尝试继续写入.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ POST /myro_write_alias/_doc
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
# 发现已经写入新的索引，因为前面已经有三个doc，这次写入触发了rollover规则
{
  &amp;#34;_index&amp;#34; : &amp;#34;myro-000002&amp;#34;,
  &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
  &amp;#34;_id&amp;#34; : &amp;#34;BdbMtnIBgpLCCHbxhihi&amp;#34;,
  &amp;#34;_version&amp;#34; : 1,
  &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
  &amp;#34;_shards&amp;#34; : {
    &amp;#34;total&amp;#34; : 2,
    &amp;#34;successful&amp;#34; : 2,
    &amp;#34;failed&amp;#34; : 0
  },
  &amp;#34;_seq_no&amp;#34; : 0,
  &amp;#34;_primary_term&amp;#34; : 1
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.4使用 Rollover 的缺点&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;必须对索引别名先进行&lt;code&gt;rollover&lt;/code&gt;规则设置才可以进行自动roll&lt;/li&gt;
&lt;li&gt;对于开发者不够友好&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;3-使用-ilm-index-lifecycle-management-管理索引&#34;&gt;3. 使用 ILM（Index Lifecycle Management ） 管理索引&lt;/h4&gt;

&lt;p&gt;ES 一直在索引管理这块进行优化迭代，从 6.7 版本推出了索引生命周期管理（Index Lifecycle Management ，简称 ILM) 机制，是目前官方提供的比较完善的索引管理方法。所谓 Lifecycle (生命周期) 是把索引定义了四个阶段：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1ggffd4ohqzj30r505a0tb.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Hot&lt;/code&gt;: 索引可写入，也可查询，也就是我们通常说的热数据，为保证性能数据通常都是在内存中的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Warm&lt;/code&gt;: 索引不可写入，但可查询，介于热和冷之间，数据可以是全内存的，也可以是在 SSD 的硬盘上的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cold&lt;/code&gt;: 索引不可写入，但很少被查询，查询的慢点也可接受，基本不再使用的数据，数据通常在大容量的磁盘上&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Delete&lt;/code&gt;: 索引可被安全的删除&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这 4 个阶段是 ES 定义的一个索引从生到死的过程，Hot -&amp;gt; Warm -&amp;gt; Cold -&amp;gt; Delete 4 个阶段只有 Hot 阶段是必须的，其他 3 个阶段根据业务的需求可选。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1简历Lifecycle策略&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1ggfff9rinjj30u00rc77v.jpg&#34; alt=&#34;kibina中创建lifecycle策略&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如图，只启用了&lt;code&gt;Hot&lt;/code&gt;阶段，并且设置了rollover规则。&lt;/p&gt;

&lt;p&gt;对应的HTTP请求参数如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ PUT _ilm/policy/myindex-lifecycle
{
  &amp;#34;policy&amp;#34;: {
    &amp;#34;phases&amp;#34;: {
      &amp;#34;hot&amp;#34;: {
        &amp;#34;min_age&amp;#34;: &amp;#34;0ms&amp;#34;,
        &amp;#34;actions&amp;#34;: {
          &amp;#34;rollover&amp;#34;: {
            &amp;#34;max_age&amp;#34;: &amp;#34;30d&amp;#34;,
            &amp;#34;max_size&amp;#34;: &amp;#34;50gb&amp;#34;,
            &amp;#34;max_docs&amp;#34;: 2
          },
          &amp;#34;set_priority&amp;#34;: {
            &amp;#34;priority&amp;#34;: 100
          }
        }
      }
    }
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.2建立索引模板&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ PUT /_template/myindex_template
{
  &amp;#34;index_patterns&amp;#34;: [
    &amp;#34;myindex-*&amp;#34;
  ],
  &amp;#34;aliases&amp;#34;: {
    &amp;#34;myindex_reade_alias&amp;#34;: {}
  },
  &amp;#34;settings&amp;#34;: {
    &amp;#34;index&amp;#34;: {
      &amp;#34;lifecycle&amp;#34;: {
        &amp;#34;name&amp;#34;: &amp;#34;myindex-lifecycle&amp;#34;,
        &amp;#34;rollover_alias&amp;#34;: &amp;#34;myindex_write_alias&amp;#34;
      },
      &amp;#34;refresh_interval&amp;#34;: &amp;#34;30s&amp;#34;,
      &amp;#34;number_of_shards&amp;#34;: &amp;#34;12&amp;#34;,
      &amp;#34;number_of_replicas&amp;#34;: &amp;#34;1&amp;#34;
    }
  },
  &amp;#34;mappings&amp;#34;: {
    &amp;#34;properties&amp;#34;: {
      &amp;#34;name&amp;#34;: {
        &amp;#34;type&amp;#34;: &amp;#34;keyword&amp;#34;
      }
    }
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;模板匹配以索引前缀开头的索引(myindex-)&lt;/li&gt;
&lt;li&gt;使用此模板的索引会自动创建&lt;code&gt;myindex_write_alias&lt;/code&gt;的别名，方便数据检索&lt;/li&gt;
&lt;li&gt;模版绑定了上面创建的 Lifecycle 策略，并且用于 rollover 的别名是&lt;code&gt;myindex_write_alias&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;4.3创建索引&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ PUT /myindex-testindex-000001
{
  &amp;#34;aliases&amp;#34;: {
    &amp;#34;myindex_write_alias&amp;#34;:{}
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.4查看索引配置&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ GET /myindex-testindex-000001
{}
{
  &amp;#34;myindex-testindex-000001&amp;#34; : {
    &amp;#34;aliases&amp;#34; : {
      &amp;#34;myindex_reade_alias&amp;#34; : { },
      &amp;#34;myindex_write_alias&amp;#34; : { }
    },
    &amp;#34;mappings&amp;#34; : {
      &amp;#34;dynamic_templates&amp;#34; : [
        {
          &amp;#34;message_full&amp;#34; : {
            &amp;#34;match&amp;#34; : &amp;#34;message_full&amp;#34;,
            &amp;#34;mapping&amp;#34; : {
              &amp;#34;fields&amp;#34; : {
                &amp;#34;keyword&amp;#34; : {
                  &amp;#34;ignore_above&amp;#34; : 2048,
                  &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34;
                }
              },
              &amp;#34;type&amp;#34; : &amp;#34;text&amp;#34;
            }
          }
        },
        {
          &amp;#34;message&amp;#34; : {
            &amp;#34;match&amp;#34; : &amp;#34;message&amp;#34;,
            &amp;#34;mapping&amp;#34; : {
              &amp;#34;type&amp;#34; : &amp;#34;text&amp;#34;
            }
          }
        },
        {
          &amp;#34;strings&amp;#34; : {
            &amp;#34;match_mapping_type&amp;#34; : &amp;#34;string&amp;#34;,
            &amp;#34;mapping&amp;#34; : {
              &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34;
            }
          }
        }
      ],
      &amp;#34;properties&amp;#34; : {
        &amp;#34;name&amp;#34; : {
          &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34;
        }
      }
    },
    &amp;#34;settings&amp;#34; : {
      &amp;#34;index&amp;#34; : {
        &amp;#34;lifecycle&amp;#34; : {
          &amp;#34;name&amp;#34; : &amp;#34;myindex-lifecycle&amp;#34;,
          &amp;#34;rollover_alias&amp;#34; : &amp;#34;myindex_write_alias&amp;#34;
        },
        &amp;#34;refresh_interval&amp;#34; : &amp;#34;30s&amp;#34;,
        &amp;#34;number_of_shards&amp;#34; : &amp;#34;12&amp;#34;,
        &amp;#34;translog&amp;#34; : {
          &amp;#34;sync_interval&amp;#34; : &amp;#34;5s&amp;#34;,
          &amp;#34;durability&amp;#34; : &amp;#34;async&amp;#34;
        },
        &amp;#34;provided_name&amp;#34; : &amp;#34;myindex-testindex-000001&amp;#34;,
        &amp;#34;max_result_window&amp;#34; : &amp;#34;65536&amp;#34;,
        &amp;#34;creation_date&amp;#34; : &amp;#34;1592222799955&amp;#34;,
        &amp;#34;unassigned&amp;#34; : {
          &amp;#34;node_left&amp;#34; : {
            &amp;#34;delayed_timeout&amp;#34; : &amp;#34;5m&amp;#34;
          }
        },
        &amp;#34;priority&amp;#34; : &amp;#34;100&amp;#34;,
        &amp;#34;number_of_replicas&amp;#34; : &amp;#34;1&amp;#34;,
        &amp;#34;uuid&amp;#34; : &amp;#34;tPwDbkuvRjKtRHiL4fKcPA&amp;#34;,
        &amp;#34;version&amp;#34; : {
          &amp;#34;created&amp;#34; : &amp;#34;7050199&amp;#34;
        }
      }
    }
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.5写入数据&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ POST /myindex_write_alias/_bulk?refresh=true
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}
{&amp;#34;create&amp;#34;:{}}
{&amp;#34;name&amp;#34;:&amp;#34;xxx&amp;#34;}

{
  &amp;#34;took&amp;#34; : 18,
  &amp;#34;errors&amp;#34; : false,
  &amp;#34;items&amp;#34; : [
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myindex-testindex-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;jF3it3IBUTVfQxRW1Xys&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 0,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    },
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myindex-testindex-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;jV3it3IBUTVfQxRW1Xys&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 0,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    },
    {
      &amp;#34;create&amp;#34; : {
        &amp;#34;_index&amp;#34; : &amp;#34;myindex-testindex-000001&amp;#34;,
        &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;,
        &amp;#34;_id&amp;#34; : &amp;#34;jl3it3IBUTVfQxRW1Xys&amp;#34;,
        &amp;#34;_version&amp;#34; : 1,
        &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;,
        &amp;#34;forced_refresh&amp;#34; : true,
        &amp;#34;_shards&amp;#34; : {
          &amp;#34;total&amp;#34; : 2,
          &amp;#34;successful&amp;#34; : 2,
          &amp;#34;failed&amp;#34; : 0
        },
        &amp;#34;_seq_no&amp;#34; : 0,
        &amp;#34;_primary_term&amp;#34; : 1,
        &amp;#34;status&amp;#34; : 201
      }
    }
  ]
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.6配置 Lifecycle 自动 Rollover 的时间间隔&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于ElasticSearch并不是一个realtime的的系统，因此很多操作并不能及时生效，因此需要在lifecycle中设置时间间隔。而ElasticSearch中默认的&lt;code&gt;ILM&lt;/code&gt;策略的时间间隔为10min。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 修改时间间隔
$ PUT _cluster/settings
{
  &amp;#34;transient&amp;#34;: {
    &amp;#34;indices.lifecycle.poll_interval&amp;#34;: &amp;#34;3s&amp;#34;
  }
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Traefik中的502-500状态码异常排查</title>
      <link>https://bgbiao.top/post/traefik%E4%B8%AD%E7%9A%84502-500%E7%8A%B6%E6%80%81%E7%A0%81%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/traefik%E4%B8%AD%E7%9A%84502-500%E7%8A%B6%E6%80%81%E7%A0%81%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;我们都知道在Kubernetes集群中通常会使用Ingress方案来统一代理集群内部的流量，而常用的Ingress方案为&lt;a href=&#34;https://docs.traefik.io/&#34;&gt;traefik&lt;/a&gt;和&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;nginx&lt;/a&gt;，和传统的Nginx作为企业内部的反向代理以及负载设备一样，在不同的场景下可能需要专有的配置才能满足需求，否则会出现奇奇怪怪的异常状态码。本篇文章一起来看下，我们在&lt;code&gt;traefik&lt;/code&gt;中遇到的500和502异常。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;一-前言&#34;&gt;一、前言&lt;/h3&gt;

&lt;p&gt;在开始之前，我们先来看几个在Nginx作为反向代理工具中经常遇到的几个异常状态码：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;499: 客户端主动断开连接。通常为一次请求未在客户端指定时间内返回，客户端主动关闭连接，客户端无数据返回(在Nginx中会记录499)。一般是&lt;code&gt;客户端超时&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;500: 服务器内部错误。服务器遇到未知错误导致无法完成请求处理，通常由于后端业务逻辑异常导致(本身Bug)&lt;/li&gt;
&lt;li&gt;502: 网关错误。通常为网关未从上游服务中获取期望的响应(&lt;code&gt;上游未返回数据或未按照协议约定返回数据&lt;/code&gt;)，网关感觉自己没用了，返回了网关错误。一般是&lt;code&gt;后端服务器宕机&lt;/code&gt;或&lt;code&gt;业务逻辑超时&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;504: 网关超时。表示网关没有及时从上游获取响应数据。一般是Nginx网关作为客户端去向上游服务请求响应的过程中，Nginx网关超时导致，但此时对于上游服务器来将，它会继续执行，直到结束。(&lt;code&gt;Nginx网关作为客户端时的超时&lt;/code&gt;)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 499 的实际情况就是，客户端指定超时时间为N秒，但是该请求在服务端实际需要执行M秒(M&amp;gt;N秒)，客户端等的不耐烦了就关闭了
# 对于499状态来讲，解决方式是优化后端代码逻辑或者修改nginx参数
$ cat nginx.conf
proxy_ignore_client_abort    on;
$ curl -i -m 3 http://127.0.0.1/hello.php


# 502的实际情况通常是Nginx网关后端的服务器直接宕机了(所以就拿不到上游的响应了)
# 当然也有可能是上游服务器真正的执行逻辑超过了上游服务器的超时时间限制(比如php-fpm.conf设置request_terminate_timeout5s，但是实际的业务逻辑需要7s才能完成)，此时上游服务器端出现`业务逻辑超时`，给Nginx网关返回了异常的数据造成的
# 502时后端的几种错误日志
recv() failed (104: Connection reset by peer) while reading response header from upstream
upstream prematurely closed connection while reading response header from upstream
connect() failed (111: Connection refused) while connecting to upstream
# 整体来说502出现的问题通常是因为后端挂了，或者因为后端负载太高，暂时不可响应
# 可以在nginx侧增加proxy_read_timeout来暂时缓解
$ cat nginx.conf
proxy_read_timeout  20s;

# 504的实际情况就是客户端-&amp;gt;Nginx-&amp;gt;Backend，在过程中Nginx需要作为客户端访问Backend服务，但是在Backend还没用执行完成时，Nginx首先超过了自己的客户端超时时间，此时就会出现504的异常(但是对于客户端来说返回什么呢?)
# 对于504场景而言，通常的做法就是优化Backend的逻辑，适当减少执行时间；另外也可以适当的增加Nginx作为客户端时的超时时间
# 要知道，当Nginx作为客户端时，是以一个Proxy的角色存在的，配置如下参数即可
$ cat nginx.conf
uwsgi_connect_timeout 5;
uwsgi_send_timeout 5;
uwsgi_read_timeout 5;
fastcgi_read_timeout 5;
fastcgi_send_timeout 5;
proxy_connect_timeout      90;
proxy_send_timeout         90;
proxy_read_timeout         90;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;二-traefik中诡异的500和502&#34;&gt;二、traefik中诡异的500和502&lt;/h3&gt;

&lt;h4 id=&#34;traefik在kubernetes集群中的部署配置&#34;&gt;traefik在Kubernetes集群中的部署配置&lt;/h4&gt;

&lt;p&gt;我们当前集群的traefik的配置如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# traefik的configmap配置文件
$ cat traefik-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: traefik-config
  namespace: kube-system
data:
  traefik.toml: |
    defaultEntryPoints = [&amp;#34;http&amp;#34;,&amp;#34;https&amp;#34;]
    debug = false
    logLevel = &amp;#34;INFO&amp;#34;

    InsecureSkipVerify = true
    [entryPoints]
      [entryPoints.http]
      address = &amp;#34;:80&amp;#34;
      compress = true
      [entryPoints.https]
      address = &amp;#34;:443&amp;#34;
        [entryPoints.https.tls]
    [web]
      address = &amp;#34;:8080&amp;#34;
    [kubernetes]
    [metrics]
      [metrics.prometheus]
      buckets=[0.1,0.3,1.2,5.0]
      entryPoint = &amp;#34;traefik&amp;#34;
    [ping]
    entryPoint = &amp;#34;http&amp;#34;

# traefik的DaemonSet配置
$ cat traefik-ds-v1.7.16.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      containers:
      - image: traefik:v1.7.16
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8080
        securityContext:
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
        - --traefikLog.filePath=/logdata/traefik.log
        - --configfile=/config/traefik.toml
        - --accesslog.filepath=/logdata/access.log
        - --accesslog.bufferingsize=100
        volumeMounts:
        - mountPath: /config
          name: config
        - mountPath: /logdata
          name: access-log
      volumes:
      - configMap:
          name: traefik-config
        name: config
      - name: access-log
        hostPath:
          path: /opt/logs/ingress/
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8080
      name: admin&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;python的对外api接口&#34;&gt;Python的对外API接口&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 接口对外的ingress
$ kubectl  get ingress -n s-data
NAME                     HOSTS                    ADDRESS   PORTS   AGE
data-api.bgbiao.cn   data-api.bgbiao.cn             80      236d
ops.bgbiao.cn       ops.bgbiao.cn                 80      236d

# 测试对外接口
$ curl data-api.bgbiao.cn  -i
HTTP/1.1 401 Unauthorized
Access-Control-Allow-Headers: Content-Type, X-TOKEN
Access-Control-Allow-Origin: *
Content-Length: 58
Content-Type: application/json
Vary: Accept-Encoding
Date: Sun, 28 Jun 2020 14:55:00 GMT

# 接口需要登录，那么我们对登录接口进行压测来模拟问题
$ curl -X POST  --data &amp;#39;@/root/login.json&amp;#39; -H &amp;#39;Content-type:application/json&amp;#39; http://data-api.bgbiao.cn/account/users/login/   -i
HTTP/1.1 200 OK
Access-Control-Allow-Headers: Content-Type, X-TOKEN
Access-Control-Allow-Origin: *
Content-Length: 250
Content-Type: application/json
Vary: Accept-Encoding
Date: Sun, 28 Jun 2020 14:56:33 GMT&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;诡异的500和502&#34;&gt;诡异的500和502&lt;/h4&gt;

&lt;p&gt;在服务部署完成后，一切皆正常，但是简单压测后发现服务出现部分请求失败。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 使用ab工具进行压测
# 由压测结果可以发现，20个并发共压测200个请求，期间出现了7次失败请求
$ ab -c 20 -n 200   -T &amp;#39;application/json&amp;#39; -p /root/login.json http://data-api.bgbiao.cn/account/users/login/
...
Benchmarking data-api.bgbiao.cn (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests


Server Software:
Server Hostname:        data-api.bgbiao.cn
Server Port:            80

Document Path:          /account/users/login/
Document Length:        250 bytes

Concurrency Level:      20
Time taken for tests:   1.340 seconds
Complete requests:      200
Failed requests:        7
   (Connect: 0, Receive: 0, Length: 7, Exceptions: 0)
Write errors:           0
Non-2xx responses:      7
Total transferred:      91371 bytes
Total body sent:        46400
HTML transferred:       48387 bytes
Requests per second:    149.21 [#/sec] (mean)
Time per request:       134.035 [ms] (mean)
Time per request:       6.702 [ms] (mean, across all concurrent requests)
Transfer rate:          66.57 [Kbytes/sec] received
                        33.81 kb/s sent
                        100.38 kb/s total

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    1   0.1      1       1
Processing:     2  116  27.8    114     179
Waiting:        2  116  27.8    114     179
Total:          3  117  27.8    116     180

Percentage of the requests served within a certain time (ms)
  50%    116
  66%    121
  75%    125
  80%    129
  90%    154
  95%    167
  98%    173
  99%    175
 100%    180 (longest request)


# 将压测结果保存到文本中进行简单分析
# 简单分析在200个压测请求中，有4个请求失败，分别为2次500错误和2次502错误
$ ab -v 10 -c 20 -n 200   -T &amp;#39;application/json&amp;#39; -p /root/login.json http://data-api.bgbiao.cn/account/users/login/  &amp;gt; ab-log.txt
$ cat ab-log.txt | grep HTTP | sort| uniq -c
    196 HTTP/1.0 200 OK
      2 HTTP/1.0 500 Internal Server Error
      2 HTTP/1.0 502 Bad Gateway
      1 POST /account/users/login/ HTTP/1.0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;traefik中500和502问题排查&#34;&gt;traefik中500和502问题排查&lt;/h4&gt;

&lt;p&gt;前面我们提到了在Nginx的场景中的500和502状态码的原因以及相关的解决方式，那么在Kubernetes集群中，traefik起到的作用和Nginx的作用也是相似的。&lt;/p&gt;

&lt;p&gt;在开始的时候，我们提到了集群内的traefik的配置信息，对于SRE来讲，任何生产的服务都必须有相关的可观测性数据，因此，我们也默认将traefik的访问日志和进程日志进行了持久化(分别对应&lt;code&gt;access.log和traefik.log&lt;/code&gt;)，同时也暴露了traefik的prometheus的metrics接口。&lt;/p&gt;

&lt;p&gt;对于上面的压测请求，我们在访问日志里抓到了如下的异常日志:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ tail -f access.log | grep data-api.bgbiao.cn | grep -v &amp;#39;HTTP/1.0&amp;#34; 200&amp;#39;
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267376 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 0ms
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267385 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.26.9:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267410 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267418 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267484 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.26.9:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:14:57:38 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 502 11 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267518 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.26.9:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:14:57:39 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122267550 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.26.9:8080&amp;#34; 4ms
192.168.0.23 - - [28/Jun/2020:15:02:06 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 502 11 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122272696 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 2ms
192.168.0.23 - - [28/Jun/2020:15:02:06 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 502 11 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122272711 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 1ms
192.168.0.23 - - [28/Jun/2020:15:02:06 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122272836 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.26.9:8080&amp;#34; 0ms
192.168.0.23 - - [28/Jun/2020:15:02:06 +0000] &amp;#34;POST /account/users/login/ HTTP/1.0&amp;#34; 500 21 &amp;#34;-&amp;#34; &amp;#34;ApacheBench/2.3&amp;#34; 122272837 &amp;#34;data-api.bgbiao.cn/&amp;#34; &amp;#34;http://20.0.41.8:8080&amp;#34; 0ms&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;可以看到，和我们压测结果里失败请求的状态码相同，都是&lt;code&gt;500&lt;/code&gt;和&lt;code&gt;502&lt;/code&gt;，虽然数量上不止4个，但这暂时不太重要。&lt;/p&gt;

&lt;p&gt;通常对于大多数人来讲，在代理层看到500或者502都会下意识的想，肯定是上游服务的问题，不过这种猜测也能很快进行排除，排除的方法基本如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在压测出现500和502期间，持续去访问上游服务器&lt;/li&gt;
&lt;li&gt;使用同样的压测参数直接压上游服务器&lt;/li&gt;
&lt;li&gt;将上游服务部署在独立的ECS上并使用同样参数进行压测&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;经过上述三种方式的测试后，我们基本排除了上游服务的问题，因此正式怀疑traefik本身是否有性能或者其他参数上的问题。&lt;/p&gt;

&lt;p&gt;修改traefki中的日志级别为&lt;code&gt;DEBUG&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat traefik-ds-v1.7.6.yaml
....
        args:
        - --api
        - --kubernetes
        - --logLevel=DEBUG
....&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后在日志中看到如下相关信息:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 500相关的日志
time=&amp;#34;2020-06-28T15:35:05Z&amp;#34; level=debug msg=&amp;#34;&amp;#39;500 Internal Server Error&amp;#39; caused by: http: server closed idle connection&amp;#34;
time=&amp;#34;2020-06-28T15:35:05Z&amp;#34; level=debug msg=&amp;#34;vulcand/oxy/forward/http: Round trip: http://20.0.26.9:8080, code: 500, Length: 21, duration: 1.486276ms&amp;#34;

# 502相关的日志
time=&amp;#34;2020-06-28T15:35:05Z&amp;#34; level=debug msg=&amp;#34;&amp;#39;502 Bad Gateway&amp;#39; caused by: EOF&amp;#34;
time=&amp;#34;2020-06-28T15:35:05Z&amp;#34; level=debug msg=&amp;#34;vulcand/oxy/forward/http: Round trip: http://20.0.26.9:8080, code: 502, Length: 11, duration: 1.530677ms&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;上面的500信息，大概可以看出来是traefik的服务进程主动关闭了空闲链接导致的，而下面的502是因为EOF，感觉像是没有读取完响应数据，就被断开了，导致traefik返回502。通常这种情况在Nginx中很常见，也很容易调整相关的配置参数(文章开始有提到)，但是traefik的部署模式以及参数调整，还是需要花心思去看相关文档的。&lt;/p&gt;

&lt;p&gt;然后在github上去翻traefik相关的issues，发现该问题曾经出现过很多次。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik/issues/4481&#34;&gt;Traefik return 500 internal error - no 500 on backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik/issues/3237&#34;&gt;Sporadic 502 response only when running through traefik&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个是500的issues，一个是502的issues，但通常这两个问题都是成双出现的。&lt;/p&gt;

&lt;h4 id=&#34;500和502问题解决方案&#34;&gt;500和502问题解决方案&lt;/h4&gt;

&lt;p&gt;在上面第一个issue中提到，traefik在http的反向代理功能中默认开启了http的keep-alive功能，但是python的应用中未开启http的keep-alive，因为我们上面的测试程序其实也是使用的python开发的，先对该参数进行调整。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 在uwsgi.ini中增加keep-alive参数即可
$ cat uwsgi.ini
[uwsgi]
http = 0.0.0.0:8080
http-keepalive = 1
chdir = /opt/app/
wsgi-file = /opt/app/main.py
callable = app
stats = 0.0.0.0:8081
processes = 2
threads = 10

# 重启应用后，再次进行压测
# 之前出现的502和500错误基本都消失了
# 并发200，共1万个请求，失败的请求数为0，总耗时1min(qps才到160😸)
$ ab  -c 200 -n 10000   -T &amp;#39;application/json&amp;#39; -p /root/login.json http://data-api.bgbiao.cn/account/users/login/
....
....

Concurrency Level:      200
Time taken for tests:   59.323 seconds
Complete requests:      10000
Failed requests:        0
Write errors:           0
Total transferred:      4670000 bytes
Total body sent:        2320000
HTML transferred:       2500000 bytes
Requests per second:    168.57 [#/sec] (mean)
Time per request:       1186.454 [ms] (mean)
Time per request:       5.932 [ms] (mean, across all concurrent requests)
Transfer rate:          76.88 [Kbytes/sec] received
                        38.19 kb/s sent
                        115.07 kb/s total

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    3  38.6      1    1035
Processing:   101  942 1457.7    857   32684
Waiting:      101  942 1457.7    857   32684
Total:        102  945 1458.0    861   32685

# p99达到7.3s
Percentage of the requests served within a certain time (ms)
  50%    861
  66%   1033
  75%   1136
  80%   1191
  90%   1886
  95%   2281
  98%   4209
  99%   7399
 100%  32685 (longest request)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;通过对业务层的http的keep-alive参数的开启，来暂时解决了500和502的问题，那能否通过traefik层的参数来优化该问题呢，上面第二个issue中其实也提到了。&lt;/p&gt;

&lt;p&gt;即，通过修改traefik的如下几个参数，并重新部署整个traefik集群即可:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 关闭traefik的keep-alive参数，参数默认为200，如果参数为0，则使用go标准库中的DefaultMaxIdleConnsPerHost参数
# keep-alive主要是用来复用链接来减少open files的，但是对于大量的短连接来将这种链接复用就可能出现上述情况
--maxidleconnsperhost=-1 
# 即通过设置重试次数，增加空闲链接的超时时间，增加转发响应的超时时间,默认是0次
--retry.attempts=10
# 该参数已经替换为--respondingtimeouts.idletimeout参数了，默认为3m0s
--idletimeout=60s
# 默认是0s
--forwardingtimeouts.responseheadertimeout=60s

# traefik 空闲链接超时
$ ./traefik --help | grep idletimeout
    --idletimeout                                 (Deprecated) maximum amount of time an idle (keep-alive) connection will remain  (default &amp;#34;0s&amp;#34;)
    --respondingtimeouts.idletimeout              IdleTimeout is the maximum amount duration an idle (keep-alive) connection will  (default &amp;#34;3m0s&amp;#34;)

# 响应超时相关参数
 $ ./traefik --help | grep respondingtimeouts
    --respondingtimeouts                          Timeouts for incoming requests to the Traefik instance                           (default &amp;#34;true&amp;#34;)
    --respondingtimeouts.idletimeout              IdleTimeout is the maximum amount duration an idle (keep-alive) connection will  (default &amp;#34;3m0s&amp;#34;)
    --respondingtimeouts.readtimeout              ReadTimeout is the maximum duration for reading the entire request, including    (default &amp;#34;0s&amp;#34;)
    --respondingtimeouts.writetimeout             WriteTimeout is the maximum duration before timing out writes of the response.   (default &amp;#34;0s&amp;#34;)


# 转发的超时
$ ./traefik --help | grep forwardingtimeouts
    --forwardingtimeouts                          Timeouts for requests forwarded to the backend servers                           (default &amp;#34;true&amp;#34;)
    --forwardingtimeouts.dialtimeout              The amount of time to wait until a connection to a backend server can be         (default &amp;#34;30s&amp;#34;)
    --forwardingtimeouts.responseheadertimeout    The amount of time to wait for a server&amp;#39;s response headers after fully writing   (default &amp;#34;0s&amp;#34;)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;最终修改后的traefik的参数如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 可以根据实际情况考虑是否要关闭keep-alive 即增加参数: --maxidleconnsperhost=-1
        - --api
        - --kubernetes
        - --logLevel=INFO
        - --traefikLog.filePath=/logdata/traefik.log
        - --configfile=/config/traefik.toml
        - --accesslog.filepath=/logdata/access.log
        - --accesslog.bufferingsize=100
        - --forwardingtimeouts.responseheadertimeout=60s
        - --respondingtimeouts.idletimeout=180s
        - --retry.attempts=10
        - --idletimeout=180s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;三-slb中诡异的503&#34;&gt;三、SLB中诡异的503&lt;/h3&gt;

&lt;p&gt;在发现域名直接解析到traefik节点上不再出现502和500后，我们将traefik的节点挂载到阿里云的内网slb中，但是又开始出现了诡异的503问题。&lt;/p&gt;

&lt;p&gt;接入slb后的简单压测情况(内网使用的是免费低配的slb😹)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# client-&amp;gt;ali-slb-&amp;gt;traefik-&amp;gt;pods
$ ab -v 10 -c 200 -n 2000   -T &amp;#39;application/json&amp;#39; -p postfile.json http://data-api.soulapp.cn/get_doc &amp;gt; slb-log.txt
$ cat slb-log.txt | grep  &amp;#39;HTTP/1.1 200&amp;#39; | wc -l
1322
$ cat slb-log.txt | grep  &amp;#39;HTTP/1.1 503&amp;#39; | wc -l
678


# client-&amp;gt;traefik-&amp;gt;pods
$ ab -v 10 -c 200 -n 2000   -T &amp;#39;application/json&amp;#39; -p postfile.json http://data-api.c.bgbiao.cn/get_doc &amp;gt; traefik-log.txt
Completed 200 requests
Completed 400 requests
Completed 600 requests
Completed 800 requests
Completed 1000 requests
Completed 1200 requests
Completed 1400 requests
Completed 1600 requests
Completed 1800 requests
Completed 2000 requests
Finished 2000 requests

$ cat traefik-log.txt  | grep  &amp;#39;HTTP/1.0 200&amp;#39; | wc -l
2000&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;后来在阿里云文档中看到如下文档，基本上就是在阿里云的SLB侧对不同规格的SLB做了一定的限流策略，此时会向客户端返回503。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://help.aliyun.com/knowledge_detail/102765.html?spm=5176.2000002.0.0.1f9641e8ymfAas&#34;&gt;阿里云TPS-503&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Golang中处理版本信息</title>
      <link>https://bgbiao.top/post/golang-version/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/golang-version/</guid>
      
        <description>&lt;h2 id=&#34;golang中的版本信息管理&#34;&gt;Golang中的版本信息管理&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;我们都知道在一些Golang写的程序中，默认会有&lt;code&gt;version&lt;/code&gt;或&lt;code&gt;-v&lt;/code&gt;相关的参数来输出软件版本信息，这些版本信息里可能包含软件版本，git中的commit记录，构建时间、构建环境等信息，那么这些信息都是如何在Golang程序中进行维护和管理的呢？请看👇.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;示例&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如我们常用的Golang开发的程序是这样输出版本相关信息的:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# k8s的客户端程序版本
$ kubectl version -o json --client
{
  &amp;#34;clientVersion&amp;#34;: {
    &amp;#34;major&amp;#34;: &amp;#34;1&amp;#34;,
    &amp;#34;minor&amp;#34;: &amp;#34;10&amp;#34;,
    &amp;#34;gitVersion&amp;#34;: &amp;#34;v1.10.11&amp;#34;,
    &amp;#34;gitCommit&amp;#34;: &amp;#34;637c7e288581ee40ab4ca210618a89a555b6e7e9&amp;#34;,
    &amp;#34;gitTreeState&amp;#34;: &amp;#34;clean&amp;#34;,
    &amp;#34;buildDate&amp;#34;: &amp;#34;2018-11-26T14:38:32Z&amp;#34;,
    &amp;#34;goVersion&amp;#34;: &amp;#34;go1.9.3&amp;#34;,
    &amp;#34;compiler&amp;#34;: &amp;#34;gc&amp;#34;,
    &amp;#34;platform&amp;#34;: &amp;#34;darwin/amd64&amp;#34;
  }
}

# docker的客户端程序版本
$ docker version
Client: Docker Engine - Community
 Version:           18.09.2
 API version:       1.39
 Go version:        go1.10.8
 Git commit:        6247962
 Built:             Sun Feb 10 04:12:39 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

# minio的客户端程序版本
$ minio --version
minio version RELEASE.2020-04-10T03-34-42Z&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;从上面的版本输出记录中我们其实可以看出，版本信息中不仅记录了基本的构建环境和版本信息，同时还记录了commitId，所以这些信息应该是在build时动态传入到程序中的，大概猜测一下应该就是提前在程序的version相关代码中预留好版本相关的变量，然后在构建的时候对变量进行赋值，以此来实现变量的动态注入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小试牛刀&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在大概猜测后，查看到相关文档中有说明可以在构建时使用参数&lt;code&gt;-ldflags -X importpath.name=value&lt;/code&gt;来动态注入变量。在官方稳定&lt;a href=&#34;https://golang.org/cmd/link/&#34;&gt;link&lt;/a&gt;中有详细说明:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;-X importpath.name=value
	Set the value of the string variable in importpath named name to value.
	This is only effective if the variable is declared in the source code either uninitialized
	or initialized to a constant string expression. -X will not work if the initializer makes
	a function call or refers to other variables.
	Note that before Go 1.5 this option took two separate arguments.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;大概意思就是: 可以设置一个字符串变量值给importpath路径下的name。而且仅当字符串变量在源码中没有初始化或初始化成常量字符串表达式时才有效。如果初始化变量调用了函数或者引用了其他变量，&lt;code&gt;-X&lt;/code&gt;参数也不会工作。&lt;/p&gt;

&lt;p&gt;所以，总结起来就是，可以使用该参数给源码中动态传入一些简单的字符串变量。&lt;/p&gt;

&lt;p&gt;接下来，我们简单试用一下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; 
&lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;		&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;buildTime&lt;/span&gt;	&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;osArch&lt;/span&gt;		&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Version: %s\nBuilt: %s\nOS/Arch: %s\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;buildTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;osArch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;直接运行&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Built&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;OS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;使用&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ldflags&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;importpath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name参数注入变量&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ldflags&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;-X &amp;#39;main.version=0.1&amp;#39; -X &amp;#39;main.buildTime=2020-06-26&amp;#39; -X &amp;#39;main.osArch=darwin/amd64&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Built&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mo&#34;&gt;06&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;OS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;darwin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;amd64&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;使用参数编译到二进制程序中&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;build&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ldflags&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;-X &amp;#39;main.version=0.1&amp;#39; -X &amp;#39;main.buildTime=2020-06-26&amp;#39; -X &amp;#39;main.osArch=darwin/amd64&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Golang&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Built&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mo&#34;&gt;06&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;OS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;darwin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;amd64&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;如上示例中简单演示了，如何在构建时，给程序注入一些版本相关的信息，这样我们在每次发版时，就可以根据当前的版本、环境、构建等信息为程序注入一个详细的版本信息了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;项目中使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面只是一个简单的示例用来演示如何利用&lt;code&gt;-ldflags -X importpath.name=value&lt;/code&gt;参数来给程序动态注入一些变量值，在实际项目中可能需要维护一个相对全面和通用的版本信息，接下来一起看看项目中大概会如何使用。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;首先&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;在项目中维护一个version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;go的文件&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;用于定义版本相关的信息&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;utils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;utils&lt;/span&gt;

&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
	&lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;s&#34;&gt;&amp;#34;runtime&amp;#34;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;      &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;gitBranch&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;gitTag&lt;/span&gt;       &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;gitCommit&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;gitTreeState&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;buildDate&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Info&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;      &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;version&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;GitBranch&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;gitBranch&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;GitTag&lt;/span&gt;       &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;gitTag&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;GitCommit&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;gitCommit&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;GitTreeState&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;gitTreeState&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;BuildDate&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;buildDate&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;GoVersion&lt;/span&gt;    &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;goVersion&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Compiler&lt;/span&gt;     &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;compiler&amp;#34;`&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Platform&lt;/span&gt;     &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;`json:&amp;#34;platform&amp;#34;`&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;info&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GitCommit&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Info&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;      &lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;GitBranch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;gitBranch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;GitTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;       &lt;span class=&#34;nx&#34;&gt;gitTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;GitCommit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;gitCommit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;GitTreeState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;gitTreeState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;BuildDate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;buildDate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;GoVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;    &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;Compiler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;     &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Compiler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;Platform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;     &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Sprintf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s/%s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GOOS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GOARCH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;然后可以在main程序中&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;对version子命令的输出调用utils&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;函数&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
	&lt;span class=&#34;s&#34;&gt;&amp;#34;fmt&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;s&#34;&gt;&amp;#34;os&amp;#34;&lt;/span&gt;

	&lt;span class=&#34;s&#34;&gt;&amp;#34;version/utils&amp;#34;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;

	&lt;span class=&#34;nx&#34;&gt;args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Args&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;version&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;utils&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;GetVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Version: %s\nGitBranch: %s\nCommitId: %s\nBuild Date: %s\nGo Version: %s\nOS/Arch: %s\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GitBranch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GitCommit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;BuildDate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;GoVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Platform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Version(hard code): %s\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;0.1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;build&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ldflags&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;-X &amp;#39;version/utils.version=0.1&amp;#39; -X &amp;#39;version/utils.gitBranch=test&amp;#39; -X &amp;#39;version/utils.gitTag=test&amp;#39; -X &amp;#39;version/utils.gitCommit=test&amp;#39; -X &amp;#39;version/utils.buildDate=2020-06-26&amp;#39; -X &amp;#39;version/utils.osArch=darwin/amd64&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; 

&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hard&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;code&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;


&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;main&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;version&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;GitBranch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;CommitId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Build&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2020&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mo&#34;&gt;06&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;Go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;go1&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;.14&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;OS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Arch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;darwin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;amd64&lt;/span&gt; &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;此时，我们已经可以对程序中的版本信息进行动态维护和管理了，但是每次手动维护版本信息还是比较麻烦，因此常见的做法是使用脚本或者&lt;code&gt;Makefile&lt;/code&gt;来对构建参数进行统一管理.&lt;/p&gt;

&lt;p&gt;我们在项目中再增加&lt;code&gt;Makefile&lt;/code&gt;来管理参数.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat Makefile 
.PHONY: list vet fmt default clean
all: list vet fmt default clean
BINARY=&amp;#34;version&amp;#34;
VERSION=0.0.1
BUILD=`date +%F`
SHELL := /bin/bash
BASEDIR = $(shell pwd)

# build with verison infos
versionDir=&amp;#34;version/utils&amp;#34;
gitTag=$(shell if [ &amp;#34;`git describe --tags --abbrev=0 2&amp;gt;/dev/null`&amp;#34; != &amp;#34;&amp;#34; ];then git describe --tags --abbrev=0; else git log --pretty=format:&amp;#39;%h&amp;#39; -n 1; fi)
gitBranch=$(shell git rev-parse --abbrev-ref HEAD)
buildDate=$(shell TZ=Asia/Shanghai date +%FT%T%z)
gitCommit=$(shell git rev-parse --short HEAD)
gitTreeState=$(shell if git status|grep -q &amp;#39;clean&amp;#39;;then echo clean; else echo dirty; fi)

ldflags=&amp;#34;-s -w -X ${versionDir}.gitTag=${gitTag} -X ${versionDir}.buildDate=${buildDate} -X ${versionDir}.gitCommit=${gitCommit} -X ${versionDir}.gitTreeState=${gitTreeState} -X ${versionDir}.version=${VERSION} -X ${versionDir}.gitBranch=${gitBranch}&amp;#34;


default:
	@echo &amp;#34;build the ${BINARY}&amp;#34;
	@GOOS=linux GOARCH=amd64 go build -ldflags ${ldflags} -o  build/${BINARY}.linux  -tags=jsoniter
	@go build -ldflags ${ldflags} -o  build/${BINARY}.mac  -tags=jsoniter
	@echo &amp;#34;build done.&amp;#34;



# 构建测试
$ make default
build the version
build done.

$ ./build/version.mac
Version(hard code): 0.1

$ ./build/version.mac version
Version: 0.0.1
GitBranch: master
CommitId: c1702a8
Build Date: 2020-06-27T13:32:42+0800
Go Version: go1.14
OS/Arch: darwin/amd64 &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;细心的小伙伴们有没有发现，此时我们的版本输出信息和前面&lt;code&gt;docker&lt;/code&gt;以及&lt;code&gt;kubectl&lt;/code&gt;程序的版本信息有那么一丢丢相似了，其实目前大多数使用Golang开源的程序基本上也都是采用这种方式来管理程序的版本信息的，比如&lt;code&gt;kubectl&lt;/code&gt;中的version命令:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kubectl/blob/master/pkg/cmd/version/version.go#L38&#34;&gt;kubectl-version&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/apimachinery/blob/master/pkg/version/types.go&#34;&gt;kubernetes-apimachinery&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;上面的示例代码，我放到了&lt;a href=&#34;https://github.com/goops-top/version&#34;&gt;go-version&lt;/a&gt;中了，有需要的小伙伴可以去看看。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Kafka运维神器之gokafka</title>
      <link>https://bgbiao.top/post/gokafka/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/gokafka/</guid>
      
        <description>&lt;h2 id=&#34;kafka运维神器&#34;&gt;Kafka运维神器&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;在Kafka集群运维过程中，我们通常会借用一些开源工具来完成kafka的日常运维需求和相关问题排查，接下来介绍几个常用的kafka运维神器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;kafka-manager&#34;&gt;kafka-manager&lt;/h3&gt;

&lt;p&gt;由雅虎开源的kafka集群管理工具，不过现在已经改名为&lt;a href=&#34;https://github.com/yahoo/CMAK&#34;&gt;CMAK&lt;/a&gt;了(说明kafka的运维痛点还是蛮多的，项目还可以做更多的事情)，核心功能如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;多集群管理&lt;/li&gt;
&lt;li&gt;集群瞬时监控(topics, brokers, 副本分布，分区分布等)&lt;/li&gt;
&lt;li&gt;优先副本选举&lt;/li&gt;
&lt;li&gt;主题，分区，副本管理(主题创建和参数调整，副本分配等)&lt;/li&gt;
&lt;li&gt;Broker和Topic级别的metrics监控&lt;/li&gt;

&lt;li&gt;&lt;p&gt;消费者基本信息管理&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 源码编译
$ ./sbt clean dist

# docker 安装
$ docker run -itd --name kafka-manager -e KAFKA_ZK_CLUSTER=&amp;#34;zk-1:2181,zk-2:2181&amp;#34; -P      bgbiao/kafka-manager:2.0.0.2 
# 自定义端口
$ docker run -itd --name kafka-manager -e KAFKA_ZK_CLUSTER=&amp;#34;zk-1:2181,zk-2:2181&amp;#34; -P      bgbiao/kafka-manager:2.0.0.2 -Dhttp.port=8080 &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v0rydqhj30xu0kkdhd.jpg&#34; alt=&#34;kafka-cluster&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v0uopt4j30v90epac2.jpg&#34; alt=&#34;kafka-topic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v1kai7sj30w50oc429.jpg&#34; alt=&#34;kafka-topic-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v1ziityj30k708kt9i.jpg&#34; alt=&#34;kafka-consumer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v2i5kt5j30qe0pxgpq.jpg&#34; alt=&#34;kafka-consumer-info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v34efi2j31rm0nbtdv.jpg&#34; alt=&#34;kafka-broker&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg6v3ivpuqj31bi0u0dnn.jpg&#34; alt=&#34;kafka-broker-info&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;kafkacat&#34;&gt;kafkacat&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/edenhill/kafkacat&#34;&gt;kafkacat&lt;/a&gt;是一个非JVM的命令行生产者和消费者，可以快速的对kafka消息进行生产和消费。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# mac 安装
$ brew install kafkacat 

# docker 安装
# 官方仅支持Debian和openSUSE系列
# 如下镜像支持在CentOS系列的环境中使用
$ docker pull bgbiao/kafkacat &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 消费者模式
$ kafkacat -b localhost:9092 -t mysql_users
% Auto-selecting Consumer mode (use -P or -C to override)
{&amp;#34;uid&amp;#34;:1,&amp;#34;name&amp;#34;:&amp;#34;Cliff&amp;#34;,&amp;#34;locale&amp;#34;:&amp;#34;en_US&amp;#34;,&amp;#34;address_city&amp;#34;:&amp;#34;St Louis&amp;#34;,&amp;#34;elite&amp;#34;:&amp;#34;P&amp;#34;}
{&amp;#34;uid&amp;#34;:2,&amp;#34;name&amp;#34;:&amp;#34;Nick&amp;#34;,&amp;#34;locale&amp;#34;:&amp;#34;en_US&amp;#34;,&amp;#34;address_city&amp;#34;:&amp;#34;Palo Alto&amp;#34;,&amp;#34;elite&amp;#34;:&amp;#34;G&amp;#34;}
[...]

# 生产者模式
# 默认是以换行符来决定一条消息(-D 可以指定分隔符)
# 默认从stdin来读取消息
$ kafkacat -b localhost:9092 -t new_topic -P
test

# 从文件中读取消息
# -l参数用来指定将文件中的每一个行作为一个消息进行发送，如果没有该参数，整个文本将会以一个消息发送(对于二进制的数据比较
有用)
# -T 参数可以用于回显到stdout
$ kafkacat -b localhost:9092 -t &amp;lt;my_topic&amp;gt; -T -P -l /tmp/msgs


# 可以指定消息的key，使用-K参数
$ kafkacat -b localhost:9092 -t keyed_topic -P -K:
1:foo
2:bar

$ kafkacat -b localhost:9092 -t keyed_topic -C -f &amp;#39;Key: %k\nValue: %s\n&amp;#39;
Key: 1
Value: foo
Key: 2
Value: bar

# 设置partition
$ kafkacat -b localhost:9092 -t partitioned_topic -P -K: -p 1
1:foo

$ kafkacat -b localhost:9092 -t partitioned_topic -P -K: -p 2
2:bar

$ kafkacat -b localhost:9092 -t partitioned_topic -P -K: -p 3
3:wibble


# 元数据监听模式
# 元数据的监听模式可以使用`-L`参数，会显示当前kafka集群的状态以及主题，分区，副本，以及ISR信息。
# `-J`参数会以json格式进行输出
$ kafkacat -b localhost:9092 -L

$ kafkacat -b mybroker -L -J



# docker方式简单使用
# 从标准输入生产数据
$ docker run --rm bgbiao/kafkacat kafkacat -b kafka-broker:9092 -t test-biao -P &amp;lt;&amp;lt;EOF
&amp;gt; ssabdkgjf
&amp;gt; asfgnh
&amp;gt; wertnh
&amp;gt; waer
&amp;gt; awegrtn
&amp;gt; 2020-04-26
&amp;gt; end time
&amp;gt; EOF

# 从指定topic接收数据
$ docker run -it --rm bgbiao/kafkacat kafkacat -b kafka-broker:9092 -t test-biao -C -f &amp;#39;\nKey (%K bytes): %k\t\nValue (%S bytes): %s\n\Partition: %p\tOffset: %o\n--\n&amp;#39;

Key (-1 bytes):
Value (13 bytes): test kafkacat
Partition: 0	Offset: 11
--
% Reached end of topic test-biao [0] at offset 12

Key (-1 bytes):
Value (18 bytes): 2020-04-26 endtime
Partition: 1	Offset: 8
--
% Reached end of topic test-biao [1] at offset 9

Key (-1 bytes):
Value (7 bytes): overlay
Partition: 2	Offset: 6
--
% Reached end of topic test-biao [2] at offset 7&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果想要把docker镜像中的&lt;code&gt;kafkacat&lt;/code&gt;二进制文件拷贝出来使用，仅需要在当前环境中安装&lt;code&gt;librdkafka-devel&lt;/code&gt;即可。&lt;/p&gt;

&lt;h3 id=&#34;gokafka&#34;&gt;gokafka&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/goops-top/gokafka&#34;&gt;gokafka&lt;/a&gt;也是一个非JVM的kafka运维管理工具，不仅可以进行简单的消息模拟生产，而且可以对指定topic进行消息预览，同时也支持kafka集群的常见的运维管理操作.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;快速开始&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ git clone https://github.com/goops-top/gokafka.git
$ cd gokafka
$ go build -o build/goops-kafka

$ ./build/goops-kafka
goops-kafka: A kafka tools with golang that can operate the kafka for describe,create,update and so on.

 Note: Without the jvm,so you must be specify the [--broker or --cluster and the Value must be in --config entry.]

Usage:
  gokafka [command]

Available Commands:
  consumer    consumer  a topic message data with specified kafka-cluster.
  create      create the kafka topic with some base params in specify kafka-cluster.
  describe    describe the kafka some info (cluster,topic,broker,loginfo)
  help        Help about any command
  init        init the gokafka some default config.
  list        list the kafka some info (cluster,topic,broker)
  producer    producer  a topic message data with specified kafka-cluster.
  version     print version info of goops-kafka tool

Flags:
      --broker string    指定broker地址
      --cluster string   指定集群
      --config string    指定配置文件(default is $HOME/.goops-kafka)
  -h, --help             help for gokafka

Use &amp;#34;gokafka [command] --help&amp;#34; for more information about a command.

# 使用make编译
# 会自动生成mac和linux发行版本的二进制文件
$ make default&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;简单使用&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看工具版本
$ ./build/gokafka.mac version
Version: 0.0.1
GitBranch: master
CommitId: 445f935
Build Date: 2020-06-26T18:49:48+0800
Go Version: go1.14
OS/Arch: darwin/amd64

# 初始化配置文件
# gokafka 采用配置文件的方式快速管理多个kafka集群
$ ./build/gokafka.mac  init
gokafka config init ok.

# 在用户家目录下生成集群配置文件
$ cat ~/.goops-kafka

app: gokafka
spec:
  clusters:
  - name: test-kafka
    version: V2_5_0_0
    brokers:
    - 10.0.0.1:9092
    - 10.0.0.2:9092
    - 10.0.0.3:9092
  - name: dev-kafka
    version: V1_0_0_0
    brokers:
    - 192.168.0.22:9092
    - 192.168.0.23:9092
    - 192.168.0.24:9092

# 也可以使用--config 来指定集群配置文件
$ ./build/gokafka.mac  --config ./kafka-cluster.yaml version
Version: 0.0.1
GitBranch: master
CommitId: 445f935
Build Date: 2020-06-26T18:53:25+0800
Go Version: go1.14
OS/Arch: darwin/amd64

# 查看配置文件中的集群详情
$ ./build/gokafka.mac  list cluster
cluster:test-kafka version:V2_5_0_0 connector_brokers:[10.0.0.1:9092]
cluster:dev-kafka version:V1_0_0_0 connector_brokers:[192.168.0.22:9092]

./build/gokafka.mac  list cluster --config ./kafka-cluster.yaml
cluster:log-kafka version:V2_5_0_0 connector_brokers:[log-kafka-1.bgbiao.cn:9092]

# 注意: 当使用集群配置文件管理集群时，需要使用--cluster全局参数指定操作的目标集群
# 当然也可以直接指定broker进行操作
$ ./build/gokafka.mac  --cluster dev-kafka describe broker
controller: 3
brokers num: 3
broker list: [2 1 3]
id:2		 broker:192.168.0.22:9092
id:1		 broker:192.168.0.23:9092
id:3		 broker:192.168.0.24:9092

$ ./build/gokafka.mac  --broker 10.0.0.1:9092  describe broker
controller: 3
brokers num: 3
broker list: [2 1 3]
id:2		 broker:192.168.0.22:9092
id:1		 broker:192.168.0.23:9092
id:3		 broker:192.168.0.24:9092&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;常用功能&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;98
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 1.创建topic
# 可以指定分区和副本数
$ ./build/gokafka.mac  --cluster dev-kafka create --topic test-bgbiao-1
true


# 2.查看topic
$ ./build/gokafka.mac  --cluster dev-kafka list topic --topic-list test-bgbiao-1
Topic:test-bgbiao-1	PartNum:3	Replicas:3	Config:
Topic-Part:test-bgbiao-1-2	ReplicaAssign:[1 3 2]
Topic-Part:test-bgbiao-1-1	ReplicaAssign:[2 1 3]
Topic-Part:test-bgbiao-1-0	ReplicaAssign:[3 2 1]

# 3.获取topic的分区和副本状态
$ ./build/gokafka.mac  --cluster dev-kafka describe  topic --topic-list test-bgbiao-1
Topic-Part:test-bgbiao-1-2	Leader:1	Replicas:[1 3 2]	ISR:[1 3 2]	OfflineRep:[]
Topic-Part:test-bgbiao-1-1	Leader:2	Replicas:[2 1 3]	ISR:[2 1 3]	OfflineRep:[]
Topic-Part:test-bgbiao-1-0	Leader:3	Replicas:[3 2 1]	ISR:[3 2 1]	OfflineRep:[]

# 4.向topic中生产消息
$ ./build/gokafka.mac  --cluster dev-kafka producer --topic test-bgbiao-1 --msg &amp;#34;Hello, BGBiao.&amp;#34;
INFO[0000] Produce msg:Hello, BGBiao. to topic:test-bgbiao-1
INFO[0000] topic:test-bgbiao-1 send ok with offset:0

$ ./build/gokafka.mac  --cluster dev-kafka producer --topic test-bgbiao-1 --msg &amp;#34;Nice to meet you.&amp;#34;
INFO[0000] Produce msg:Nice to meet you. to topic:test-bgbiao-1
INFO[0000] topic:test-bgbiao-1 send ok with offset:0

# 5.消费消息(gokafka中创建了一个默认的消费组用来预览消息)
# 在终端进行实时消费，ctrl+c 可取消
$ ./build/gokafka.mac  --cluster dev-kafka consumer --topic test-bgbiao-1
INFO[0000] Sarama consumer up and running!...
INFO[0004] part:2 offset:0
msg: Nice to meet you.
INFO[0004] part:1 offset:0
msg: Hello, BGBiao.

# 6.查看集群的broker列表以及controller
$ ./build/gokafka.mac  --cluster dev-kafka describe broker
controller: 3
brokers num: 3
broker list: [2 1 3]
id:2		 broker:192.168.0.23:9092
id:1		 broker:192.168.0.22:9092
id:3		 broker:192.168.0.24:9092

# 7.查看topic的日志大小
$ ./build/gokafka.mac  --cluster dev-kafka describe loginfo --topic-list test-bgbiao-1
topic:test-bgbiao-1
172.16.32.23:9092
logdir:/soul/data/kafka/kafka-logs
topic-part		log-size(M)		offset-lag
----------		-----------		----------
test-bgbiao-1-0		0		0
test-bgbiao-1-1		0		0
test-bgbiao-1-2		0		0
172.16.32.22:9092
logdir:/soul/data/kafka/kafka-logs
topic-part		log-size(M)		offset-lag
----------		-----------		----------
test-bgbiao-1-0		0		0
test-bgbiao-1-1		0		0
test-bgbiao-1-2		0		0
172.16.32.24:9092
logdir:/soul/data/kafka/kafka-logs
topic-part		log-size(M)		offset-lag
----------		-----------		----------
test-bgbiao-1-0		0		0
test-bgbiao-1-1		0		0
test-bgbiao-1-2		0		0

# 8.列出kafka集群的消费者组
$ ./build/gokafka.mac  --cluster dev-kafka list  consumer-g | grep -i gokafka
GoKafka

# 9.查看消费者组详细信息
# 因为上面我们停止了消费，该消费者组当前是空的
$ ./build/gokafka.mac  --cluster dev-kafka describe consumer-g --consumer-group-list GoKafka
--------------------------------------------------------------------------------------------
consumer-group:GoKafka consumer-state:Empty

# 我们来看一个有实际消费状态的消费者组
# 可以看到一个消费者组下的全部消费者线程以及消费者实例，消费的对应的topic列表
$ ./build/gokafka.mac  --cluster dev-kafka describe consumer-g --consumer-group-list group-sync
--------------------------------------------------------------------------------------------
consumer-group:group-sync consumer-state:Stable
consumer-id					consumer-ip			topic-list
consumer-1-a9437739-e5cb-4b41-a9d3-2640b9878965	/172.16.64.207		[sync-dev]
consumer-1-92eb690b-d327-468b-8990-9c21e1ee405d	/172.16.32.235		[sync-dev]


# 10. 还可以查看某个消费者组消费某个topic的日志详情
$ ./build/gokafka.mac  --cluster dev-kafka describe consumer-group-offset --group group-sync --topic sync-dev
sync-dev
topic-part:sync-dev-0 log-offsize:98
topic-part:sync-dev-1 log-offsize:0
topic-part:sync-dev-2 log-offsize:340
topic-part:sync-dev-3 log-offsize:261&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Kafka在Zookeeper中的存储结构</title>
      <link>https://bgbiao.top/post/kafka%E5%9C%A8zookeeper%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E5%9C%A8zookeeper%E4%B8%AD%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;我们都知道，自从Kafka诞生之际，就一直使用Zookeeper服务来进行kafka集群的元数据和状态管理，虽然在&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&#34;&gt;KIP-500&lt;/a&gt;中有提议未来将移除Zookeeper的依赖，使用Raft协议来实现新的元数据和状态管理，但在这之前，我们仍然需要对kafka集群的整个元数据和状态有一定理解，才能更好的维护和保障kafka集群。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;

&lt;p&gt;在kafka集群中，ZooKeeper集群用于&lt;code&gt;存放集群元数据&lt;/code&gt;、&lt;code&gt;成员管理&lt;/code&gt;、&lt;code&gt;Controller 选举&lt;/code&gt;，以及其他一些&lt;code&gt;管理类任务&lt;/code&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;存放元数据&lt;/code&gt;: 是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他“人” 都要与它保持对齐。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;成员管理&lt;/code&gt;: 是指 Broker 节点的注册、注销以及属性变更。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Controller 选举&lt;/code&gt;: 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper服务&#34;&gt;Zookeeper服务&lt;/h3&gt;

&lt;p&gt;在开始之前，我们首先需要对Zookeeper服务有一定的了解。在官方文档中，Zookeeper有如下能力:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置管理: 其实就是单纯的K/V存储，可以用来配置的存储和管理，实现对分布式系统组件的集中式的配置管理&lt;/li&gt;
&lt;li&gt;命名: 命令空间管理，在zookeeper中配置可通过不同的根路径来实现简单的命名空间隔离(简单的chroot隔离)&lt;/li&gt;
&lt;li&gt;分布式的同步服务: 可保证分布式的同步&lt;/li&gt;
&lt;li&gt;分组服务: 可以将一组服务配置进行分组管理，其实在Dubbo的注册中心中，就是使用分组和命名来统一进行生产者的注册和发现&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg095r9zy2j30go0553z6.jpg&#34; alt=&#34;Zookeeper架构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在Zookeeper中所有的命名空间和文件系统比较类似，每个节点都有一个唯一的&lt;code&gt;路径&lt;/code&gt;，如下图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg09dvjkrnj30ca071mxh.jpg&#34; alt=&#34;zookeeper内部存储结构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为什么Zookeeper服务可以满足配置管理和协调服务呢？主要是因为它的节点属性，通常也是经常可能会忽略的问题，即在Zookeeper中存在两种节点: &lt;code&gt;持久节点&lt;/code&gt;和&lt;code&gt;临时节点&lt;/code&gt;，节点也称之为&lt;code&gt;znode&lt;/code&gt;，而znode本身除了数据之外，还会存储一些额外的信息:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据变更的版本号&lt;/li&gt;
&lt;li&gt;ACL变更的版本号&lt;/li&gt;
&lt;li&gt;时间戳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每次znode中的数据有变更，版本号都会递增，并且client在向znode获取数据时，不仅会获取实际数据，而且会获取到数据的版本，这在整个配置管理领域会相当有用。&lt;/p&gt;

&lt;p&gt;前面说到的&lt;code&gt;持久节点&lt;/code&gt;只要znode创建后，便一直会存在，这种节点主要用于配置的持久化存储，只要zookeeper集群整体可用，那该节点也一直可用(及时集群异常后恢复，该节点依旧存在)；而&lt;code&gt;临时节点&lt;/code&gt; 随着某个创建 znode 的会话的开始，被创建，而一旦这个会话被撤除掉，这个 znode 就会自动被 ZooKeeper 删除。&lt;/p&gt;

&lt;p&gt;对于&lt;code&gt;临时节点&lt;/code&gt;来讲，经常会被用在如下场景:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dubbo中的服务注册&lt;/li&gt;
&lt;li&gt;其他分布式服务中的leader选举&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而真正使得Zookeeper在Java语言生态中有如此大影响还依赖于另外一个功能: &lt;code&gt;watches&lt;/code&gt;，Client 可以对某个 znode 设置&lt;code&gt;watch&lt;/code&gt; 当这个 znode 有变更的时候，就会产生&lt;code&gt;watch&lt;/code&gt; 事件，这个事件会由 ZooKeeper 通知至 Client, 即是 Client 会收到来自 Server 的通知，可以实现数据的动态变更。(之所以说是Java语言生态，是因为在云原生领域，Etcd几乎是Zookeeper的替代品，不同的是它是Golang语言生态体系中的)&lt;/p&gt;

&lt;h3 id=&#34;kafka集群数据在zookeeper的存储&#34;&gt;kafka集群数据在zookeeper的存储&lt;/h3&gt;

&lt;p&gt;前面对Zookeeper服务进行了大概的说明,接下来我们一起看看kafka的集群数据在zookeeper中是如何存储和分布的。&lt;/p&gt;

&lt;p&gt;链接zk:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 前面说到zookeeper支持命名空间，因此我们可以使用一个zookeeper集群来管理多个kafka集群
# 只需要在启动kafka时指定zk的chroot环境，比如/kafka 在zookeeper中将存储名称为`kafka`的集群的相关数据
sh-4.2# sh zkCli.sh -server 127.0.0.1:2181
Connecting to 127.0.0.1:2181
....
[zk: 127.0.0.1:2181(CONNECTED) 0] ls /
[kafka, zookeeper]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;查看kafka数据存储结构:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[zk: 127.0.0.1:2181(CONNECTED) 1] ls /kafka
[admin, brokers, cluster, config, consumers, controller, controller_epoch, isr_change_notification, latest_producer_id_block, log_dir_event_notification]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;kafka元数据存储目录&lt;/strong&gt;
- admin: 存储管理员接口操作的相关信息，主要为topic删除事件，分区迁移事件，优先副本选举，信息(一般为临时节点)
- brokers: 主要存储broker相关的信息，broker节点以及节点上的topic相关信息
- cluster: 存储kafka集群信息
- config: 存储broker，client，topic，user以及changer相关的配置信息
- consumers: 存放消费者相关信息(一般为空)
- controller: 用于存放控制节点信息(注意: 该节点是一个临时节点，用于controller节点注册)
- controller_epoch: 用于存放controller节点当前的年龄
- isr_change_notification: 用于存储isr的变更通知(临时节点，当有isr进行变动时，会用于事件通知，可进行watch获取集群isr状态变更)
- latest_producer_id_block:  该节点用于存储处理事务相关的pid范围
- log_dir_event_notification: 日志目录事件通知&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;admin目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[zk: 127.0.0.1:2181(CONNECTED) 2] ls /kafka/admin
[delete_topics]
[zk: 127.0.0.1:2181(CONNECTED) 3] ls /kafka/admin/delete_topics
[]
[zk: 127.0.0.1:2181(CONNECTED) 4] get  /kafka/admin/delete_topics
null&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;brokers目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# broker和topic列表数据
[zk: 127.0.0.1:2181(CONNECTED) 5] ls /kafka/brokers
[ids, seqid, topics]

# 表示当前集群有3个节点
[zk: 127.0.0.1:2181(CONNECTED) 6] ls /kafka/brokers/ids
[1, 2, 3]
[zk: 127.0.0.1:2181(CONNECTED) 7] ls /kafka/brokers/seqid
[]
# 表示集群当前的topic信息
[zk: 127.0.0.1:2181(CONNECTED) 8] ls /kafka/brokers/topics
[__consumer_offsets, appjsonlog_heartbeat, nginx_log,ingress_log ]

# broker详情
[zk: 127.0.0.1:2181(CONNECTED) 10] get  /kafka/brokers/ids/1
{&amp;#34;listener_security_protocol_map&amp;#34;:{&amp;#34;PLAINTEXT&amp;#34;:&amp;#34;PLAINTEXT&amp;#34;},&amp;#34;endpoints&amp;#34;:[&amp;#34;PLAINTEXT://10.0.0.1:9092&amp;#34;],&amp;#34;jmx_port&amp;#34;:9999,&amp;#34;host&amp;#34;:&amp;#34;10.0.0.1&amp;#34;,&amp;#34;timestamp&amp;#34;:&amp;#34;1588925944886&amp;#34;,&amp;#34;port&amp;#34;:9092,&amp;#34;version&amp;#34;:4}

# topic详情
[zk: 127.0.0.1:2181(CONNECTED) 11] get  /kafka/brokers/topics/__consumer_offsets
{&amp;#34;version&amp;#34;:2,&amp;#34;partitions&amp;#34;:{&amp;#34;1&amp;#34;:[2,1,3],&amp;#34;0&amp;#34;:[3,2,1],&amp;#34;2&amp;#34;:[1,2,3],&amp;#34;adding_replicas&amp;#34;:{},&amp;#34;removing_replicas&amp;#34;:{}}


[zk: localhost:2181(CONNECTED) 3] ls /brokers/topics/__consumer_offsets
[partitions]
[zk: localhost:2181(CONNECTED) 4] ls /brokers/topics/__consumer_offsets/partitions
[0, 1, 2]

# 查看topic某个分区的状态详情
[zk: localhost:2181(CONNECTED) 6] ls /brokers/topics/__consumer_offsets/partitions/1
[state]
[zk: localhost:2181(CONNECTED) 7] ls /brokers/topics/__consumer_offsets/partitions/1/state
[]
[zk: localhost:2181(CONNECTED) 8] get  /brokers/topics/__consumer_offsets/partitions/1/state
{&amp;#34;controller_epoch&amp;#34;:3,&amp;#34;leader&amp;#34;:1,&amp;#34;version&amp;#34;:1,&amp;#34;leader_epoch&amp;#34;:12,&amp;#34;isr&amp;#34;:[3,1]}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;cluster目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[zk: 127.0.0.1:2181(CONNECTED) 5] get   /kafka/cluster/id
{&amp;#34;version&amp;#34;:&amp;#34;1&amp;#34;,&amp;#34;id&amp;#34;:&amp;#34;5C-JZf4vRdqKzlca7Lv7pA&amp;#34;}
cZxid = 0x100000018
ctime = Fri Mar 30 22:21:07 CST 2018
mZxid = 0x100000018
mtime = Fri Mar 30 22:21:07 CST 2018
pZxid = 0x100000018
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 45
numChildren = 0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;config目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;[zk: 127.0.0.1:2181(CONNECTED) 12] ls /kafka/config
[brokers, changes, clients, topics, users]

# 需要注意的是，config目录用来存放各种实体的配置，用于使用kafka相关工具对实体进行的配置变更存储
# 因此，一般在kafka集群运行后，如不设置相关动态参数，该目录下的配置一般为空
[zk: 127.0.0.1:2181(CONNECTED) 19] ls /kafka/config/brokers
[]
[zk: 127.0.0.1:2181(CONNECTED) 20] ls /kafka/config/changes
[]
[zk: 127.0.0.1:2181(CONNECTED) 21] ls /kafka/config/clients
[]
[zk: 127.0.0.1:2181(CONNECTED) 22] ls /kafka/config/topics
[__consumer_offsets]
[zk: 127.0.0.1:2181(CONNECTED) 23] ls /kafka/config/users
[]

# 可以看到，存储消费者偏移量的topic在配置中
# 是因为该topic有一些额外的topic级别参数
# 如果我们对topic参数有过动态变更，将会在这里存储
[zk: 127.0.0.1:2181(CONNECTED) 24] get /kafka/config/topics/__consumer_offsets
{&amp;#34;version&amp;#34;:1,&amp;#34;config&amp;#34;:{&amp;#34;segment.bytes&amp;#34;:&amp;#34;104857600&amp;#34;,&amp;#34;compression.type&amp;#34;:&amp;#34;producer&amp;#34;,&amp;#34;cleanup.policy&amp;#34;:&amp;#34;compact&amp;#34;}}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;controller目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 可以看到当前broker-1为集群的controller节点
[zk: 127.0.0.1:2181(CONNECTED) 30] get  /kafka/controller
{&amp;#34;version&amp;#34;:1,&amp;#34;brokerid&amp;#34;:1,&amp;#34;timestamp&amp;#34;:&amp;#34;1588833869354&amp;#34;}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;controller_epoch 目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 可以看到controller的年龄是2，说明controller经历过2次变更了
[zk: 127.0.0.1:2181(CONNECTED) 32] get  /kafka/controller_epoch
2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;其他几个目录结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 存储事务相关的pid范围数据
# broker启动时提前预分配一段 PID，当前是 0~999，即提前分配出 1000 个 PID 来
# 一旦 PID 超过了 999，则目前会按照 1000 的步长重新分配
# 集群中所有 broker 启动时都会启动一个叫 TransactionCoordinator 的组件，该组件能够执行预分配 PID 块和分配 PID 的工作，而所有 broker 都使用 /latest_producer_id_block 节点来保存 PID 块

[zk: 127.0.0.1:2181(CONNECTED) 37] get  /kafka/latest_producer_id_block
{&amp;#34;version&amp;#34;:1,&amp;#34;broker&amp;#34;:1,&amp;#34;block_start&amp;#34;:&amp;#34;19000&amp;#34;,&amp;#34;block_end&amp;#34;:&amp;#34;19999&amp;#34;}


[zk: 127.0.0.1:2181(CONNECTED) 39] ls /kafka/isr_change_notification
[]
[zk: 127.0.0.1:2181(CONNECTED) 40] get  /kafka/isr_change_notification
null

[zk: 127.0.0.1:2181(CONNECTED) 41] ls /kafka/log_dir_event_notification
[]
[zk: 127.0.0.1:2181(CONNECTED) 42] get  /kafka/log_dir_event_notification
null&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;以上就是整个kafka元数据在zookeeper集群中的整体存储结构，下面附上一张kafka的元数据存储结构图。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;kafka元数据在zk中的分布&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gg0a21u6coj31am0u0tlf.jpg&#34; alt=&#34;kafka在zookeeper中的存储结构&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>一文帮你理解整个SRE运维体系</title>
      <link>https://bgbiao.top/post/sre%E8%BF%90%E7%BB%B4%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/sre%E8%BF%90%E7%BB%B4%E4%BD%93%E7%B3%BB/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;SRE运维体系的构建和工作职责划分。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;可观测性系统&#34;&gt;可观测性系统&lt;/h4&gt;

&lt;p&gt;在任何有一定规模的企业内部，一旦推行起来整个SRE的运维模式，那么对于可观测性系统的建设将变得尤为重要，而在整个可观测性系统中，通常我们会分为如下三个方面:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;指标监控：即各种指标监控，比如基础资源指标，服务性能指标，业务的调用指标。&lt;/li&gt;
&lt;li&gt;日志：各种设备以及服务的运行日志监控。&lt;/li&gt;
&lt;li&gt;调用链：业务层面的调用链分析，通常在分布式系统中帮助运营、开发以及运维人员快速识别整体调用的瓶颈点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一整套的可观测系统，它能确保你洞察系统，跟踪系统的健康状态、可用性以及系统内部发生的事情。&lt;/p&gt;

&lt;p&gt;对于整个可观测系统的建设，需要注意如下两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;确定质量标准是什么，并确保系统持续逼近或保持在质量标准极限范围内&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;系统地关注这项工作—而不应该只是随机地查看一下系统&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在整个企业级可观测系统中，我认为至少应该包括如下几个特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;完备指标采集: 可以对接企业内大部分的设备与技术栈相应的监控指标；同时，支持常见设备的监控指标体系，可以快速接入监控设备和指标，避免所有设备监控都是从头构建；对于日志数据的采集支持&lt;/li&gt;
&lt;li&gt;海量设备支持: 企业IT系统数量和规模越来越大，因此监控系统比以前需要监控海量设备监控。&lt;/li&gt;
&lt;li&gt;监控数据存储和分析: 监控数据是运维分析、运维自动化和智能化的基础，因此海量监控数据存储以及基于监控数据的可视化分析是一个监控系统的基本能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可观测系统是整个运维体系的基础，它需要提供整个运维体系的数据化支持。&lt;/p&gt;

&lt;p&gt;因此，一个企业级的可观测性系统应该是平台化的。一方面可以通过配置或者开发实现更多 &lt;code&gt;运维指标&lt;/code&gt;的接入；另一方面，亦可对接更多的&lt;code&gt;专业运维工具&lt;/code&gt;，整合并打通多元的运维数据，为更多运维场景提供数据服务。从整体上，可观测性系统为企业运维提供了一个&lt;code&gt;数据基础&lt;/code&gt;，让我们对&lt;code&gt;事故响应以及容量预测&lt;/code&gt;等方面更多使用数据而非凭借以往经验和拍脑袋做出决策。&lt;/p&gt;

&lt;h4 id=&#34;故障响应&#34;&gt;故障响应&lt;/h4&gt;

&lt;p&gt;如果有什么东西出了故障，该如何提醒大家并做出回应？工具可以帮助解决这个问题，国为它可以定义提醒人类的规则。&lt;/p&gt;

&lt;p&gt;故障响应是建立在&lt;code&gt;使用可观测性系统构建的数据&lt;/code&gt;之上，并借助反馈循环，来帮助我们加强对服务的监控。&lt;/p&gt;

&lt;p&gt;故障响应通常包含如下几个动作:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;关注: 不论是主动发现瓶颈点或异常点，还是通过可观测性系统被动暴露瓶颈点，我们都应该进行主动关注&lt;/li&gt;
&lt;li&gt;交流: 及时将观察到风险点通知到相关方，并告知影响面以及相关的补救措施&lt;/li&gt;
&lt;li&gt;恢复: 三方达成一致后，根据补救措施进行修复相关风险点和异常点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是，如果在前期整个可观测性系统能够做好，通常故障应当始于一个简单的告警信息或一个报障电话，因此，通常情况下，可观测系统做的足够好仅能起到追溯和排查的作用，但是无法起到及时发现的作用，此时就需要依赖于各个观测数据进行计算和评估告警，以及时将相关的告警通知到相关人，以暴露风险点。&lt;/p&gt;

&lt;p&gt;告警只是整个故障响应的第一个环节，解决的是故障如何发现的问题，而大多数的故障响应工作都是关于定义处理策略和提供培训的，以便人们在收到警报时知道该怎么做，通常这部分更多的是过去历史经验和运维经历的总结和沉淀，包括经验的一些抽象和工具化沉淀，以保证故障响应的效率和普遍化(即不依赖人为经验)。&lt;/p&gt;

&lt;p&gt;而对于整个告警系统来说，需要确保的是告警的有效性，否则，整个报警系统很有可能沦落为垃圾数据制造机，告警有效性意味着需要满足如下两个需求:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;告警及时性: 系统有问题需要及时通过告警信息告知运维处理人员及时处理告警;&lt;/li&gt;
&lt;li&gt;告警准确性: 只要有告警信息系统必然出现问题(对于很多企业可能存在大量的无用告警，比如磁盘问题，mem等相关问题，当然这里涉及到了自动化、业务形态、告警阈值的问题);&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在整个运维过程中，我们经常会发现有大量的无关紧要的告警信息，让运维人员的注意力迷失在告警海洋当中，而通常非运维领域的领导会关注整个告警的响应程度，因此，抑制和消除无效的告警，让运维人员不被告警风暴所吞没，也是告警管理中重点建设的内容。&lt;/p&gt;

&lt;p&gt;通常情况，在我们的各个可观测系统构建完成后，可以通过整合到监控平台中的各种监控数据，应用趋势预测、短周期检测、间歇性恢复、基线判断、重复压缩等算法和手段实现告警压缩收敛，强化告警的有效性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfxkaxxf68j30u00dhjtx.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同时，面向一线的运维人员，我们需要根据同一个系统或设备的多个监控指标进行综合性建模和分析，汇总成一个健康度的分值，给予一线运维人员系统的基于健康度的系统分层评价体系，真实、直观反映系统运行状态，实现问题快速定界。&lt;/p&gt;

&lt;p&gt;比如，通过基础资源的多个指标进行综合加权计算来整体评估该资源的利用率；通过一个应用关联的全部资源的资源利用率以及应用的运维架构整体建模分析来计算一个分值来整体评估该应用的健康程度。&lt;/p&gt;

&lt;p&gt;这个过程如果做得成熟一些，可以根据内部已有的解决方案和告警进行闭环打通，一个简单的场景就是，当磁盘满时，告警会首先触发一次标准化的磁盘巡检，并进行相关的可丢弃数据的删除，如果依然无法解决该报警，下次可直接关联到一线运维进行人工干预，之后进行标准化经验总结。&lt;/p&gt;

&lt;h4 id=&#34;故障复盘&#34;&gt;故障复盘&lt;/h4&gt;

&lt;p&gt;故障复盘就是对于过去的一些服务异常和服务中断情况进行回顾和总结，以确保相同问题下次不会再出现。为了让大家团结协作，我们希望建立一种无指责、透明的事后文化。个人不应该害怕事故，而是确信如果事故发生，团队将会响应和改进系统。&lt;/p&gt;

&lt;p&gt;备注: 其实在国内的SRE文化中，一般只有对大型，对业务有重大影响的事故才会进行复盘，但实际上如果在时间和经历允许的情况下，对于一般的普通事故也应该在小范围进行复盘，正所谓大的故障都是从不断的小问题一点一点积累的。另外，其实对于运维相关的个人而言，我们也应当及时的进行小故障复盘，以不断加强个人的故障处理和修复能力。&lt;/p&gt;

&lt;p&gt;我认为SRE的一个关键共识正是承认了系统的不完美性，追求永不停机的系统是不现实的。基于不完美系统，我们无可避免要面对和经历系统故障与失败。&lt;/p&gt;

&lt;p&gt;所以我们重要的并非找到为这个故障责任的这个人或者那个人，而是更应该创根问底地复盘这个故障和失败的根本原因是什么，以及如何避免再次出现相同的故障。系统可靠性是整个团队共同奋斗的方向，从失败中快速恢复并吸取教训，每个人放心地提出问题，应对停机，并努力改进系统。&lt;/p&gt;

&lt;p&gt;备注: 通常很多企业内部在故障复盘过程中，相关人员可能将故障和失败的根因追溯 不经意间 当做了故障定责和一系列的惩罚措施，通过一些惩戒措施来强行约定故障的发生，这种方式往往是非常不可取的，试想每个人都不想出现事故，要么是认知之外，要么是规则缺陷，永远没有一个人明知会有故障而偏偏去制造故障的。&lt;/p&gt;

&lt;p&gt;需要牢记的是: &lt;code&gt;故障是我们可以从中学习的东西，而不是让人害怕和羞耻的事情！&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在日常运维过程中，出现故障等事故对于我们而言其实是一个很好的复盘学习机会。通过历史监控数据，分析事故其中的根本原因，制定后续应对策略，并且通过运维平台将这些应对策略编辑成标准化、可重用、自动化的运维应用场景，为后续相同问题的处理提供标准且快捷的解决方案。这正是事后回顾这个过程最真实的价值体现。&lt;/p&gt;

&lt;h4 id=&#34;测试与发布&#34;&gt;测试与发布&lt;/h4&gt;

&lt;p&gt;测试与发布对于整个稳定性和可靠性的主要出于一个预防的作用，预防是指尝试限制发生的事故数量，并确保在发布新代码时基础架构和服务能够保持稳定。&lt;/p&gt;

&lt;p&gt;作为一个长期从事运维工作的人，可能内心中最为恐惧的莫过于新应用版本发布。因为除了硬件和网络设备损坏这个属于天灾级别的概率事件外，新应用版本发布的第二天通常是停机与事故的高危期。所以，对于一些量级较大的产品通常会在节假日以及重要活动前夕进行封网操作，以避免新版本上线而导致的业务bug出现。&lt;/p&gt;

&lt;p&gt;而测试是在成本和风险之间找到适当的平衡活动。如果过于冒险，你们可能就会疲于应付系统失败；反过来说，如果你太保守，你就不能足够快地发布新东西，让企业在市场上生存下来。&lt;/p&gt;

&lt;p&gt;在错误预算比较多（即在一段时间内故障导致系统停机时长较少）的情况下，可以适当减少测试资源并放宽系统上线的测试和条件，让业务可以有更多的功能上线，以保持业务的敏态；在错误预算比较少（即在一段时间内故障导致系统停机时长较多）的情况下，则要增加测试资源并收紧系统上线的测试，让系统的潜在风险得到更多有效的释放，避免系统停机保持系统的稳态。这种敏态与稳态之间的平衡，需要整个运维与开发团队来共同承担。&lt;/p&gt;

&lt;p&gt;除了测试外，应用发布也是一项运维团队通常要承担的责任。SRE的一个原则是将一切可以重复性劳动代码化和工具化；此外，应用发布的复杂程度往往与系统的复杂程度成正比。因此在应用系统上规模企业，往往已经着手基于自动化框架构建自动化的应用发布过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfxl3eouisj30u00c8dhq.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过自动化发布工具，我们可以构建流水线实现部署的过程中所有的操作（如编译打包、测试发布、生产准备、告警屏蔽、服务停止、数据库执行、应用部署、服务重启等）全部自动化。&lt;/p&gt;

&lt;h4 id=&#34;容量规划&#34;&gt;容量规划&lt;/h4&gt;

&lt;p&gt;容量规划是关于预测未来和发现系统极限的，容量规划也是为了确保系统可以随着时间的推移得到完善和增强。&lt;/p&gt;

&lt;p&gt;规划的主要目标是管理风险和期望，对于容量规划，涉及到将容量扩展到整个业务；所关注的期望是人们在看到业务增长时期望服务如何响应。风险是在额外的基础设施上花费时间和金钱来处理这个问题。&lt;/p&gt;

&lt;p&gt;容量规划首先是对未来预测性的分析与判断，其预测的基础正是海量的运维数据。因此，容量规划除了有相应的架构和规划团队外，一个全面的运维数据中心是实现系统容量规划的必须设施。&lt;/p&gt;

&lt;p&gt;容量趋势预警和分析将综合地从各种运维监控、流程管理等数据源中收集、整理、清洗并结构化地存储各种运维数据，将这些来自于各种工具的运维数据打通融合并且构建各种数据主题。&lt;/p&gt;

&lt;p&gt;应用这些数据主题的数据用于帮助运维人员对问题进行评估，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当前的容量是多少&lt;/li&gt;
&lt;li&gt;何时达到容量极限&lt;/li&gt;
&lt;li&gt;应该如何更改容量&lt;/li&gt;
&lt;li&gt;执行容量规划&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;运维平台除了可以提供必要的数据支持外，还需要提供必要的数据可视化支持能力。运维数据可视化提供了一些必要的能力保障运维人员可以更好地利用其中的运维数据评估容量。&lt;/p&gt;

&lt;p&gt;首先，运维平台需要有极强的数据检索能力。运维平台存储着海量的运维数据，运维人员为了尝试建立和验证一个探索性场景的时候，往往多次反复检索和查询特定数据。如果运维数据分析平台的数据查询很慢或者查询角度很少的情况下，运维人员建立场景的时间就会拖得很长甚至进行不下去。因此，运维人员可通过平台可以实现关键字、统计函数、单条件、多条件、模糊多维度查找功能，以及实现海量数据秒级查询，才能更有效帮助运维人员更便捷分析数据。&lt;/p&gt;

&lt;p&gt;其二，平台需要强大的数据可视化能力。人们常说“千言万语不及一图”，运维人员经常会通过各系统的运维数据进行统计分析并生成各类实时报表，对各类运维数据（如应用日志、交易日志、系统日志）进行多维度、多角度深入分析、预测及可视化展现，将他们分析的预测结果和经验向他人表达和推广。&lt;/p&gt;

&lt;h4 id=&#34;自动化工具开发&#34;&gt;自动化工具开发&lt;/h4&gt;

&lt;p&gt;SRE不仅涉及运营，还涉及软件开发，当然这部分指的是和运维以及SRE领域相关的工具和平台开发。在Google的SRE体系中，SRE工程师将花费大约一半的时间来开发新的工具和服务，这些工具的一部分用于自动化一些手动任务，而其他部分用于来不断填补和修复整个SRE体系内部的其他系统。&lt;/p&gt;

&lt;p&gt;通过编写代码把自己和其他人从重复的工作中解放出来，如果我们不需要人类来完成任务，那么就编写代码，这样人类就不需要参与其中了。&lt;/p&gt;

&lt;p&gt;SRE从内心上鄙视重复性的工作，将从原有的人工加被动响应，转变为&lt;code&gt;更高效、更为自动化&lt;/code&gt;的运维体系。&lt;/p&gt;

&lt;p&gt;自动化运维框架:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfxlg6x4l2j30u00cogoj.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;自动化运维工具的优势和必要性:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;提高效率: 由程序自动化操作，有效地降低运维人力资源的投入，也让运维人员的精力得以释放并投向更为重要的领域。&lt;/li&gt;
&lt;li&gt;操作的标准化: 将原来许多复杂、易错的手工操作实现统一运维操作入口，实现运维操作白屏化，提升运维操作的可管理性；同时，减少由于运维人员情绪带来手工误操作，避免“从删库到跑路”这样的悲剧的发生。&lt;/li&gt;
&lt;li&gt;运维经验能力的传承: 运维自动化工具将原来许多运维团队积累的经验以代码方式总结为各种运维工具，实现自动化和白屏化的运维操作。运维团队的后来者，可以有效地继承、重复使用并优化它们。这种代码化的工作传承，将个人能力转变为团队能力，并减少人员流动带来对工作的影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;构建自动化运维体系就必须以&lt;code&gt;运维场景&lt;/code&gt;为基础，这些运维场景是在本企业内反复迭代和打造，是企业中最常用的运维场景。&lt;/p&gt;

&lt;p&gt;比如常见的运维场景：软件安装部署、应用发布交付、资产管理、告警自动处理、故障分析、资源申请、自动化巡检等等。因此，整个自动化运维体系建设时也应支持多种不同类型的自动化作业配置能力，通过简单的脚本开发、场景配置和可视化定制流程实现更多运维场景的实现。&lt;/p&gt;

&lt;h4 id=&#34;用户体验&#34;&gt;用户体验&lt;/h4&gt;

&lt;p&gt;用户体验这一层要说的是，作为SRE来讲，从用户的角度来保证业务的稳定性和可用性才是最终目标。这个才传统意义上的运维人员是不会关注这一点的，因为大家通常只会考虑到我底层运维的系统或底层资源是否稳定，但实际上整个业务的稳定才是SRE需要关心的问题，而业务的稳定性和可用性通常需要站在用户的角度来模拟和衡量整体的可用性和可靠性。&lt;/p&gt;

&lt;p&gt;在前面提到的所有SRE相关的工作范畴，无论是监控、事故响应、回顾、测试与发布、容量规划以及构建自动化工具，无非都是为了提供更好的系统用户业务体验而服务的。因此，我们在运维的过程中无不需要注意关注系统的用户体验。&lt;/p&gt;

&lt;p&gt;而在实际运维工作中，我们往往可以通过应用日志、监控数据、业务拔测等业务相关的用户体验信息。在运维数据平台中，通过这些用户体验监测数据之间的关联和串联，重现用户的最终业务调用链路以及各应用环节对性能数据的关系。最终形成从业务用户体验数据入手，逐步实现系统运行状态数据、设备运行状态数据链路的打通，让运维体系实现以最终用户体验为中心的目标。&lt;/p&gt;

&lt;p&gt;这些用户体验的信息，对于运维团队掌握客户整体的用户体验情况、系统可用性的监测以及系统针对性的优化提供着无可替代的作用。&lt;/p&gt;

&lt;p&gt;其实，SRE运维体系更为强调以用户的体验为核心，以自动化和运维数据为手段，实现应用业务连续性保障，从这个点出发，我们会发现和以往的传统运维还是有很大的区别的，我们不再仅仅是单纯的安装和部署工程师，我们需要通过一系列的技术手段来不断保障上层业务的稳定性和可靠性。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>kafka中关于HW(High Watermark)和Leader Epoch的讨论</title>
      <link>https://bgbiao.top/post/kafka%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8Cleader-epoch%E7%9A%84%E8%AE%A8%E8%AE%BA/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8Cleader-epoch%E7%9A%84%E8%AE%A8%E8%AE%BA/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;我们知道在kafka中有一个名词叫做HW(High Watermark)，但是具体这个高水位是用来做什么的呢？我们一起来学习下&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;kafka中的高水位的作用:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。&lt;/li&gt;
&lt;li&gt;帮助 Kafka 完成副本同步&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfva86hzzrj31bc0h6go3.jpg&#34; alt=&#34;kafka高水位以及消息提交图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;值得注意的是，在kafka的某个topic中，分区和副本都有HW的概念，而分区的HW是所有副本HW的最小值，也是消费者能够消费到最大消息。(即: 消费者只能消费已经提交的消息)&lt;/p&gt;

&lt;p&gt;另外，位移值等于高水位的消息也属于未提交消息。也就是说，&lt;code&gt;高水位上的消息是不能被消费者消费&lt;/code&gt;的。&lt;/p&gt;

&lt;p&gt;图中还有一个日志末端位移的概念，即 Log End Offset，简写是 LEO。它表示副本写入下一条消息的位移值。注意，数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15。显然，介于高水位和 LEO 之间的消息就属于未提交消息。这也从侧面告诉了我们一个重要的事实，那就是：&lt;code&gt;同一个副本对象，其高水位值不会大于 LEO 值&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;高水位更新机制&#34;&gt;高水位更新机制&lt;/h3&gt;

&lt;p&gt;现在，我们知道了每个副本对象都保存了一组高水位值和 LEO 值，但实际上，在 Leader 副本所在的 Broker 上，还保存了其他 Follower 副本的 LEO 值。我们一起来看看下面这张图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvb7on0vpj316f0u0dju.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在这张图中，我们可以看到，Broker 0 上保存了某分区的 Leader 副本和所有 Follower 副本的 LEO 值，而 Broker 1 上仅仅保存了该分区的某个 Follower 副本。Kafka 把 Broker 0 上保存的这些 Follower 副本又称为&lt;code&gt;远程副本&lt;/code&gt; Remote Replica）。Kafka 副本机制在运行过程中，会更新 Broker 1 上 Follower 副本的高水位和 LEO 值，同时也会更新 Broker 0 上 Leader 副本的高水位和 LEO 以及所有远程副本的 LEO，但它不会更新远程副本的高水位值，也就是我在图中标记为灰色的部分。&lt;/p&gt;

&lt;p&gt;为什么要在 Broker 0 上保存这些远程副本呢？其实，它们的主要作用是，&lt;code&gt;帮助 Leader 副本确定其高水位，也就是分区高水位&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;为了帮助你更好地记忆这些值被更新的时机，我做了一张表格。只有搞清楚了更新机制，我们才能开始讨论 Kafka 副本机制的原理，以及它是如何使用高水位来执行副本消息同步的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvb9nilwvj30h60fogo4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;判断Leader 副本保持同步的条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;远程 Follower 副本在 ISR 中&lt;/li&gt;
&lt;li&gt;Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参数 replica.lag.time.max.ms 的值。如果使用默认值的话，就是不超过 10 秒&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;乍一看，这两个条件好像是一回事，因为目前某个副本能否进入 ISR 就是靠第 2 个条件判断的。但有些时候，会发生这样的情况：即 Follower 副本已经 “追上” 了 Leader 的进度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 1 个条件的话，就可能出现某些副本具备了 “进入 ISR” 的资格，但却尚未进入到 ISR 中的情况。此时，分区高水位值就可能超过 ISR 中副本 LEO，而高水位 &amp;gt; LEO 的情形是不被允许的。&lt;/p&gt;

&lt;h3 id=&#34;副本同步机制解析&#34;&gt;副本同步机制解析&lt;/h3&gt;

&lt;p&gt;副本同步的全过程:&lt;/p&gt;

&lt;p&gt;首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbgu2idsj30nd03awet.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当生产者给主题分区发送一条消息后，状态变更为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbh4glr3j30nd07wwf7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。&lt;/p&gt;

&lt;p&gt;Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbhh5e15j30nc08a3z8.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。&lt;code&gt;它们需要在下一轮的fetch request中被更新&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbi5gvykj30nu0cft9w.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 =1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。&lt;/p&gt;

&lt;h3 id=&#34;leader-epoch-登场&#34;&gt;Leader Epoch 登场&lt;/h3&gt;

&lt;p&gt;从刚才的分析中，我们知道，Follower 副本的高水位更新需要一轮额外的拉取请求才能实现。如果把上面那个例子扩展到多个 Follower 副本，情况可能更糟，也许需要多轮拉取请求。也就是说，Leader 副本高水位更新和 Follower 副本高水位更新在时间上是存在错配的。这种错配是很多 “数据丢失” 或 “数据不一致” 问题的根源。基于此，社区在 0.11 版本正式引入了 Leader Epoch 概念，来规避因高水位更新错配导致的各种不一致问题。&lt;/p&gt;

&lt;p&gt;所谓 Leader Epoch，我们大致可以认为是 &lt;code&gt;Leader 版本&lt;/code&gt;。它由两部分数据组成。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力&lt;/li&gt;
&lt;li&gt;起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我举个例子来说明一下 Leader Epoch。假设现在有两个 Leader Epoch&lt;0, 0&gt; 和 &lt;1, 120&gt;，那么，第一个 Leader Epoch 表示版本号是 0，这个版本的 Leader 从位移 0 开始保存消息，一共保存了 120 条消息。之后，Leader 发生了变更，版本号增加到 1，新版本的起始位移是 120。&lt;/p&gt;

&lt;p&gt;Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目，否则就不做更新。这样，每次有 Leader 变更时，新的 Leader 副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。&lt;/p&gt;

&lt;p&gt;接下来，我们来看一个实际的例子，它展示的是 Leader Epoch 是如何防止数据丢失的。请先看下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbnxpmjcj30x30u0q75.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我稍微解释一下，单纯依赖高水位是怎么造成数据丢失的。开始时，副本 A 和副本 B 都处于正常状态，A 是 Leader 副本。某个使用了默认 acks 设置的生产者程序向 A 发送了两条消息，A 全部写入成功，此时 Kafka 会通知生产者说两条消息全部发送成功。现在我们假设 Leader 和 Follower 都写入了这两条消息，而且 Leader 副本的高水位也已经更新了，但 Follower 副本高水位还未更新 —— 这是可能出现的。还记得吧，Follower 端高水位的更新与 Leader 端有时间错配。倘若此时副本 B 所在的 Broker 宕机，当它重启回来后，副本 B 会执行日志截断操作，将 LEO 值调整为之前的高水位值，也就是 1。这就是说，位移值为 1 的那条消息被副本 B 从磁盘中删除，此时副本 B 的底层磁盘文件中只保存有 1 条消息，即位移值为 0 的那条消息。&lt;/p&gt;

&lt;p&gt;当执行完截断操作后，副本 B 开始从 A 拉取消息，执行正常的消息同步。如果就在这个节骨眼上，副本 A 所在的 Broker 宕机了，那么 Kafka 就别无选择，只能让副本 B 成为新的 Leader，此时，当 A 回来后，需要执行相同的日志截断操作，即将高水位调整为与 B 相同的值，也就是 1。这样操作之后，位移值为 1 的那条消息就从这两个副本中被永远地抹掉了。这就是这张图要展示的数据丢失场景。&lt;/p&gt;

&lt;p&gt;严格来说，这个场景发生的前提是 Broker 端参数 &lt;code&gt;min.insync.replicas 设置为 1&lt;/code&gt;。此时一旦消息被写入到 Leader 副本的磁盘，就会被认为是 “已提交状态”，但现有的时间错配问题导致 Follower 端的高水位更新是有滞后的。如果在这个短暂的滞后时间窗口内，接连发生 Broker 宕机，那么这类数据的丢失就是不可避免的。&lt;/p&gt;

&lt;p&gt;现在，我们来看下如何利用 Leader Epoch 机制来规避这种数据丢失。我依然用图的方式来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfvbp51hefj319g0u0wj2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;场景和之前大致是类似的，只不过引用 Leader Epoch 机制后，Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 Leader 的 LEO 值。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &amp;gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。这是对高水位机制的一个明显改进，即副本是否执行日志截断不再依赖于高水位进行判断。&lt;/p&gt;

&lt;p&gt;现在，副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。这样，通过 Leader Epoch 机制，Kafka 完美地规避了这种数据丢失场景。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka经典面试题详解</title>
      <link>https://bgbiao.top/post/kafka%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AF%A6%E8%A7%A3/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;无论是作为面试官，还是应聘者，我都接触过很多 Kafka 面试题。而在最近面试了很多候选人，发现写了熟悉Kafka，但是对于Kafka相关的知识却是只知道大概用处，简单搭建和使用。我想说，虽然我们是SRE(可靠性工程师)，但不论你是业务层的SRE还是基础设施层的SRE，我们都需要对业务方的使用场景有足够理解，或者对我们要提供的服务有足够的了解才行，这样你才能整体的保证你的业务连续性以及业务可靠性。因此，专门总结了如下经典的kafka面试详解。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;以下面试题，参考胡大的&lt;code&gt;Kafka 核心源码解读&lt;/code&gt;，对相关的知识进行了补充和思考。&lt;/p&gt;

&lt;h3 id=&#34;基础题目&#34;&gt;基础题目&lt;/h3&gt;

&lt;h4 id=&#34;1-apache-kafka-是什么&#34;&gt;1.Apache Kafka 是什么？&lt;/h4&gt;

&lt;p&gt;能问这道题，主要是想看候选人对于kafka的使用场景以及定位认知理解有多深，同时候可以知道候选人对于这项技术的关注度。&lt;/p&gt;

&lt;p&gt;我们都知道，在开源软件中，大部分软件随着用户量的增加，整个软件的功能和定位也有了新的变化，而Apache Kafka 一路发展到现在，已经由最初的分布式提交日志系统逐渐演变成了实时流处理框架。&lt;/p&gt;

&lt;p&gt;因此，这道题你最好这么回答：&lt;strong&gt;Apach Kafka 是一款分布式流处理平台，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用(通常也会称之为消息总线message bus)。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于&lt;code&gt;分布式流处理平台&lt;/code&gt;，其实从它官方的logo以及slogan我们就很容易看出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kafka.apache.org/images/logo.png&#34; alt=&#34;kafka-logo&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-什么是消费者组&#34;&gt;2.什么是消费者组?&lt;/h4&gt;

&lt;p&gt;消费者组是 Kafka 独有的概念，如果面试官问这个，就说明他对此是有一定了解的。&lt;/p&gt;

&lt;p&gt;胡大给的标准答案是: &lt;strong&gt;官网上的介绍言简意赅，即消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;但实际上，消费者组(Consumer Group)其实包含两个概念，作为&lt;code&gt;队列&lt;/code&gt;，消费者组允许你分割数据处理到一组进程集合上(即一个消费者组中可以包含多个消费者进程，他们共同消费该topic的数据)，这有助于你的消费能力的动态调整；作为&lt;code&gt;发布-订阅模型(publish-subscribe)&lt;/code&gt;，kafka允许你将同一份消息广播到多个消费者组里，以此来丰富多种数据使用场景。&lt;/p&gt;

&lt;p&gt;需要注意的是: &lt;strong&gt;在消费者组中，多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组 ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。&lt;/strong&gt; 因此，消费者组在一定程度上也保证了消费者程序的高可用性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfs6dbcw1yj30d6070aar.jpg&#34; alt=&#34;kafka-consumer-group&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 消费者组的题目，能够帮你在某种程度上掌控下面的面试方向。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你擅长&lt;code&gt;位移值原理(Offset)&lt;/code&gt;，就不妨再提一下消费者组的位移提交机制；&lt;/li&gt;
&lt;li&gt;如果你擅长&lt;code&gt;Kafka Broker&lt;/code&gt;，可以提一下消费者组与 Broker 之间的交互；&lt;/li&gt;
&lt;li&gt;如果你擅长与消费者组完全不相关的 &lt;code&gt;Producer&lt;/code&gt;，那么就可以这么说：“消费者组要消费的数据完全来自于 Producer 端生产的消息，我对 Producer 还是比较熟悉的。”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总之，你总得对&lt;code&gt;consumer group&lt;/code&gt;相关的方向有一定理解，然后才能像面试官表名你对某一块很理解。&lt;/p&gt;

&lt;h4 id=&#34;3-在-kafka-中-zookeeper-的作用是什么&#34;&gt;3.在 Kafka 中，ZooKeeper 的作用是什么？&lt;/h4&gt;

&lt;p&gt;这道题，也是我经常会问候选人的题，因为任何分布式系统中虽然都通过一些列的算法去除了传统的关系型数据存储，但是毕竟还是有些数据要存储的，同时分布式系统的特性往往是需要有一些中间人角色来统筹集群。比如我们在整个微服务框架中的&lt;code&gt;Dubbo&lt;/code&gt;，它也是需要依赖一些注册中心或配置中心类的中间件的，以及云原生的Kubernetes使用&lt;code&gt;Etcd&lt;/code&gt;作为整个集群的枢纽。&lt;/p&gt;

&lt;p&gt;标准答案: &lt;strong&gt;目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。之后，等 KIP-500 提案完成后，Kafka 将完全不再依赖于 ZooKeeper。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“存放元数据” 是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。&lt;/li&gt;
&lt;li&gt;“成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。&lt;/li&gt;
&lt;li&gt;“Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;KIP-500 思想，是使用社区自研的基于 Raft 的共识算法，替代 ZooKeeper，实现 Controller 自选举。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-解释下-kafka-中位移-offset-的作用&#34;&gt;4.解释下 Kafka 中位移（offset）的作用&lt;/h4&gt;

&lt;p&gt;标准答案: &lt;strong&gt;在 Kafka 中，每个主题分区下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。这个 ID 数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;答完这些之后，你还可以把整个面试方向转移到你希望的地方:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你深谙 Broker 底层日志写入的逻辑，可以强调下消息在日志中的存放格式&lt;/li&gt;
&lt;li&gt;如果你明白位移值一旦被确定不能修改，可以强调下 “Log Cleaner 组件都不能影响位移值” 这件事情&lt;/li&gt;
&lt;li&gt;如果你对消费者的概念还算熟悉，可以再详细说说&lt;code&gt;位移值&lt;/code&gt;和&lt;code&gt;消费者位移值&lt;/code&gt;之间的区别&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-阐述下-kafka-中的领导者副本-leader-replica-和追随者副本-follower-replica-的区别&#34;&gt;5.阐述下 Kafka 中的领导者副本（Leader Replica）和追随者副本（Follower Replica）的区别&lt;/h4&gt;

&lt;p&gt;推荐的答案: &lt;strong&gt;Kafka 副本当前分为领导者副本和追随者副本。只有 Leader 副本才能对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉（PULL）的方式，被动地同步 Leader 副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备应聘 Leader 副本。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;加分点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;强调 Follower 副本也能对外提供读服务&lt;/strong&gt;。自 Kafka 2.4 版本开始，社区通过引入新的 Broker 端参数，允许 Follower 副本有限度地提供读服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强调 Leader 和 Follower 的消息序列在实际场景中不一致&lt;/strong&gt;。通常情况下，很多因素可能造成leader和follower之间的不同步，比如程序问题，网络问题，broker问题等，短暂的不同步我们可以关注(秒级别)，但长时间的不同步可能就需要深入排查了，因为一旦leader所在节点异常，可能直接影响可用性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 之前确保一致性的主要手段是高水位机制(HW)，但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了&lt;code&gt;Leader Epoch&lt;/code&gt; 机制，来修复高水位值的弊端。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/112118?utm_source=pinpaizhuanqu&amp;amp;utm_medium=geektime&amp;amp;utm_campaign=guanwang&amp;amp;utm_term=guanwang&amp;amp;utm_content=0511&#34;&gt;关于高水位和 Leader Epoch 的讨论&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;实操题目&#34;&gt;实操题目&lt;/h3&gt;

&lt;h4 id=&#34;6-如何设置-kafka-能接收的最大消息的大小&#34;&gt;6.如何设置 Kafka 能接收的最大消息的大小?&lt;/h4&gt;

&lt;p&gt;对于SRE来讲，该题简直是送分题啊，但是，最大消息的设置通常情况下有生产者端，消费者端，broker端和topic级别的参数，我们需要正确设置，以保证可以正常的生产和消费。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Broker端参数: &lt;code&gt;message.max.bytes&lt;/code&gt;,&lt;code&gt;max.message.bytes(topic级别)&lt;/code&gt;,&lt;code&gt;replica.fetch.max.bytes(否则follow会同步失败)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Consumer端参数: &lt;code&gt;fetch.message.max.bytes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;7-监控-kafka-的框架都有哪些&#34;&gt;7.监控 Kafka 的框架都有哪些？&lt;/h4&gt;

&lt;p&gt;对于SRE来讲，依然是送分题。但基础的我们要知道，kafka本身是提供了&lt;code&gt;jmx(Java Management Extensions)&lt;/code&gt;的，我们可以通过它来获取到kafka内部的一些基本数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kafka Manager&lt;/strong&gt;: 更多是kafka的管理，对于SRE非常友好，也提供了简单的瞬时指标监控&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Monitor&lt;/strong&gt;: LinkedIn 开源的免费框架，支持对集群进行系统测试，并实时监控测试结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CruiseControl&lt;/strong&gt;: 也是 LinkedIn 公司开源的监控框架，用于实时监测资源使用率，以及提供常用运维操作等。无 UI 界面，只提供 REST API，可以进行多集群管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMX 监控&lt;/strong&gt;: 由于 Kafka 提供的监控指标都是基于 JMX 的，因此，市面上任何能够集成 JMX 的框架都可以使用，比如 Zabbix 和 Prometheus。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;已有大数据平台自己的监控体系&lt;/strong&gt;: 像 Cloudera 提供的 CDH 这类大数据平台，天然就提供 Kafka 监控方案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMXTool&lt;/strong&gt;: 社区提供的命令行工具，能够实时监控 JMX 指标。可以使用&lt;code&gt;kafka-run-class.sh kafka.tools.JmxTool&lt;/code&gt;来查看具体的用法。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;8-broker-的-heap-size-如何设置&#34;&gt;8.Broker 的 Heap Size 如何设置？&lt;/h4&gt;

&lt;p&gt;其实对于SRE还是送分题，因为目前来讲大部分公司的业务系统都是使用Java开发，因此SRE对于基本的JVM相关的参数应该至少都是非常了解的，核心就在于JVM的配置以及GC相关的知识。&lt;/p&gt;

&lt;p&gt;标准答案: &lt;strong&gt;任何 Java 进程 JVM 堆大小的设置都需要仔细地进行考量和测试。一个常见的做法是，以默认的初始 JVM 堆大小运行程序，当系统达到稳定状态后，手动触发一次 Full GC，然后通过 JVM 工具查看 GC 后的存活对象大小。之后，将堆大小设置成存活对象总大小的 1.5~2 倍。对于 Kafka 而言，这个方法也是适用的。不过，业界有个最佳实践，那就是将 Broker 的 Heap Size 固定为 6GB。经过很多公司的验证，这个大小是足够且良好的。&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;9-如何估算-kafka-集群的机器数量&#34;&gt;9.如何估算 Kafka 集群的机器数量?&lt;/h4&gt;

&lt;p&gt;该题也算是SRE的送分题吧，对于SRE来讲，任何生产的系统第一步需要做的就是容量预估以及集群的架构规划，实际上也就是&lt;strong&gt;机器数量和所用资源之间的关联关系&lt;/strong&gt;，资源通常来讲就是cpu，内存，磁盘容量，带宽。但需要注意的是，kafka因为独有的设计，对于磁盘的要求并不是特别高，普通机械硬盘足够，而通常的瓶颈会出现在带宽上。&lt;/p&gt;

&lt;p&gt;在预估磁盘的占用时，你一定不要忘记计算副本同步的开销。如果一条消息占用 1KB 的磁盘空间，那么，在有 3 个副本的主题中，你就需要 3KB 的总空间来保存这条消息。同时，需要考虑到整个业务Topic数据保存的最大时间，以上几个因素，基本可以预估出来磁盘的容量需求。&lt;/p&gt;

&lt;p&gt;需要注意的是: 对于磁盘来讲，一定要提前和业务沟通好场景，而不是等待真正有磁盘容量瓶颈了才去扩容磁盘或者找业务方沟通方案。&lt;/p&gt;

&lt;p&gt;对于带宽来说，常见的带宽有 1Gbps 和 10Gbps，通常我们需要知道，当带宽占用接近总带宽的 90% 时，丢包情形就会发生。&lt;/p&gt;

&lt;h4 id=&#34;10-leader-总是-1-怎么破&#34;&gt;10.Leader 总是 -1，怎么破？&lt;/h4&gt;

&lt;p&gt;对于有经验的SRE来讲，早期的kafka版本应该多多少少都遇到过该种情况，通常情况下就是&lt;code&gt;controller&lt;/code&gt;不工作了，导致无法分配leader，那既然知道问题后，解决方案也就很简单了。重启controller节点上的kafka进程，让其他节点重新注册controller角色，但是如上面&lt;code&gt;zookeeper&lt;/code&gt;的作用，你要知道为什么&lt;code&gt;controller&lt;/code&gt;可以自动注册。&lt;/p&gt;

&lt;p&gt;当然了，当你知道&lt;code&gt;controller&lt;/code&gt;的注册机制后，你也可以说: &lt;strong&gt;删除 ZooKeeper 节点 /controller，触发 Controller 重选举。Controller 重选举能够为所有主题分区重刷分区状态，可以有效解决因不一致导致的 Leader 不可用问题&lt;/strong&gt;。但是，需要注意的是，直接操作&lt;code&gt;zookeeper&lt;/code&gt;是一件风险很大的操作，就好比在Linux中执行了&lt;strong&gt;rm -rf /xxx&lt;/strong&gt;一样，如果在&lt;code&gt;/&lt;/code&gt;和&lt;code&gt;xxx&lt;/code&gt;之间不小心多了几个空格，那&amp;rdquo;恭喜你&amp;rdquo;，今年白干了。&lt;/p&gt;

&lt;h3 id=&#34;炫技式题目&#34;&gt;炫技式题目&lt;/h3&gt;

&lt;h4 id=&#34;11-leo-lso-ar-isr-hw-都表示什么含义&#34;&gt;11.LEO、LSO、AR、ISR、HW 都表示什么含义？&lt;/h4&gt;

&lt;p&gt;讲真，我不认为这是炫技的题目，特别是作为SRE来讲，对于一个开源软件的原理以及概念的理解，是非常重要的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LEO(Log End Offset)&lt;/strong&gt;: 日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。举个例子，如果日志有 10 条消息，位移值从 0 开始，那么，第 10 条消息的位移值就是 9。此时，LEO = 10。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSO(Log Stable Offset)&lt;/strong&gt;: 这是 Kafka 事务的概念。如果你没有使用到事务，那么这个值不存在（其实也不是不存在，只是设置成一个无意义的值）。该值控制了事务型消费者能够看到的消息范围。它经常与 Log Start Offset，即日志起始位移值相混淆，因为有些人将后者缩写成 LSO，这是不对的。在 Kafka 中，LSO 就是指代 Log Stable Offset。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AR(Assigned Replicas)&lt;/strong&gt;: AR 是主题被创建后，分区创建时被分配的副本集合，副本个数由副本因子决定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISR(In-Sync Replicas)&lt;/strong&gt;: Kafka 中特别重要的概念，指代的是 AR 中那些与 Leader 保持同步的副本集合。在 AR 中的副本可能不在 ISR 中，但 Leader 副本天然就包含在 ISR 中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HW(High watermark)&lt;/strong&gt;: 高水位值，这是控制消费者可读取消息范围的重要字段。一个普通消费者只能 “看到” Leader 副本上介于 Log Start Offset 和 HW（不含）之间的所有消息。水位以上的消息是对消费者不可见的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是，通常在&lt;code&gt;ISR&lt;/code&gt;中，可能会有人问到为什么有时候副本不在ISR中，这其实也就是上面说的Leader和Follower不同步的情况，为什么我们前面说，短暂的不同步我们可以关注，但是长时间的不同步，我们需要介入排查了，因为ISR里的副本后面都是通过&lt;code&gt;replica.lag.time.max.ms&lt;/code&gt;，即Follower 副本的 LEO 落后 Leader LEO 的时间是否超过阈值来决定副本是否在ISR内部的。&lt;/p&gt;

&lt;h4 id=&#34;12-kafka-能手动删除消息吗&#34;&gt;12.Kafka 能手动删除消息吗？&lt;/h4&gt;

&lt;p&gt;Kafka 不需要用户手动删除消息。它本身提供了留存策略，能够自动删除过期消息。当然，它是支持手动删除消息的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对于设置了 Key 且参数 &lt;code&gt;cleanup.policy=compact&lt;/code&gt; 的主题而言，我们可以构造一条 的消息发送给 Broker，依靠 Log Cleaner 组件提供的功能删除掉该 Key 的消息。&lt;/li&gt;
&lt;li&gt;对于普通主题而言，我们可以使用 kafka-delete-records 命令，或编写程序调用 Admin.deleteRecords 方法来删除消息。这两种方法殊途同归，底层都是调用 Admin 的 deleteRecords 方法，通过将分区 Log Start Offset 值抬高的方式间接删除消息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;13-consumer-offsets-是做什么用的&#34;&gt;13.__consumer_offsets 是做什么用的？&lt;/h4&gt;

&lt;p&gt;这是一个内部主题，主要用于存储消费者的偏移量，以及消费者的元数据信息(&lt;code&gt;消费者实例，消费者id&lt;/code&gt;等等)&lt;/p&gt;

&lt;p&gt;需要注意的是: Kafka 的 &lt;code&gt;GroupCoordinator&lt;/code&gt; 组件提供对该主题完整的管理功能，包括该主题的创建、写入、读取和 Leader 维护等。&lt;/p&gt;

&lt;h4 id=&#34;14-分区-leader-选举策略有几种&#34;&gt;14.分区 Leader 选举策略有几种？&lt;/h4&gt;

&lt;p&gt;分区的 Leader 副本选举对用户是完全透明的，它是由 &lt;code&gt;Controller&lt;/code&gt; 独立完成的。你需要回答的是，在哪些场景下，需要执行分区 Leader 选举。每一种场景对应于一种选举策略。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OfflinePartition Leader 选举&lt;/strong&gt;: 每当有分区上线时，就需要执行 Leader 选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区 Leader 选举场景。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReassignPartition Leader 选举&lt;/strong&gt;: 当你手动运行 kafka-reassign-partitions 命令，或者是调用 Admin 的 alterPartitionReassignments 方法执行分区副本重分配时，可能触发此类选举。假设原来的 AR 是 [1，2，3]，Leader 是 1，当执行副本重分配后，副本集合 AR 被设置成 [4，5，6]，显然，Leader 必须要变更，此时会发生 Reassign Partition Leader 选举。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PreferredReplicaPartition Leader 选举&lt;/strong&gt;: 当你手动运行 kafka-preferred-replica-election 命令，或自动触发了 Preferred Leader 选举时，该类策略被激活。所谓的 Preferred Leader，指的是 AR 中的第一个副本。比如 AR 是 [3，2，1]，那么，Preferred Leader 就是 3。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ControlledShutdownPartition Leader 选举&lt;/strong&gt;: 当 Broker 正常关闭时，该 Broker 上的所有 Leader 副本都会下线，因此，需要为受影响的分区执行相应的 Leader 选举。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这 4 类选举策略的大致思想是类似的，即从 AR 中挑选首个在 ISR 中的副本，作为新 Leader。&lt;/p&gt;

&lt;h4 id=&#34;15-kafka-的哪些场景中使用了零拷贝-zero-copy&#34;&gt;15.Kafka 的哪些场景中使用了零拷贝（Zero Copy）&lt;/h4&gt;

&lt;p&gt;其实这道题对于SRE来讲，有点超纲了，不过既然&lt;code&gt;Zero Copy&lt;/code&gt;是kafka高性能的保证，我们需要了解它。&lt;/p&gt;

&lt;p&gt;Zero Copy 是特别容易被问到的高阶题目。在 Kafka 中，体现 Zero Copy 使用场景的地方有两处：&lt;strong&gt;基于 mmap 的索引和日志文件读写所用的 TransportLayer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先说第一个。索引都是基于 MappedByteBuffer 的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap 虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap 的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消 Zero Copy 带来的性能优势。由于这种不确定性，在 Kafka 中，只有索引应用了 mmap，最核心的日志并未使用 mmap 机制。&lt;/p&gt;

&lt;p&gt;再说第二个。TransportLayer 是 Kafka 传输层的接口。它的某个实现类使用了 FileChannel 的 transferTo 方法。该方法底层使用 sendfile 实现了 Zero Copy。对 Kafka 而言，如果 I/O 通道使用普通的 PLAINTEXT，那么，Kafka 就可以利用 Zero Copy 特性，直接将页缓存中的数据发送到网卡的 Buffer 中，避免中间的多次拷贝。相反，如果 I/O 通道启用了 SSL，那么，Kafka 便无法利用 Zero Copy 特性了。&lt;/p&gt;

&lt;h3 id=&#34;深度思考题&#34;&gt;深度思考题&lt;/h3&gt;

&lt;h4 id=&#34;16-kafka-为什么不支持读写分离&#34;&gt;16.Kafka 为什么不支持读写分离？&lt;/h4&gt;

&lt;p&gt;这其实是分布式场景下的通用问题，因为我们知道CAP理论下，我们只能保证C(可用性)和A(一致性)取其一，如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣，因为通常的场景下，副本之间都是通过同步来实现副本数据一致的，那同步过程中肯定会有时间的消耗，如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。&lt;/p&gt;

&lt;p&gt;Leader/Follower 模型并没有规定 Follower 副本不可以对外提供读服务。很多框架都是允许这么做的，只是 Kafka 最初为了避免不一致性的问题，而采用了让 Leader 统一提供服务的方式。&lt;/p&gt;

&lt;p&gt;不过，&lt;strong&gt;自 Kafka 2.4 之后，Kafka 提供了有限度的读写分离，也就是说，Follower 副本能够对外提供读服务&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;17-如何调优-kafka&#34;&gt;17.如何调优 Kafka？&lt;/h4&gt;

&lt;p&gt;作为SRE来讲，任何生产环境的调优，首先需要&lt;strong&gt;识别问题和瓶颈点&lt;/strong&gt;，而不是随意的进行臆想调优。随后，需要&lt;strong&gt;确定优化目标，并且定量给出目标&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于kafka来讲，常见的调优方向基本为: 吞吐量、延时、持久性和可用性，每种目标之前都是由冲突点，这也就要求了，我们在对业务接入使用时，要进行业务场景的了解，以对业务进行相对的集群隔离，因为每一个方向的优化思路都是不同的，甚至是相反的。&lt;/p&gt;

&lt;p&gt;确定了目标之后，还要明确优化的维度。有些调优属于通用的优化思路，比如对操作系统、JVM 等的优化；有些则是有针对性的，比如要优化 Kafka 的 TPS。我们需要从 3 个方向去考虑：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Producer 端&lt;/strong&gt;: 增加&lt;code&gt;batch.size&lt;/code&gt;和&lt;code&gt;linger.ms&lt;/code&gt;，启用压缩，关闭重试&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Broker 端&lt;/strong&gt;: 增加&lt;code&gt;num.replica.fetchers&lt;/code&gt;提升 Follower 同步 TPS，避免 Broker Full GC 等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer&lt;/strong&gt;: 增加&lt;code&gt;fetch.min.bytes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;18-controller-发生网络分区-network-partitioning-时-kafka-会怎么样&#34;&gt;18.Controller 发生网络分区（Network Partitioning）时，Kafka 会怎么样&lt;/h4&gt;

&lt;p&gt;这道题目能够诱发我们对分布式系统设计、CAP 理论、一致性等多方面的思考。&lt;/p&gt;

&lt;p&gt;一旦发生 Controller 网络分区，那么，第一要务就是查看集群是否出现 “脑裂”，即同时出现两个甚至是多个 Controller 组件。这可以根据 Broker 端监控指标 ActiveControllerCount 来判断。&lt;/p&gt;

&lt;p&gt;不过，通常而言，我们在设计整个部署架构时，为了避免这种网络分区的发生，一般会将broker节点尽可能的防止在一个机房或者可用区。&lt;/p&gt;

&lt;p&gt;由于 Controller 会给 Broker 发送 3 类请求，&lt;code&gt;LeaderAndIsrRequest&lt;/code&gt;，&lt;code&gt;StopReplicaRequest&lt;/code&gt;，&lt;code&gt;UpdateMetadataRequest&lt;/code&gt;，因此，一旦出现网络分区，这些请求将不能顺利到达 Broker 端。&lt;/p&gt;

&lt;p&gt;这将影响主题的创建、修改、删除操作的信息同步，表现为集群仿佛僵住了一样，无法感知到后面的所有操作。因此，网络分区通常都是非常严重的问题，要赶快修复。&lt;/p&gt;

&lt;h4 id=&#34;19-java-consumer-为什么采用单线程来获取消息&#34;&gt;19.Java Consumer 为什么采用单线程来获取消息？&lt;/h4&gt;

&lt;p&gt;在回答之前，如果先把这句话说出来，一定会加分：&lt;strong&gt;Java Consumer 是双线程的设计。一个线程是用户主线程，负责获取消息；另一个线程是心跳线程，负责向 Kafka 汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的 “假死” 情况。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。另外一个可能的好处是，可以简化代码的开发。多线程交互的代码是非常容易出错的。&lt;/p&gt;

&lt;h4 id=&#34;20-简述-follower-副本消息同步的完整流程&#34;&gt;20.简述 Follower 副本消息同步的完整流程&lt;/h4&gt;

&lt;p&gt;首先，Follower 发送 FETCH 请求给 Leader。&lt;/p&gt;

&lt;p&gt;接着，Leader 会读取底层日志文件中的消息数据，再更新它内存中的 Follower 副本的 LEO 值，更新为 FETCH 请求中的 fetchOffset 值。&lt;/p&gt;

&lt;p&gt;最后，尝试更新分区高水位值。Follower 接收到 FETCH 响应之后，会把消息写入到底层日志，接着更新 LEO 和 HW 值。&lt;/p&gt;

&lt;p&gt;Leader 和 Follower 的 HW 值更新时机是不同的，Follower 的 HW 更新永远落后于 Leader 的 HW。这种时间上的错配是造成各种不一致的原因。&lt;/p&gt;

&lt;p&gt;因此，对于消费者而言，消费到的消息永远是所有副本中最小的那个HW。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gfs986oapjj30u01hdaj9.jpg&#34; alt=&#34;胡大的kafka源码课程&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Git常用命令</title>
      <link>https://bgbiao.top/post/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;在日常工作中，可能经常会遇到一些一致性需求，需要将本地代码和Git远端代码保持一致，因此这里就主要来记录一些Git的日常操作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;强制覆盖本地代码&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有时候，我们不小心修改错了代码或者之前构思的业务逻辑被推翻了，但是这个迭代中我们增加了很多代码，想要尽快回滚到上一个稳定版本的分支，我们就可以采用强制覆盖本地代码的方式来实现，此时距离上一次commit修改的代码将会被强制覆盖，可以很好的将我们本次的错误需求代码清理掉。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 首先将远端代码全部fetch下来
➜  kafka git:(master) ✗ git fetch --all
Fetching origin
Fetching bgbiao
From https://github.com/goops-top/utils
 * [new branch]      master     -&amp;gt; bgbiao/master

# 将本地代码设置到远端的稳定版本
➜  kafka git:(master) ✗ git reset --hard origin/master
HEAD is now at 1223981 update the go.mod fix the &amp;#39;module declares its path as:&amp;#39;

# 重新pull
➜  kafka git:(master) git pull
Already up to date.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>一文帮你快速回顾正则表达式知识</title>
      <link>https://bgbiao.top/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 在日常工作中，我们经常会使用正则表达式来快速匹配和过滤一些我们期望的字符串来处理一些简单又繁琐的文字统计和过滤操作；而作为一名技术从业者，我们也经常会在程序中或者配置文件中使用正则表达式来处理字符或进行批量配置项的查询和更改，但通常情况下，我们需要对编写的正则表达式进行不断测试才能满足我们的需求，本篇文章带你重新回顾正则表达式，并分享一个在线的正则表达式工具(&lt;a href=&#34;https://regex101.com/)，帮你在工作中快速测试你的正则表达式。&#34;&gt;https://regex101.com/)，帮你在工作中快速测试你的正则表达式。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;什么是正则表达式&#34;&gt;什么是正则表达式？&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;正则表达式是一组由字母和符号组成的特殊文本，它可以用来从文本中找出满足你想要的格式的句子。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个正则表达式是一种从左到右匹配主体字符串的模式。
“Regular expression”这个词比较拗口，我们常使用缩写的术语“regex”或“regexp”。
正则表达式可以从一个基础字符串中根据一定的匹配模式替换文本中的字符串、验证表单、提取字符串等等。&lt;/p&gt;

&lt;p&gt;想象你正在写一个应用，然后你想设定一个用户命名的规则，让用户名包含字符、数字、下划线和连字符，以及限制字符的个数，好让名字看起来没那么丑。
我们使用以下正则表达式来验证一个用户名：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gficxu10luj30hl0bsq3e.jpg&#34; alt=&#34;用户名匹配&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以上的正则表达式可以接受 &lt;code&gt;john_doe&lt;/code&gt;、&lt;code&gt;jo-hn_doe&lt;/code&gt;、&lt;code&gt;john12_as&lt;/code&gt;。
但不匹配&lt;code&gt;Jo&lt;/code&gt;，因为它包含了大写的字母而且太短了。&lt;/p&gt;

&lt;h1 id=&#34;目录&#34;&gt;目录&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#1-基本匹配&#34;&gt;1. 基本匹配&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2-元字符&#34;&gt;2. 元字符&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#21-点运算符-&#34;&gt;2.1 点运算符 .&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#22-字符集&#34;&gt;2.2 字符集&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#221-否定字符集&#34;&gt;2.2.1 否定字符集&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#23-重复次数&#34;&gt;2.3 重复次数&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#231--号&#34;&gt;2.3.1 * 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#232--号&#34;&gt;2.3.2 + 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#233--号&#34;&gt;2.3.3 ? 号&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#24--号&#34;&gt;2.4 {} 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#25--特征标群&#34;&gt;2.5 (&amp;hellip;) 特征标群&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#26--或运算符&#34;&gt;2.6 | 或运算符&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#27-转码特殊字符&#34;&gt;2.7 转码特殊字符&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#28-锚点&#34;&gt;2.8 锚点&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#281--号&#34;&gt;2.8.1 ^ 号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#282--号&#34;&gt;2.8.2 $ 号&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3-简写字符集&#34;&gt;3. 简写字符集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#4-零宽度断言前后预查&#34;&gt;4. 零宽度断言(前后预查)&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#41--正先行断言&#34;&gt;4.1 ?=&amp;hellip; 正先行断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#42--负先行断言&#34;&gt;4.2 ?!&amp;hellip; 负先行断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#43---正后发断言&#34;&gt;4.3 ?&amp;lt;= &amp;hellip; 正后发断言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#44--负后发断言&#34;&gt;4.4 ?&amp;lt;!&amp;hellip; 负后发断言&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#5-标志&#34;&gt;5. 标志&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#51-忽略大小写-case-insensitive&#34;&gt;5.1 忽略大小写（Case Insensitive）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#52-全局搜索-global-search&#34;&gt;5.2 全局搜索（Global search）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#53-多行修饰符-multiline&#34;&gt;5.3 多行修饰符（Multiline）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#额外补充&#34;&gt;额外补充&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#贡献&#34;&gt;贡献&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#许可证&#34;&gt;许可证&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;1-基本匹配&#34;&gt;1. 基本匹配&lt;/h2&gt;

&lt;p&gt;正则表达式其实就是在执行搜索时的格式，它由一些字母和数字组合而成。
例如：一个正则表达式 &lt;code&gt;the&lt;/code&gt;，它表示一个规则：由字母&lt;code&gt;t&lt;/code&gt;开始，接着是&lt;code&gt;h&lt;/code&gt;，再接着是&lt;code&gt;e&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;the&#34; =&gt; The fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dmRygT/1&#34;&gt;https://regex101.com/r/dmRygT/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;正则表达式&lt;code&gt;123&lt;/code&gt;匹配字符串&lt;code&gt;123&lt;/code&gt;。它逐个字符的与输入的正则表达式做比较。&lt;/p&gt;

&lt;p&gt;正则表达式是大小写敏感的，所以&lt;code&gt;The&lt;/code&gt;不会匹配&lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;The&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/1paXsy/1&#34;&gt;https://regex101.com/r/1paXsy/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-元字符&#34;&gt;2. 元字符&lt;/h2&gt;

&lt;p&gt;正则表达式主要依赖于元字符。
元字符不代表他们本身的字面意思，他们都有特殊的含义。一些元字符写在方括号中的时候有一些特殊的意思。以下是一些元字符的介绍：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;元字符&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;.&lt;/td&gt;
&lt;td&gt;句号匹配任意单个字符除了换行符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;[ ]&lt;/td&gt;
&lt;td&gt;字符种类。匹配方括号内的任意字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;[^ ]&lt;/td&gt;
&lt;td&gt;否定的字符种类。匹配除了方括号里的任意字符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;*&lt;/td&gt;
&lt;td&gt;匹配&amp;gt;=0个重复的在*号之前的字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;+&lt;/td&gt;
&lt;td&gt;匹配&amp;gt;=1个重复的+号前的字符。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&lt;/td&gt;
&lt;td&gt;标记?之前的字符为可选.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;{n,m}&lt;/td&gt;
&lt;td&gt;匹配num个大括号之前的字符或字符集 (n &amp;lt;= num &amp;lt;= m).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;(xyz)&lt;/td&gt;
&lt;td&gt;字符集，匹配与 xyz 完全相等的字符串.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&amp;#124;&lt;/td&gt;
&lt;td&gt;或运算符，匹配符号前或后的字符.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&amp;#92;&lt;/td&gt;
&lt;td&gt;转义字符,用于匹配一些保留的字符 &lt;code&gt;[ ] ( ) { } . * + ? ^ $ \ &amp;#124;&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;^&lt;/td&gt;
&lt;td&gt;从开始行开始匹配.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;$&lt;/td&gt;
&lt;td&gt;从末端开始匹配.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;2-1-点运算符&#34;&gt;2.1 点运算符 &lt;code&gt;.&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt;是元字符中最简单的例子。
&lt;code&gt;.&lt;/code&gt;匹配任意单个字符，但不匹配换行符。
例如，表达式&lt;code&gt;.ar&lt;/code&gt;匹配一个任意字符后面跟着是&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;r&lt;/code&gt;的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;.ar&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/xc9GkU/1&#34;&gt;https://regex101.com/r/xc9GkU/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-2-字符集&#34;&gt;2.2 字符集&lt;/h2&gt;

&lt;p&gt;字符集也叫做字符类。
方括号用来指定一个字符集。
在方括号中使用连字符来指定字符集的范围。
在方括号中的字符集不关心顺序。
例如，表达式&lt;code&gt;[Tt]he&lt;/code&gt; 匹配 &lt;code&gt;the&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;[Tt]he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/2ITLQ4/1&#34;&gt;https://regex101.com/r/2ITLQ4/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;方括号的句号就表示句号。
表达式 &lt;code&gt;ar[.]&lt;/code&gt; 匹配 &lt;code&gt;ar.&lt;/code&gt;字符串&lt;/p&gt;

&lt;pre&gt;
&#34;ar[.]&#34; =&gt; A garage is a good place to park a c&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;ar.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/wL3xtE/1&#34;&gt;https://regex101.com/r/wL3xtE/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-2-1-否定字符集&#34;&gt;2.2.1 否定字符集&lt;/h3&gt;

&lt;p&gt;一般来说 &lt;code&gt;^&lt;/code&gt; 表示一个字符串的开头，但它用在一个方括号的开头的时候，它表示这个字符集是否定的。
例如，表达式&lt;code&gt;[^c]ar&lt;/code&gt; 匹配一个后面跟着&lt;code&gt;ar&lt;/code&gt;的除了&lt;code&gt;c&lt;/code&gt;的任意字符。&lt;/p&gt;

&lt;pre&gt;
&#34;[^c]ar&#34; =&gt; The car &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/nNNlq3/1&#34;&gt;https://regex101.com/r/nNNlq3/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-3-重复次数&#34;&gt;2.3 重复次数&lt;/h2&gt;

&lt;p&gt;后面跟着元字符 &lt;code&gt;+&lt;/code&gt;，&lt;code&gt;*&lt;/code&gt; or &lt;code&gt;?&lt;/code&gt; 的，用来指定匹配子模式的次数。
这些元字符在不同的情况下有着不同的意思。&lt;/p&gt;

&lt;h3 id=&#34;2-3-1-号&#34;&gt;2.3.1 &lt;code&gt;*&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;*&lt;/code&gt;号匹配 在&lt;code&gt;*&lt;/code&gt;之前的字符出现&lt;code&gt;大于等于0&lt;/code&gt;次。
例如，表达式 &lt;code&gt;a*&lt;/code&gt; 匹配0或更多个以a开头的字符。表达式&lt;code&gt;[a-z]*&lt;/code&gt; 匹配一个行中所有以小写字母开头的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;[a-z]*&#34; =&gt; T&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;he&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;parked&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;in&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;garage&lt;/strong&gt;&lt;/a&gt; #21.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/7m8me5/1&#34;&gt;https://regex101.com/r/7m8me5/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;*&lt;/code&gt;字符和&lt;code&gt;.&lt;/code&gt;字符搭配可以匹配所有的字符&lt;code&gt;.*&lt;/code&gt;。
&lt;code&gt;*&lt;/code&gt;和表示匹配空格的符号&lt;code&gt;\s&lt;/code&gt;连起来用，如表达式&lt;code&gt;\s*cat\s*&lt;/code&gt;匹配0或更多个空格开头和0或更多个空格结尾的cat字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;\s*cat\s*&#34; =&gt; The fat&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt; cat &lt;/strong&gt;&lt;/a&gt;sat on the con&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt;enation.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/gGrwuz/1&#34;&gt;https://regex101.com/r/gGrwuz/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-3-2-号&#34;&gt;2.3.2 &lt;code&gt;+&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;+&lt;/code&gt;号匹配&lt;code&gt;+&lt;/code&gt;号之前的字符出现 &amp;gt;=1 次。
例如表达式&lt;code&gt;c.+t&lt;/code&gt; 匹配以首字母&lt;code&gt;c&lt;/code&gt;开头以&lt;code&gt;t&lt;/code&gt;结尾，中间跟着至少一个字符的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;c.+t&#34; =&gt; The fat &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat sat on the mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Dzf9Aa/1&#34;&gt;https://regex101.com/r/Dzf9Aa/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-3-3-号&#34;&gt;2.3.3 &lt;code&gt;?&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;在正则表达式中元字符 &lt;code&gt;?&lt;/code&gt; 标记在符号前面的字符为可选，即出现 0 或 1 次。
例如，表达式 &lt;code&gt;[T]?he&lt;/code&gt; 匹配字符串 &lt;code&gt;he&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;[T]he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in the garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/cIg9zm/1&#34;&gt;https://regex101.com/r/cIg9zm/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;[T]?he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in t&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;he&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/kPpO2x/1&#34;&gt;https://regex101.com/r/kPpO2x/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-4-号&#34;&gt;2.4 &lt;code&gt;{}&lt;/code&gt; 号&lt;/h2&gt;

&lt;p&gt;在正则表达式中 &lt;code&gt;{}&lt;/code&gt; 是一个量词，常用来限定一个或一组字符可以重复出现的次数。
例如， 表达式 &lt;code&gt;[0-9]{2,3}&lt;/code&gt; 匹配最少 2 位最多 3 位 0~9 的数字。&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{2,3}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;999&lt;/strong&gt;&lt;/a&gt;7 but we rounded it off to &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/a&gt;.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/juM86s/1&#34;&gt;https://regex101.com/r/juM86s/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;我们可以省略第二个参数。
例如，&lt;code&gt;[0-9]{2,}&lt;/code&gt; 匹配至少两位 0~9 的数字。&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{2,}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;9997&lt;/strong&gt;&lt;/a&gt; but we rounded it off to &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/a&gt;.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Gdy4w5/1&#34;&gt;https://regex101.com/r/Gdy4w5/1&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;如果逗号也省略掉则表示重复固定的次数。
例如，&lt;code&gt;[0-9]{3}&lt;/code&gt; 匹配3位数字&lt;/p&gt;

&lt;pre&gt;
&#34;[0-9]{3}&#34; =&gt; The number was 9.&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;999&lt;/strong&gt;&lt;/a&gt;7 but we rounded it off to 10.0.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/Sivu30/1&#34;&gt;https://regex101.com/r/Sivu30/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-5-特征标群&#34;&gt;2.5 &lt;code&gt;(...)&lt;/code&gt; 特征标群&lt;/h2&gt;

&lt;p&gt;特征标群是一组写在 &lt;code&gt;(...)&lt;/code&gt; 中的子模式。&lt;code&gt;(...)&lt;/code&gt; 中包含的内容将会被看成一个整体，和数学中小括号（ ）的作用相同。例如, 表达式 &lt;code&gt;(ab)*&lt;/code&gt; 匹配连续出现 0 或更多个 &lt;code&gt;ab&lt;/code&gt;。如果没有使用 &lt;code&gt;(...)&lt;/code&gt; ，那么表达式 &lt;code&gt;ab*&lt;/code&gt; 将匹配连续出现 0 或更多个 &lt;code&gt;b&lt;/code&gt; 。再比如之前说的 &lt;code&gt;{}&lt;/code&gt; 是用来表示前面一个字符出现指定次数。但如果在 &lt;code&gt;{}&lt;/code&gt; 前加上特征标群 &lt;code&gt;(...)&lt;/code&gt; 则表示整个标群内的字符重复 N 次。&lt;/p&gt;

&lt;p&gt;我们还可以在 &lt;code&gt;()&lt;/code&gt; 中用或字符 &lt;code&gt;|&lt;/code&gt; 表示或。例如，&lt;code&gt;(c|g|p)ar&lt;/code&gt; 匹配 &lt;code&gt;car&lt;/code&gt; 或 &lt;code&gt;gar&lt;/code&gt; 或 &lt;code&gt;par&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;
&#34;(c|g|p)ar&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; is &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;par&lt;/strong&gt;&lt;/a&gt;ked in the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;gar&lt;/strong&gt;&lt;/a&gt;age.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/tUxrBG/1&#34;&gt;https://regex101.com/r/tUxrBG/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-6-或运算符&#34;&gt;2.6 &lt;code&gt;|&lt;/code&gt; 或运算符&lt;/h2&gt;

&lt;p&gt;或运算符就表示或，用作判断条件。&lt;/p&gt;

&lt;p&gt;例如 &lt;code&gt;(T|t)he|car&lt;/code&gt; 匹配 &lt;code&gt;(T|t)he&lt;/code&gt; 或 &lt;code&gt;car&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he|car&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;car&lt;/strong&gt;&lt;/a&gt; is parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/fBXyX0/1&#34;&gt;https://regex101.com/r/fBXyX0/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-7-转码特殊字符&#34;&gt;2.7 转码特殊字符&lt;/h2&gt;

&lt;p&gt;反斜线 &lt;code&gt;\&lt;/code&gt; 在表达式中用于转码紧跟其后的字符。用于指定 &lt;code&gt;{ } [ ] / \ + * . $ ^ | ?&lt;/code&gt; 这些特殊字符。如果想要匹配这些特殊字符则要在其前面加上反斜线 &lt;code&gt;\&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;例如 &lt;code&gt;.&lt;/code&gt; 是用来匹配除换行符外的所有字符的。如果想要匹配句子中的 &lt;code&gt;.&lt;/code&gt; 则要写成 &lt;code&gt;\.&lt;/code&gt; 以下这个例子 &lt;code&gt;\.?&lt;/code&gt;是选择性匹配&lt;code&gt;.&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;
&#34;(f|c|m)at\.?&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt; sat on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/DOc5Nu/1&#34;&gt;https://regex101.com/r/DOc5Nu/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;2-8-锚点&#34;&gt;2.8 锚点&lt;/h2&gt;

&lt;p&gt;在正则表达式中，想要匹配指定开头或结尾的字符串就要使用到锚点。&lt;code&gt;^&lt;/code&gt; 指定开头，&lt;code&gt;$&lt;/code&gt; 指定结尾。&lt;/p&gt;

&lt;h3 id=&#34;2-8-1-号&#34;&gt;2.8.1 &lt;code&gt;^&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;^&lt;/code&gt; 用来检查匹配的字符串是否在所匹配字符串的开头。&lt;/p&gt;

&lt;p&gt;例如，在 &lt;code&gt;abc&lt;/code&gt; 中使用表达式 &lt;code&gt;^a&lt;/code&gt; 会得到结果 &lt;code&gt;a&lt;/code&gt;。但如果使用 &lt;code&gt;^b&lt;/code&gt; 将匹配不到任何结果。因为在字符串 &lt;code&gt;abc&lt;/code&gt; 中并不是以 &lt;code&gt;b&lt;/code&gt; 开头。&lt;/p&gt;

&lt;p&gt;例如，&lt;code&gt;^(T|t)he&lt;/code&gt; 匹配以 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt; 开头的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/5ljjgB/1&#34;&gt;https://regex101.com/r/5ljjgB/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;^(T|t)he&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; car is parked in the garage.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/jXrKne/1&#34;&gt;https://regex101.com/r/jXrKne/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;2-8-2-号&#34;&gt;2.8.2 &lt;code&gt;$&lt;/code&gt; 号&lt;/h3&gt;

&lt;p&gt;同理于 &lt;code&gt;^&lt;/code&gt; 号，&lt;code&gt;$&lt;/code&gt; 号用来匹配字符是否是最后一个。&lt;/p&gt;

&lt;p&gt;例如，&lt;code&gt;(at\.)$&lt;/code&gt; 匹配以 &lt;code&gt;at.&lt;/code&gt; 结尾的字符串。&lt;/p&gt;

&lt;pre&gt;
&#34;(at\.)&#34; =&gt; The fat c&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt; s&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt; on the m&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/y4Au4D/1&#34;&gt;https://regex101.com/r/y4Au4D/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;(at\.)$&#34; =&gt; The fat cat. sat. on the m&lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;at.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/t0AkOd/1&#34;&gt;https://regex101.com/r/t0AkOd/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;3-简写字符集&#34;&gt;3. 简写字符集&lt;/h2&gt;

&lt;p&gt;正则表达式提供一些常用的字符集简写。如下:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;简写&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;.&lt;/td&gt;
&lt;td&gt;除换行符外的所有字符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\w&lt;/td&gt;
&lt;td&gt;匹配所有字母数字，等同于 &lt;code&gt;[a-zA-Z0-9_]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\W&lt;/td&gt;
&lt;td&gt;匹配所有非字母数字，即符号，等同于： &lt;code&gt;[^\w]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\d&lt;/td&gt;
&lt;td&gt;匹配数字： &lt;code&gt;[0-9]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\D&lt;/td&gt;
&lt;td&gt;匹配非数字： &lt;code&gt;[^\d]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\s&lt;/td&gt;
&lt;td&gt;匹配所有空格字符，等同于： &lt;code&gt;[\t\n\f\r\p{Z}]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\S&lt;/td&gt;
&lt;td&gt;匹配所有非空格字符： &lt;code&gt;[^\s]&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\f&lt;/td&gt;
&lt;td&gt;匹配一个换页符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\n&lt;/td&gt;
&lt;td&gt;匹配一个换行符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\r&lt;/td&gt;
&lt;td&gt;匹配一个回车符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\t&lt;/td&gt;
&lt;td&gt;匹配一个制表符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\v&lt;/td&gt;
&lt;td&gt;匹配一个垂直制表符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;\p&lt;/td&gt;
&lt;td&gt;匹配 CR/LF（等同于 &lt;code&gt;\r\n&lt;/code&gt;），用来匹配 DOS 行终止符&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;4-零宽度断言-前后预查&#34;&gt;4. 零宽度断言（前后预查）&lt;/h2&gt;

&lt;p&gt;先行断言和后发断言都属于&lt;strong&gt;非捕获簇&lt;/strong&gt;（不捕获文本 ，也不针对组合计进行计数）。
先行断言用于判断所匹配的格式是否在另一个确定的格式之前，匹配结果不包含该确定格式（仅作为约束）。&lt;/p&gt;

&lt;p&gt;例如，我们想要获得所有跟在 &lt;code&gt;$&lt;/code&gt; 符号后的数字，我们可以使用正后发断言 &lt;code&gt;(?&amp;lt;=\$)[0-9\.]*&lt;/code&gt;。
这个表达式匹配 &lt;code&gt;$&lt;/code&gt; 开头，之后跟着 &lt;code&gt;0,1,2,3,4,5,6,7,8,9,.&lt;/code&gt; 这些字符可以出现大于等于 0 次。&lt;/p&gt;

&lt;p&gt;零宽度断言如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;符号&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?=&lt;/td&gt;
&lt;td&gt;正先行断言-存在&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?!&lt;/td&gt;
&lt;td&gt;负先行断言-排除&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&amp;lt;=&lt;/td&gt;
&lt;td&gt;正后发断言-存在&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;?&amp;lt;!&lt;/td&gt;
&lt;td&gt;负后发断言-排除&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;4-1-正先行断言&#34;&gt;4.1 &lt;code&gt;?=...&lt;/code&gt; 正先行断言&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;?=...&lt;/code&gt; 正先行断言，表示第一部分表达式之后必须跟着 &lt;code&gt;?=...&lt;/code&gt;定义的表达式。&lt;/p&gt;

&lt;p&gt;返回结果只包含满足匹配条件的第一部分表达式。
定义一个正先行断言要使用 &lt;code&gt;()&lt;/code&gt;。在括号内部使用一个问号和等号： &lt;code&gt;(?=...)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;正先行断言的内容写在括号中的等号后面。
例如，表达式 &lt;code&gt;(T|t)he(?=\sfat)&lt;/code&gt; 匹配 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt;，在括号中我们又定义了正先行断言 &lt;code&gt;(?=\sfat)&lt;/code&gt; ，即 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt; 后面紧跟着 &lt;code&gt;(空格)fat&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he(?=\sfat)&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/IDDARt/1&#34;&gt;https://regex101.com/r/IDDARt/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-2-负先行断言&#34;&gt;4.2 &lt;code&gt;?!...&lt;/code&gt; 负先行断言&lt;/h3&gt;

&lt;p&gt;负先行断言 &lt;code&gt;?!&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其后不跟随着断言中定义的格式。
&lt;code&gt;正先行断言&lt;/code&gt;  定义和 &lt;code&gt;负先行断言&lt;/code&gt; 一样，区别就是 &lt;code&gt;=&lt;/code&gt; 替换成 &lt;code&gt;!&lt;/code&gt; 也就是 &lt;code&gt;(?!...)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;表达式 &lt;code&gt;(T|t)he(?!\sfat)&lt;/code&gt; 匹配 &lt;code&gt;The&lt;/code&gt; 和 &lt;code&gt;the&lt;/code&gt;，且其后不跟着 &lt;code&gt;(空格)fat&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(T|t)he(?!\sfat)&#34; =&gt; The fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/V32Npg/1&#34;&gt;https://regex101.com/r/V32Npg/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-3-正后发断言&#34;&gt;4.3 &lt;code&gt;?&amp;lt;= ...&lt;/code&gt; 正后发断言&lt;/h3&gt;

&lt;p&gt;正后发断言 记作&lt;code&gt;(?&amp;lt;=...)&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其前跟随着断言中定义的格式。
例如，表达式 &lt;code&gt;(?&amp;lt;=(T|t)he\s)(fat|mat)&lt;/code&gt; 匹配 &lt;code&gt;fat&lt;/code&gt; 和 &lt;code&gt;mat&lt;/code&gt;，且其前跟着 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(?&lt;=(T|t)he\s)(fat|mat)&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; cat sat on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/avH165/1&#34;&gt;https://regex101.com/r/avH165/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;4-4-负后发断言&#34;&gt;4.4 &lt;code&gt;?&amp;lt;!...&lt;/code&gt; 负后发断言&lt;/h3&gt;

&lt;p&gt;负后发断言 记作 &lt;code&gt;(?&amp;lt;!...)&lt;/code&gt; 用于筛选所有匹配结果，筛选条件为 其前不跟随着断言中定义的格式。
例如，表达式 &lt;code&gt;(?&amp;lt;!(T|t)he\s)(cat)&lt;/code&gt; 匹配 &lt;code&gt;cat&lt;/code&gt;，且其前不跟着 &lt;code&gt;The&lt;/code&gt; 或 &lt;code&gt;the&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;
&#34;(?&amp;lt;!(T|t)he\s)(cat)&#34; =&gt; The cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/8Efx5G/1&#34;&gt;https://regex101.com/r/8Efx5G/1&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;5-标志&#34;&gt;5. 标志&lt;/h2&gt;

&lt;p&gt;标志也叫模式修正符，因为它可以用来修改表达式的搜索结果。
这些标志可以任意的组合使用，它也是整个正则表达式的一部分。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;标志&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;i&lt;/td&gt;
&lt;td&gt;忽略大小写。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;g&lt;/td&gt;
&lt;td&gt;全局搜索。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;m&lt;/td&gt;
&lt;td&gt;多行修饰符：锚点元字符 &lt;code&gt;^&lt;/code&gt; &lt;code&gt;$&lt;/code&gt; 工作范围在每行的起始。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;5-1-忽略大小写-case-insensitive&#34;&gt;5.1 忽略大小写（Case Insensitive）&lt;/h3&gt;

&lt;p&gt;修饰语 &lt;code&gt;i&lt;/code&gt; 用于忽略大小写。
例如，表达式 &lt;code&gt;/The/gi&lt;/code&gt; 表示在全局搜索 &lt;code&gt;The&lt;/code&gt;，在后面的 &lt;code&gt;i&lt;/code&gt; 将其条件修改为忽略大小写，则变成搜索 &lt;code&gt;the&lt;/code&gt; 和 &lt;code&gt;The&lt;/code&gt;，&lt;code&gt;g&lt;/code&gt; 表示全局搜索。&lt;/p&gt;

&lt;pre&gt;
&#34;The&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dpQyf9/1&#34;&gt;https://regex101.com/r/dpQyf9/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/The/gi&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The&lt;/strong&gt;&lt;/a&gt; fat cat sat on &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;the&lt;/strong&gt;&lt;/a&gt; mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/ahfiuh/1&#34;&gt;https://regex101.com/r/ahfiuh/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;5-2-全局搜索-global-search&#34;&gt;5.2 全局搜索（Global search）&lt;/h3&gt;

&lt;p&gt;修饰符 &lt;code&gt;g&lt;/code&gt; 常用于执行一个全局搜索匹配，即（不仅仅返回第一个匹配的，而是返回全部）。
例如，表达式 &lt;code&gt;/.(at)/g&lt;/code&gt; 表示搜索 任意字符（除了换行）+ &lt;code&gt;at&lt;/code&gt;，并返回全部结果。&lt;/p&gt;

&lt;pre&gt;
&#34;/.(at)/&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; cat sat on the mat.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/jnk6gM/1&#34;&gt;https://regex101.com/r/jnk6gM/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/.(at)/g&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;sat&lt;/strong&gt;&lt;/a&gt; on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat&lt;/strong&gt;&lt;/a&gt;.
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/dO1nef/1&#34;&gt;https://regex101.com/r/dO1nef/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;5-3-多行修饰符-multiline&#34;&gt;5.3 多行修饰符（Multiline）&lt;/h3&gt;

&lt;p&gt;多行修饰符 &lt;code&gt;m&lt;/code&gt; 常用于执行一个多行匹配。&lt;/p&gt;

&lt;p&gt;像之前介绍的 &lt;code&gt;(^,$)&lt;/code&gt; 用于检查格式是否是在待检测字符串的开头或结尾。但我们如果想要它在每行的开头和结尾生效，我们需要用到多行修饰符 &lt;code&gt;m&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;例如，表达式 &lt;code&gt;/at(.)?$/gm&lt;/code&gt; 表示小写字符 &lt;code&gt;a&lt;/code&gt; 后跟小写字符 &lt;code&gt;t&lt;/code&gt; ，末尾可选除换行符外任意字符。根据 &lt;code&gt;m&lt;/code&gt; 修饰符，现在表达式匹配每行的结尾。&lt;/p&gt;

&lt;pre&gt;
&#34;/.at(.)?$/&#34; =&gt; The fat
                cat sat
                on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/hoGMkP/1&#34;&gt;https://regex101.com/r/hoGMkP/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/.at(.)?$/gm&#34; =&gt; The &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;fat&lt;/strong&gt;&lt;/a&gt;
                  cat &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;sat&lt;/strong&gt;&lt;/a&gt;
                  on the &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;mat.&lt;/strong&gt;&lt;/a&gt;
&lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/E88WE2/1&#34;&gt;https://regex101.com/r/E88WE2/1&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&#34;6-贪婪匹配与惰性匹配-greedy-vs-lazy-matching&#34;&gt;6. 贪婪匹配与惰性匹配（Greedy vs lazy matching）&lt;/h3&gt;

&lt;p&gt;正则表达式默认采用贪婪匹配模式，在该模式下意味着会匹配尽可能长的子串。我们可以使用 &lt;code&gt;?&lt;/code&gt; 将贪婪匹配模式转化为惰性匹配模式。&lt;/p&gt;

&lt;pre&gt;
&#34;/(.*at)/&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The fat cat sat on the mat&lt;/strong&gt;&lt;/a&gt;. &lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/AyAdgJ/1&#34;&gt;https://regex101.com/r/AyAdgJ/1&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;
&#34;/(.*?at)/&#34; =&gt; &lt;a href=&#34;#learn-regex&#34;&gt;&lt;strong&gt;The fat&lt;/strong&gt;&lt;/a&gt; cat sat on the mat. &lt;/pre&gt;

&lt;p&gt;(在线练习)(&lt;a href=&#34;https://regex101.com/r/AyAdgJ/2&#34;&gt;https://regex101.com/r/AyAdgJ/2&lt;/a&gt;)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>ElasticSearch架构解析与最佳实践</title>
      <link>https://bgbiao.top/post/elasticsearch%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/elasticsearch%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6talv0b0j30u00gwgmv.jpg&#34; alt=&#34;目录&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6taz9e6mj30u00gwgn1.jpg&#34; alt=&#34;应用概述-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tbcoytlj30u00gw0v2.jpg&#34; alt=&#34;应用概述-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tc1k3flj30u00gwdih.jpg&#34; alt=&#34;应用概述-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tcd3b6zj30u00gw416.jpg&#34; alt=&#34;应用概述-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tcptmk3j30u00gwju7.jpg&#34; alt=&#34;Lucene内核原理-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tdh8oo9j30u00gwq5d.jpg&#34; alt=&#34;Lucene内核原理-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tdtnjioj30u00gwq67.jpg&#34; alt=&#34;Lucene内核原理-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6te64te2j30u00gw76q.jpg&#34; alt=&#34;Lucene内核原理-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tegzbfej30u00gwgnr.jpg&#34; alt=&#34;Lucene内核原理-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tesbdjrj30u00gwq4l.jpg&#34; alt=&#34;Lucene内核原理-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tf62pxfj30u00gwmzk.jpg&#34; alt=&#34;Lucene内核原理-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tfo8dnyj30u00gwdit.jpg&#34; alt=&#34;ElasticSearch架构解析&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tg98nsrj30u00gwwgz.jpg&#34; alt=&#34;ElasticSearch架构解析-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tgl8k6aj30u00gw41m.jpg&#34; alt=&#34;ElasticSearch架构解析-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tgy5lhqj30u00gwtbh.jpg&#34; alt=&#34;ElasticSearch架构解析-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6th9bynxj30u00gwgoi.jpg&#34; alt=&#34;ElasticSearch架构解析-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6thjuhgtj30u00gwwgb.jpg&#34; alt=&#34;ElasticSearch架构解析-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6thyvb72j30u00gwwgy.jpg&#34; alt=&#34;ElasticSearch架构解析-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tiaoksoj30u00gwq57.jpg&#34; alt=&#34;最佳实践-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tinieeyj30u00gwq51.jpg&#34; alt=&#34;最佳实践-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tiy8yc4j30u00gw40r.jpg&#34; alt=&#34;最佳实践-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tj6kki5j30u00gwmz3.jpg&#34; alt=&#34;最佳实践-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tjflhouj30u00gwmzs.jpg&#34; alt=&#34;最佳实践-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tjrhom9j30u00gw414.jpg&#34; alt=&#34;最佳实践-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tk30ujjj30u00gwwgd.jpg&#34; alt=&#34;最佳实践-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tkez1t6j30u00gwacw.jpg&#34; alt=&#34;最佳实践-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tksdke2j30u00gwgmw.jpg&#34; alt=&#34;性能调优-1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tl2qkemj30u00gw76f.jpg&#34; alt=&#34;性能调优-2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlejqftj30u00gwjtk.jpg&#34; alt=&#34;性能调优-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlpduy6j30u00gw0ut.jpg&#34; alt=&#34;性能调优-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tlz6ifvj30u00gwmzi.jpg&#34; alt=&#34;性能调优-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tm9ln5dj30u00gw410.jpg&#34; alt=&#34;性能调优-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tmjx424j30u00gwmyd.jpg&#34; alt=&#34;性能调优-7&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tmta1rxj30u00gwacb.jpg&#34; alt=&#34;性能调优-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tn4mub6j30u00gw76f.jpg&#34; alt=&#34;性能调优-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tni8rnxj30u00gw410.jpg&#34; alt=&#34;性能调优-10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6tnset4mj30u00gwacc.jpg&#34; alt=&#34;性能调优-11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf6to3orh5j30u00gwmxu.jpg&#34; alt=&#34;性能调优-12&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>kafka端到端的延迟</title>
      <link>https://bgbiao.top/post/kafka%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%BB%B6%E8%BF%9F/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%BB%B6%E8%BF%9F/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 在大规模的使用kafka过程中，我们通常会遇到各种各样的问题，比如说，通常会有一些大数据集群中的Job发现总有几个task会比较慢，导致整体的任务迟迟不能完成运行，这种情况通常问题会比较复杂，想要知道具体延迟在哪里，我们需要知道在Kafka集群中哪些点可能会增加端到端的延迟。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;接下来的内容翻译自&lt;code&gt;confluent&lt;/code&gt;官网博客中的一篇文章，希望能够帮助大家理解kafka使用过程中端到端的延迟。&lt;a href=&#34;https://www.confluent.io/blog/configure-kafka-to-minimize-latency/&#34;&gt;99th Percentile Latency at Scale with Apache Kafka&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;欺诈检测、支付系统和股票交易平台只是许多Apache Kafka用例中的一小部分，这些用例需要快速且可预测的数据交付。例如，在线银行交易的欺诈检测必须实时发生，以交付业务价值，而不需要为每个交易增加超过50 100毫秒的开销，以保持良好的客户体验。&lt;/p&gt;

&lt;p&gt;在Kafka术语中，数据交付时间(data delivery time)是由&lt;code&gt;端到端延迟(end-to-end latency)&lt;/code&gt;定义的，即&lt;code&gt;消费者获取一条向Kafka生成的记录所需的时间&lt;/code&gt;。延迟目标表示为目标延迟和满足此目标的重要性。例如，您的延迟目标可以表示为:我希望99%的情况下从Kafka获得端到端延迟为50 ms。&lt;/p&gt;

&lt;p&gt;这将增加&lt;code&gt;可用性、持久性和吞吐量&lt;/code&gt;目标。实现高持久性和高吞吐量两个目标，我们需要进行一定的权衡，挑战在于在保持延迟界限的同时扩展应用程序的吞吐量，并调整Kafka集群的大小以使用可接受的Broker延迟来处理客户端和复制的请求。延迟也取决于您对硬件或云提供商的选择，所以您需要能够监视和调优您的客户端，以在您独特的环境中实现您的特定延迟目标。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 通常情况下，Broker所在的网络区域其实也会对延迟造成很大影响，当然这仍然取决于您对可用性和延迟的权衡。&lt;/p&gt;

&lt;p&gt;之前，我们有写过白皮书&lt;a href=&#34;https://www.confluent.io/white-paper/optimizing-your-apache-kafka-deployment/&#34;&gt;optimizing-your-apache-kafka-deployment&lt;/a&gt;，其中列出了配置Kafka部署以优化各种目标的指导原则。&lt;/p&gt;

&lt;p&gt;这篇文章将帮助您进一步获得更好的直觉和对端到端延迟的理解，并配置和扩展您的应用程序的吞吐量，同时保持延迟的界限。&lt;/p&gt;

&lt;h4 id=&#34;理解到端的延迟-end-to-end-latency&#34;&gt;理解到端的延迟(end-to-end latency)&lt;/h4&gt;

&lt;p&gt;端到端延时是指应用逻辑调用&lt;code&gt;KafkaProducer.send()&lt;/code&gt;生产消息到该消息被应用逻辑通过&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;消费到之间的时间。&lt;/p&gt;

&lt;p&gt;下图显示了一条记录在系统中的路径，从Kafkas生产者到Kafka的Broker节点，副本的复制，以及消费者最终在其主体分区日志中获取到具体的消息。&lt;/p&gt;

&lt;p&gt;因此，端到端的延迟主要会由以下几个部分组成:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Produce time&lt;/code&gt;: 内部Kafka producer处理消息并将消息打包的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Publish time&lt;/code&gt;: producer发送到broker并写入到leader副本log的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Commit time&lt;/code&gt;: follower副本备份消息的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Catch-up time&lt;/code&gt;: 消费者追赶消费进度，消费到该消息位移值前所花费的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Fetch time&lt;/code&gt;: 从broker读取该消息的时间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2l82tu4nj30nd0dz40n.jpg&#34; alt=&#34;kafka端到端的延迟&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在接下来的内容中，我们将分别解释这五个延迟阶段的具体含义，特定的客户端配置或应用逻辑设计通常会极大地影响端到端延时，因此我们有必要精准定位哪个因素对延时的影响最大。&lt;/p&gt;

&lt;h4 id=&#34;produce-time&#34;&gt;Produce time&lt;/h4&gt;

&lt;p&gt;Produce time 指的是从应用程序通过&lt;code&gt;KafkaProducer.send()&lt;/code&gt;生产一条记录到包含该消息的生产者请求被发往leader副本所在的broker之间的时间。(因此，生产者所处的网络环境以及对应topic分区leader副本所在的broker的网络可能会影响到produce time的延迟)&lt;/p&gt;

&lt;p&gt;Kafka producer会将&lt;code&gt;相同topic分区&lt;/code&gt;下的一组消息打包在一起形成一个批次（batch）以提升网络I/O性能。(在必要情况下，我们可以对生产者的batch size进行一定的调整)&lt;/p&gt;

&lt;p&gt;默认情况下，producer会立即发送batch，这样一个batch中通常不会包含太多的消息。为了提高batch的效率，生产者通常会对&lt;code&gt;linger.ms&lt;/code&gt;来人为设置一个较小的延迟来保证有足够多的消息记录能封装在一个batch中。一旦过了&lt;code&gt;linger.ms&lt;/code&gt;设置的事件，或者batch size已经达到最大值(&lt;code&gt;batch.size&lt;/code&gt;的参数值)，这个batch将被认为已经完成。&lt;/p&gt;

&lt;p&gt;如果生产者也开启了压缩(&lt;code&gt;compression.type&lt;/code&gt;)，kafka的生产者会将已完成的batch进行压缩。在batch完成之前，它的大小时根据生产者指定的压缩类型和之前观测到的压缩比率估算出来的。&lt;/p&gt;

&lt;p&gt;如果发送给leader副本的未确认的生产者请求数量已经达到最大(&lt;code&gt;max.inflight.requests.per.connection=5&lt;/code&gt;)，则在生产者的批处理可能需要等待更长的时间。因此，broker响应生产者请求越快，生产者的等待时间也将会变得更小。&lt;/p&gt;

&lt;h4 id=&#34;publish-time&#34;&gt;Publish time&lt;/h4&gt;

&lt;p&gt;Publish time是指内部kafka生产者发送生产者请求到一个broker节点，并且对应的消息到达leader副本日志之间的时间。当请求到达Broker节点时，负责连接的网络线程将获取该请求并将其放入请求队列中。其中一个请求处理程序线程从队列中获取请求并处理它们。(对应broker节点的num.thread 和num.io.thread两个相关参数)&lt;/p&gt;

&lt;p&gt;因此，Publish time包含生产者请求的网络时间，broker上的排队时间，以及将消息追加到日志所消耗的时间(通常也是page cache 的访问时间)。当Broker端负载比较低，网络和日志的追加写入时间会影响publish time，随着broker负载变高，队列延迟的增加
将会更多的影响publish time。&lt;/p&gt;

&lt;h4 id=&#34;commit-time&#34;&gt;Commit time&lt;/h4&gt;

&lt;p&gt;Commit time是指从leader副本中复制消息到全部的同步副本(all in-sync replicas)中所消耗的时间。kafka只会将已提交(committed)的消息暴露给consumer，也就是该消息必须在全部的ISR中包含。follower副本中的消息会从leader副本中并行的拉取，在一个正常的集群中，我们通常不希望副本处于不同步状态(当然有的业务场景可能会导致短暂的不同步现象)。这意味着消息被提交的时间等于ISR中最慢的follower副本所在broker去从ledaer broker节点获取记录并写入到follower副本日志的时间。&lt;/p&gt;

&lt;p&gt;为了复制数据，follower所在的broker会想leader节点发送fetch请求，准确的来讲消费者也是使用fetch请求来获取消息。但是，官方在副本复制的fetch请求中，broker端优化了默认配置: leader副本会尽早的发送请求，只要有一个字节可用，就会发起fetch请求(由&lt;code&gt;replica.fetch.min.bytes&lt;/code&gt;参数控制)或者当&lt;code&gt;replica.fetch.wait.max.ms&lt;/code&gt;满足条件。Commit time主要受副本因此配置参数的影响以及集群的当前负载情况。&lt;/p&gt;

&lt;h4 id=&#34;catch-up-time&#34;&gt;Catch-up time&lt;/h4&gt;

&lt;p&gt;Kafka中消息是按照其生产的顺序被消费的，除非显示的声明了一个新的offset或者有一个新的消费者从最新的offset进行消费。同一个分区下，consumer必须要消费完之前发布的消息后才能读取后面的消息。假设在提交消息时，消费者的偏移量是提交消息后面的N条消息，那么，Catch-up time就是消费者消费者N条消息的总时间.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2mnjafg2j30rs0723z1.jpg&#34; alt=&#34;Catch-up time&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当我们在构建实时处理应用的时候，最好让catch-up时间为0，即一旦消息被提交，消费者可以立马读取到消息。如果消费者总是落后，端到端延迟可能会变得无限大。因此，catch-up 时间通常依赖于消费者的能力是否能够追赶上生产者的吞吐量。&lt;/p&gt;

&lt;h4 id=&#34;fetch-time&#34;&gt;Fetch time&lt;/h4&gt;

&lt;p&gt;订阅主题分区的消费者会不断轮询去从leader副本中获取更多的数据，Fetch time是从leader副本所在broker节点获取消息记录的s时间，可能需要等待足够的数据来形成对fetch请求的响应，并从&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;的响应中返回记录。在默认的配置下，已经对于消费者的fetch延迟做了优化(&lt;code&gt;fetch.min.bytes&lt;/code&gt;=1)，即及时只有一个字节可用的时候，fetch请求也会响应数据，或者在一个短暂超时之后&lt;code&gt;fetch.max.wait.ms&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;end-to-end-latency-vs-producer-and-consumer-latencies&#34;&gt;End-to-end latency VS producer and consumer latencies&lt;/h4&gt;

&lt;p&gt;下图显示了Kafka客户端观察到的延迟(通常称为生产者延迟和消费者延迟)与端到端延迟之间的关系。&lt;/p&gt;

&lt;p&gt;生产者延迟是指&lt;code&gt;KafkaProducer.send()&lt;/code&gt;发送和生产的消息被确认间的事件。消息的确认依赖于&lt;code&gt;acks&lt;/code&gt;的配置，该参数可以控制消息的持久性(durability):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当&lt;code&gt;acks=0&lt;/code&gt;，立即确认，不等待broker的返回&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;acks=1&lt;/code&gt;，消息被追加到leader副本所在分区后再确认&lt;/li&gt;
&lt;li&gt;当&lt;code&gt;acks=all&lt;/code&gt;，在所有的ISR(同步副本)都接收到消息时才确认&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，生产者延迟包含&lt;code&gt;produce time&lt;/code&gt;,&lt;code&gt;publich time(如果acks &amp;gt;= 1)&lt;/code&gt;,&lt;code&gt;commit time(如果acks=all)&lt;/code&gt; 以及生产者响应从broker返回到生产者的时间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2n8dbz3bj30rs08a75c.jpg&#34; alt=&#34;end-to-end-latency and producer time&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图清晰的向我们展示了为何改变&lt;code&gt;acks&lt;/code&gt;参数能够减少生产者延迟(其实是通过从生产者延迟中移除几个延迟概念来减少的&lt;code&gt;publish和commit&lt;/code&gt;)。不过，无论我们如何配置生产者的&lt;code&gt;acks&lt;/code&gt;参数，publish和commit 时间总是端到端延迟的一部分。&lt;/p&gt;

&lt;p&gt;消费者延迟(Consumer latency)是指消费者发起一个fetch请求到broker节点，以及broker节点向consumer返回响应的时间。计算方法是&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;返回的时间。Consumer的延迟主要包含了上图中的fetch time&lt;/p&gt;

&lt;h4 id=&#34;控制end-to-end-latency&#34;&gt;控制end-to-end latency&lt;/h4&gt;

&lt;p&gt;如果我们思考一条消息的生命周期，控制端到端延时其实就是控制消息在系统中流转的时间总和。很多Kafka clients端和broker端参数的默认值已然对延时做了优化：比如减少人为等待时间来提高批处理的能力(通过&lt;code&gt;linger.ms&lt;/code&gt;,&lt;code&gt;fetch.min.bytes&lt;/code&gt;,&lt;code&gt;replica.fetch.min.bytes&lt;/code&gt;参数来适当调优)。其他的延时可能来自于broker端上的队列等候时间，控制这种延时就要涉及控制broker的负载（CPU或吞吐量），通常情况下我们要时刻关注broker节点的各项基础监控指标。&lt;/p&gt;

&lt;p&gt;如果我们将系统视为一个整体，那么整个端到端的延迟还要求系统中的每一个部分(生产者,broker,消费者)都能够可靠的维持应用程序逻辑所需的吞吐量。&lt;/p&gt;

&lt;p&gt;例如，如果您的应用程序逻辑以100 MB/s发送数据，但是由于某种原因，您的Kafka消费者吞吐量在几秒钟内下降到10 MB/s，那么在此之前产生的大多数消息都需要在系统中等待更长的时间，直到消费者赶上了。此时，你需要一种高效的方式来扩展你的Kafka clients程序以提升吞吐量——高效地利用broker端资源来减少队列等候时间和偶发的网络拥塞。&lt;/p&gt;

&lt;p&gt;理想情况下，限制延迟意味着确保所有延迟都低于目标。但实际生产环境中，由于意外故障和峰值负载，这种严格的保证是不可能的。不过，可以设计应用程序并对系统进行调优，以实现95%的延迟目标，控制所有的消息延迟在95~99%低于目标延迟时间。高百分位延迟也称为尾部延迟，因为它们是延迟频谱的尾部。&lt;/p&gt;

&lt;p&gt;目标延时所用的百分位越大，你需要降低或容忍应用最差表现所做的努力就越多。比如，偶尔的大请求可能会阻塞全部的请求，从而增加整体的延迟，这也就是所谓的&lt;code&gt;head-of-line&lt;/code&gt;队首阻塞。同时，大量低速率客户端可能偶尔会同时向kafka发送生产或消费请求，或全部刷新集群元数据，也会导致请求队列比平常更长，从而引发比平时更严重的尾延迟。这种行为就是所谓的&lt;code&gt;micro-bursting&lt;/code&gt;(微型冲击，可能就是水滴石穿的意思吧)&lt;/p&gt;

&lt;h4 id=&#34;不同客户端配置的延迟测试&#34;&gt;不同客户端配置的延迟测试&lt;/h4&gt;

&lt;p&gt;在这接下来的内容中，我们使用实验结果来说明Kafka客户端配置和吞吐量扩展技术对性能的影响。我们使用kafka内置的&lt;a href=&#34;https://github.com/apache/kafka/tree/trunk/tools/src/main/java/org/apache/kafka/trogdor&#34;&gt;Trogdor&lt;/a&gt;测试框架以及生产者和消费者的基准测试，&lt;code&gt;ProduceBench&lt;/code&gt;和&lt;code&gt;ConsumeBench&lt;/code&gt;来进行我们的生产者和消费者实验测试。&lt;/p&gt;

&lt;p&gt;我们所有的测试都在一个包含9个代理的Kafka集群上运行，该集群的复制因子为3，这保证了在出现最多两个同时发生的节点故障时不会丢失消息。&lt;/p&gt;

&lt;p&gt;Kafka集群运行在AWS的&lt;code&gt;r5.xlarge&lt;/code&gt;实例上，使用有2T的EBS(弹性块存储)。Kafka的broker节点分布在同一区域内的三个可用性区域(AZ)，以获得更强的容错性，其中每个主题分区副本被放置在一个不同的AZ上，并且kafka客户端配置使用SASL认证和SSL加密，Broker之间使用&lt;code&gt;PLAINTEXT&lt;/code&gt;进行通信。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;主题:&lt;/code&gt;需要注意的是，分布式集群中节点如果在不同可用区也可能导致延迟的增加，当然这要在延迟和容错性角度进行权衡，也需要考虑到云厂商的可用区之间本身的延迟。&lt;/p&gt;

&lt;p&gt;我们的实验使用了以下非默认客户端配置和其他规范:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数项&lt;/th&gt;
&lt;th&gt;参数值&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;副本数&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;topic的分区数&lt;/td&gt;
&lt;td&gt;108&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;security.protocol&lt;/td&gt;
&lt;td&gt;SASL_SSL&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;sasl.mechanism&lt;/td&gt;
&lt;td&gt;PLAIN&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;acks&lt;/td&gt;
&lt;td&gt;all&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;linger.ms&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;compression.type&lt;/td&gt;
&lt;td&gt;lz4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Producer record size&lt;/td&gt;
&lt;td&gt;value=521bytes/key=4bytes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Trogdor record value generator&lt;/td&gt;
&lt;td&gt;uniformRandom&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Trogdor record key generator&lt;/td&gt;
&lt;td&gt;sequential&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Number of Trogdor agents&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这个测试场景会产生额外的延迟: 多可用区可能增加commit时间，由于是跨可用区的副本。无论是clients端还是broker端，SSL加密也是有开销的。同时由于SSL无法利用Zero Copy特性进行数据传输，因为consumer获取消息时也会增加额外的开销。&lt;/p&gt;

&lt;p&gt;虽然这些因素都会影响延迟，但是通常情况下企业内部可能还是需要这种架构上的考虑，因此采用该部署结构进行测试。&lt;/p&gt;

&lt;h4 id=&#34;持久性设置对延迟的影响&#34;&gt;持久性设置对延迟的影响&lt;/h4&gt;

&lt;p&gt;当将延迟目标与其他需求叠加在一起时，首先考虑持久性需求是很有用的。由于数据的重要性，通常需要一定程度的持久性。&lt;/p&gt;

&lt;p&gt;优化持久性会增加端到端延迟，因为这会增加延迟的复制开销(提交时间)，并向Broker添加复制负载，从而增加排队延迟。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Replication factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Replication factor 是Kafka持久化保证的核心，它定义了Kafka集群上保存的topic副本数。Replication factor = N 表示我们最多能够容忍N-1台broker宕机而不必数据丢失。N=1能够令端到端延时最小化，但却是最低的持久化保证。&lt;/p&gt;

&lt;p&gt;增加副本数会增加备份开销并给broker额外增加负载。如果clients端带宽在broker端均匀分布，那么每个broker都会使用&lt;code&gt;N * w写带宽&lt;/code&gt;和&lt;code&gt;r + (N - 1) * w读带宽&lt;/code&gt;，其中w是clients端在broker上的写入带宽占用，r是读带宽占用。&lt;/p&gt;

&lt;p&gt;由此，降低N 对端到端延时影响的最佳方法就是确保每个broker上的负载是均匀的。这会降低commit time，因为commit time是由最慢的那个follower副本决定的。&lt;/p&gt;

&lt;p&gt;如果你的Kafka broker使用了过多的磁盘带宽或CPU，follower就会开始出现追不上leader的情况从而推高了commit time。(其实还需要注意的是，当最小的ISR默认为副本的数量个数时，在出现follower和leader不同步时恰巧leader节点宕机，会导致topic本身不可用)&lt;/p&gt;

&lt;p&gt;我们建议为副本同步消息流量设置成使用不同的listener来减少与正常clients流量的干扰。你也可以在follower broker上增加I/O并行度，并增加副本拉取线程数量&lt;code&gt;number.replica.fetchers&lt;/code&gt;来改善备份性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;纵然我们配置了多个副本，producer还是必须通过acks参数来配置可靠性水平。设置acks=all能够提供最强的可靠性保证，但同时也会增加broker应答PRODUCE请求的时间，就像我们之前讨论的那样。&lt;/p&gt;

&lt;p&gt;Broker端应答的速度变慢通常会降低单个producer的吞吐量，进而增加producer的等待时间。这是因为producer端会限制未应答请求的数量(&lt;code&gt;max.inflight.requests.per.connection&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;举个例子，在我们的环境中acks=1，我们启动了9个producer（同时也跑了9个consumer），吞吐量达到了195MB/秒。当acks切换成all时，吞吐量下降到161MB/秒。设置更高级别的acks通常要求我们扩展producer程序才能维持之前的吞吐量水平以及最小化producer内部的等待时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Min.insync.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;是一个重要的持久化参数，因为它定义了broker端ISR副本中最少要有多少个副本写入消息才算PRODUCE请求成功。这个参数会影响可用性，但是不会影响端到端的延时。因此，选择一个小一点的值并不能减少commit time并减少延迟。&lt;/p&gt;

&lt;h4 id=&#34;在满足延迟目标的前提下扩展吞吐&#34;&gt;在满足延迟目标的前提下扩展吞吐&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;延迟和吞吐的权衡&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;优化Kafka clients端吞吐量意味着优化batching的效果。Kafka producer内部会执行一类batching，即收集多条消息到一个batch中。&lt;/p&gt;

&lt;p&gt;每个batch被统一压缩然后作为一个整体被写入日志或从日志中读取。这说明消息备份也是以batch为单位进行的。&lt;/p&gt;

&lt;p&gt;Batching会减少每条消息的成本，因为它将这些成本摊还到clients端和broker端。通常来说，batch越大这种开销降低的效果就越高，减少的网络和磁盘I/O就越多。&lt;/p&gt;

&lt;p&gt;另一类batching就是在单个网络请求/响应中收集多个batch以减少网络数据传输量。这能降低clients端和broker端的请求处理开销。这类batching能够提升吞吐量和降低延时，因为batch越大，网络传输I/O量越小，CPU和磁盘使用率越低，故最终能够优化吞吐量。另外batch越大还能减低端到端延时，因为每条消息的成本降低了，使得系统处理相同数量消息的总时间变少了。&lt;/p&gt;

&lt;p&gt;这里的延时-吞吐量权衡是指通过人为增加等待时间来提升打包消息的能力。但过了某个程度，人为等待时间的增加可能会抵消或覆盖你从打包机制获得的延时收益。因此你的延时目标有可能会限制你能实施打包化的水平，进而减少所能达到的吞吐量并增加延时。如果拉低了本能达到的吞吐量或端到端延时水平，你可以通过扩展集群来换取或“购买”更多的吞吐量或处理能力。&lt;/p&gt;

&lt;h4 id=&#34;配置kafka的生产者和消费者以实现batching&#34;&gt;配置kafka的生产者和消费者以实现batching&lt;/h4&gt;

&lt;p&gt;对于producer而言，batching由两个参数进行控制: &lt;code&gt;batch.size(16KB)&lt;/code&gt;和&lt;code&gt;linger.ms(0)&lt;/code&gt;，前者控制batch的大小，后者限制延迟量。如果使用场景中，应用会频繁的像kafka集群发送数据，及时设置了&lt;code&gt;linger.ms=0&lt;/code&gt;，整个batch也会被尽快填满。如果应用生产数据的频率较低，可以通过增加&lt;code&gt;linger.ms&lt;/code&gt;来增加batch。&lt;/p&gt;

&lt;p&gt;对于consumer而言，可以调整&lt;code&gt;fetch.min.bytes(1)&lt;/code&gt;来限制每个消费者在每个fetch响应中接收的数据量，该参数指定了broker应该在一个fetch响应中返回的最小数据，以及&lt;code&gt;fetch.max.wait.ms(500)&lt;/code&gt;来设置等待数据的超时时间。在fetch响应中的数据越多，就会有更少的fetch请求。&lt;/p&gt;

&lt;p&gt;在生产者端的batching也会间接影响produce和fetch的请求数量，因为batch定义了数据能够被获取的最小数据量。&lt;/p&gt;

&lt;p&gt;值得注意的是，默认情况下，Kafka producer和consumer设置的是无人为等待时间，这么做的目的是为了降低延时。但是，即使你的目标就是了使延时最小化，我们依然推荐你设置一个不为0的linger.ms值，比如5~10ms。当然，这么做是有前提的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果你扩展了你的producer程序，平均下来使得每个producer实例的发送速率变得很低，那么你的batch只会包含很少的几条消息。如果你整体的吞吐量已然很高了，那么你可能会直接把你的Kafka集群压挂，导致超高的队列等候时间从而推高延时。此时，设置一个较小的&lt;code&gt;linger.ms&lt;/code&gt;值确实能够改善延时。&lt;/li&gt;
&lt;li&gt;如果你在意尾延时，那么增加&lt;code&gt;linger.ms&lt;/code&gt;可能会降低请求速率以及同时到达broker端的瞬时冲击流量。这种冲击越大，请求在尾部的延时就越高。这些瞬时冲击流量决定了你的尾延时水平。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面这个实验说明了以上两种场景。我们启动了90个producer，向一个有108个分区的topic发送消息。生产端整体的吞吐量峰值在90MB/秒。我们跑了3次测试，每一次对应一种不同的producer配置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2squjyvij30rs0fzaaz.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因为在给定的总吞吐下，我们有相对大量的生产者，因此&lt;code&gt;linger.ms = 0&lt;/code&gt;导致在生产者端机会没有batch操作。将&lt;code&gt;linger.ms&lt;/code&gt;从0调整到5可以增加batching能力: 向kafka发起的生产者请求从2800降低到了1100。这减少了50%和99%的生产者延迟。&lt;/p&gt;

&lt;p&gt;增加&lt;code&gt;batch.size&lt;/code&gt;不会直接影响生产者的等待时间，因为生产者在填满batch的时间不会超过&lt;code&gt;linger.ms&lt;/code&gt;的限制。在我们的实验中，增加&lt;code&gt;batch.size&lt;/code&gt;从16KB到128KB没有增加bacth的效果，因为每个生产者的吞吐量非常低。正如预期的那样，生产者延迟在两种配置之间没有变化。&lt;/p&gt;

&lt;p&gt;总之，如果您的目标是最小化延迟，我们建议保留默认的客户端批处理配置，并尽可能增加&lt;code&gt;linger.ms&lt;/code&gt;。如果你在意尾延时，最好调优下打包水平来减少请求发送率以及大请求冲击的概率。&lt;/p&gt;

&lt;h4 id=&#34;不增加人为延迟以提高batching效率&#34;&gt;不增加人为延迟以提高batching效率&lt;/h4&gt;

&lt;p&gt;batching效果不好的另一个原因是producer发送消息给大量分区。&lt;code&gt;如果消息不是发往同一个分区的，它们就无法聚集在一个batch下&lt;/code&gt;。因此，通常最好设计成让每个producer都只向有限的几个分区发送消息。&lt;/p&gt;

&lt;p&gt;另外，可以考虑升级到Kafka 2.4 producer。这个版本引入了一个全新的Sticky分区器。该分区器能够改善non-keyed topic的打包效果，同时还无需引入人为等待。&lt;/p&gt;

&lt;h4 id=&#34;clients的数量对尾延迟-tail-latency-的影响&#34;&gt;clients的数量对尾延迟(tail-latency)的影响&lt;/h4&gt;

&lt;p&gt;即使整体的生产和消费的吞吐量保持不变，通常也是Clients数越多，broker上负载越大。这是因为clients数量多会导致更多的METADATA请求发到Kafka，继而要维护更多的连接，故给broker带来更大的开销。&lt;/p&gt;

&lt;p&gt;相对于50%或平均延时的影响，Clients数量增加对尾延时的影响更大。&lt;/p&gt;

&lt;p&gt;每个producer最多发送&lt;code&gt;max.inflight.requests.per.connection&lt;/code&gt;个PRODUCE请求给单个broker，而每个consumer一次最多只会给一个broker发送FETCH请求。Clients越多，同一时刻发送到broker的PRODUCE和FETCH请求也就越多，这就增加了形成请求瞬时冲击的概率，进而推高了尾延时。&lt;/p&gt;

&lt;p&gt;Consumer数量通常由topic分区数量以及期望consumer没有较大lag的目标共同决定。但是，我们却很容易为了扩展吞吐量而引入大量的producer。&lt;/p&gt;

&lt;p&gt;基于吞吐量的考量增加producer实例数可能有相反的效果，因为producer会导致更少的消息被打包，毕竟每个producer处理了更少的消息，因而发送速率会变慢。同时producer还必须等待更长的时间来积累相同数量的消息进到batch里面。&lt;/p&gt;

&lt;p&gt;在我们的实验中，我们将producer的数量从90增加到900，发现吞吐量没有他打变化：90MB/秒。&lt;/p&gt;

&lt;p&gt;我们使用&lt;code&gt;batch.size=16KB&lt;/code&gt;,&lt;code&gt;linger.ms=5&lt;/code&gt;,&lt;code&gt;acks=all&lt;/code&gt;的生产者配置，实验结果如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2s85pax9j30rs0f60tm.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结果显示增加producer数量(90-&amp;gt;900)增加了60%的中位数延时值，而99%延时值几乎增加了3倍。&lt;/p&gt;

&lt;p&gt;延时的增加是因为producer端打包效果变差导致的。&lt;/p&gt;

&lt;p&gt;尾延时的增加是因为更大的请求瞬时冲击，这会拉升broker端延时，同时producer端会等待更长的时间来接收应答。&lt;/p&gt;

&lt;p&gt;在900个producer的测试中，broker完全被PRODUCE请求压垮了。用于处理请求的时间几乎占到了broker端CPU使用率的100%。另外由于我们使用了SSL，它也会进一步引入请求级的开销。&lt;/p&gt;

&lt;p&gt;如果你通过添加producer来提升吞吐量，那么可以考虑增加单个proudcer的吞吐量，即&lt;code&gt;改善batching的效果&lt;/code&gt;。不管怎样，你最终可能会有很多producer实例。比如，大公司收集设备上的统计指标，而设备数可能有成千上万。此时，你可以考虑使用一个Broker收集来自多个clieints的请求，然后把它们转换成更高效的PRODUCE请求再发给Kafka。你也可以增加broker数来降低单个broker上的请求负载。&lt;/p&gt;

&lt;h4 id=&#34;关于增加消费者数量的说明&#34;&gt;关于增加消费者数量的说明&lt;/h4&gt;

&lt;p&gt;当扩展消费者时需要注意，在同一个消费者组的消费者会提交offset信息和心跳到broker节点上(controller节点)。如果按时间间隔执行偏移提交(&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;)，则消费者组中的更多消费者者会增加偏移提交率。偏移量提交本质上是向内部&lt;code&gt;__consumer_offsets&lt;/code&gt;产生请求，因此增加consumer数量会导致broker上的请求负载增加，特别是&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;值很小的时候。&lt;/p&gt;

&lt;h4 id=&#34;压缩配置的影响&#34;&gt;压缩配置的影响&lt;/h4&gt;

&lt;p&gt;默认情况下，Kafka producer不做压缩。&lt;code&gt;compression.type&lt;/code&gt;参数可以决定要不要做压缩。&lt;/p&gt;

&lt;p&gt;压缩会在producer端引入额外的开销来压缩消息，在broker端做校验时解压缩从而引入额外的开销，另外在consumer端解压缩也是开销。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;:通常情况下broker端的压缩参数需要设置成&lt;code&gt;producer&lt;/code&gt;，以避免压缩方式冲突导致数据无法正常消费，这样broker只需要直接将压缩后的日志写入&lt;/p&gt;

&lt;p&gt;虽然压缩会增加CPU开销，但它还是可能减少端到端延时的，因为它能显著地降低处理数据所需的带宽占用，进而减少broker端的负载。压缩是在batch级别上完成的，故打包效果越好，压缩效果也就越好。&lt;/p&gt;

&lt;h4 id=&#34;更多的分区可能增加延迟&#34;&gt;更多的分区可能增加延迟&lt;/h4&gt;

&lt;p&gt;一个主题的分区是kafka中的并行单元。发送到不同分区的消息可以由生产者并行发送，由不同的Broker并行写入，并可以由不同的消费者并行读取。因此，更多的分区通常会导致更高的吞吐量，不过单从吞吐量的角度来看，我们能够从每个Broker有10个分区的kafka集群，就已经能够达到最大的吞吐量了。您可能需要更多的主题分区来支持您的应用程序逻辑。&lt;/p&gt;

&lt;p&gt;但是，太多的分区可能导致更多的端到端的延迟。每个主题的分区越多，对生产者的批处理就越少。每个Broker的主题分区越多，每个follow副本获取请求的开销就越大。每个fetch请求必须去枚举自己感兴趣的分区，并且每个leader副本必须去检查状态，同时从请求的每个分区中去fetch数据，这通常会导致较小的磁盘I/O。因此，越多的分区，可能会导致更长的commit time和更高的cpu使用，最终导致较长的排队延迟。&lt;/p&gt;

&lt;p&gt;提交时间的增加和更高的CPU负载会导致所有共享同一个Kafka集群的客户端端到端延迟的增加，即使是那些只生产和使用少量主题分区的客户端来说，也是如此。&lt;/p&gt;

&lt;p&gt;我们使用两个topic来做此次测试。一个Topic有9个生产者生产5MB/s的数据，然后有一个对应9个消费者的消费者组。这个实验持续了几天，我们将这个主题中的分区数量从108个逐步增加到7200个(每个Broker8000个)，每个步骤运行一个小时。第二个主题在整个实验运行期间有9个分区和9个生产者，每个生产者向一个分区和一个对应的消费者组(每个分区一个)生产消息，该主题每秒生产一个512bytes的数据。&lt;/p&gt;

&lt;p&gt;下图显示了分区数量对客户端访问9分区主题的99%的端到端延迟的影响，随着每个broker上分区数的增加，clients的端到端延时大致呈线性增加趋势。分区数的增加会推高broker上的CPU负载同时拖慢所有clients的备份，即使是对那些只与固定分区数量交互的clients而言，也会抬高端到端延迟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2rwiufyuj30rs0eh0ty.jpg&#34; alt=&#34;mutli-partition-latency&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了减少延时，最好还是限制每个broker上的分区数，方法是减少总的分区数或扩展集群。你还可以通过增加fetcher线程数量的方式来改善commit time。&lt;/p&gt;

&lt;h4 id=&#34;broker节点负载对延迟的影响&#34;&gt;broker节点负载对延迟的影响&lt;/h4&gt;

&lt;p&gt;我们已经讨论了Broker上的负载导致增加排队延迟，从而增加了端到端的延迟，很容易看出为什么请求速率的增加会加剧排队延迟，因为更多的请求会导致更大的队列。&lt;/p&gt;

&lt;p&gt;broker节点上高资源利用率(磁盘或cpu)可能导致更高的队列的延迟，并且延迟的增长会随着资源利用率的增长呈指数级增长。这是一个可以有排队理论解释的已知属性: Kingman公式证明等待某种资源的时间正比于资源繁忙程度/资源空闲程度&lt;code&gt;(% of time resource is busy)/(% of time resource is idle)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gf2r3oe03wj30rs0gb0tp.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于延迟随资源利用率呈指数增长，如果broker中的任何资源的利用率接近100%，您可能会看到很高的延迟。通过减少每个Broker的资源使用(比如减少每个broker的链接数，请求以及分区数)或扩展集群来整体降低每个broker节点的资源使用率，在这种情况可以显著降低延迟。保持负载在broker之间平均通常情况下是非常有用的，同时也可以&lt;code&gt;均匀地或基于负载分布分区副本&lt;/code&gt;也能降低尾部延迟。&lt;/p&gt;

&lt;p&gt;因此，通常情况下，负责kafka集群的SRE团队需要自动检测Broker节点上的高资源利用率(磁盘和CPU)，然后重新平衡集群上的分区，以便更均匀地在Broker之间重新分配负载，或者在需要时扩展集群。而如果使用云厂商提供的kafka服务，则可以适当避免这类事情的发生，因为云服务会去做相关的事情。&lt;/p&gt;

&lt;h4 id=&#34;总结&#34;&gt;总结&lt;/h4&gt;

&lt;p&gt;我们已经演示了，在为吞吐量扩展客户机和分区时的边界延迟要求时可以通过限制每个broker的连接数、分区数和请求速率来限制每个broker的使用。&lt;/p&gt;

&lt;p&gt;边界尾延迟需要额外注意减少来自客户机的任何突发(连接和请求)或应用程序行为中的差异。&lt;/p&gt;

&lt;p&gt;均匀加载的broker节点对于最小化尾部延迟也很重要，因为它受到最慢broker的影响。&lt;/p&gt;

&lt;p&gt;如下是一些相关扩展的文章，可能有助于我们控制整体延迟:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/white-paper/optimizing-your-apache-kafka-deployment/&#34;&gt;Optimizing Your Apache Kafka Deployment&lt;/a&gt;提供配置Kafka部署的指导方针，以优化各种目标:吞吐量、延迟、持久性和可用性(公众号回复:&lt;code&gt;kafka&lt;/code&gt;可获取资料)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster&#34;&gt;How to Choose the Number of Topics/Partitions in a Kafka Cluster?&lt;/a&gt;(2016) 和&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster&#34;&gt;follow-updates&lt;/a&gt;有一些kafka 2.0版本的优化&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner&#34;&gt;Improving batching with the new sticky partitioner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-345%3A+Introduce+static+membership+protocol+to+reduce+consumer+rebalances&#34;&gt;KIP-345&lt;/a&gt;: 引入静态成员协议来减少消费者的再平衡&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka如何合理规划分区数量</title>
      <link>https://bgbiao.top/post/kafka%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E8%A7%84%E5%88%92%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E8%A7%84%E5%88%92%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 如同其他分布式系统一样，在kafka集群中，单Topic的partition也并不是越多越好，但通常对于业务方来说，可能会简单的根据生产者或消费者的处理能力来提出扩partition的需求，此时就需要根据具体的场景进行分析以确定partition的数量。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于Kafka集群承载的业务Topic来说，分区的数量，可以体现出整个业务的量级同时能够尽可能的提供更高的吞吐，但并不是越多的分区就意味着越高的吞吐和处理能力，通常情况下需要业务方和基础服务方一起来进行分析。&lt;/p&gt;

&lt;p&gt;以下为多分区Topic的优缺点，可以适当根据需求和场景进行规划分区数量。&lt;/p&gt;

&lt;h3 id=&#34;目录&#34;&gt;目录&lt;/h3&gt;

&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h3 id=&#34;多分区可以提高吞吐-higher-throughput&#34;&gt;多分区可以提高吞吐(Higher Throughput)&lt;/h3&gt;

&lt;p&gt;首先，我们需要理解的是，在kafka集群中，topic分区&lt;code&gt;partition&lt;/code&gt;是一个并行单位。&lt;/p&gt;

&lt;p&gt;在生产者和broker端，可以完全并行完成对不同分区的写入操作。一些昂贵的操作，比如压缩(compression)，需要消耗更多的硬件资源。&lt;/p&gt;

&lt;p&gt;在消费者端，kafka总是会给每个消费者线程一个单分区的数据，因此当分区的数量其实也就限制了消费者线程的最大数据量，如果消费者不足以在最短时间消费数据，可以通过优化客户端程序或增加partition数量的方式(同时增加消费者线程)来缓解，但后者需要topic级别的调整，同时需要确认生产者是否有分区绑定相关操作。&lt;/p&gt;

&lt;p&gt;因此，一般而言，kafka集群的拥有越多的分区也意味着可以获取更高的吞吐。&lt;/p&gt;

&lt;p&gt;选择分区的数量一般可用基于吞吐来进行简单计算。&lt;/p&gt;

&lt;p&gt;您可以在单个分区上对生产(称为p)和消费(称为c)所能实现的所有性能进行度量。假如我们的目标吞吐是&lt;code&gt;t&lt;/code&gt;，然后我们可以设置分区数量为&lt;code&gt;max(t/p, t/c)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在生产者端，可以通过设置&lt;code&gt;batch size&lt;/code&gt;,&lt;code&gt;compression&lt;/code&gt;,&lt;code&gt;ack&lt;/code&gt;,&lt;code&gt;replication factor&lt;/code&gt;等参数来计算单个分区的吞吐。
不过如&lt;a href=&#34;https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines&#34;&gt;LinkedIn-Benchmarking&lt;/a&gt;中显示，通常单个分区可以承载每秒10 Million调数据的写入。&lt;/p&gt;

&lt;p&gt;在消费者端吞吐量通常依赖于应用程序，因为它对应于使用者逻辑处理每个消息的速度，因此得实际进行测量。&lt;/p&gt;

&lt;p&gt;尽管在topic创建后期，可以根据需求进行扩容分区，但是对于有&lt;code&gt;keys&lt;/code&gt;的消息需要注意。&lt;/p&gt;

&lt;p&gt;因为当生产者写入一个带&lt;code&gt;key&lt;/code&gt;的消息后，kafka将依据该&lt;code&gt;key&lt;/code&gt;的hash来决定数据映射到具体的分区，这样就可以保证具有相同&lt;code&gt;key&lt;/code&gt;的消息会被路由到同一个分区，从而保证了一类消息的有序性。&lt;/p&gt;

&lt;p&gt;如果此时分区数量突然增加，将可能导致数据的无序性，为了避免未来这种问题的出现，一般而言会在业务接入初期进行分区的过度分配&lt;code&gt;over-partition&lt;/code&gt;，即在topic创建时尽量多创建一些，但基本上在接入之前需要预估未来的吞吐量以确定一个合理的分区数量，这样即使当前集群规模较小，可以对topic进行提前规划，待后期集群规模大之后进行迁移即可，否则刚开始因为集群规模小，而对分区数量没有合理规划，后期会比较麻烦，而且这样当生产者使用带&lt;code&gt;key&lt;/code&gt;的消息时，您可以跟上吞吐量的增长，而不会破坏应用程序中的语义。&lt;/p&gt;

&lt;p&gt;除了吞吐量之外，在规划分区数时还需要考虑一些其他的因素，因为在吞吐增加的同时可能会增加一些其他影响。&lt;/p&gt;

&lt;h3 id=&#34;需要更多的open-file-handles&#34;&gt;需要更多的Open File Handles&lt;/h3&gt;

&lt;p&gt;每个分区会映射到broker机器的其中一个目录，在每个日志目录每个日志段(segment)包含四个文件:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;00000000000029487197.index: 索引文件&lt;/li&gt;
&lt;li&gt;00000000000029487197.log: 真正的日志文件&lt;/li&gt;
&lt;li&gt;00000000000029487197.snapshot: 快照&lt;/li&gt;
&lt;li&gt;00000000000029487197.timeindex: 时间索引&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在kafka中，broker会为每个segment打开一个file handle ，不过这仅是一个配置问题，通常在生产集群可以配置OS层面的打开文件数为&lt;code&gt;30 thousand&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;多分区可能增加整体不可用性&#34;&gt;多分区可能增加整体不可用性&lt;/h3&gt;

&lt;p&gt;整体可用性的降低是因为在异常时有更多的分区需要进行恢复数据，此时多分区之间的数据同步可能在网络上需要消耗。&lt;/p&gt;

&lt;p&gt;kafka集群内部的副本机制，可以提供比较高的可用性和持久性。一个分区如果有多个副本，每个副本将会存储到不同的broker上，副本被设计为leader和follow副本。&lt;/p&gt;

&lt;p&gt;在内部，Kafka自动管理所有这些副本，并确保它们保持同步，生产者和消费者对分区的请求都将由leader副本来响应，当broker宕机后，该节点上的leader副本将暂时不可用，kafka内部的controller角色将自动将分区的leader副本切换到其他满足条件的副本上，以尽快提供读写请求(是否能尽快切换到其他副本上取决于数据的一致性和可靠性要求)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;leader副本的切换动作会涉及到controller从zookeeper中去获取对应分区的相关副本元数据，在controller内部，操作zookeeper是串行的。&lt;/p&gt;

&lt;p&gt;在通常情况下，当一个Broker被优雅地关闭时，控制器会主动地将leader从关闭的代理中移开，每次只关闭一个，一个leader的切换通常仅会需要消耗几毫秒，因此，对于客户端而言，当使用优雅重启时，仅有一个很小的不可用窗口。&lt;/p&gt;

&lt;p&gt;然而，当broker被异常关闭时(&lt;code&gt;kill -9&lt;/code&gt;)，观测到的不可用性可能与分区的数量成正比。假设每个broker共2000个分区，每个分区共2个副本，基本每个broker将负责1000个分区，当该broker异常关闭时，所有1000个分区将在同一时间不可用。假设为单个分区选主的时间需要消耗5ms，选举1000个分区将消耗5s。&lt;/p&gt;

&lt;p&gt;因此，对于某些分区，其观察到的不可用性可能是5秒加上检测故障所需的时间。&lt;/p&gt;

&lt;p&gt;如果不行的是，异常关闭的broker节点刚好是controller角色，在这种情况下，分区选leader的操作将不会立即进行，知道controller本身转移到正常的broker节点上。&lt;/p&gt;

&lt;p&gt;controller控制器自动发生故障转移，但需要新控制器在初始化期间从ZooKeeper读取每个分区的一些元数据。&lt;/p&gt;

&lt;p&gt;例如，如果Kafka集群中有10,000个分区，并且每个分区初始化来自ZooKeeper的元数据需要2 ms时间，这可能会给不可用窗口增加20秒。&lt;/p&gt;

&lt;p&gt;一般来说，异常的关闭是罕见的。但是，如果关心在这些罕见情况下的可用性，那么最好将每个Broker的分区数量限制在&lt;code&gt;2到4000&lt;/code&gt;个，集群中的分区总数限制在数万个以内。&lt;/p&gt;

&lt;h3 id=&#34;可能增加端到端的延迟-end-to-end-latency&#34;&gt;可能增加端到端的延迟(End-to-end Latency)&lt;/h3&gt;

&lt;p&gt;Kafka中的端到端延迟是由&lt;code&gt;生产者发布消息到消费者读取消息&lt;/code&gt;的时间定义的。&lt;/p&gt;

&lt;p&gt;Kafka只在&lt;code&gt;提交消息之后&lt;/code&gt;才向使用者公开消息(commited log)，即当消息被复制到所有同步副本时。因此，提交消息的时间可能是端到端延迟的重要部分。&lt;/p&gt;

&lt;p&gt;默认情况下，Kafka的broker节点仅使用一个线程来复制来自另一个Broker的数据，用于在两个Broker之间共享副本的所有分区。(可以设置适当大参数来调整同步线程数)&lt;/p&gt;

&lt;p&gt;实验表明，将1000个分区从一个Broker复制到另一个Broker可以增加大约20 ms延迟，这意味着端到端延迟至少是20 ms，这对于某些实时计算类的应用来说，整体的延迟其实有点高，当然如果整个集群比较大时，分区分布在不同的broker上，该问题可以适当缓解(其余的broker可以从这一个broker上平均fetch消息)&lt;/p&gt;

&lt;p&gt;因此，由于提交消息而增加的延迟将只有几ms，而不是几十ms。&lt;/p&gt;

&lt;p&gt;如果关系延迟指标，可以参照如下方式来计算分区:&lt;/p&gt;

&lt;p&gt;将每个Broker的分区数量限制在&lt;code&gt;100 * b * r&lt;/code&gt;可能是一个好主意，其中b是Kafka集群中的Broker数量，r是复制因子。&lt;/p&gt;

&lt;h3 id=&#34;更多的分区可能在客户端需要更多的内存&#34;&gt;更多的分区可能在客户端需要更多的内存&lt;/h3&gt;

&lt;p&gt;在客户端在内部，生产者缓冲每个分区的消息。在积累了足够的数据或经过了足够的时间之后，将从缓冲区中删除累积的消息并将其发送给Broker。&lt;/p&gt;

&lt;p&gt;如果增加分区的数量，消息将在客户端区域中的更多分区中累积。所使用的内存总量现在可能超过了配置的内存限制。&lt;/p&gt;

&lt;p&gt;当发生这种情况时，生产者必须阻止或删除任何新消息，这两种方法都不理想。为了防止这种情况发生，需要重新配置生成器，使其具有更大的内存大小。&lt;/p&gt;

&lt;p&gt;根据经验，要获得良好的吞吐量，应该为生产者中生成的每个分区分配至少几十KB的内存，如果分区数量显著增加，还应该调整内存总量。&lt;/p&gt;

&lt;p&gt;消费者也存在类似的问题。消费者为每个分区获取一批消息。消费者使用的分区越多，所需的内存就越多。然而，这通常只是一个针对非实时用户的问题。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;通常，Kafka集群中的分区越多，吞吐量就越高。但是，必须意识到总分区或每个Broker拥有太多分区对可用性和延迟等方面的潜在影响，通常这部分需要业务方和基础服务方进行合理规划和调整。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相关文档&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster/&#34;&gt;kafka-supports-200k-partitions-per-cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/&#34;&gt;kafka-topic-partition-numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka常用运维操作</title>
      <link>https://bgbiao.top/post/kafka%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 在kafka的集群运维操作过程中，我们需要通过一些工具来实现集群的高可用以及负载的平均操作，而对于kafka集群的SRE来说，需要掌握好如下几点，才能更好的维护和保证kafka集群服务的稳定性，可靠性和整体性能。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;要想kafka跑的好，如下几点要知晓。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Graceful shutdown&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;建议开启如下参数:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;controlled.shutdown.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 只有在broker上承载的分区都具有副本时(副本大于1，且副本存活)，controller节点才会成功关闭&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Balancing leadership&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每当Broker停止或崩溃时，该broker的分区的领导权就转移到其他副本。&lt;/p&gt;

&lt;p&gt;这意味着，默认情况下，当broker重新启动时，它将只是所有分区的关注者，这意味着它不会用于客户端读写，这对于整个集群来说吞吐会受到1/N的降低(N表示集群节点数)&lt;/p&gt;

&lt;p&gt;为了避免这种不平衡，kafka提供了一种优先副本的概念&lt;code&gt;preferred replicas&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;如果一个分区的副本列表是1、5、9，那么节点1比节点5或节点9更适合作为leader，因为它位于副本列表的前面。&lt;/p&gt;

&lt;p&gt;可以使用如下命令来恢复已恢复副本的领导权:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 老版本工具
bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot

# 新版本工具&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当然每次在服务器启动后执行该操作，可能很无聊，因此可以设置如下参数来自动执行:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;auto.leader.rebalance.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Balancing Replicas Across Racks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;机架层面的副本均衡。&lt;/p&gt;

&lt;p&gt;机架感知特性将相同分区的副本分散到不同的机架上，这扩展了Kafka为broker失败提供的覆盖机架失败的保证，如果机架上的所有broker同时失败，就限制了数据丢失的风险。&lt;/p&gt;

&lt;p&gt;该特性还可以应用于其他broker分组，如EC2中的可用性区域。&lt;/p&gt;

&lt;p&gt;您可以通过向broker配置添加属性来指定broker属于特定的机架：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;broker.rack=my-rack-id&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当创建、修改或重新分发一个主题时，将遵循机架约束，确保副本尽可能多地跨越多个机架(一个分区将跨越最小(#机架，复制因子)不同的机架)。&lt;/p&gt;

&lt;p&gt;用于将副本副本分配给broker的算法，会确保每个broker的leader数量是恒定的，而不管broker是如何分布在机架上的。这确保了平衡的吞吐量。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 明智的做法是为每个机架配置相同数量的broker&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mirroring data between clusters&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们将在Kafka集群之间复制数据的过程称为“镜像”，以避免与单个集群中节点之间的复制混淆。&lt;/p&gt;

&lt;p&gt;Kafka附带一个用于在Kafka集群之间镜像数据的工具，即&lt;code&gt;MirrorMaker&lt;/code&gt;，该工具可以从源集群进行消费，并生产到目标集群。&lt;/p&gt;

&lt;p&gt;常用的场景就是在另外一个数据中心提供副本。&lt;/p&gt;

&lt;p&gt;您可以运行许多这样的镜像进程来提高吞吐量和容错能力。&lt;/p&gt;

&lt;p&gt;使用mirrormaker进行迁移topic到另外的集群:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-mirror-maker.sh
      --consumer.config consumer.properties
      --producer.config producer.properties --whitelist my-topic&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;需要注意，我们必须使用&lt;code&gt;--whitelist&lt;/code&gt;参数指定topic，该参数支持java的正则表达式结构，比如&lt;code&gt;--whitelist &#39;A|B&#39;&lt;/code&gt;，或者&lt;code&gt;--whitelist &#39;*&#39;&lt;/code&gt; .&lt;/p&gt;

&lt;p&gt;通常在使用kafka-mirror-maker时，建议配合&lt;code&gt;auto.create.topics.enable=true&lt;/code&gt;使用，可以大批量的进行topic迁移。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Checking consumer position&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查消费者的位移，有时候了解消费者当前的位置时很有必要的。&lt;/p&gt;

&lt;p&gt;kafka有一个工具，它将显示所有消费者在一个消费者组中的位置，以及他们与日志结束的距离&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 在my-group的消费者上消费my-topic的主题
# 可以查看整个消费者组的消费情况
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Managing Consumer Groups&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ConsumerGroupCommand工具可以&lt;code&gt;list, describe, or delete&lt;/code&gt;一个消费组，消费者组可以手动删除，也可以在该组最后提交的偏移量过期时自动删除。&lt;/p&gt;

&lt;p&gt;只有在组中没有任何活动成员时，手动删除才有效。&lt;/p&gt;

&lt;p&gt;如下命令可以列出所有主题的所有消费者组:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;查看指定消费者组&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当然可用试用一些额外的参数来查看更多的消费者信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ndash;members: 查看消费者组中活跃的消费者&lt;/li&gt;
&lt;li&gt;&amp;ndash;members &amp;ndash;verbose: 该参数还可以查看分配给每个成员的分区&lt;/li&gt;
&lt;li&gt;&amp;ndash;offsets: 该参数实际上可以被&lt;code&gt;--describe&lt;/code&gt;参数中的内容覆盖掉&lt;/li&gt;
&lt;li&gt;&amp;ndash;state: 该参数可以提供组级别的信息&lt;/li&gt;
&lt;li&gt;&amp;ndash;delete: 该参数可以手动删除一个或多个消费者组&lt;/li&gt;

&lt;li&gt;&lt;p&gt;-reset-offsets: 该参数用于重置消费者组的偏移量，此选项在同一时间支持一个消费者组，同时需要使用&lt;code&gt;--all-topics或--topic&lt;/code&gt;指定范围&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看消费者组成员
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --members

CONSUMER-ID                                    HOST            CLIENT-ID       #PARTITIONS
consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1       2
consumer4-117fe4d3-c6c1-4178-8ee9-eb4a3954bee0 /127.0.0.1      consumer4       1
consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2       3
consumer3-ecea43e4-1f01-479f-8349-f9130b75d8ee /127.0.0.1      consumer3       0

# 查看消费者组成员详细信息(分区)
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --members --verbose

CONSUMER-ID                                    HOST            CLIENT-ID       #PARTITIONS     ASSIGNMENT
consumer1-3fc8d6f1-581a-4472-bdf3-3515b4aee8c1 /127.0.0.1      consumer1       2               topic1(0), topic2(0)
consumer4-117fe4d3-c6c1-4178-8ee9-eb4a3954bee0 /127.0.0.1      consumer4       1               topic3(2)
consumer2-e76ea8c3-5d30-4299-9005-47eb41f3d3c4 /127.0.0.1      consumer2       3               topic2(1), topic3(0,1)
consumer3-ecea43e4-1f01-479f-8349-f9130b75d8ee /127.0.0.1      consumer3       0               -

# --state参数

$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group --state

COORDINATOR (ID)          ASSIGNMENT-STRATEGY       STATE                #MEMBERS
localhost:9092 (0)        range                     Stable               4

# 删除消费者组
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group my-group --group my-other-group

Deletion of requested consumer groups (&amp;#39;my-group&amp;#39;, &amp;#39;my-other-group&amp;#39;) was successful.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; &lt;code&gt;--reset-offsets&lt;/code&gt;选项支持如下三个执行选项:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;显示要重置的偏移量&lt;/li&gt;
&lt;li&gt;&amp;ndash;execute: 执行&lt;code&gt;--reset-offsets&lt;/code&gt;进程&lt;/li&gt;
&lt;li&gt;&amp;ndash;export: 以csv格式导出执行结果&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;--reset-offsets&lt;/code&gt;参数还有如下方案可供选择:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ndash;to-datetime: 重置offset到另外一个offset (format:YYYY-MM-DDTHH:mm:SS.sss)&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-earliest: 重置offset到最早的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-latest: 重置为最新的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;shift-by: 重置offset为n&lt;/li&gt;
&lt;li&gt;&amp;ndash;from-file: 重置到csv中定义的offset&lt;/li&gt;
&lt;li&gt;&amp;ndash;to-current: 重置offset到当前&lt;/li&gt;
&lt;li&gt;&amp;ndash;by-duration: 重置offset为当前时间( Format: &amp;lsquo;PnDTnHnMnS&amp;rsquo;)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;to-offset: 重置offset为指定的值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 设置消费者组的offset为最新
$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --reset-offsets --group consumergroup1 --topic topic1 --to-latest

TOPIC                          PARTITION  NEW-OFFSET
topic1                         0          0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果你还是使用老的&lt;code&gt;high-level&lt;/code&gt;消费者，并且将组的元数据存储在zk中(&lt;code&gt;offsets.storage=zookeeper&lt;/code&gt;)，可以使用&lt;code&gt;--zookeeper&lt;/code&gt;来代替&lt;code&gt;bootstrap-server&lt;/code&gt;参数:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;bin/kafka-consumer-groups.sh --zookeeper localhost:2181 --list&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Expanding your cluster&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;集群的扩展.&lt;/p&gt;

&lt;p&gt;将服务器添加到Kafka集群很容易，只需为它们分配一个惟一的brokerid，并在新服务器上启动Kafka.&lt;/p&gt;

&lt;p&gt;然而，这些新服务器不会自动分配任何数据分区，因此，除非将分区移动到它们，否则在创建新主题之前，它们不会做任何工作。&lt;/p&gt;

&lt;p&gt;因此，通常在向集群中添加机器时，您会希望将一些现有数据迁移到这些机器上。&lt;/p&gt;

&lt;p&gt;迁移数据的过程是手动启动的，但是完全自动化。&lt;/p&gt;

&lt;p&gt;实际上，Kafka将添加新服务器作为它正在迁移的分区的追随者，并允许它完全复制该分区中的现有数据。&lt;/p&gt;

&lt;p&gt;当新服务器完全复制了该分区的内容并加入同步副本时，现有副本中的一个将删除其分区的数据。&lt;/p&gt;

&lt;p&gt;可以使用分区重新分配工具在broker之间移动分区。&lt;/p&gt;

&lt;p&gt;理想的分区分布应该确保所有broker之间的数据负载和分区大小是一致的。&lt;/p&gt;

&lt;p&gt;分区重新分配工具不具备自动研究Kafka集群中的数据分布并移动分区以获得均匀的负载分布的能力，因此，管理员必须确定应该移动哪些主题或分区。&lt;/p&gt;

&lt;p&gt;分区迁移工具可以运行在三种互斥模式下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--generate&lt;/code&gt;: 给定主题列表和broker列表，该工具生成一个候选重新分配，将指定主题的所有分区移动到新的broker，该参数仅帮助管理员方便的来生成给定主题和目标broker列表的分区重新分配计划&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 该工具根据用户提供的重新分配计划开始重新分配分区(使用&lt;code&gt;--reassignment-json-file&lt;/code&gt;指定生成的迁移配置)，- &lt;code&gt;--verify&lt;/code&gt;: 该工具将验证列出的所有分区的重新分配状态，可以是成功完成、失败或正在进行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;1.自动迁移数据到新的服务器&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;分区重新分配工具可用于将某些主题从当前broker集移到新添加的broker。 这在扩展现有集群时通常很有用，因为与一次移动一个分区相比，将整个主题移至新的broker集更容易。 用于执行此操作时，用户应提供应移至新的一组broker的主题列表和新broker的目标列表。 然后，该工具将给定主题列表中的所有分区平均分配到新的一组broker中。 在此过程中，主题的复制因子保持不变。 有效地，将输入主题列表的所有分区的副本从旧的broker集移至新添加的broker。&lt;/p&gt;

&lt;p&gt;如下示例(topic:foo1和foo2的全部分区移动到broker 5和6上，迁移完成后，该topic的全部分区将在Broker5和6上):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat topics-to-move.json
{&amp;#34;topics&amp;#34;: [{&amp;#34;topic&amp;#34;: &amp;#34;foo1&amp;#34;},
            {&amp;#34;topic&amp;#34;: &amp;#34;foo2&amp;#34;}],
&amp;#34;version&amp;#34;:1
}

# 准备好json文件之后，使用分区重新分配工具生成一个候选分配
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --topics-to-move-json-file topics-to-move.json --broker-list &amp;#34;5,6&amp;#34; --generate
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

Proposed partition reassignment configuration

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]}]
}

# 该工具生成一个将移动所有分区的候选分配(分配到哪些broker上)，此时分区移动还没有开始，它只告诉您当前的分配和建议的新分配。
# 应该保存当前的赋值，以防您想要回滚到它.
# 使用生成的迁移计划进行迁移
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file expand-cluster-reassignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3,4]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[5,6]}]
}

# 最后使用--verify选项验证迁移状态
# 注意:使用相同的迁移计划任务expand-cluster-reassignment.json
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file expand-cluster-reassignment.json --verify
Status of partition reassignment:
Reassignment of partition [foo1,0] completed successfully
Reassignment of partition [foo1,1] is in progress
Reassignment of partition [foo1,2] is in progress
Reassignment of partition [foo2,0] completed successfully
Reassignment of partition [foo2,1] completed successfully
Reassignment of partition [foo2,2] completed successfully&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;2.自定义分区分配和迁移&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;分区重分配工具还可以用于有选择地将分区的副本移动到一组特定的broker。&lt;/p&gt;

&lt;p&gt;当我们以这种方式使用时，假设用户知道重新分配计划，并且不需要该工具来生成候选的重新分配，即直接使用用户的分配策略进行数据迁移。&lt;/p&gt;

&lt;p&gt;示例: 迁移topic&lt;code&gt;foo1&lt;/code&gt;的partition-0到broker5和6，partition-1到broker2和3&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义迁移计划
$ cat custom-reassignment.json
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},{&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]}

# 使用--execute选项执行上述的迁移计划
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file custom-reassignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[1,2]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[3,4]}]
}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo1&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6]},
              {&amp;#34;topic&amp;#34;:&amp;#34;foo2&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2,3]}]
}

# --verify来验证迁移状态

$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file custom-reassignment.json --verify
Status of partition reassignment:
Reassignment of partition [foo1,0] completed successfully
Reassignment of partition [foo2,1] completed successfully&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Decommissioning brokers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;分区重新分配工具还不能自动生成用于退役broker的重新分配计划，因此，管理员必须制定一个重新分配计划，将托管在代理上的所有分区的副本迁移到代理的其余部分。&lt;/p&gt;

&lt;p&gt;这可能比较繁琐，因为重新分配需要确保所有副本不会从已退役的代理移动到另一个代理。为了简化这个过程，我们计划在将来为退役代理添加工具支持。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Increasing replication factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;增加现有分区的复制因子很容易，只需在定制的重新分配json文件中指定额外的副本，并使用—execute选项来增加指定分区的复制因子。&lt;/p&gt;

&lt;p&gt;示例: 将主题foo的partition-0的副本从1增加到3。在增加复制因子之前，代理5上只存在分区的副本，作为增加复制因子的一部分，我们将在代理6和代理7上添加更多的副本。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义迁移配置
$ cat increase-replication-factor.json
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6,7]}]}

# 执行
bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions
{&amp;#34;version&amp;#34;:1,
&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;foo&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[5,6,7]}]}

# 验证
bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --verify
Status of partition reassignment:
Reassignment of partition [foo,0] completed successfully

# 查看副本数
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic foo --describe
Topic:foo   PartitionCount:1    ReplicationFactor:3 Configs:
  Topic: foo    Partition: 0    Leader: 5   Replicas: 5,6,7 Isr: 5,6,7&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Limiting Bandwidth Usage during Data Migration&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kafka允许您对复制流量施加限制，设置用于将副本从一台机器移动到另一台机器的带宽上限。&lt;/p&gt;

&lt;p&gt;这在重新平衡集群、引导新代理或添加或删除代理时非常有用，因为它限制了这些数据密集型操作对用户的影响&lt;/p&gt;

&lt;p&gt;最简单的方式就是在使用&lt;code&gt;kafka-reassign-partitions.sh&lt;/code&gt;脚本时，使用限流功能，不过&lt;code&gt;kafka-configs.sh&lt;/code&gt;脚本也具有该功能。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 限制在执行重平衡时，迁移速度不能超过50MB/s.
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --execute --reassignment-json-file bigger-cluster.json —throttle 50000000

# 当然，如果要改变速率的限制，可以重新运行
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181  --execute --reassignment-json-file bigger-cluster.json --throttle 700000000
  There is an existing assignment running.
  The throttle limit was set to 700000000 B/s

# 一旦完成重平衡后，就可以再次验证
# 需要注意:当冲平衡完成后，使用--verify验证时需要删除限流，否则会影响正常复制
$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181  --verify --reassignment-json-file bigger-cluster.json
Status of partition reassignment:
Reassignment of partition [my-topic,1] completed successfully
Reassignment of partition [mytopic,0] completed successfully
Throttle was removed.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;查看broker的限流配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type brokers
Configs for brokers &amp;#39;2&amp;#39; are leader.replication.throttled.rate=700000000,follower.replication.throttled.rate=700000000
Configs for brokers &amp;#39;1&amp;#39; are leader.replication.throttled.rate=700000000,follower.replication.throttled.rate=700000000&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;这显示了应用于复制协议的leader和follower端上的节流。默认情况下，两边分配相同的节流吞吐量值。&lt;/p&gt;

&lt;p&gt;查看限流的副本:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ bin/kafka-configs.sh --describe --zookeeper localhost:2181 --entity-type topics
Configs for topic &amp;#39;my-topic&amp;#39; are leader.replication.throttled.replicas=1:102,0:101,
    follower.replication.throttled.replicas=1:101,0:102&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Setting quotas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配额设置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 为user=user1, client-id=clientA配置自定义配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1 --entity-type clients --entity-name clientA
Updated config for entity: user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39;.

# 为user=user1配置配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1
Updated config for entity: user-principal &amp;#39;user1&amp;#39;.

# 为client-id=clientA配置配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type clients --entity-name clientA
Updated config for entity: client-id &amp;#39;clientA&amp;#39;.

# 为user=userA配置默认的配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-name user1 --entity-type clients --entity-default
Updated config for entity: user-principal &amp;#39;user1&amp;#39;, default client-id.

# 为user配置默认配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type users --entity-default
Updated config for entity: default user-principal.

# 为client-id配置默认配额
$  bin/kafka-configs.sh  --zookeeper localhost:2181 --alter --add-config &amp;#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&amp;#39; --entity-type clients --entity-default
Updated config for entity: default client-id.

# 查看配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-name user1 --entity-type clients --entity-name clientA
Configs for user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-name user1
Configs for user-principal &amp;#39;user1&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type clients --entity-name clientA
Configs for client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

# 如果不指定entity name ，将显示所有的entity-type的配额
$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users
Configs for user-principal &amp;#39;user1&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200
Configs for default user-principal are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200

$ bin/kafka-configs.sh  --zookeeper localhost:2181 --describe --entity-type users --entity-type clients
Configs for user-principal &amp;#39;user1&amp;#39;, default client-id are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200
Configs for user-principal &amp;#39;user1&amp;#39;, client-id &amp;#39;clientA&amp;#39; are producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 在broker的配置中增加如下配置，会默认为全部的生产者和消费者进行配额限制.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 生产者和消费者10MB/s
quota.producer.default=10485760
quota.consumer.default=10485760&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#operations&#34;&gt;kafka-operations&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gehf9xu0tzj30p00angou.jpg&#34; alt=&#34;交流群&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>kafka生产规划和运维</title>
      <link>https://bgbiao.top/post/kafka%E7%94%9F%E4%BA%A7%E8%A7%84%E5%88%92%E5%92%8C%E8%BF%90%E7%BB%B4/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/kafka%E7%94%9F%E4%BA%A7%E8%A7%84%E5%88%92%E5%92%8C%E8%BF%90%E7%BB%B4/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;前言: 通常对于初创企业或者初创业务团队来说，对于开源组件的使用都会显的比较随意，而这种情况会随着业务量级的增长或时间的推移导致开源服务的滥用，进而造成的结果就是服务整体的稳定性和可靠性相对较差，且是边际效应递减的，如果此时不对整体业务以及开源服务进行规划和改造，那么风险和成本将是同比增长的。在我过去的工作经历中，经历过类似服务的有&lt;code&gt;Redis集群&lt;/code&gt;，&lt;code&gt;ElasticSearch&lt;/code&gt;集群，虽然整体改造后并不一定将成本降到最低，但是可以将服务的可用性和可靠性提高很多，而且根据业务场景以及使用方式来规划集群后会使得整体的边际成本呈递减状态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;笔者目前所处的团队所管理的kafka集群也处于该种状态，集群当前规模大约为20+ECS，总数据量大约400T，其中承接的Topic服务主要分为&lt;code&gt;日志收集&lt;/code&gt;、&lt;code&gt;数据管道&lt;/code&gt;、&lt;code&gt;流式计算&lt;/code&gt;、&lt;code&gt;业务事件存储&lt;/code&gt;几种大场景，我们需要知道，以上几种使用场景对于kafka集群的的&lt;code&gt;可用性&lt;/code&gt;，&lt;code&gt;可靠性&lt;/code&gt;，&lt;code&gt;数据一致性&lt;/code&gt;要求其实是不同的，如果将所有场景耦合到同一个集群，在数据量较大的情况下，任何的小异常点都可能造成整体服务受到影响，并且整个集群的恢复周期会很长，如果业务没有及时的降级策略很可能影响核心业务的处理。&lt;/p&gt;

&lt;p&gt;鉴于以前对开源分布式服务的规划和改造经验，本篇文章将根据官方文档以及经验来分享一些关于Kafka生产集群规划和运维管理相关的知识.&lt;/p&gt;

&lt;h2 id=&#34;一-kafka集群运维和规划&#34;&gt;一、Kafka集群运维和规划&lt;/h2&gt;

&lt;p&gt;其实任何开源的分布式系统在开始规划时，就需要考虑到业务场景，以及生产环境的周边可观测系统，比如如下几个方面:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;规划和部署生产级别的集群(包含官方最佳实践以及一些针对不停场景推荐的配置项变更)&lt;/li&gt;
&lt;li&gt;执行一些部署后的操作(比如滚动重启集群，集群备份，数据迁移等等)&lt;/li&gt;
&lt;li&gt;集群的可观测性(监控重要统计数据，理解kafka内部行为的具体含义以及是否需要报警通知)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;二-集群规划&#34;&gt;二、集群规划&lt;/h2&gt;

&lt;p&gt;本节主要介绍，kafka集群在生产环境部署前的一些规划，包含硬件配置选择，网络以及文件系统和其他考虑的选型.&lt;/p&gt;

&lt;h3 id=&#34;1-硬件和os&#34;&gt;1.硬件和OS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;通常对于分布式的开源服务来将对于硬件本身没有太高的要求，但当需要承载一定量级的业务时，我们需要考虑一些硬件是否能够支撑对应的业务场景，并且通常来讲针对不同的业务场景选择不同的硬件(如果可选择)，也许会适当降低资源成本。&lt;/p&gt;

&lt;h4 id=&#34;1-0-os&#34;&gt;1.0 OS&lt;/h4&gt;

&lt;p&gt;一般来说，对于运行Linux中的kafka集群不需要过多的OS以及kernel参数调整，但如下几种情况可以根据具体情况进行参考:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;文件描述符(fd)&lt;/code&gt;: broker节点上fd限制可以参考&lt;code&gt;(number_of_partitions)*(partition_size/segment_size)&lt;/code&gt;公式&lt;/li&gt;
&lt;li&gt;&lt;code&gt;套接字缓冲区(socket buffer)&lt;/code&gt;: 该参数可以增加多数据中心之间的数据传输(一般异地集群备份建议调整以增加吞吐)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;最大内存映射区域数(vm.max_map_count)&lt;/code&gt;: 当kafka broker节点拥有太多分区时应该密切关注系统级别的该参数，默认为65535。每一个日志段，分配的分区，都需要一对&lt;code&gt;index/timeindex&lt;/code&gt;文件，而每个文件都会消耗一个内存区域(一个日志段使用2个内存映射区域)，因此一个分区至少需要2个内存区域，一个broker上拥有50000分区时，将会消耗100000个内存区域，此时默认的参数就会导致broker 以&lt;code&gt;OutOfMemoryError&lt;/code&gt;方式crash掉。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;每个分区的日志段的数量取决于段(segment)的大小，负载，以及保留策略&lt;/p&gt;

&lt;p&gt;kafka使用大量的文件以及socket和客户端进行通讯，我们都知道，在Linux下，一切皆文件，因此系统需要设置更多的可用文件描述符&amp;gt;。&lt;/p&gt;

&lt;p&gt;在大多数的默认系统配置中，单个进程可用使用1024个文件描述符，对于kafka来说太小了，建议调整到至少&lt;code&gt;100000&lt;/code&gt;，但是通常和操作
系统以及发行版本有关系，需要根据具体的OS进行调整。&lt;/p&gt;

&lt;p&gt;可用通过计算Kafka数据目录中的&lt;code&gt;.index&lt;/code&gt;文件来计算当前的mmap编号。&lt;code&gt;.index&lt;/code&gt;文件大多数代表了内存映射文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 1.统计.index文件个数
$ find . -name &amp;#39;*index&amp;#39; | wc -l

# 2.为每个session设置vm.max_map_count参数，这将计算当前内存映射文件的数量，mmap限制的最小值就是打开文件的ulimit限制
# 该值要远大于index的数量
$ sysctl -w vm.max_map_count=262144

# 3.持久化mmap参数
$ echo &amp;#39;vm.max_map_count=262144&amp;#39; &amp;gt;&amp;gt; /etc/sysctl.conf
$ sysctl -p&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;1-1-内存&#34;&gt;1.1 内存&lt;/h4&gt;

&lt;p&gt;Kafka严重依赖文件系统来存储和缓存消息。&lt;/p&gt;

&lt;p&gt;所有数据都会立即写入文件系统上的持久日志中，而不必刷新到磁盘。实际上，这仅意味着将其转移到内核的页面缓存&lt;code&gt;pagecache&lt;/code&gt;中。 当回收内存时，操作系统会将可用内存转移到磁盘缓存中，而对性能的影响很小。&lt;/p&gt;

&lt;p&gt;同时，Kafka非常小心地使用堆空间&lt;code&gt;heap space&lt;/code&gt;，不需要将堆大小设置为超过6 GB，这样将会在32G内存的机器上缓存28-30G的数据到文件系统。&lt;/p&gt;

&lt;p&gt;因此，生产集群需要足够的内存来缓存活动的reader和writer。在Confluent的使用建议中，提出了对内存需求的粗略估计方式，比如需要缓冲30s，那么内存需求大概为&lt;code&gt;write_throughput * 30&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通常来讲&lt;code&gt;64G&lt;/code&gt;内存配置的机器是一个不错的选择.&lt;/p&gt;

&lt;h4 id=&#34;1-2-cpu&#34;&gt;1.2 CPU&lt;/h4&gt;

&lt;p&gt;大多数的kafka集群对于cpu的要求不是那么高，因此对于CPU的配置没有像其他资源那么重要(但是通常同等资源都是由一定比例配比的)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果开启了SSL，那么可能对集群的整体性能有一定影响，且对cpu有一定要求，具体需要考虑到cpu的类型以及具体的JVM实现细节(通常来讲内部服务均不会开启SSL，因为管理成本很高，且性能上略有损失，安全上可以通过整体的IT安全进行要求和管控)&lt;/p&gt;

&lt;p&gt;通常情况下建议使用较新的多核处理器，通用集群可以设置为&lt;code&gt;24&lt;/code&gt;核心。&lt;/p&gt;

&lt;p&gt;如果需要在更快的CPU或更多的内核之间进行选择，请选择更多的内核，因为多核提供的额外并发性将远远超过稍快的时钟速度。&lt;/p&gt;

&lt;h4 id=&#34;1-3-disk&#34;&gt;1.3 Disk&lt;/h4&gt;

&lt;p&gt;生产集群建议使用多块磁盘来最大化整体的吞吐，不要与应用程序日志或其他OS文件系统活动共享用于Kafka数据的相同驱动器，以确保良好的延迟。&lt;/p&gt;

&lt;p&gt;在官方的最佳实践中建议，可以将&lt;code&gt;多块磁盘构建成RAID&lt;/code&gt;，或者直接将独立的&lt;code&gt;多块磁盘&lt;/code&gt;作为kafka的数据存储，也就是JBOD方案(Just Bunch Of Disks)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注:&lt;/code&gt;如果软RAID的话其实会在存储方面增加一层数据均衡，增加了集群的复杂度，因此一般可用选择后者，而且RAID主要用于提供冗余，对于开源分布式服务来讲，在软件层面上基本都会保证数据的冗余。&lt;/p&gt;

&lt;p&gt;不过在实际的场景中，具体选择使用多块盘做RAID还是直接使用多块盘挂载，以下有几种场景可以考虑:&lt;/p&gt;

&lt;p&gt;如果配置多个数据目录，则Broker将在路径中放置一个新分区，该分区中当前存储的分区数最少。每个分区将完全位于数据目录之一中，如果&lt;code&gt;分区之间的数据不平衡，就会导致磁盘之间的负载不平衡&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;RAID在平衡磁盘之间的负载方面做得更好，它能在较低的水平上平衡负载。RAID的主要缺点是减少了可用的磁盘空间(RAID0除外)，好处是可以容忍磁盘故障(RAID1，RAID5等)。&lt;/p&gt;

&lt;p&gt;在生产中强烈不建议使用RAID 5 or RAID 6 ,会严重影响到写吞吐的性能，并且在磁盘故障时会有重建阵列的I/O成本(&lt;code&gt;RAID0下也存在重建I/O的成本&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;如果额外的成本可以接受，建议使用RAID10(容量减半，多一份冗余)，否则，建议Kafka服务器配置多个日志目录，每个目录都安装在单独的驱动器上。&lt;/p&gt;

&lt;p&gt;linked使用8x7200转的sata磁盘，一般来说，磁盘吞吐量是性能瓶颈，磁盘越多越好。&lt;/p&gt;

&lt;p&gt;kafka官方文档中其实建议使用多个驱动器以获得良好的吞吐量，因为每个路径都独立挂载在不同的磁盘上，这使得多块物理磁盘磁头同时执行物理I/O写操作，可以极大地加速Kafka消息生产的速度。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 通常在使用本地盘时，容量可能会比较大，当磁盘容量超过2T时，Linux下默认的MBR分区就不能满足容量的要求了，此时需要在分区时进行GPT分区，否则等线上业务真正上线后会发现超过2T的空间就被浪费了。&lt;/p&gt;

&lt;p&gt;另外一个问题就是，磁盘容量规划的问题，虽然kafka默认为全部的日志数据设置了7天保留时间，但是往往在海量的数据消费场景中，单天的数据量也可能达到好几个T，这就导致了需要提前对业务的场景和使用方式进行提前规划，并提前计算最少的存储量。&lt;/p&gt;

&lt;p&gt;但一般对于磁盘空间的规划可以根据消息量大概估算，比如一天7亿条消息，单条1kb，消息副本为3(可保证2节点同时挂)，那么大概的存储空间为&lt;code&gt;7亿*3*1KB/1000/1000=2100G&lt;/code&gt;，也就是这种规模下的数据，一天产生2T的数据，实际使用数据为700G，1400G数据为冗余数据，此时我们在规划磁盘容量时就需要考虑到单天数据量的大小，以及数据的保留时间。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果客户端开启了消息压缩，整体的数据能再相对小一些，可以根据具体情况来考虑&lt;/p&gt;

&lt;h4 id=&#34;1-4-network&#34;&gt;1.4 Network&lt;/h4&gt;

&lt;p&gt;在分布式系统中，快速可靠的网络是性能的一个重要组成部分(&lt;code&gt;因此通常分布式系统中建议在同机房&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;低延迟确保节点可以轻松通信，而高带宽有助于集群节点之前的副本移动和恢复(&lt;code&gt;往往在kafka集群中优先瓶颈点都是带宽&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;目前大多数的数据中心基本都是千兆(1 GbE)或万兆网络(10 GbE)，对于大多数集群通常都是足够的。&lt;/p&gt;

&lt;p&gt;应该尽量避免集群跨越多个数据中心，即使数据中心在很近的距离同地区，也要避免跨越巨大地理距离的集群。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注:&lt;/code&gt;实际上在分布式系统中分区是肯定会发生的，通过避免跨机房部署能够降低分区的概率&lt;/p&gt;

&lt;p&gt;Kafka集群假设所有节点都是相等的，较大的延迟可能会加剧分布式系统中的问题，并使调试和解决变得更加困难。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果业务上需要异地进行数据读写，推荐的方法是在每个数据中心中部署一个本地Kafka集群，每个数据中心中的应用程序实例只与它们的本地集群交互，并在集群之间进行镜像(kafka提供了mirror-maker工具)。&lt;/p&gt;

&lt;h4 id=&#34;1-5-filesystem&#34;&gt;1.5 Filesystem&lt;/h4&gt;

&lt;p&gt;现在操作系统中，大部分的系统应该都使用了&lt;code&gt;Ext4&lt;/code&gt;或&lt;code&gt;XFS&lt;/code&gt;系统，官方也推荐使用这两种文件系统，但是对于具体的文件系统的选择，官方提供了如下几种场景和需要注意的点。&lt;/p&gt;

&lt;p&gt;使用各种文件系统创建和挂载选项，在具有大量消息负载的集群上执行了比较测试，XFS带来了更好的本地时间(最好的EXT4配置是160ms vs. 250ms+)，以及更低的平均等待时间。XFS性能在磁盘性能方面的可变性也较小。&lt;/p&gt;

&lt;p&gt;不论是使用哪种文件系统，推荐修改默认的挂载参数:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;noatime&lt;/code&gt;: 此选项禁止在读取文件时更新文件的atime(最后访问时间)属性,这可以消除大量的文件系统写操作，特别是在引导消费者的情况下,Kafka完全不依赖于atime属性，所以禁用它是安全的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat /etc/fstab
UUID=&amp;#34;4231b126-7e67-45c4-b8bf-554006291d35&amp;#34;  /export1    xfs    defaults,noatime         0 2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;XFS文件系统挂载参数优化:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;largeio&lt;/code&gt;: 这会影响stat调用报告的首选I/O大小，尽管这可以在较大的磁盘写入上实现更高的性能，但实际上对性能的影响很小或没有影响&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nobarrier&lt;/code&gt;: 于具有电池后备缓存的基础设备，此选项可以通过禁用定期写刷新来提供更高的性能。 但是，如果基础设备的行为良&amp;gt;好，它将向文件系统报告它不需要刷新，并且此选项将无效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EXT文件系统挂载参数优化:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在ext4文件系统下，要获得最佳性能，则需要调整几个参数。这些选项在故障情况下通常是不安全的，并且将导致更多的数据丢失和损坏，对于单个broker故障，可以擦除磁盘并从群集重建副本，在多数情况下，多broker异常意味着潜在的文件系统损坏，无法轻易恢复。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data=writeback&lt;/code&gt;: Ext4默认为data = ordered，这使某些写入操作具有很强的顺序，在Kafka场景下其实不需要该参数，此设置消除了排序约束，并且似乎大大减少了延迟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Disabling journaling&lt;/code&gt;: 日志记录是一个折衷:它使服务器崩溃后重新引导更快，但它引入了大量额外的锁定，增加了写入性能的差异&lt;/li&gt;
&lt;li&gt;&lt;code&gt;commit=num_secs&lt;/code&gt;: 这调整了ext4提交到其元数据日志的频率。 将此值设置为较低的值可以减少崩溃期间未刷新数据的丢失。 将此值设置为较高的值将提高吞吐量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nobh&lt;/code&gt;: 此设置控制在使用data=writeback模式时附加的排序保证，可以提高吞吐量和延迟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delalloc&lt;/code&gt;: 延迟分配意味着文件系统避免在物理写入发生之前分配任何块，此功能非常适合吞吐量&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-6-application-vs-os-flush-management&#34;&gt;1.6 Application vs. OS Flush Management&lt;/h4&gt;

&lt;p&gt;Kafka始终会立即将所有数据写入文件系统，并支持配置刷新策略的功能，该策略控制何时使用刷新将数据从OS缓存中强制出到磁盘上。&lt;/p&gt;

&lt;p&gt;可以控制此刷新策略，以在一段时间后或在写入一定数量的消息之后将数据强制到磁盘。 在此配置中有几种选择。&lt;/p&gt;

&lt;p&gt;Kafka必须最终调用fsync才能知道数据已刷新。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;当从崩溃中恢复任何未知的日志段时，Kafka将通过检查其消息的CRC来检查每条消息的完整性，并在启动时执行的恢复过程中重建附带的偏移索引文件&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;请注意，Kafka中的持久性不需要将数据同步到磁盘，因为发生故障的节点将始终从其副本中恢复。&lt;/p&gt;

&lt;p&gt;我们建议使用默认刷新设置，该设置将完全禁用应用程序的fsync。&lt;/p&gt;

&lt;p&gt;这意味着依靠操作系统和Kafka自己的后台刷新来完成后台刷新。&lt;/p&gt;

&lt;p&gt;这为所有用途提供了最佳的解决方案：无需调节配置，提高吞吐量和延迟，并提供完全恢复保证。&lt;/p&gt;

&lt;p&gt;通常，我们认为&lt;code&gt;复制&lt;/code&gt;提供的保证要强于&lt;code&gt;同步到本地磁盘&lt;/code&gt;，但是偏执狂仍然更愿意同时拥有两者，并且仍然支持应用程序级fsync策略。&lt;/p&gt;

&lt;p&gt;使用应用程序级刷新设置的缺点是，其磁盘使用模式效率较低（它给操作系统减少了重新排序写操作的余地），并且由于大多数Linux文件系统中的fsync阻止了文件写入，因此它会引入延迟。 后台刷新进行更精细的页面级锁定。&lt;/p&gt;

&lt;h4 id=&#34;1-7-理解linux操作系统的flush行为&#34;&gt;1.7 理解Linux操作系统的Flush行为&lt;/h4&gt;

&lt;p&gt;在Linux中，写入文件系统的数据将保留在页面缓存中，直到必须将其写出到磁盘为止（由于应用程序级fsync或操作系统自身的刷新策略）。&lt;/p&gt;

&lt;p&gt;数据刷新是通过一组称为pdflush的后台线程完成的（或在2.6.32版的内核“冲洗线程”中）。&lt;/p&gt;

&lt;p&gt;Pdflush具有可配置的策略，该策略控制可以在缓存中维护多少脏数据以及必须将多脏数据写回到磁盘的时间.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://web.archive.org/web/20160518040713/http://www.westnet.com/~gsmith/content/linux-pdflush.htm&#34;&gt;pdflush刷新策略&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当Pdflush无法跟上写入数据的速度时，它将最终导致写入过程阻塞写入中的延迟，从而减慢数据的累积。&lt;/p&gt;

&lt;p&gt;与进程内缓存相比，使用pagecache存储将写入磁盘的数据有几个优点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I/O调度将连续的小写批量写到更大的物理写中，从而提高吞吐量&lt;/li&gt;
&lt;li&gt;I/O调度尝试重新排序写操作，以最小化磁盘头的移动，从而提高吞吐量&lt;/li&gt;
&lt;li&gt;它会自动使用机器上所有的空闲内存&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-节点配置&#34;&gt;2.节点配置&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1.避免使用太小的节点配置，因为这样整个集群的节点数可能会特别多，在这种机器上运行kafka将会有更多的开销&lt;/li&gt;
&lt;li&gt;2.避免使用太高配计算机，因为它们经常导致资源使用不平衡，比如内存优先不够了，但cpu还剩余很多。如果在每个高配机器上运行多个broker节点，将会增加整体的复杂度&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-jvm配置&#34;&gt;3.JVM配置&lt;/h3&gt;

&lt;p&gt;在当前大多数Java类应用下，基本都在使用JDK8(建议使用最新的jdk8)，在此环境下默认使用的是&lt;code&gt;G1&lt;/code&gt;的垃圾回收器，因此一般情况下仅需要修改如下参数即可:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MaxGCPauseMillis&lt;/code&gt;: 指定每次垃圾回收默认的停顿时间，默认值200ms&lt;/li&gt;
&lt;li&gt;&lt;code&gt;InitiatingHeapOccupancyPercent&lt;/code&gt;: G1 启动新一轮垃圾回收之前可以使用的堆内存百分比，默认值是45&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;官方推荐的GC参数如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20
       -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M
       -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;作为参考，LinkedIn最繁忙的集群当前是如下情况:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;60 brokers&lt;/li&gt;
&lt;li&gt;50k partitions (replication factor 2)&lt;/li&gt;
&lt;li&gt;800k messages/sec in&lt;/li&gt;
&lt;li&gt;300 MBps inbound, 1 GBps + outbound&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面的GC调优看起来比较激进，但集群中的所有broker都会有90%的gc中止时间，大概21ms，它们做不到每秒一个young GC&lt;/p&gt;

&lt;p&gt;作为同样是图片社交的&lt;code&gt;Pinterest&lt;/code&gt;来讲，他们采用如下的JVM参数:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/how-pinterest-runs-kafka-at-scale-ff9c6f735be&#34;&gt;Pinterest的大规模kafka实践&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 61G的内存
-Xms8g -Xmx8g -XX:NewSize=512m -XX:MaxNewSize=512m -XX:MetaspaceSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=25
       -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=25 
       -XX:MaxMetaspaceFreeRatio=75
       -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:PrintTenuringDistribution 
       -Xloggc:/var/log/kafka/gc.log -XX:UseGCLogFileRotation -XX:NumberOfGCLogFiles=40
       -XX:GCLogFileSize=50M&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;-Xmx10G -Xms10G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xloggc:/opt/app/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;4-kafka核心配置&#34;&gt;4.kafka核心配置&lt;/h3&gt;

&lt;p&gt;Kafka默认设置在大多数情况下都能工作，特别是与性能相关的设置和选项，但是考虑到集群的规划以及场景用途，有一些补充的配置参数可以对生产环境进行调优。&lt;/p&gt;

&lt;p&gt;通常配置上来讲会分为&lt;code&gt;broker端配置&lt;/code&gt;、&lt;code&gt;produser端配置&lt;/code&gt;、&lt;code&gt;consumer端配置&lt;/code&gt;，由于各个业务方当前均使用开源客户端，因此对于客户端的配置无法做到严格管控(如果有内部的sdk封装可能会比较好)。&lt;/p&gt;

&lt;h4 id=&#34;4-1-重要的客户端配置&#34;&gt;4.1 重要的客户端配置&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks&lt;/code&gt;: 消息一致性保证(0:投递即成功,1:副本同步即成功,all/-1:全部ISR同步即成功)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression&lt;/code&gt;: 压缩类型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch size&lt;/code&gt;: 批处理大小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 对于消费者来说，最重要的参数为&lt;code&gt;fetch size&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;鉴于集群的整体可用性可靠性其实很大一部分和客户端的使用方式有关，后面会列举一些常见的生产者和消费者端的核心参数&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#configuration&#34;&gt;kafka详细参数列表&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-2-broker核心配置&#34;&gt;4.2 broker核心配置&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;zookeeper.connect&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;zk连接串，建议写全部的zk节点地址。&lt;/p&gt;

&lt;p&gt;brokers链接的zk集群地址，该值默认采用&lt;code&gt;host:ip/path&lt;/code&gt;来指定一个zk中的znode节点，通常情况下用来隔离环境. kafka的zk路径中使
用了&lt;code&gt;chroot&lt;/code&gt;环境，如果不指定使用默认的&lt;code&gt;/&lt;/code&gt;来作为存储路径。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;broker.id&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker唯一标识，该值可以任意设定(int类型)。默认&lt;code&gt;reserved.broker.max&lt;/code&gt;开始，每次+1&lt;/p&gt;

&lt;p&gt;在分布式集群中，可以手动指定每个broker的节点信息，同时也可以使用如下方式来自动生成每个broker的id&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;#broker.id
broker.id.generation.enable=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;log.dirs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;kafka存储的日志消息都是保存在该参数指定的日志路径下，该值可以指定多个磁盘路径，通常我们会绑定到多个磁盘上。比如&lt;code&gt;log.dirs=/exoprt/kafka1,/export/kafka2,/export/kafka3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;对应的另外一个默认参数为&lt;code&gt;log.dir&lt;/code&gt;，默认值为&lt;code&gt;/tmp/kafka-logs&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;listeners&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker监听列表，默认将为&lt;code&gt;PLAINTEXT://myhost:9092&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;advertised.listeners&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;监听器发布到zk集群中的地址，供客户端使用，默认采用&lt;code&gt;listeners&lt;/code&gt;参数值&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.recovery.threads.per.data.dir&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每个数据目录用于在启动时进行日志恢复和在关闭时进行刷新的线程数，默认值为: &lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;生产环境下，该值可以适当的调整大一些，用来增加正常关闭时数据flush的速度，以及启动时日志恢复的速度，可以提高broker节点的整体可用性。&lt;/p&gt;

&lt;p&gt;对于如下几种情况，kafka会使用&lt;code&gt;可配置的线程池&lt;/code&gt;来处理日志片段.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器正常启动: 用于打开每个分区的日志片段&lt;/li&gt;
&lt;li&gt;服务器崩溃后重启: 用于检查和截断每个分区的日志片段&lt;/li&gt;
&lt;li&gt;服务器正常关闭: 用于关闭日志片段&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;默认情况下，每个日志目录采用一个线程，因为这些线程仅有在启动和关闭时才用到，所以可以适当设置大一点，并不会影响到整体服务的性能，特别是对于包含大量分区的服务器来说，一旦发生崩愤，在进行恢复时使用井行操作可能会省下数小时的时间。&lt;/p&gt;

&lt;p&gt;需要注意的是，该值是每个日志目录的线程数，因此总线程数需要考虑到&lt;code&gt;log.dirs&lt;/code&gt;的配置&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注&lt;/code&gt;: 这也是在使用RAID和JBOD两种磁盘方案的另外一个考虑点&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;delete.topic.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否允许删除topic，默认为: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果为false，通过管理工具删除topic仅为标记删除，此时使用&lt;code&gt;describe&lt;/code&gt;命令可以查看到topic的详情信息，但是无法写入，可以通过删除&lt;code&gt;zk&lt;/code&gt;中的节点来删除&lt;/p&gt;

&lt;p&gt;&lt;code&gt;备注&lt;/code&gt;: 生产环境建议设置为&lt;code&gt;false&lt;/code&gt;，由集群管理员定期统一的进行删除和管理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.create.topics.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;默认情况下，kafka会使用如下三种方式创建topic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;当一个生产者开始往主题写入消息时&lt;/li&gt;
&lt;li&gt;当一个消费者开始从主题读取消息时&lt;/li&gt;
&lt;li&gt;当任意一个客户端向主题发送元数据请求时&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推荐是设置成&lt;code&gt;false&lt;/code&gt;，不允许客户端直接创建topic，否则topic会无法管理。默认值为&lt;code&gt;true&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.leader.rebalance.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否开启&lt;code&gt;leader&lt;/code&gt;自动平衡，默认值为&lt;code&gt;true&lt;/code&gt;。后台会有线程进行定期检查leader的分布情况&lt;/p&gt;

&lt;p&gt;kafka中有一个被称为优先副本（preferred replicas）的概念(通常分区会有主分区和副本分区的概念，主分区先写入，然后push到其他副本分区)。&lt;/p&gt;

&lt;p&gt;如果一个分区有3个副本，且这3个副本的优先级别分别为0,1,2，根据优先副本的概念，0会作为leader 。&lt;/p&gt;

&lt;p&gt;当0节点的broker挂掉时，会启动1这个节点broker当做leader。&lt;/p&gt;

&lt;p&gt;当0节点的broker再次启动后，会自动恢复为此partition的leader。不会导致负载不均衡和资源浪费，这就是leader的均衡机制(前提是第一次partition在分配的时候，它本身就是一个相对平均的分配)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;auto.leader.rebalance.enable=true
# 对应影响的其他两个参数
# leader.imbalance.per.broker.percentage : 每个broker允许leader不平衡比例(如果每个broker上超过了这个值，controller将会&amp;gt;执行分区再平衡)，默认值10.
# leader.imbalance.check.interval.seconds: 主分区再平衡的频率，默认值为300s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;其实，在重要业务的场景中，需要将&lt;code&gt;leader.imbalance.per.broker.percentage&lt;/code&gt;参数适当调整小一些，以避免broker中leader不平衡率导致节点的吞吐不均匀&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动创建topic的默认分区数，默认为1，通常生产集群不建议打开topic自动创建，一方面是不便于管理和追溯，另外一方面因为自动创建默认分区时1，且无法动态变更，造成的风险可能会比较大。&lt;/p&gt;

&lt;p&gt;多分区的topic有这更好的数据平衡能力，并且可以帮助消费者进行并行化消费。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 对于有key的数据，避免改变分区的数量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;default.replication.factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;适用于自动创建的主题的默认复制因子，推荐至少设置为2，默认为1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.insync.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当使用&lt;code&gt;required.acks=-1(all)&lt;/code&gt;提交到生产请求所需的ISR中的最小副本数，默认为1，建议在数据一致性要求较高的topic中设置至少为2&lt;/p&gt;

&lt;p&gt;指定&lt;code&gt;ISR&lt;/code&gt;的最小数量。当producer设置&lt;code&gt;ack=all(-1)&lt;/code&gt;时，该值指定的副本必须全部写成功，才认为消息写入成功，否则生产者将抛异常(&lt;code&gt;either NotEnoughReplicas or NotEnoughReplicasAfterAppend&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: &lt;code&gt;min.insync.replicas&lt;/code&gt;参数和生产者&lt;code&gt;ack&lt;/code&gt;参数一起使用，可以加强整个消息的持久性&lt;/p&gt;

&lt;p&gt;示例:(3副本的topic,可以设置该值为2,同时生产者ack设置为all，这将确保大多数副本没有收到写操作时，生产者直接异常)&lt;/p&gt;

&lt;p&gt;默认值为:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;unclean.leader.election.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否启用不在ISR集中的副本以选作领导者，即使这样做可能会导致数据丢失。该参数可以提高整体Topic的可用性，但是可能会造成数据的整体不一致性(部分数据的丢失)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#topicconfigs&#34;&gt;kafka可用性和可靠性保证&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;默认值为:&lt;code&gt;false&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;为false，就只从ISR中获取leader保证了数据的可靠性，但是partition就失效了，&lt;code&gt;true&lt;/code&gt;则从replica中获取，则可用性增强，但是数&amp;gt;据可能存在丢失情况&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;  该参数实际上在设置的时候也有一定的争议性，比如，我们知道副本是有&lt;code&gt;ISR&lt;/code&gt;的，即正在同步的副本，如果当前的broker宕&amp;gt;机导致需要选举leader partition，此时如果ISR内除了leader之外还有其他副本(但谁又能保证一定有呢)，那直接从ISR中选举leader&amp;gt;即可，如果没有的话，当&lt;code&gt;auto.leader.rebalance.enable=true&lt;/code&gt;时，就会去其他存活的副本中选举leader，此时可以增强整体的可用性，但是如果存活的副本不在ISR中，即意味着数据可能有一定的丢失了。但是如果该参数为false的话，ISR中没有，就直接异常了，为了保证数据的一致性。&lt;/p&gt;

&lt;p&gt;该参数的存在其实是在可用性和可靠性之间做了一个权衡，为true时保证了可用性AP，为false时保证了一致性CP&lt;/p&gt;

&lt;p&gt;&lt;code&gt;数据一致性保证&lt;/code&gt;: ISR就保存了kafka认为可靠的副本，它们具备这样的条件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;落后leader的消息条数在一定阈值内&lt;/li&gt;
&lt;li&gt;或者落后在一定时间内；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;num.replica.fetchers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数指定了fetch线程的数量(从源broker中复制消息的fetch线程)，默认值: &lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其实可以适当的调整大一些，可以增强副本之前的同步效率，设置为2可以满足大多数的场景&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.io.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker处理请求的 IO 线程数，需要考虑到磁盘的IO状况。默认值为:&lt;code&gt;8&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该值通常情况下在生产环境也可以适当的调整大一些，但是通常情况下需要考虑到所使用的的磁盘的整体情况，可以尝试设置为&lt;code&gt;num.network.threads&lt;/code&gt;的两倍，比如&lt;code&gt;d1ne.4xlarge&lt;/code&gt;的规格其实可以设置为20&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.network.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定broker用来接收来自网络的请求和发送网络的响应的线程数，默认值为: &lt;code&gt;3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在生产环境中，可以根据网络的情况以及cpu和内存的使用情况将该值默认调大一些，基本上可以为逻辑cpu核心的2/3都是可以的，比如我们生产环境采用&lt;code&gt;d1ne.4xlarge&lt;/code&gt;规格的实例，可以设置该值为10&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;background.threads&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;后台任务处理线程数(例如过期消息删除等)。默认值为:&lt;code&gt;10&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;socket相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;socket.send.buffer.bytes: (socket发送缓冲区:SO_SNDBUFF) 默认值:&lt;code&gt;102400&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;socket.receive.buffer.bytes: (socket接收缓冲区:SO_RCVBUFF) 默认值:&lt;code&gt;102400&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;socket.request.max.bytes: (请求最大值，message.max.bytes要小于该值较好) 默认值:&lt;code&gt;104857600&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在生产环境中如果涉及到多可用区，或多机房环境时，socket缓冲区的默认值也是有点小的，因此尝试可以尝试将该值设置为&lt;code&gt;1M&lt;/code&gt;或者&lt;code&gt;2M&lt;/code&gt;，即&lt;code&gt;socket.send.buffer.bytes=2097152/1048576&lt;/code&gt;，生产环境推荐优化该参数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.max.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该值表示kafka允许的最大的batch大小(不是单个message的大小)，默认值为&lt;code&gt;1000012&lt;/code&gt;，即1MB.&lt;/p&gt;

&lt;p&gt;在最新的消息格式版本中，为了提高效率，一般消息的提交都是采用batch的方式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在以前的消息格式版本中，未压缩的记录不会分组成批，在这种情况下，此限制仅适用于单个记录。&lt;/p&gt;

&lt;p&gt;在每个topic级别可以使用&lt;code&gt;max.message.bytes&lt;/code&gt;设置&lt;/p&gt;

&lt;p&gt;通常情况下，如果是一个集群承担多种业务场景，通常需要将该值设置为可以满足大多数场景的配置，比如&lt;code&gt;4194304&lt;/code&gt;即&lt;code&gt;4MB&lt;/code&gt;，&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;log相关(具体到topic级别)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;log.segment.bytes: 单个日志段(segment)的大小，默认为&lt;code&gt;1073741824&lt;/code&gt;,即1GB&lt;/li&gt;
&lt;li&gt;log.segment.delete.delay.ms: 日志段从文件系统中删除前等待的时间，默认为&lt;code&gt;60000&lt;/code&gt;，即1min&lt;/li&gt;
&lt;li&gt;log.cleanup.policy: 保留窗口之外的日志清理策略可同时指定多个策略如: [&lt;code&gt;delete&lt;/code&gt;,compact]&lt;/li&gt;
&lt;li&gt;log.cleaner.enable: 启用日志清除器进程，和&lt;code&gt;cleanup.policy = compact&lt;/code&gt;参数结合使用，默认为&lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.cleaner.threads: 日志清理的后台线程数量，默认为&lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.cleaner.delete.retention.ms: 删除的日志保留的时间，默认为&lt;code&gt;86400000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.retention.bytes: 删除日志前，日志最大的大小，超过该值即删除，默认&lt;code&gt;-1&lt;/code&gt;，作用在每个partition，会影响整个topic的容量&lt;/li&gt;
&lt;li&gt;log.retention.minutes(hours|ms): 日志保留时间，如果没指定，默认使用hours参数&lt;/li&gt;
&lt;li&gt;log.retention.check.interval.ms: 日志清理器检查日志是否符合删除条件的频率，默认为&lt;code&gt;300000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.interval.messages: 将消息刷新到磁盘之前在日志分区上累积的消息数，默认为&lt;code&gt;9223372036854775807&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.interval.ms: 主题中的消息在刷新到磁盘之前保存在内存中的最大时间，默认为&lt;code&gt;null&lt;/code&gt;(log.flush.scheduler.interval.ms参数的值)&lt;/li&gt;
&lt;li&gt;log.flush.scheduler.interval.ms: 日志刷新器检查是否需要将日志刷新到磁盘的频率，默认&lt;code&gt;9223372036854775807&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.offset.checkpoint.interval.ms: 更新最后一次刷新的持久记录(被作为恢复点)的频率，默认为&lt;code&gt;60000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.flush.start.offset.checkpoint.interval.ms: 更新日志起始偏移量的持久记录的频率，默认&lt;code&gt;60000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log.roll.hours: 新日志段(segment)被创建前的最大时间，默认&lt;code&gt;168&lt;/code&gt;，如果没设置优先使用&lt;code&gt;log.roll.ms&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;offsets相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;offsets.commit.required.acks: offset提交之前是否需要ack确认,默认值:&lt;code&gt;-1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.commit.timeout.ms: 当偏移量注意&lt;code&gt;_offset&lt;/code&gt;的所有副本接收到提交或超时达到该时间时，offset提交将延迟. 默认值:&lt;code&gt;5000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.load.buffer.size: 偏移量加载到缓存中时从偏移量段读取的批处理大小. 默认值:&lt;code&gt;5242880&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.retention.check.interval.ms: 历史offset检查的频率，默认值:&lt;code&gt;600000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.retention.minutes: 在消费者组的消费者全部异常之后，offset保留的时间，默认值:&lt;code&gt;10080&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.topic.compression.codec: 偏移量主题的压缩解码器，默认:&lt;code&gt;0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;offsets.topic.num.partitions: offset提交主题的分区数量，默认:&lt;code&gt;50&lt;/code&gt;(&lt;code&gt;注意:&lt;/code&gt;集群部署后不要改变)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;offsets.topic.replication.factor&lt;/code&gt;: offset提交主题的副本数，默认:&lt;code&gt;3&lt;/code&gt; (在集群大小满足此复制因子要求之前，内部主题创建将&amp;gt;失败,该主题非常重要，需要要求强一致性)&lt;/li&gt;
&lt;li&gt;offsets.topic.segment.bytes: offset提交主题的段大小，设置相对较小，以便更快地实现日志压缩和缓存负载，默认值:&lt;code&gt;104857600&lt;/code&gt;，即1Mb&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;queue相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;queued.max.requests: 在网络阻塞线程前，数据平面允许的排队请求数，默认值:&lt;code&gt;500&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;replica相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;replica.fetch.min.bytes:每个fetch响应所需的最小字节数，默认值:&lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.wait.max.ms: 由follow副本发起的每个fetch请求的最大等待时间，该值应小于&lt;code&gt;replica.lag.time.max.ms&lt;/code&gt;，以避免
为低吞吐量的主题频繁地收缩ISR，默认值:&lt;code&gt;500&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.lag.time.max.ms: follow副本在该时间内没有和leader副本同步，或没有发送任何同步请求，将会被leader副本从ISR中删&amp;gt;除. 默认值:&lt;code&gt;10000&lt;/code&gt;，即10s&lt;/li&gt;
&lt;li&gt;replica.socket.receive.buffer.bytes: 副本接收请求的网络缓冲区，默认值:&lt;code&gt;65535&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.socket.timeout.ms: 网络请求的超时时间，默认值:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.backoff.ms: 发生获取分区错误时要休眠的时间，参数不是很重要，默认值:&lt;code&gt;1000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;replica.fetch.max.bytes: 尝试为每个分区获取的消息字节数，参数不是很重要，默认值:&lt;code&gt;1048576&lt;/code&gt;,即1M&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;broker.rack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker所在的机架，用来感知机架的变化，通常多个分区不会放在同一个机架上&lt;/p&gt;

&lt;p&gt;示例: &lt;code&gt;RACK1&lt;/code&gt;, &lt;code&gt;us-east-1d&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;controller控制器相关&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;controlled.shutdown.enable&lt;/code&gt;: 启用控制器关闭，默认:&lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;controlled.shutdown.max.retries: 控制器会因为各种原因而宕机，该值表示控制器的重试次数，默认:&lt;code&gt;3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;controlled.shutdown.retry.backoff.ms: 在每次重试之前，系统从前一次故障(控制器fail over或副本延迟)的状态中恢复过来的时
间，默认:&lt;code&gt;5000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;controller.socket.timeout.ms&lt;/code&gt;: 控制器到broker角色转换的socket超时时间，默认:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;group相关(消费组)&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;group.max.size: 消费组中最大消费者数量&lt;/li&gt;
&lt;li&gt;group.initial.rebalance.delay.ms:注册消费者允许的最小会话超时，默认:&lt;code&gt;6000&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 很多参数是有不同级别的生效范围的，比如:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;read-only&lt;/code&gt;: 仅在broker重启后才能生效&lt;/li&gt;
&lt;li&gt;&lt;code&gt;per-broker&lt;/code&gt;: 可以为每个broker动态更新&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster-wide&lt;/code&gt;: 可作为集群范围内的值动态更新，也可以在每个broker上更新进行测试&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#brokerconfigs&#34;&gt;broker配置作用范围&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;示例配置&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# ZooKeeper地址
zookeeper.connect=[list of ZooKeeper servers]

# kafka log相关配置
num.partitions=8
default.replication.factor=3
log.dirs=[List of directories. Kafka should have its own dedicated disk(s) or SSD(s).]

# 其他配置核心配置
broker.id=[An integer. Start with 0 and increment by 1 for each new broker.]
listeners=[list of listeners]
auto.create.topics.enable=false
# 最小的isr数量，可以在topic级别设置
min.insync.replicas=2
queued.max.requests=[number of concurrent requests]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在kafka集群中，当broker集群参数确定后，还有一些针对topic的参数是可以进行动态调整的，以提高kafka服务的灵活性。&lt;/p&gt;

&lt;h4 id=&#34;4-3-topic级别的动态参数调整&#34;&gt;4.3 Topic级别的动态参数调整&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#topicconfigs&#34;&gt;Topic级别的配置&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;: 如下topic的参数可以在使用过程中进行动态调整，使用&lt;code&gt;kafka-topic.sh&lt;/code&gt;工具中的&lt;code&gt;alter&lt;/code&gt;参数来直接修改topic相关的参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cleanup.policy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个字符串是“删除”或“压缩”或两者兼而有之. 默认值: &lt;code&gt;[compact, delete]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;compression.type&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;日志压缩类型，默认值为&lt;code&gt;producer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;delete.retention.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用于日志压缩主题的删除保留时间。默认值:&lt;code&gt;86400000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.message.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每个topic可发送的最大消息(batch size)字节数.(区别于全局的&lt;code&gt;message.max.bytes&lt;/code&gt;参数)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定创建topic的默认分区数量，该值默认为1，建议根据具体的情况进行设定，越多的分区对于海量数据来说可以提高吞吐，但是对于少量数据来说，也可能增加网络消耗.&lt;/p&gt;

&lt;p&gt;一般情况下，我们会对默认的topic的分区进行过度分配，以防止后期带key的message扩容分区导致的问题，一般建议初始值设置为5-10&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;分区数一旦指定，只能增加，不能减少&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;default.replication.factor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定kafka副本数，默认每个主题分区均有一个副本，当该副本所在主机异常，可能造成数据的丢失，建议在适当场景将副本至少设置成
2个，以尽快保证数据的一致性。默认值:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;自动创建主题的副本因子&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retention.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;kafka的log保留时间，也可以使用&lt;code&gt;log.retention.hours&lt;/code&gt;参数来配置保留时间，默认168小时，即一周。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retention.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定log保留的大小，作用在每一个partition上，加入一个topic有3个partition，设置了&lt;code&gt;log.retention.bytes&lt;/code&gt;为1GB，则表示整个topic仅可以存储3GB的数据，超过该容量的数据会被进行自动删除。&lt;/p&gt;

&lt;p&gt;此时，临时增加该topic的容量的方法就是调整该参数，或调整topic的partition个数。&lt;/p&gt;

&lt;p&gt;-1表示不限制&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;segment.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每个日志段的大小，通常在消息到达broker时，会被追加到分区的当前日志段上(segment)，当日志段大小超过该参数指定的值(默认1GB)，当前日志段就会被关闭，一个新的日志段被打开。&lt;/p&gt;

&lt;p&gt;如果一个日志片段被关闭，就开始等待过期，该值不建议设置太小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;segment.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面会指定日志段的分割，该参数会指定历史的日志段的过期时间。该参数会和&lt;code&gt;log.retention.bytes&lt;/code&gt;一起校验，谁先满足就生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.max.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该值用来限制单个消息的大小，默认值为&lt;code&gt;1000 000&lt;/code&gt;即&lt;code&gt;1MB&lt;/code&gt;，如果超过该大小，broker不会接受，而且会抛出相关异常&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;该参数指的是消息被压缩后的大小，通常生产中的消息生产会使用gzip或snappy来进行压缩&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;消息的大小对于性能有比较显著的影响，越大负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求，还会增加磁
盘写入块的大小，从而影响 IO 吞吐量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;file.delete.delay.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在从文件系统中删除一个文件前的等待时间&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flush.messages&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数允许我们指定一个间隔来强制同步数据到本地磁盘，比如设置为1，表示每条消息后都会执行同步磁盘，如果设置为5表示，每5个消息同步一次。&lt;/p&gt;

&lt;p&gt;一般情况下，管法定不建议修改该参数，可以使用副本机制来保证持久性和开启操作系统的后台flush功能，会更加有效率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flush.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;同上，但是指定的是时间间隔。比如设置1000，表示1000ms后执行一次同步操作.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;follower.replication.throttled.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对日志复制的副本列表应该被在follow侧进行限流。&lt;/p&gt;

&lt;p&gt;副本列表应该为&lt;code&gt;[PartitionId]:[BrokerId],[PartitionId]:[BrokerId]&lt;/code&gt;格式，或者使用通配符&lt;code&gt;*&lt;/code&gt;来表示给topic的所有副本进行限流。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;leader.replication.throttled.replicas&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;同上，在leader侧进行限流&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;index.interval.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来控制多久kafka会增加一个index实体数据到它的offset的index上。默认设置确保我们大约每4096字节索引一条消息。索引越多，读取越接近日志中的确切位置，但索引越大。通常不需要修改该参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.message.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;被kafka允许的最大记录的batch size。&lt;/p&gt;

&lt;p&gt;如果增加了该值，并且有消费者版本老于&lt;code&gt;0.10.2&lt;/code&gt;，消费者的&lt;code&gt;fetch size&lt;/code&gt;也必须增加，这样就能获取到该批次大小的数据。&lt;/p&gt;

&lt;p&gt;在高版本的消息格式(message format)中，为了效率，记录总是会被分组成batch；而在之前的消息格式版本中，未被压缩的消息不会被分组成batch，在这种情况下，该参数仅在单条记录上生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.downconversion.enable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此配置用于控制是否启用消息格式的向下兼容以满足消费者请求。&lt;/p&gt;

&lt;p&gt;当设置成&lt;code&gt;false&lt;/code&gt;，对于希望使用较旧消息格式的消费者来说，broker将不会执行向下转换。来自旧客户端的消费者请求，broker将会返回&lt;code&gt;UNSUPPORTED_VERSION&lt;/code&gt;错误码。&lt;/p&gt;

&lt;p&gt;此配置不适用于可能需要复制到follower的消息格式转换。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.format.version&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定消息格式版本，broker将使用&lt;code&gt;append&lt;/code&gt;方式追加message到log里。该值必须是一个可用的ApiVersion，比如&lt;code&gt;0.8.2, 0.9.0.0, 0.10.0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;通过设置特定的消息格式版本，用户可以验证已存在磁盘上的消息是否小于或者等于指定的版本。&lt;/p&gt;

&lt;p&gt;错误地设置此值将导致使用较旧版本的使用者中断，因为他们将收到他们不理解的格式的消息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.timestamp.difference.max.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker接收到消息的时间戳和在消息体内部的时间戳的最大时间差距。如果&lt;code&gt;message.timestamp.type=CreateTime&lt;/code&gt;，当时间戳的差值大于该值，一个message将被拒绝。如果&lt;code&gt;message.timestamp.type=LogAppendTime&lt;/code&gt;，该参数将被忽略。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;message.timestamp.type&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定message中时间戳的类型。&lt;code&gt;CreateTime&lt;/code&gt;或&lt;code&gt;LogAppendTime&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.cleanable.dirty.ratio&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用于控制，日志压缩器(log compactor)将尝试清除日志的频率。默认情况下，我们将避免清除已压缩超过50％的日志的日志。这个比率限制了最大空间浪费(日志中的重复,50%或50%以上的日志重复)。&lt;/p&gt;

&lt;p&gt;比率越高，意味着越少，更有效的清理，但是也意味着更多的日志空间浪费。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min.compaction.lag.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一条消息保持未压缩的最小时间。仅适用于正在压缩的日志。&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;4-3-producer核心参数&#34;&gt;4.3 Producer核心参数&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;bootstrap.servers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定broker地址&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;key.serializer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker 需要接收到序列化之后的&lt;code&gt;k/v&lt;/code&gt;值，所以生产者需要将序列化后的值发送过来。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;org.apache.kafka.common.serialization.Serializer&lt;/code&gt;该类表示把键对象序列化为字节数组&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ByteArraySerializer: 默认的序列化方式&lt;/li&gt;
&lt;li&gt;StringSerializer:&lt;/li&gt;
&lt;li&gt;IntegerSerializer:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;value.serializer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定序列化后的value，需要实现&lt;code&gt;org.apache.kafka.common.serialization.Serializer&lt;/code&gt;接口&lt;/p&gt;

&lt;p&gt;&lt;code&gt;org.apache.kafka.common.serialization.StringSerializer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;compression.type&lt;/strong&gt;
指定消息压缩类型:gzip,snappy等，&lt;/p&gt;

&lt;p&gt;broker端也有该参数，默认值为:&lt;code&gt;producer&lt;/code&gt;，表示遵循生产者的压缩方式&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;生产者使用何种压缩方式，消费者将必须使用该方式进行解压缩&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;acks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来声明要有多少个分区副本接收消息后，生产者才认为消息写入成功，也就是数据一致性衡量，该参数对消息的丢失的影响较&amp;gt;大. 默认值为:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt;: 表示生产者不知道消息是否被broker成功接收被处理，反正自己发出去了就认为是成功了，该种清理增加了吞吐，但是也&amp;gt;增加的数据丢失的风险，因为程序的稳定性，网络的稳定性都可能会影响到消息的生产&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt;: 只要集群中leader接收到消息并成功处理，就返回给生产者写入成功的消息。该种情况，如果发送过程中网络出现问题或&amp;gt;者kafka集群异常导致leader没工作而导致消息写入失败，生产者会受到写入失败相关的异常，此时生产者可进行重试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all/-1&lt;/code&gt;: 表示所有参与复制的节点都收到消息时，生产者才会接收到来自服务器端写入成功的消息，该种情况下，整体的消息
确认延迟会更高一些，但是数据的一致性也更强一些&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 消息的发送其实也分&lt;code&gt;sync&lt;/code&gt;和&lt;code&gt;async&lt;/code&gt;，即同步和异步，kafka为了保证消息高效传输会决定是同步发送还是异步发送。如果让&amp;gt;客户端等待服务器的响应(通过调用get()方法)也会增加延迟，如果采用客户端回调方式，延迟问题可能会有好转。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;buffer.memory&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来设置生产者内存缓冲区的大小，生产者会用它来缓冲要发送到服务器的消息，以此来提供消息传递的效率。默认值:&lt;code&gt;33554432&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足，此时&lt;code&gt;send()&lt;/code&gt;方法就会阻塞或者直接异常，取
决于&lt;code&gt;block.on.buffer.null&lt;/code&gt;参数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;retries&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;生产者从服务器收到的错误有可能是临时性的错误，比如暂时找不到&lt;code&gt;leader&lt;/code&gt;或者当前partition正在迁移无法找到相关的partition，&amp;gt;这种情况下，该参数可以决定生产者的行为，如果重试次数超过之后，生产者就会放弃重试，并返回错误。&lt;/p&gt;

&lt;p&gt;默认情况下，生产者在每次重试之间等待100ms，这个等待参数可以通过&lt;code&gt;retry.backoff.ms&lt;/code&gt;来修改&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;batch.size&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定每次提交的batch大小，默认值:&lt;code&gt;16384&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当有多个消息需要被发送&lt;code&gt;同一个分区&lt;/code&gt;(如何决定是发送到同一个分区?)时，生产者会把他们发送到同一个批次里.&lt;/p&gt;

&lt;p&gt;该参数用来指定一个批次提交的大小，当达到该batch的大小，所有的消息会被统一发送至broker&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;client.id&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用来指定客户端的id，不过可以不用指定，注册后为每个客户端生成64为的id&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.in.flight.requests.per.connection&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此参数指定了生产者在收到服务器响应之前可以发送多少消息，它的值越高，就会占用越多的内存，不过也会提高吞吐量&lt;/p&gt;

&lt;p&gt;把它设为1 可以保证消息是&lt;code&gt;按照发送的顺序&lt;/code&gt;写入服务器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;timeout相关参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;request.timeout.ms&lt;/code&gt;: 生产者在发送数据时等待服务器返回的响应时间，默认值:&lt;code&gt;30000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;metadata.fetch.timeout.ms&lt;/code&gt;: 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout.ms&lt;/code&gt;: 指定了 broker 等待同步副本返回消息确认的时间，与 asks 的配置相匹配&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;max.block.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此参数指定了在调用 send() 方法或使用 partitionFor() 方法获取元数据时生产者的阻塞时间.&lt;/p&gt;

&lt;p&gt;当生产者的发送缓冲区已捕，或者没有可用的元数据时，这些方法就会阻塞，阻塞时间超过该参数值时，生产者抛出异常&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.request.size&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;该参数用于控制生产者发送的&lt;code&gt;请求大小&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息的总大小&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;receive.buffer.bytes和send.buffer.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了保证可靠的消息传输，这两个参数分别指定了 TCP Socket &lt;code&gt;接收和发送数据包的缓冲区&lt;/code&gt;的大小，默认为-1，表示使用操作系统的&amp;gt;默认值。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 如果生产者或消费者与broker所处的数据中心不同，该值可以适当调大&lt;/p&gt;

&lt;h4 id=&#34;4-4-consumer核心参数&#34;&gt;4.4 Consumer核心参数&lt;/h4&gt;

&lt;p&gt;在消费者组中的消费者重平衡期间，消费者无法读取消息，造成整个消费者组在重平衡的期间都不可用&lt;/p&gt;

&lt;p&gt;消费者通过向组织协调者（Kafka Broker）发送心跳来维护自己是消费者组的一员并确认其拥有的分区。&lt;/p&gt;

&lt;p&gt;对于不同步的消费群体来说，其组织协调者可以是不同的。&lt;/p&gt;

&lt;p&gt;只要消费者定期发送心跳，就会认为消费者是存活的并处理其分区中的消息。当消费者检索记录或者提交它所消费的记录时就会发送心&amp;gt;跳。&lt;/p&gt;

&lt;p&gt;如果一段时间，消费者不发送心跳了，会话（Session）就会过期，组织协调者就会认为这个 Consumer 已经死亡，就会触发一次重平衡
。&lt;/p&gt;

&lt;p&gt;如果消费者宕机并且停止发送消息，组织协调者会等待几秒钟，确认它死亡了才会触发重平衡.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在这段时间里，组里的消费者将不处理消息(STW)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_consumer_offset&lt;/code&gt;主题就主要是用来记录相关消费者的偏移量以及消费者分区分配的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;fetch.min.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者从服务器获取记录的最小字节数，默认:&lt;code&gt;1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它&amp;gt;返回给消费者。&lt;/p&gt;

&lt;p&gt;这样可以降低消费者和 broker 的工作负载，因为它们在主题使用频率不是很高的时候就不用来回处理消息。&lt;/p&gt;

&lt;p&gt;如果没有很多可用数据，但消费者的 CPU 使用率很高，那么就需要把该属性的值设得比默认值大。&lt;/p&gt;

&lt;p&gt;如果消费者的数量比较多，把该属性的值调大可以降低 broker 的工作负载。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;fetch.max.wait.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面参数用来控制每次fetch时的最小数据量，但也不能一直等待数据的容量满足要求，因此还有另外一个参数，即&lt;code&gt;fetch.max.wait.ms&lt;/code&gt;，指定多长时间还没满足数据容量就进行fetch数据，默认是&lt;code&gt;500ms&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.partition.fetch.bytes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了服务器从每个分区里返回给消费者的&lt;code&gt;最大字节数&lt;/code&gt;，默认值为&lt;code&gt;1MB&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;即&lt;code&gt;KafkaConsumer.poll()&lt;/code&gt;方法从每个分区返回的记录最多不超过该值指定的大小。&lt;/p&gt;

&lt;p&gt;加入一个20分区的主题，拥有5个消费者，那么每个消费者必须至少&lt;code&gt;4MB&lt;/code&gt;的内存来接收消息(每个消费者消费4个分区，每个分区返回消&amp;gt;费者的最大字节数1MB)。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 该参数的设置要适当的设置大一些，防止单个消费者异常后，整体内存受限。&lt;/p&gt;

&lt;p&gt;至少，该参数的值要大于&lt;code&gt;max.message.size&lt;/code&gt;(broker接收消息的最大字节数)，否则消费者无法读取这些消息，导致消费者一直重试并&amp;gt;挂起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;session.timeout.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s，在这个时间内没有发送心跳就会直接认为消费者死亡，此时
协调器就会进行触发consumer rebalance.&lt;/p&gt;

&lt;p&gt;此参数与&lt;code&gt;heartbeat.interval.ms&lt;/code&gt;(poll() 方法向群组协调器发送心跳的频率)强相关。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto.offset.reset&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下的该如何处理，默认值为&lt;code&gt;latest&lt;/code&gt;，意思是在偏移量无效的情况下&amp;gt;，默认从最新的记录下开始读取数据。可选值为&lt;code&gt;earliest&lt;/code&gt;，表示从最开始位置进行读取.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;enable.auto.commit&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;指定了消费者是否自动提交偏移量，默认值是 true，对应&lt;code&gt;auto.commit.interval.ms&lt;/code&gt;参数来保证每次提交偏移量的频率&lt;/p&gt;

&lt;p&gt;为了避免数据重复和丢失，消费者可以设置为false，由自己决定自己的消费位置(客户端保证数据消费的一致性)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;partition.assignment.strategy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;PartitionAssignor&lt;/code&gt;(分区分配器)会根据给定的消费者和主题，决定哪些分区应该被分配到哪个消费者，默认有两个策略:&lt;code&gt;Range&lt;/code&gt;和&lt;code&gt;RoundRobin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;max.poll.records&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用于控制&lt;code&gt;单次调用call()&lt;/code&gt; 方法能够返回的记录数量，可以帮你控制在轮询中需要处理的数据量.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;heartbeat.interval.ms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在消费组中，消费者心跳到消费者协调器的频率，默认值:&lt;code&gt;3000ms&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;三-集群管理&#34;&gt;三、集群管理&lt;/h2&gt;

&lt;p&gt;任何一款优秀的开源软件，都会提供比较丰富的集群管理工具来帮助使用者(管理员和实际使用者)来对集群进行操作，记下来从三个角度来大概讲解集群管理相关的操作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;官方提供的操作脚本&lt;/li&gt;
&lt;li&gt;kafka-manager&lt;/li&gt;
&lt;li&gt;kafkacat&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-官方工具&#34;&gt;1. 官方工具&lt;/h3&gt;

&lt;p&gt;在kafka的发行包中，默认包含了如下管理工具脚本:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ ls
connect-distributed.sh        kafka-delete-records.sh              kafka-server-stop.sh
connect-mirror-maker.sh       kafka-dump-log.sh                    kafka-streams-application-reset.sh
connect-standalone.sh         kafka-leader-election.sh             kafka-topics.sh
kafka-acls.sh                 kafka-log-dirs.sh                    kafka-verifiable-consumer.sh
kafka-broker-api-versions.sh  kafka-mirror-maker.sh                kafka-verifiable-producer.sh
kafka-configs.sh              kafka-preferred-replica-election.sh  trogdor.sh
kafka-console-consumer.sh     kafka-producer-perf-test.sh          windows
kafka-console-producer.sh     kafka-reassign-partitions.sh         zookeeper-security-migration.sh
kafka-consumer-groups.sh      kafka-replica-verification.sh        zookeeper-server-start.sh
kafka-consumer-perf-test.sh   kafka-run-class.sh                   zookeeper-server-stop.sh
kafka-delegation-tokens.sh    kafka-server-start.sh                zookeeper-shell.sh&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;这里主要介绍几个常用的工具脚本:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运维管理类&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-topics.sh&lt;/code&gt;: 用来创建，删除，查看，改变一个topic参数的工具&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-reassign-partitions.sh&lt;/code&gt;: 用来对partition进行重新分配(管理员会较多使用)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-log-dirs.sh&lt;/code&gt;: 用来查看指定broker下日志目录的使用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-leader-election.sh&lt;/code&gt;: 用于一组Topic分区的leader重新分配，可以支持优先副本和非同步副本(不在ISR中)，老版本中的kafka-preferred-replica-election.sh脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-replica-verification.sh&lt;/code&gt;: 该工具可以用来检查topic的一组副本的数据是否一致&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-broker-api-versions.sh&lt;/code&gt;: 用来查看指定broker当前支持的各个接口的版本(kafka高版本已经保证了向下兼容)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-configs.sh&lt;/code&gt;: 用来操作和查看topic, client, user or broker的实体配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;kafka操作类&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-console-consumer.sh&lt;/code&gt;: 通过终端来启动消费者&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-console-producer.sh&lt;/code&gt;: 通过终端来启动生产者&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-consumer-groups.sh&lt;/code&gt;: 用来查看，删除或者重置消费者组offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-consumer-perf-test.sh&lt;/code&gt;: 用来进行消费者压力测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-producer-perf-test.sh&lt;/code&gt;: 用来进行生产者压力测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-delete-records.sh&lt;/code&gt;: 删除指定分区的记录，直到指定的offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-mirror-maker.sh&lt;/code&gt;: 用于多集群之间同步topic数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-server-start.sh&lt;/code&gt;: broker启动脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-server-stop.sh&lt;/code&gt;: broker关闭脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kafka-streams-application-reset.sh&lt;/code&gt;: 流式应用工具&lt;/li&gt;
&lt;li&gt;&lt;code&gt;zookeeper-shell.sh&lt;/code&gt;: kafka工具中也默认提供了zookeeper管理工具(不太好用)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-1-kafka-topics-sh&#34;&gt;1.1 kafka-topics.sh&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;topic创建&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--create&lt;/code&gt;: 创建topic&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--topic&lt;/code&gt;: 指定topic名称&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--partitions&lt;/code&gt;: 指定分区数量&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--replication-factor&lt;/code&gt;: 指定副本数量(仅在创建时可用)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--config&lt;/code&gt;: 指定topic级别的参数(动态参数，可修改)&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--replica-assignment&lt;/code&gt;: 手动指定partition到broker的分配&lt;part1_replica1:part1_replica2,part2_replica1:part2_replica2&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建topic
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --create --topic bgbiao.top
Created topic bgbiao.top.

# 查看默认创建topic的参数详情(由broker配置决定)
# 默认3个分区，1个副本
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 1	Leader: 2	Replicas: 2	Isr: 2
	Topic: bgbiao.top	Partition: 2	Leader: 3	Replicas: 3	Isr: 3

# 指定参数创建topic
# 指定分区为5，副本为3，topic数据保留2分钟
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --create --topic bgbiao.top-1 --partitions 5 --replication-factor 3 --config retention.ms=120000

# 分区，副本和指定参数都改变了
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top-1
Topic: bgbiao.top-1	PartitionCount: 5	ReplicationFactor: 3	Configs: min.insync.replicas=1,segment.bytes=1073741824,retention.ms=120000
	Topic: bgbiao.top-1	Partition: 0	Leader: 2	Replicas: 2,3,1	Isr: 2,3,1
	Topic: bgbiao.top-1	Partition: 1	Leader: 3	Replicas: 3,1,2	Isr: 3,1,2
	Topic: bgbiao.top-1	Partition: 2	Leader: 1	Replicas: 1,2,3	Isr: 1,2,3
	Topic: bgbiao.top-1	Partition: 3	Leader: 2	Replicas: 2,1,3	Isr: 2,1,3
	Topic: bgbiao.top-1	Partition: 4	Leader: 3	Replicas: 3,2,1	Isr: 3,2,1&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;topic更改&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; topic的分区(partitions)可以根据需要进行调整(只能调整大，不能调整小)，而且在调整分区的过程中，对于一个有&lt;code&gt;key&lt;/code&gt;的主题来说，一条消息的分区逻辑和顺序性可能会受到影响。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 副本数一旦topic创建之后，就不能再修改了，除非进行重分配(副本数不能超过broker数量哦)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--alter&lt;/code&gt;: 修改分区数量，replica分配，或者topic的动态配置项(结合&amp;ndash;topic参数)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--partitions&lt;/code&gt;: 修改指定Topic的分区数量&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--replica-assignment&lt;/code&gt;: 手动指定part到broker的分配&lt;a href=&#34;p1-r1:p1-r2,p2-r1:p2-r2&#34;&gt;p1-r1:p1-r2,p2-r1:p2-r2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--config&lt;/code&gt;: 修改topic的指定参数(动态参数调整:key=value)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--delete-config&lt;/code&gt;: 删除topipc的指定参数()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 通常情况下&lt;code&gt;--replica-assignment&lt;/code&gt;参数需要和&lt;code&gt;--partitions&lt;/code&gt;一同使用才可以指定分区下的副本到broker节点上的分配，相当于手动扩容迁移&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 上面我们刚开始创建的bgbiao.top的topic是1个分区1个副本，这里采用alter参数进行修改基本配置
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --alter  --topic bgbiao.top --replica-assignment 1,2,3,1,2 --partitions 5

# 因为bgbiao.top 这个topic再创建时只有一个replication，因此--replica-assignment参数只能指定副本分配在那个broker上，无法指定多个副本的关系
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 5	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 1	Leader: 2	Replicas: 2	Isr: 2
	Topic: bgbiao.top	Partition: 2	Leader: 3	Replicas: 3	Isr: 3
	Topic: bgbiao.top	Partition: 3	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 4	Leader: 2	Replicas: 2	Isr: 2

 &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;topic相关信息查看&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--list&lt;/code&gt;: 列出topic&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看topic详情信息&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--topic&lt;/code&gt;: 指定topic查看详情信息&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--exclude-internal&lt;/code&gt;: 排除内部topic(consumer_offset_topic)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--unavailable-partitions&lt;/code&gt;: 仅显示leader不可用的分区(在集群异常时快速排查受影响的分区)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--under-min-isr-partitions&lt;/code&gt;: 仅显示isr小于配置的min-isr-partitions的分区&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--under-replicated-partitions&lt;/code&gt;: 仅显示不同步的分区&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在低版本的kafka中使用&amp;ndash;zookeeper来链接集群，高版本中基本都通过&amp;ndash;bootstrap-server指定broker来连接集群&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 列出集群topic
# --list参数列出可用的topic
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --list
__consumer_offsets
....
....

# 也可以使用--topic指定topic
# 如果指定topic不存在，将返回空
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --list --topic __consumer_offsets
__consumer_offsets

# 列出topic详情信息
# --describe参数(同时可以使用--topic指定topic查看)
# --exclude-internal参数可以排除内部的topic(__consumer_offsets)
# --unavailable-partitions参数可以列出leader不可用的topic，在集群故障时快速查看受影响的topic
# 
# 可以查看某个topic的分区和副本分布，以及topic级别的相关配置
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic __consumer_offsets
Topic: __consumer_offsets	PartitionCount: 50	ReplicationFactor: 1	Configs: compression.type=producer,min.insync.replicas=1,cleanup.policy=compact,segment.bytes=104857600
	Topic: __consumer_offsets	Partition: 0	Leader: 3	Replicas: 3	Isr: 3
	Topic: __consumer_offsets	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
....
....

# 查看集群leader不可用的分区
# 可以发现leader都为-1，是因为副本和isr的id是4，而broker4其实已经光荣阵亡了
$ /opt/app/kafka_2.11-1.0.1/bin/kafka-topics.sh --zookeeper 172.16.217.38:2181/log-kafka --describe --unavailable-partitions
...
	Topic: realtime_kafka.post_alg_real	Partition: 2	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 11	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 20	Leader: -1	Replicas: 4	Isr: 4
	Topic: realtime_kafka.post_alg_real	Partition: 29	Leader: -1	Replicas: 4	Isr: 4
	Topic: rm-bp1d3u2p9v3l4da7c632	Partition: 1	Leader: -1	Replicas: 4	Isr: 4
	Topic: rm-bp1udb05091x11q5x	Partition: 1	Leader: -1	Replicas: 4	Isr: 4

# 查看副本不同步的分区详情
# 可以发现副本中有不同步的情况，是因为有副本所在的节点已经挂了，通常有一部分是因为资源或者网络原因未同步，还有就是如上述broker阵亡的情况
# 如果说--unavailable-partitions可以直接查看到受影响的topic，那么--under-replicated-partitions就可以查看可用性受影响的topic，因为当副本为2时，此时broker4阵亡的前提下，topic下的分区是无法保证高可用的
$ /opt/app/kafka_2.11-1.0.1/bin/kafka-topics.sh --zookeeper 172.16.217.38:2181/log-kafka --describe --under-replicated-partitions
...
...
	Topic: androidregister	Partition: 1	Leader: 2	Replicas: 4,2	Isr: 2
	Topic: eventjsonlog	Partition: 11	Leader: 2	Replicas: 4,2	Isr: 2
	Topic: eventjsonlog	Partition: 27	Leader: 2	Replicas: 2,4	Isr: 2
	Topic: eventjsonlog	Partition: 38	Leader: 13	Replicas: 13,4	Isr: 13
	Topic: eventjsonlog	Partition: 44	Leader: 10	Replicas: 4,10	Isr: 10
	Topic: eventjsonlog	Partition: 52	Leader: 12	Replicas: 12,4	Isr: 12
	Topic: eventjsonlog	Partition: 59	Leader: 11	Replicas: 4,11	Isr: 11
	Topic: eventlog	Partition: 8	Leader: 16	Replicas: 16,4	Isr: 16
	Topic: eventlog	Partition: 23	Leader: 3	Replicas: 4,3	Isr: 3
	Topic: eventlog	Partition: 38	Leader: 13	Replicas: 13,4	Isr: 13
	Topic: eventlog	Partition: 44	Leader: 10	Replicas: 4,10	Isr: 10
	Topic: eventlog	Partition: 52	Leader: 12	Replicas: 12,4	Isr: 12
	Topic: eventlog	Partition: 59	Leader: 11	Replicas: 4,11	Isr: 11
	Topic: pusheventlog	Partition: 9	Leader: 1	Replicas: 1,4	Isr: 1
	Topic: pusheventlog	Partition: 12	Leader: 7	Replicas: 4,7	Isr: 7&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;删除&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--delete&lt;/code&gt;: 指定topic删除&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在删除Topic时会受&lt;code&gt;delete.topic.enable&lt;/code&gt;参数的影响，如果为true，则topic直接删除，如果为false，删除仅是标记删除，即在topic的config中增加一个删除标记&lt;code&gt;MarkedForDeletion:true&lt;/code&gt;，待broker重启后完全删除(也可通过zk中的数据删除)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 如果delete.topic.enable=true，则直接删除掉
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --delete   --topic bgbiao.top&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;topic真正的元数据结构: &lt;code&gt;/brokers/topics/topic-name&lt;/code&gt;,删除这个即删除&lt;/li&gt;
&lt;li&gt;标记删除的topic元数据: &lt;code&gt;/admin/delete_topics/topic-name&lt;/code&gt;,删除这个才算数据清理完成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-2-kafka-reassign-partitions-sh&#34;&gt;1.2 kafka-reassign-partitions.sh&lt;/h4&gt;

&lt;p&gt;该脚本用于在副本之间移动topic的分区，也就是对副本进行重新分配，也是SRE在日常操作中会比较常用的脚本，需要注意的是，在做迁移时需要注意到当前集群的整体情况，毕竟在移动副本时，需要设计到新副本的数据同步，也会占用一定资源。&lt;/p&gt;

&lt;p&gt;通常，将服务器添加到Kafka集群很容易，只需为它们分配一个惟一的brokerid，并在新服务器上启动Kafka。然而，这些新服务器不会自动分配任何数据分区，因此，除非将分区移动到它们，否则在创建新主题之前，它们不会做任何工作。因此，向集群中添加机器时，您会希望将一些现有数据迁移到这些机器上。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--broker-list&lt;/code&gt;: 指定分区需要重新分配到的broker节点，如果&lt;code&gt;--topics-to-move-json-file&lt;/code&gt;参数被指定用来生成重分配配置时，必须制定该参数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--topics-to-move-json-file&lt;/code&gt;: 生成一个移动指定topic的分区到指定broker(&lt;code&gt;--broker-list&lt;/code&gt;)的配置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--generate&lt;/code&gt;: 生成候选分区分配的配置，该参数仅会生成候选的分配方案，不会进行执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reassignment-json-file&lt;/code&gt;: 分区手动分配的配置参数，该参数可由&lt;code&gt;generate&lt;/code&gt;参数生成，通常一般会进行微调&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--replica-alter-log-dirs-throttle&lt;/code&gt;: 在相同的broker上日志目录之间的副本移动将被限流为该值bytes/sec，限流应该至少设置为1 KB/s，默认是-1表示不限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--throttle&lt;/code&gt;: broker之间的分区移动可以使用该值进行限流(bytes/sec)，同上&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 通过指定&lt;code&gt;--reassignment-json-file&lt;/code&gt;参数来执行重新分配&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--verify&lt;/code&gt;: 如果一个重分配完成了，可以指定&lt;code&gt;--reassignment-json-file&lt;/code&gt;参数来查看重分配的进度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;topics-to-move-json-file文件示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;{&amp;#34;topics&amp;#34;:
[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;},{&amp;#34;topic&amp;#34;: &amp;#34;foo1&amp;#34;}],
&amp;#34;version&amp;#34;:1
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;reassignment-json-file文件示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 注意:log_dirs是可选参数，需要指定绝对路径，也可以指定为any，当指定后需要和replicas的长度相等
  {&amp;#34;partitions&amp;#34;:
  	[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;,
  	  &amp;#34;partition&amp;#34;: 1,
  	  &amp;#34;replicas&amp;#34;: [1,2,3],
  	  &amp;#34;log_dirs&amp;#34;: [&amp;#34;dir1&amp;#34;,&amp;#34;dir2&amp;#34;,&amp;#34;dir3&amp;#34;]
    }],
  &amp;#34;version&amp;#34;:1
  }&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;分区重分配示例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看当前topic详情
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 1	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 3	Replicas: 3	Isr: 3
	Topic: bgbiao.top	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 2	Leader: 2	Replicas: 2	Isr: 2

# 1.编辑move.json配置
$ cat move.json
{&amp;#34;topics&amp;#34;: [{&amp;#34;topic&amp;#34;: &amp;#34;bgbiao.top&amp;#34;}],
&amp;#34;version&amp;#34;:1
}

# 2.生成迁移配置
# 指定正确的zookeeper地址来获取分区的分布状态以及待迁移的状态
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --topics-to-move-json-file move.json --broker-list &amp;#34;1,2,3&amp;#34; --generate
Current partition replica assignment
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

Proposed partition reassignment configuration
{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

# 编辑迁移配置
# 当前分区状态为:bgbiao.top-2的副本在broker2,bgbiao.top-1的副本在broker1,bgbiao.top-0的副本在broker3
# 迁移后的分区状态:bgbiao.top-2的副本在broker3,bgbiao.top-1的副本在broker2,bgbiao.top-0的副本在broker1
# 然后将期望的迁移配置保存下来做相关修改即可.
# 我们是想给某个分区增加副本，因此可以修改成如下配置
$ cat assignment.json
{
    &amp;#34;partitions&amp;#34;: [
        {
            &amp;#34;partition&amp;#34;: 0,
            &amp;#34;replicas&amp;#34;: [
                3,1,2
            ],
            &amp;#34;topic&amp;#34;: &amp;#34;bgbiao.top&amp;#34;
        }
    ],
    &amp;#34;version&amp;#34;: 1
}

# 3.根据上述的迁移配置执行迁移
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --reassignment-json-file ./assignment.json --execute
Current partition replica assignment

{&amp;#34;version&amp;#34;:1,&amp;#34;partitions&amp;#34;:[{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:2,&amp;#34;replicas&amp;#34;:[2],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:1,&amp;#34;replicas&amp;#34;:[1],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]},{&amp;#34;topic&amp;#34;:&amp;#34;bgbiao.top&amp;#34;,&amp;#34;partition&amp;#34;:0,&amp;#34;replicas&amp;#34;:[3],&amp;#34;log_dirs&amp;#34;:[&amp;#34;any&amp;#34;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.

# 4.查看上述迁移的进度(将--execute参数改为--verify参数)
$ sh /opt/app/kafka/bin/kafka-reassign-partitions.sh --zookeeper 172.29.203.62:2181 --reassignment-json-file ./assignment.json --verify
Status of partition reassignment:
Reassignment of partition bgbiao.top-0 completed successfully

# 再次查看topix详情
# 如期望，partition-1增加了两个副本,该副本的整体可用性提高了3倍
$ sh /opt/app/kafka/bin/kafka-topics.sh --bootstrap-server 172.29.203.62:9092 --describe --topic bgbiao.top
Topic: bgbiao.top	PartitionCount: 3	ReplicationFactor: 3	Configs: min.insync.replicas=1,segment.bytes=1073741824
	Topic: bgbiao.top	Partition: 0	Leader: 3	Replicas: 3,1,2	Isr: 3,1,2
	Topic: bgbiao.top	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bgbiao.top	Partition: 2	Leader: 2	Replicas: 2	Isr: 2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 该工具可以让集群部分节点故障后，及时将新部分的partition进行调整，以恢复partition的高可用性。同时能够让集群在扩展后，快速将已有topic的数据均衡的分布在新节点上，以实现整体负载的均衡。&lt;/p&gt;

&lt;h4 id=&#34;1-3-kafka-log-dirs-sh&#34;&gt;1.3 kafka-log-dirs.sh&lt;/h4&gt;

&lt;p&gt;该脚本参数用于查看kafka各个broker节点以及topic的磁盘使用率情况&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看topic和broker的磁盘使用情况&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--broker-list&lt;/code&gt;: 指定查看的broker列表&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--topic-list&lt;/code&gt;: 指定需要查看的topic列表&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 当指定topic后会从全部的broker中进行查找
$ sh /opt/app/kafka/bin/kafka-log-dirs.sh --bootstrap-server 172.29.203.62:9092 --describe --topic-list myapp-yum-log,myapp
Querying brokers for log directories information
Received log directory information from brokers 1,2,3
{&amp;#34;version&amp;#34;:1,&amp;#34;brokers&amp;#34;:[{&amp;#34;broker&amp;#34;:1,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-2&amp;#34;,&amp;#34;size&amp;#34;:13291235,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-0&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]},{&amp;#34;broker&amp;#34;:2,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-1&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-0&amp;#34;,&amp;#34;size&amp;#34;:13258726,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]},{&amp;#34;broker&amp;#34;:3,&amp;#34;logDirs&amp;#34;:[{&amp;#34;logDir&amp;#34;:&amp;#34;/opt/data/kafka/kafka-logs&amp;#34;,&amp;#34;error&amp;#34;:null,&amp;#34;partitions&amp;#34;:[{&amp;#34;partition&amp;#34;:&amp;#34;myapp-2&amp;#34;,&amp;#34;size&amp;#34;:0,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false},{&amp;#34;partition&amp;#34;:&amp;#34;myapp-yum-log-1&amp;#34;,&amp;#34;size&amp;#34;:13264869,&amp;#34;offsetLag&amp;#34;:0,&amp;#34;isFuture&amp;#34;:false}]}]}]}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结果是json串，可以看到&lt;code&gt;myapp-yum-log-2&lt;/code&gt;在broker-1上占用了&lt;code&gt;13291235&lt;/code&gt;字节，也就是&lt;code&gt;12M&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;1-4-kafka-leader-election-sh&#34;&gt;1.4 kafka-leader-election.sh&lt;/h4&gt;

&lt;p&gt;用于一组 Topic 分区的 leader 重新分配，可以支持优先副本和非同步副本。一般用于指定topic的分区存在非预选副本或非同步副本的情况，对整个leader进行适当调整&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--admin.config&lt;/code&gt;: 传给admin客户端的配置文件&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--all-topic-partitions&lt;/code&gt;: 基于选举类型&lt;code&gt;--election-type&lt;/code&gt;来对符合条件的topic进行选举&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--bootstrap-server&lt;/code&gt;: 指定broker地址&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--election-type&lt;/code&gt;: 指定选举类型&lt;code&gt;[preferred,unclean]&lt;/code&gt;，对优先副本进行选举或非同步副本进行选举&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--partition&lt;/code&gt;: 指定需要选举的指定topic分区的id(和&amp;ndash;topic一起使用)&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;--path-to-json-file&lt;/code&gt;: 使用json配置文件来保存重分配信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 比如我们发现topic的partition-1当前的leader不是优先副本(broker相对倾斜),可以使用如下配置进行leader重新选举
$ sh kafka-leader-election.sh --bootstrap-server 172.29.203.62:9092 --topic test-bgbiao-1 --partition 0 --election-type preferred
Valid replica already elected for partitions


{&amp;#34;partitions&amp;#34;:
[{&amp;#34;topic&amp;#34;: &amp;#34;foo&amp;#34;, &amp;#34;partition&amp;#34;: 1},
{&amp;#34;topic&amp;#34;: &amp;#34;foobar&amp;#34;, &amp;#34;partition&amp;#34;: 2}]
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-5-kafka-configs-sh&#34;&gt;1.5 kafka-configs.sh&lt;/h4&gt;

&lt;p&gt;用来查看和修改kafka相关的配置信息，包含集群的动态配置，topic级别的动态配置等等&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--all&lt;/code&gt;: 列出给定实体的全部配置文件(默认已经生效的全部参数，如果没有all仅对动态参数生效)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--entity-type&lt;/code&gt;: 实体类型[topics/clients/users/brokers/broker-loggers]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--entity-name&lt;/code&gt;: 实体名称[topic名称/client-id/user-name/broker-id]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 列出给定实体的配置文件&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--force&lt;/code&gt;: 强制生效&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--topic&lt;/code&gt;: 指定topic名称&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--alter&lt;/code&gt;: 修改指定实体的配置文件 &lt;code&gt;注意:当使用delete-config和add-config时必须使用--alter&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete-config&lt;/code&gt;: 删除指定的配置&amp;rdquo;k1,k2&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add-config&lt;/code&gt;: 给指定的实体增加配置(k=v,k2=[v1,v2,v3],k3=v3)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;topic级别的动态参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cleanup.policy&lt;/code&gt;: 清理策略&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression.type&lt;/code&gt;: 压缩类型(通常建议在produce端控制)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;delete.retention.ms&lt;/code&gt;: 压缩日志的保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flush.messages&lt;/code&gt;: 持久化message限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flush.ms&lt;/code&gt;: 持久化频率&lt;/li&gt;
&lt;li&gt;&lt;code&gt;follower.replication.throttled.replicas&lt;/code&gt;: follower副本限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leader.replication.throttled.replicas&lt;/code&gt;: leader副本限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.message.bytes&lt;/code&gt;: 最大的batch的message大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.downconversion.enable&lt;/code&gt;: message向下兼容&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.format.version&lt;/code&gt;: message格式版本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;: 最小的ISR&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retention.ms&lt;/code&gt;: 日志保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retention.bytes&lt;/code&gt;: 日志保留大小(通常按照时间限制)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segment.bytes&lt;/code&gt;: segment的大小限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segment.ms&lt;/code&gt;: segment的切割时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;unclean.leader.election.enable&lt;/code&gt;: 是否允许非同步副本选主(针对可用性设置的一个参数)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;broker级别的动态参数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;broker级别的动态参数比较多，这里只列举常用的几个&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;log.retention.ms&lt;/code&gt;: 日志保留时间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.connections&lt;/code&gt;: 最大连接数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.connections.per.ip&lt;/code&gt;: 每个ip的最大连接数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message.max.bytes&lt;/code&gt;: batch的message的最大限制&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min.insync.replicas&lt;/code&gt;: 最小的ISR&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.io.threads&lt;/code&gt;: IO线程数(网络线程数的两倍)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.network.threads&lt;/code&gt;: 网络线程数(cpu的2/3较好)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.recovery.threads.per.data.dir&lt;/code&gt;: 每个数据目录的恢复线程&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num.replica.fetchers&lt;/code&gt;: 副本的fetchers数量(默认为1,可适当调大)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;user级别的参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SCRAM-SHA-256&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SCRAM-SHA-512&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consumer_byte_rate&lt;/code&gt;: 针对消费者user进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;producer_byte_rate&lt;/code&gt;: 针对生产者进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;request_percentage&lt;/code&gt;: 请求百分比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;clients级别参数&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;consumer_byte_rate&lt;/code&gt;: 针对消费者user进行限流&lt;/li&gt;
&lt;li&gt;&lt;code&gt;producer_byte_rate&lt;/code&gt;: 针对生产者进行限流&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;request_percentage&lt;/code&gt;: 请求百分比&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 修改topic的数据保留时间
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --add-config retention.ms=10000000 --alter

# 查看topic的动态参数配置
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --describe
Dynamic configs for topic push-test are:
retention.ms=10000000 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:retention.ms=10000000}

# 删除topic动态参数
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --alter --delete-config retention.ms
Completed updating config for topic push-test.

# 查看broker全部的参数(--all会获取全部的参数)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092 --all --broker-defaults  --describe
Default configs for brokers in the cluster are:

# 也可以使用如下参数查看broker的全部参数(动态的和默认的参数)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --all --entity-type brokers --entity-name  1  --describe
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --all --broker 1  --describe

# broker的动态参数(去除了--all之后，会发现列出的是动态的配置，默认broker是没有动态参数调整的)
$ sh kafka-configs.sh --bootstrap-server 172.29.203.62:9092  --broker 1  --describe
Dynamic configs for broker 1 are:

# user和client也是类似的&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-6-kafka-broker-api-versions-sh&#34;&gt;1.6 kafka-broker-api-versions.sh&lt;/h4&gt;

&lt;p&gt;查看kafka对外的各个api版本.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看当前kafka版本
$ sh kafka-broker-api-versions.sh --bootstrap-server 172.29.203.62:9092 --version
2.5.0 (Commit:66563e712b0b9f84)

# 查看集群所有节点的api版本
$ sh kafka-broker-api-versions.sh --bootstrap-server 172.29.203.62:9092
172.29.203.106:9092 (id: 2 rack: null) -&amp;gt; (
	Produce(0): 0 to 8 [usable: 8],
	Fetch(1): 0 to 11 [usable: 11],
	ListOffsets(2): 0 to 5 [usable: 5],
	Metadata(3): 0 to 9 [usable: 9],
	LeaderAndIsr(4): 0 to 4 [usable: 4],
	StopReplica(5): 0 to 2 [usable: 2],
	UpdateMetadata(6): 0 to 6 [usable: 6],
	ControlledShutdown(7): 0 to 3 [usable: 3],
	OffsetCommit(8): 0 to 8 [usable: 8],
	OffsetFetch(9): 0 to 7 [usable: 7],
	FindCoordinator(10): 0 to 3 [usable: 3],
	JoinGroup(11): 0 to 7 [usable: 7],
	Heartbeat(12): 0 to 4 [usable: 4],
	LeaveGroup(13): 0 to 4 [usable: 4],
	SyncGroup(14): 0 to 5 [usable: 5],
	DescribeGroups(15): 0 to 5 [usable: 5],
	ListGroups(16): 0 to 3 [usable: 3],
	SaslHandshake(17): 0 to 1 [usable: 1],
	ApiVersions(18): 0 to 3 [usable: 3],
	CreateTopics(19): 0 to 5 [usable: 5],
	DeleteTopics(20): 0 to 4 [usable: 4],
	DeleteRecords(21): 0 to 1 [usable: 1],
	InitProducerId(22): 0 to 3 [usable: 3],
	OffsetForLeaderEpoch(23): 0 to 3 [usable: 3],
	AddPartitionsToTxn(24): 0 to 1 [usable: 1],
	AddOffsetsToTxn(25): 0 to 1 [usable: 1],
	EndTxn(26): 0 to 1 [usable: 1],
	WriteTxnMarkers(27): 0 [usable: 0],
	TxnOffsetCommit(28): 0 to 3 [usable: 3],
	DescribeAcls(29): 0 to 2 [usable: 2],
	CreateAcls(30): 0 to 2 [usable: 2],
	DeleteAcls(31): 0 to 2 [usable: 2],
	DescribeConfigs(32): 0 to 2 [usable: 2],
	AlterConfigs(33): 0 to 1 [usable: 1],
	AlterReplicaLogDirs(34): 0 to 1 [usable: 1],
	DescribeLogDirs(35): 0 to 1 [usable: 1],
	SaslAuthenticate(36): 0 to 2 [usable: 2],
	CreatePartitions(37): 0 to 2 [usable: 2],
	CreateDelegationToken(38): 0 to 2 [usable: 2],
	RenewDelegationToken(39): 0 to 2 [usable: 2],
	ExpireDelegationToken(40): 0 to 2 [usable: 2],
	DescribeDelegationToken(41): 0 to 2 [usable: 2],
	DeleteGroups(42): 0 to 2 [usable: 2],
	ElectLeaders(43): 0 to 2 [usable: 2],
	IncrementalAlterConfigs(44): 0 to 1 [usable: 1],
	AlterPartitionReassignments(45): 0 [usable: 0],
	ListPartitionReassignments(46): 0 [usable: 0],
	OffsetDelete(47): 0 [usable: 0]
)&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;1-7-生产者和消费者工具&#34;&gt;1.7 生产者和消费者工具&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kafka-console-consumer.sh&lt;/code&gt;: 终端消费者工具&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;kafka-console-producer.sh&lt;/code&gt;: 终端生产者工具&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 指定topic从终端写入数据
$ sh /opt/app/kafka/bin/kafka-console-producer.sh --bootstrap-server 172.29.203.62:9092 --topic test-push
&amp;gt;hello xxb
&amp;gt;BGBiao
&amp;gt;My website is https://bgbiao.top.
&amp;gt;And
&amp;gt;公众号: BGBiao


# 指定消费者组对topic进行消费
# --from-beginning表示从头开始消费
# 因为开始生产者刚开始生产并生产topic，导致topic无leader会有警告信息
# 可以看到client-id就是consumer-test-bgbiao-1,即consumer的前缀加消费组加数字后缀
$ sh kafka-console-consumer.sh --bootstrap-server 172.29.203.62:9092 --topic push-test --group test-bgbiao
[2020-05-31 19:52:13,472] WARN [Consumer clientId=consumer-test-bgbiao-1, groupId=test-bgbiao] Error while fetching metadata with correlation id 2 : {test-push=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
hello xxb
BGBiao
My website is https://bgbiao.top.

公众号: BGBiao&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;1-8-kafka-consumer-groups-sh&#34;&gt;1.8 kafka-consumer-groups.sh&lt;/h4&gt;

&lt;p&gt;消费组管理工具，可以列出所有的消费组，查看消费组详情，删除消费组信息以及重置消费组的offset&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--all-groups&lt;/code&gt;: 应用到所有的消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--all-topics&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete&lt;/code&gt;: 删除topic分区的offset,以及拥有者和消费组信息(&amp;ndash;group g1 &amp;ndash;group g2)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--delete-offsets&lt;/code&gt;: 删除消费组的offset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--describe&lt;/code&gt;: 查看消费组信息以及消费者的offset lag&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--execute&lt;/code&gt;: 指定操作，支持&lt;code&gt;reset-offsets&lt;/code&gt;操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--export&lt;/code&gt;: 导出操作执行到csv，支持&lt;code&gt;reset-offsets&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--from-file&lt;/code&gt;: 指定文件中指定的值重置offset (csv文件)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--group&lt;/code&gt;: 指定消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--list&lt;/code&gt;: 列出所有的消费组&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--members&lt;/code&gt;: 查看消费组中的成员&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--state&lt;/code&gt;: 查看消费组的状态&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--offsets&lt;/code&gt;: 查看消费组并且列出每个消费组所有topic的分区以及消息的offset lag&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--reset-offsets&lt;/code&gt;: 重置消费组的offset (需要指定如下一个参数)&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-datetime&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--by-period&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-earliest&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--to-latest&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--shift-by&lt;/code&gt;:&lt;/li&gt;
&lt;li&gt;- &lt;code&gt;--from-file&lt;/code&gt;:&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;--to-current&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 查看全部的消费者组
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --all-grou  --list
KMOffsetCache-daf27df49ede
test-bgbiao

# 查看消费者详情
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --describe

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
test-bgbiao     test-push       0          1               1               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       1          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       2          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1

# 查看消费组的成员
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --members --describe

GROUP           CONSUMER-ID                                                 HOST            CLIENT-ID              #PARTITIONS
test-bgbiao     consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1 3

# 查看消费组状态
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --state --describe

GROUP                     COORDINATOR (ID)          ASSIGNMENT-STRATEGY  STATE           #MEMBERS
test-bgbiao               172.29.203.62:9092 (1)    range                Stable          1


# 查看消费组的offset信息
$ sh /opt/app/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 172.29.203.62:9092 --group test-bgbiao --offsets --describe
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
test-bgbiao     test-push       0          1               1               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       1          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-push       2          2               2               0               consumer-test-bgbiao-1-a915f28c-3ee0-46ee-a8d8-6c93bddb7686 /172.29.203.62  consumer-test-bgbiao-1
test-bgbiao     test-full-push    2          61392           61430           38              -                                                           -               -
test-bgbiao     test-full-push    1          61056           61088           32              -                                                           -               -
test-bgbiao     test-full-push    0          61299           61337           38              -&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-kafka-manager&#34;&gt;2. kafka-manager&lt;/h3&gt;

&lt;h2 id=&#34;四-集群监控&#34;&gt;四、集群监控&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://kafka.apache.org/24/documentation.html#monitoring&#34;&gt;kafka-doc-monitor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>你还记得你JVM的的初始堆大小吗</title>
      <link>https://bgbiao.top/post/jvm%E7%9A%84%E5%88%9D%E5%A7%8B%E5%A0%86/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/jvm%E7%9A%84%E5%88%9D%E5%A7%8B%E5%A0%86/</guid>
      
        <description>&lt;p&gt;通常对于很多java应用来说，当打成jar包后会下意识的使用&lt;code&gt;java -jar xxx.jar&lt;/code&gt;来运行应用，而不是根据自己业务或实际debug的一些需求来增加一些JVM的辅助参数，这样导致的问题就是，后续出了问题之后不容易进行管理以及相关故障追踪和排查。&lt;/p&gt;

&lt;p&gt;那么问题来了，当你在&lt;code&gt;jar -jar&lt;/code&gt;的时候，默认的JVM堆内存是多少呢?&lt;/p&gt;

&lt;p&gt;其实，JVM在不同架构(配置)的OS下回体现出不同的JVM配置，比如在一个&lt;code&gt;8c16g&lt;/code&gt;的ECS上，默认的Heap值如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ java -XX:+PrintFlagsFinal -version | grep HeapSize
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 264241152                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 4206886912                          {product}
java version &amp;#34;1.8.0_141&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;由上述的输出可知，初始的堆内存为&lt;code&gt;264241152/1024/1024=252M&lt;/code&gt;，而堆内存最大为&lt;code&gt;4206886912/1024/1024/1024=3G&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个时候可能就会有一个问题就是，该ECS上跑多少个&lt;code&gt;java -jar xxx.jar&lt;/code&gt;这类的服务会比较好呢？如果按照每个服务都能使用3G的堆内存来算，该机器上做多跑4个这类的服务是一个比较合理的规划，但是考虑实际的业务使用需求，单纯这样考虑可能会有点唐突了，因此还是建议每个应用在部署时指定一些基础的参数，比如初始堆和最大堆，并且这两个参数一般建议设置成一致，以免在运行过程中堆的扩容造成的损耗。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>分布式对象存储Minio的可观测性方案</title>
      <link>https://bgbiao.top/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8minio%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8minio%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>

&lt;blockquote&gt;
&lt;p&gt;背景: 对于初创企业来说，在很长一段时间一些基础的开源服务基本都是&amp;rdquo;裸奔&amp;rdquo;上线的，除了一些传统的主机级别的监控之外，很难有一些额外的性能指标来描述该服务的整体性能情况。因此，在我们的&lt;a href=&#34;https://bgbiao.top/post/minio%E5%88%86%E5%B8%83%E5%BC%8F%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/&#34;&gt;Minio对象存储服务&lt;/a&gt;上线到最近一直也是裸奔的，虽然暂时也没出现过故障，但是作为一名专业搞笑的SRE来讲，服务的可观测性一定得跟上，不然后期铁锅是妥妥的背定了，这篇文章就主要介绍下&lt;code&gt;Minio&lt;/code&gt;的可观测性方案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;开源组件的可观测性现状&#34;&gt;开源组件的可观测性现状&lt;/h3&gt;

&lt;p&gt;在开头提到了，初创企业的开源服务初期大多都是裸奔上线的，出现这种情况我认为一般分为内因和外因:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;内因是开源的基础中间件性能指标通常很多，不容易抽象，因此这些服务的性能指标数据通常可以通过内部的api或cli来获取，不太容易直接和开源的监控系统进行集成;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;外因是对于初创企业来说，人力有限并且对于众多开源组件的理解不够深入导致前面说的&amp;rdquo;裸奔&amp;rdquo;上线的现象。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不过随着以&lt;code&gt;Kubernetes&lt;/code&gt;，&lt;code&gt;Prometheus&lt;/code&gt;为代表的CloudNative理念不断发展，越来越多的开源中间件也支持了兼容&lt;code&gt;Prometheus Metrics&lt;/code&gt;格式的性能指标，这对于初创企业的技术团队来说可谓是一个福音。&lt;/p&gt;

&lt;p&gt;截止目前，我们所熟知的很多开源软件已经内置了兼容&lt;code&gt;Prometheus Metrics&lt;/code&gt;的API接口，不再需要第三方的&lt;code&gt;exporter&lt;/code&gt;来导出一些性能指标数据。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[内置Metrics接口的开源软件](https://prometheus.io/docs/instrumenting/exporters/#software-exposing-prometheus-metrics)&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.ceph.com/docs/master/mgr/prometheus/&#34;&gt;Ceph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-metrics&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/operations/admin.html#get--stats?format=prometheus&#34;&gt;Envoy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coreos/etcd&#34;&gt;Etcd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/flink&#34;&gt;Flink&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://docs.grafana.org/administration/metrics/&#34;&gt;Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kong/kong-plugin-prometheus&#34;&gt;Kong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/kubernetes&#34;&gt;Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/BuoyantIO/linkerd&#34;&gt;Linkerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/minio/minio&#34;&gt;Minio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rabbitmq.com/prometheus.html&#34;&gt;RabbitMQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/influxdata/telegraf/tree/master/plugins/outputs/prometheus_client&#34;&gt;Telegraf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik&#34;&gt;Traefik&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openzipkin/zipkin/tree/master/zipkin-server#metrics&#34;&gt;Zipkin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;minio集群的可观测性&#34;&gt;Minio集群的可观测性&lt;/h3&gt;

&lt;p&gt;得益于&lt;code&gt;Minio&lt;/code&gt;的云原生化，这款分布式的对象存储服务天然的支持了&lt;code&gt;Prometheus Metrics&lt;/code&gt;格式的指标数据以及服务端点(API)，因此，如果想要在已有的Minio集群中增加性能指标的监控，将是一件很容易的事情。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.min.io/docs/how-to-monitor-minio-using-prometheus.html&#34;&gt;使用Prometheus监控Minio服务&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Minio服务通过内置的服务端点暴露监控数据，用来监控服务整体的健康状态以及性能指标:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Healthcheck 探针: 提供两个服务探活接口，一个用于检测服务是否启动，另外一个用于检测服务是否可以正常对外提供服务(服务就绪)&lt;/li&gt;
&lt;li&gt;- 探活接口: &lt;code&gt;/minio/health/live&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;- 就绪接口: &lt;code&gt;/minio/health/ready&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Prometheus 探针: 提供了prometheus metrics格式的性能指标数据&lt;/li&gt;
&lt;li&gt;- Metrics接口: &lt;code&gt;/minio/prometheus/metrics&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Healthcheck相关的探针默认是非认证的接口，服务启动后可直接访问; Prometheus探针的接口默认是基于&lt;code&gt;JWT认证&lt;/code&gt;的接口，需要额外设置来访问其Metrics数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Minio的Metrics数据暴露&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;管理员可通过下述方式获取Metrics端点的jwt token:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 获取token
$ mc admin prometheus generate  minio
scrape_configs:
- job_name: minio-job
  bearer_token: eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJleHAiOjQ3NDAwMzM4MjAsImlzcyI6InByb21ldGhldXMiLCJzdWIiOiJNaW5pb1NvdWwifQ.1QiANgXVCpAPWCdF9EejhH608rZbdCRcHe3RtalC2XnScWtYMk_OG0ih-Z3t4ADb1cnYREdTrQwWscFw6Xvk3Q
  metrics_path: /minio/prometheus/metrics
  scheme: http
  static_configs:
  - targets: [minio.bgbiao.top]

# 在配置prometheus的scrape时配置如上相关参数&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;通常对于内部系统间的调用来说，权限可能没那么重要，可以增加如下环境变量来开启metrics的非认证方式:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;MINIO_PROMETHEUS_AUTH_TYPE=&amp;#34;public&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;此时，直接访问接口可以获取到如下的Metrics数据:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ curl -s  minio.bgbiao.top/minio/prometheus/metrics | head -10
# HELP disk_storage_available Total available space left on the disk
# TYPE disk_storage_available gauge
disk_storage_available{disk=&amp;#34;/data/minio&amp;#34;} 2.78376280064e+11
# HELP disk_storage_total Total space on the disk
# TYPE disk_storage_total gauge
disk_storage_total{disk=&amp;#34;/data/minio&amp;#34;} 3.00809048064e+11
# HELP disk_storage_used Total disk storage used on the disk
# TYPE disk_storage_used gauge
disk_storage_used{disk=&amp;#34;/data/minio&amp;#34;} 2.2432768e+10
# HELP go_gc_duration_seconds A summary of the GC invocation durations.&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;minio-metrics相关定义&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;标准的运行时指标使用以&lt;code&gt;go_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;进程级别的指标以&lt;code&gt;process_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;prometheus暴露的指标&lt;code&gt;promhttp_&lt;/code&gt;开头&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_used&lt;/code&gt;: 磁盘使用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_available&lt;/code&gt;: 磁盘可用空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disk_storage_total&lt;/code&gt;: 磁盘总空间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minio_disks_offline&lt;/code&gt;: 当前minio实例中处于下线状态的个数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minio_disks_total&lt;/code&gt;: 当前minio实例的磁盘总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_requests_total&lt;/code&gt;: 当前minio实例中s3接口总请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_errors_total&lt;/code&gt;: s3接口错误请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_requests_current&lt;/code&gt;: 活动状态的s3请求数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;internode_rx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例接收的节点间字节的总数(bytes)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;internode_tx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例发送到其他节点的字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_rx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例接收的s3字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_tx_bytes_total&lt;/code&gt;: 当前MinIO服务器实例发送的s3字节总数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;s3_ttfb_seconds_&lt;/code&gt;: 统计s3请求的延迟信息&lt;/li&gt;
&lt;li&gt;- bucket: bucket操作相关的延迟&lt;/li&gt;
&lt;li&gt;- count: 延迟统计&lt;/li&gt;
&lt;li&gt;- sum: 总延迟&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Minio不同的版本的Metrics数据有区别，需要查看具体暴露的数据指标&lt;/p&gt;

&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 打开文件数
process_open_fds{job=&amp;#34;minio-metrics&amp;#34;}

# 启动时间(时间戳)
process_start_time_seconds{job=&amp;#34;minio-metrics&amp;#34;}

# 虚拟内存使用
process_virtual_memory_bytes{job=&amp;#34;minio-metrics&amp;#34;}

# cpu占用时间
process_cpu_seconds_total{job=&amp;#34;minio-metrics&amp;#34;}

# minio对外的http接口状态
promhttp_metric_handler_requests_total{job=&amp;#34;minio-metrics&amp;#34;}

# 链接中的http请求
promhttp_metric_handler_requests_in_flight{job=&amp;#34;minio-metrics&amp;#34;}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;配置prometheus数据抓取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 我们的Prometheus是使用CRD方式部署在Kubernetes集群中的，因此抓取外部Metrics数据需要做如下的操作.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 暴露minio服务
$ cat endpoint-minio.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: minio-metrics
  namespace: monitoring
  labels:
    app: minio-metrics
subsets:
- addresses:
  - ip: 192.168.0.148
  - ip: 192.168.0.149
  - ip: 192.168.0.150
  - ip: 192.168.0.151
  ports:
  - port: 9000
    name: http-metrics
    protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  name: minio-metrics
  labels:
    app: minio-metrics
spec:
  ports:
  - name: http-metrics
    port: 9000
    targetPort: 9000
    protocol: TCP

# prometheus servicemonitor
$ cat prometheus-minio.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: minio-metrics
  name: minio-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
  # 可以定义两个采集端点，一个是minio服务本身的监控，一个是minio节点的基础监控
  - interval: 30s
    port: http-metrics
    path: /minio/prometheus/metrics
  jobLabel: app
  # 匹配monitoring命名空间的app=minio-metrics的svc
  namespaceSelector:
    matchNames:
    - monitoring
  selector:
    matchLabels:
      app: minio-metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;查看prometheus监控的minio相关数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prometheus成功抓取minio metrics数据后，即可在prometheus中查看到先关数据:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdnrt82rfpj324a0t47at.jpg&#34; alt=&#34;minio-prometheus-metrics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在Grafana中配置关心的指标以及相关图表:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdofcrk9bbj31gr0u04a4.jpg&#34; alt=&#34;minio-grafana监控&#34; /&gt;&lt;/p&gt;

&lt;p&gt;为了方便其他运维小伙伴们，我将Minio的Grafana模板开源出来，有需求的可以直接使用如下模板:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/12063&#34;&gt;minio-grafana模板&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Traefik的可观测性方案</title>
      <link>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/traefik%E7%9A%84%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>&lt;h2 id=&#34;traefik的可观测性支持&#34;&gt;Traefik的可观测性支持&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.traefik.io/observability/logs/&#34;&gt;traefik-observability&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在Traefik-2.X的生态里，将可观测性分为了如下几个部分，并提升到了专门的功能说明中&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务日志: Traefik进程本身相关的操作日志&lt;/li&gt;
&lt;li&gt;访问日志: 由Traefik接管的代理服务的访问日志(access.log)&lt;/li&gt;
&lt;li&gt;Metrics: Traefik提供的自身详细的metrics数据&lt;/li&gt;
&lt;li&gt;Tracing: Traefik也提供了追踪相关的接口，用来可视化分布式或微服务中的调用情况&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;服务日志&#34;&gt;服务日志&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;默认的环境中,Traefik会将日志以&lt;code&gt;text&lt;/code&gt;格式写入到stdout中，如果使用docker的方式部署的话，想要查看日志需要使用&lt;code&gt;docker logs container_name&lt;/code&gt;方式来查看日志。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;相关配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[log]
  filePath = &amp;#34;/path/to/traefik.log&amp;#34;   # 配置traefik的进程日志路径
  format = &amp;#34;json&amp;#34;                     # 配置日志文件的格式[text(text|json)]
  level = &amp;#34;DEBUG&amp;#34;                     # 指定日志输出的级别[ERROR(ERROR|DEBUG|INFO|PANIC|FATAL|WARN)]

# cli 配置
--log.filePath=/path/to/traefik.log
--log.format=json
--log.level=DEBUG&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 具体的日志配置参数需要和当前环境中的traefik大版本兼容，否则可能会出现意想不到的问题。&lt;/p&gt;

&lt;h3 id=&#34;访问日志&#34;&gt;访问日志&lt;/h3&gt;

&lt;p&gt;访问日志用来记录通过traefik进来的各个请求的访问详情，包含HTTP请求的各个header以及响应时间等数据，类似于Nginx中的&lt;code&gt;access.log&lt;/code&gt;，通常情况，我们可以使用访问日志来分析整个traefik的整体流量以及各个服务流量以及状态详情。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 访问日志默认也是以&lt;code&gt;text&lt;/code&gt;格式被写到标准输出的&lt;/p&gt;

&lt;p&gt;&lt;code&gt;相关配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[accessLog]
  filePath = &amp;#34;/path/to/traefik.log&amp;#34;
  format = &amp;#34;&amp;#34;                       # 指定访问日志的格式，默认使用CLF(Common Log Format)，可以指定为json格式
  bufferingSize = 100               # 以异步方式写入日志需要指定该参数，表示写入到指定输出设备前保留在内存中的日志行数
  [accessLog.filters]               # 指定一组逻辑上是Or的过滤连接器,指定多个过滤器将比只指定一个过滤器保留更多的访问日志
    statusCodes = [&amp;#34;200&amp;#34;, &amp;#34;300-302&amp;#34;] # 过滤指定状态码范围的请求日志
    retryAttempts = true             # 当有重试时保留日志
    minDuration = &amp;#34;10ms&amp;#34;             # 当请求花费的时间超过指定的持续时间时，保留访问日志
    
  [accessLog.fields]                # 限制访问日志中的字段(可以使用fields.names和fields.header选项来决定字段的输出)
    defaultMode = &amp;#34;keep&amp;#34;            # 每种字段可以设置成如下字段(keep:保留字段,drop:丢弃,redact:使用redacted替换值)
    [accessLog.fields.names]        # 指定限制的字段名称
      &amp;#34;ClientUsername&amp;#34; = &amp;#34;drop&amp;#34;     # 设置ClientUsername字段为丢弃
    [accessLog.fields.headers]      # 设置headers相关字段
      defaultMode = &amp;#34;keep&amp;#34;          # 对全部的header进行默认保留
      [accessLog.fields.headers.names] # 对指定的header字段设置保留规则
        &amp;#34;User-Agent&amp;#34; = &amp;#34;redact&amp;#34;
        &amp;#34;Authorization&amp;#34; = &amp;#34;drop&amp;#34;
        &amp;#34;Content-Type&amp;#34; = &amp;#34;keep&amp;#34;

# cli 配置
--accesslog=true
--accesslog.filepath=/path/to/access.log
--accesslog.format=json
--accesslog.bufferingsize=100
--accesslog.filters.statuscodes=200,300-302
--accesslog.filters.retryattempts
--accesslog.filters.minduration=10ms
--accesslog.fields.defaultmode=keep
--accesslog.fields.names.ClientUsername=drop
--accesslog.fields.headers.defaultmode=keep
--accesslog.fields.headers.names.User-Agent=redact
--accesslog.fields.headers.names.Authorization=drop
--accesslog.fields.headers.names.Content-Type=keep&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 由于我们是将Traefik当做Kubernetes集群中的边缘节点，去代理内部HTTP服务的，因此Traefik部署在集群内部,将进程日志和访问日志都以volume的方式挂载到边缘节点的数据目录中。&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;DaemonSet&lt;/code&gt;方式将Traefik部署在k8s集群内部，具体的配置如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;97
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat traefik-ds.yml
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      affinity:
        # 定义node的亲和性，不允许调度到master节点
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      containers:
      - image: traefik:v1.7.16
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8080
        securityContext:
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
        - --traefikLog.filePath=/logdata/traefik.log
        - --configfile=/config/traefik.toml
        - --accesslog.filepath=/logdata/access.log
        - --accesslog.bufferingsize=100
        volumeMounts:
        - mountPath: /config
          name: config
        - mountPath: /logdata
          name: access-log
      volumes:
      - configMap:
          name: traefik-config
        name: config
      - name: access-log
        hostPath:
          path: /opt/logs/ingress/

# 查看traefik 的状态
$ kubectl  get pods -n kube-system  | grep traefik
traefik-ingress-controller-2dx7k   1/1     Running   0          5h28m
...
...

$ kubectl  get svc -n kube-system  | grep traefik
traefik-ingress-service   ClusterIP   10.253.132.216   &amp;lt;none&amp;gt;        80/TCP,8080/TCP          123d
traefik-web-ui            ClusterIP   10.253.54.184    &amp;lt;none&amp;gt;        80/TCP                   172d


# 可以通过节点的ping接口和admin接口来查看traefik服务是否正常
$ curl 10.253.132.216/ping
OK

$ curl 10.253.132.216:8080
&amp;lt;a href=&amp;#34;/dashboard/&amp;#34;&amp;gt;Found&amp;lt;/a&amp;gt;.


# 在调度到treafik的节点上查看进程日志和访问日志
$ tree -L 2 /opt/logs/ingress/
/opt/logs/ingress/
├── access.log
└── traefik.log

$ tail -n 10 /opt/logs/ingress/traefik.log
time=&amp;#34;2020-04-07T08:53:38Z&amp;#34; level=warning msg=&amp;#34;Endpoints not available for my-data/my-data-selfaccess-dev&amp;#34;
time=&amp;#34;2020-04-07T08:53:38Z&amp;#34; level=warning msg=&amp;#34;Endpoints not available for my-data/my-data-metadata-prod1&amp;#34;


$ tail -n 10 /opt/logs/ingress/access.log
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;POST /.kibana/_search?ignore_unavailable=true&amp;amp;filter_path=aggregations.types.buckets HTTP/1.1&amp;#34; 503 161 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491674 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.41.10:9200&amp;#34; 1ms
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;POST /.kibana/_search?ignore_unavailable=true&amp;amp;filter_path=aggregations.types.buckets HTTP/1.1&amp;#34; 503 161 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491671 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.26.20:9200&amp;#34; 1ms
172.16.21.28 - - [07/Apr/2020:08:52:54 +0000] &amp;#34;GET /.kibana/doc/config%3A6.4.0 HTTP/1.1&amp;#34; 503 301 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 491675 &amp;#34;prod-es-cluster.soulapp-inc.cn&amp;#34; &amp;#34;http://20.0.14.6:9200&amp;#34; 1ms&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;从访问日志的输出格式中，我们可以看到，traefik的访问日志和Nginx的访问日志会比较相似，有了这份日志后，我们可以通过一些ELK之类的日志分析方案来分期网站的整体状态，比如UV,PV,区域分布，状态分布以及响应时间等等。&lt;/p&gt;

&lt;p&gt;另外，我们是将访问日志直接持久化输出到node节点上，后面可以通过node主机上的日志采集插件，将日志发送到ELK Stack中，进行分析，当然也可以直接将ELK Stack的日志采集端部署到traefik的pod中，也是可以的。&lt;/p&gt;

&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;

&lt;p&gt;Traefik默认支持四种Metrics的后端实现:
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/datadog/&#34;&gt;Datadog&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/influxdb/&#34;&gt;Influxdb&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/prometheus/&#34;&gt;Prometheus&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/metrics/statsd/&#34;&gt;StatsD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;想要开启&lt;code&gt;metrics&lt;/code&gt;的支持，只需要做如下配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
    [metrics]
      [metrics.prometheus]
      buckets=[0.1,0.3,1.2,5.0]
      entryPoint = &amp;#34;traefik&amp;#34;

# yaml 配置文件
metrics: {}

# cli 配置
--metrics=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Datadog后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置文件
[metrics]
  [metrics.datadog]
    address = &amp;#34;127.0.0.1:8125&amp;#34;
    addEntryPointsLabels = true   #在入口处增加metrics标签[true]
    addServicesLabels = true      #在service中启用meirtcs[true]
    pushInterval = 10s            #push metrics到datalog的间隔时间[10s]

# cli 配置
--metrics.datadog=true
--metrics.datadog.address=127.0.0.1:8125
--metrics.datadog.addEntryPointsLabels=true
--metrics.datadog.addServicesLabels=true
--metrics.datadog.pushInterval=10s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;InfluxDB后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置
[metrics]
  [metrics.influxDB]
    address = &amp;#34;localhost:8089&amp;#34;     #指定influxdb地址 [localhost:8089]
    protocol = &amp;#34;udp&amp;#34;               #influxdb的传输协议 [udp(udp|http)]
    database = &amp;#34;db&amp;#34;                #指定metrics写入的库[&amp;#34;&amp;#34;]
    retentionPolicy = &amp;#34;two_hours&amp;#34;  #metrics在influxdb中的保留策略 [&amp;#34;&amp;#34;]
    username = &amp;#34;&amp;#34;                  #influxdb用户名
    password = &amp;#34;&amp;#34;                  #influxdb密码
    addEntryPointsLabels = true    #入口处增加metrics标签[true]
    addServicesLabels = true       #在service中启用meirtcs[true]
    pushInterval = 10s             #push metrics到datalog的间隔时间[10s]

# cli 配置
--metrics.influxdb=true
--metrics.influxdb.address=localhost:8089
--metrics.influxdb.protocol=udp
--metrics.influxdb.database=db
--metrics.influxdb.retentionPolicy=two_hours
--metrics.influxdb.username=john
--metrics.influxdb.password=secret
--metrics.influxdb.addEntryPointsLabels=true
--metrics.influxdb.addServicesLabels=true
--metrics.influxdb.pushInterval=10s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Prometheus后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;配置详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml配置
[metrics]
  [metrics.prometheus]
    buckets = [0.1,0.3,1.2,5.0]      #延迟的metrics的bucket存储[0.100000, 0.300000, 1.200000, 5.000000]
    addEntryPointsLabels = true      #入口处增加metrics标签[true]
    addServicesLabels = true         #在service中启用meirtcs[true]
    entryPoint = &amp;#34;traefik&amp;#34;           #指定metrics的端点[traefik(默认是管理端口8080/metrics)],也可以自定义
    manualRouting = true             #是否禁用内部路由[false]

# cli配置
--metrics.prometheus=true
--metrics.prometheus.buckets=0.100000, 0.300000, 1.200000, 5.000000
--metrics.prometheus.addEntryPointsLabels=true
--metrics.prometheus.addServicesLabels=true
## 自定义了一个metrics端点，并指定了端口
--metrics.prometheus.entryPoint=metrics
--entryPoints.metrics.address=:8082
--metrics.prometheus.manualrouting=true&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt;和其他两种方式不同的是，prometheus仅会暴露metrics，是需要使用prometheus-server定期进行&lt;code&gt;pull&lt;/code&gt;来收集数据的。&lt;/p&gt;

&lt;p&gt;配置生效后，可以访问如下端口进行测试:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 自定义了metrics端点
$ curl localhost:8082/metrics

# 使用默认的traefik端点(用的是admin的端口)
$ curl localhost:8080/metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;StatsD后端支持&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;详细配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置
[metrics]
  [metrics.statsD]
    address = &amp;#34;localhost:8125&amp;#34;          # 指定statsD服务地址
    addEntryPointsLabels = true         # 入口处增加metrics标签[true] 
    addServicesLabels = true            # 在service中启用meirtcs[true]
    pushInterval = 10s                  # push间隔
    prefix = &amp;#34;traefik&amp;#34;                  # 定义metrics收集的前缀[traefik]

# cli 配置
--metrics.statsd=true
--metrics.statsd.address=localhost:8125
--metrics.statsd.addEntryPointsLabels=true
--metrics.statsd.addServicesLabels=true
--metrics.statsd.pushInterval=10s
--metrics.statsd.prefix=&amp;#34;traefik&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Prometheus后端的Metrics示例&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 由于在生产环境使用的是traefik-1.7.6版本，因此上述的一些配置参数可能并不适用于该版本，详细的参数需要查看具体版本的支持参数，同时我们将traefik当做kubernetes集群中的ingress方案，因此如下操作在一个可用的k8s集群内部。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.traefik.io/v1.7/configuration/metrics/&#34;&gt;traefik-1.7-metrics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;1.traefik的metrics配置&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# traefik metrics 配置
$ cat traefik-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: traefik-config
  namespace: kube-system
data:
  traefik.toml: |
    defaultEntryPoints = [&amp;#34;http&amp;#34;,&amp;#34;https&amp;#34;]
    debug = false
    logLevel = &amp;#34;INFO&amp;#34;

    InsecureSkipVerify = true
    [entryPoints]
      [entryPoints.http]
      address = &amp;#34;:80&amp;#34;
      compress = true
      [entryPoints.https]
      address = &amp;#34;:443&amp;#34;
        [entryPoints.https.tls]
    [web]
      address = &amp;#34;:8080&amp;#34;
    [kubernetes]
    # 定义metrics相关参数
    [metrics]
      [metrics.prometheus]
      buckets=[0.1,0.3,1.2,5.0]
      entryPoint = &amp;#34;traefik&amp;#34;
    [ping]
    entryPoint = &amp;#34;http&amp;#34;

# 重新调度pod后，即可查看暴露的endpoint

$ kubectl  get ep -A | grep traefik
kube-system            traefik-ingress-service                    172.16.171.163:80,172.16.21.26:80,172.16.21.27:80 + 11 more...            122d
kube-system            traefik-web-ui                             172.16.171.163:8080,172.16.21.26:8080,172.16.21.27:8080 + 4 more...       171d

$ kubectl  get svc -n kube-system | grep traefik
traefik-ingress-service   ClusterIP   10.253.132.216   &amp;lt;none&amp;gt;        80/TCP,8080/TCP          122d
traefik-web-ui            ClusterIP   10.253.54.184    &amp;lt;none&amp;gt;        80/TCP                   171d

# 测试访问metrics服务(因为和traefik相关的两个service均路由到了traefil-ingress的pod上,下面两个效果是一致的)
$ curl -s  10.253.132.216:8080/metrics  | head -10
....
....
$ curl -s  10.253.54.184/metrics | head -10&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 推荐使用traefik-web-ui暴露的svc地址&lt;/p&gt;

&lt;p&gt;指标以及相关含义:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标项&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;process_max_fds&lt;/td&gt;
&lt;td&gt;traefik进程最大的fd&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_open_fds&lt;/td&gt;
&lt;td&gt;进程打开的fd&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_resident_memory_bytes&lt;/td&gt;
&lt;td&gt;进程占用内存&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_start_time_seconds&lt;/td&gt;
&lt;td&gt;进程启动时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;process_virtual_memory_bytes&lt;/td&gt;
&lt;td&gt;进程占用虚拟内存&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_open_connections&lt;/td&gt;
&lt;td&gt;traefik后端打开链接&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_bucket&lt;/td&gt;
&lt;td&gt;traefik后端请求处理时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_sum&lt;/td&gt;
&lt;td&gt;总时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_request_duration_seconds_count&lt;/td&gt;
&lt;td&gt;总请求时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_requests_total&lt;/td&gt;
&lt;td&gt;一个后端处理的总请求数(按status code, protocol, and method划分)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_backend_server_up&lt;/td&gt;
&lt;td&gt;后端是否up(0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_last_reload_failure&lt;/td&gt;
&lt;td&gt;traefik上次失败reload的时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_last_reload_success&lt;/td&gt;
&lt;td&gt;上次成功reload的时间&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_reloads_failure_total&lt;/td&gt;
&lt;td&gt;失败次数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_config_reloads_total&lt;/td&gt;
&lt;td&gt;成功次数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_open_connections&lt;/td&gt;
&lt;td&gt;入口点存在打开链接的数量(method and protocol划分)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_request_duration_seconds_bucket&lt;/td&gt;
&lt;td&gt;在入口点处理请求花费的时间(status code, protocol, and method.)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;traefik_entrypoint_requests_total&lt;/td&gt;
&lt;td&gt;一个入口点处理的总请求数(状态码分布)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code&gt;2.配置prometheus-server&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意，此时我们需要配置prometheus-server来对traefik暴露的metrics进行定期的pull采集。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 在k8s中创建一个prometheus monitor service
$ cat prometheus-traefik.yml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    k8s-app: traefik-ingress-lb
  name: traefik-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
    # 定义endpoint采集的时间
  - interval: 30s
    port: admin
    path: /metrics
  jobLabel: k8s-app
  # 匹配monitoring命名空间的app=gpu-metrics的svc
  namespaceSelector:
    matchNames:
    - kube-system
  selector:
    matchLabels:
      k8s-app: traefik-ingress-lb

$ kubectl apply -f prometheus-traefik.yml&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;配置完成后，即可在prometheus中查看相关的metrics数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdl4lcmvwsj32620o0ah5.jpg&#34; alt=&#34;prometheus-traefik-metrics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;3.根据指标配置Grafana&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/12041&#34;&gt;grafana模板&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdl6drdnotj31kw0u0gxk.jpg&#34; alt=&#34;Traefik-全局监控详情&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有了Merics的可视化后，针对于HTTP服务来说做各种滚动升级以及切流发布时，就很容易能够看到整个流量的变化。&lt;/p&gt;

&lt;h3 id=&#34;tracing&#34;&gt;Tracing&lt;/h3&gt;

&lt;p&gt;追踪系统可以开发人员可视化其基础架构中的调用流程.&lt;/p&gt;

&lt;p&gt;Traefik遵循OpenTracing规范(一个为分布式跟踪而设计的开放标准)&lt;/p&gt;

&lt;p&gt;Traefik支持五种追踪系统后端:
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/jaeger/&#34;&gt;Jaeger&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/zipkin/&#34;&gt;Zipkin&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/datadog/&#34;&gt;Datadog&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/instana/&#34;&gt;Instana&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/haystack/&#34;&gt;Haystack&lt;/a&gt;
- &lt;a href=&#34;https://docs.traefik.io/observability/tracing/elastic/&#34;&gt;Elastic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; Datadog,Instana,Haystack为商业解决方案，以下不做介绍&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.配置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 默认情况下，traefik使用&lt;code&gt;Jaeger&lt;/code&gt;来最为追踪系统的后端实现.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  serviceName = &amp;#34;traefik&amp;#34;			# 选择追踪系统的后端实现[traefik(表示使用jaeger)]
  spanNameLimit = 150					# 限制长名称的名称阶段(这可以防止某些跟踪提供程序删除超过其长度限制的跟踪)

# cli 配置
--tracing=true
--tracing.serviceName=traefik
--tracing.spanNameLimit=150&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.Jaeger&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  [tracing.jaeger]					# 开启jaeger的追踪支持
    samplingServerURL = &amp;#34;http://localhost:5778/sampling&amp;#34; 		# 指定jaeger-agent的http采样地址
    samplingType = &amp;#34;const&amp;#34;	# 指定采样类型[const(const|probabilistic|rateLimiting)]
    samplingParam = 1.0			# 采样参数的值[1.0(const:0|1,probabilistic:0-1,rateLimiting:每秒的span数)]
    localAgentHostPort = &amp;#34;127.0.0.1:6831&amp;#34;										# 本地agent主机和端口(会发送到jaeger-agent)
    gen128Bit = true				# 生成128位的traceId,兼容OpenCensus
    propagation = &amp;#34;jaeger&amp;#34;  # 设置数据传输的header类型[jaeger(jaeger|b3兼容OpenZipkin)]
    traceContextHeaderName = &amp;#34;uber-trace-id&amp;#34;  # 跟踪上下文的header,用于传输跟踪上下文的http头名
  [tracing.jaeger.collector]  # 指定jaeger的collector服务
    endpoint = &amp;#34;http://127.0.0.1:14268/api/traces?format=jaeger.thrift&amp;#34;
    user = &amp;#34;my-user&amp;#34;          # 向collector提交时的http认证用户[&amp;#34;&amp;#34;]
    password = &amp;#34;my-password&amp;#34;  # 向collector提交时的http认证密码[&amp;#34;&amp;#34;]


# cli 配置
--tracing.jaeger=true
--tracing.jaeger.samplingServerURL=http://localhost:5778/sampling
--tracing.jaeger.samplingType=const
--tracing.jaeger.samplingParam=1.0
--tracing.jaeger.localAgentHostPort=127.0.0.1:6831
--tracing.jaeger.gen128Bit
--tracing.jaeger.propagation=jaeger
--tracing.jaeger.traceContextHeaderName=uber-trace-id
--tracing.jaeger.collector.endpoint=http://127.0.0.1:14268/api/traces?format=jaeger.thrift
--tracing.jaeger.collector.user=my-user
--tracing.jaeger.collector.password=my-password&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3.Zipkin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
[tracing]
  [tracing.zipkin]                  # 指定使用zipkin追踪系统
    httpEndpoint = &amp;#34;http://localhost:9411/api/v2/spans&amp;#34;   # 指定zipkip收集数据的http端点
    sameSpan = true                 # 使用Zipkin SameSpan RPC 类型追踪方式
    id128Bit = true                 # 使用Zipkin 128 bit的追踪id(true)
    sampleRate = 0.2                # 指定请求trace系统的频率[1.0(0.1-1.0)]

# cli 配置
--tracing.zipkin=true
--tracing.zipkin.httpEndpoint=http://localhost:9411/api/v2/spans
--tracing.zipkin.sameSpan=true
--tracing.zipkin.id128Bit=false
--tracing.zipkin.sampleRate=0.2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4.Elastic&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;相关配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# toml 配置文件
$ cat traefik.toml
[tracing]
  [tracing.elastic]
    serverURL = &amp;#34;http://apm:8200&amp;#34;     # 指定Elastic APM服务地址
    secretToken = &amp;#34;&amp;#34;                  # 指定Elastic APM服务的安全token
    serviceEnvironment = &amp;#34;&amp;#34;           # 指定APM Server的环境

# cli 配置
--tracing.elastic=true
--tracing.elastic.serverurl=&amp;#34;http://apm:8200&amp;#34;
--tracing.elastic.secrettoken=&amp;#34;mytoken&amp;#34;
--tracing.elastic.serviceenvironment=&amp;#34;production&amp;#34;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007S8ZIlly1gdra6n69uhj30f00kkgot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>基于DCGM和Prometheus的GPU监控方案</title>
      <link>https://bgbiao.top/post/%E5%9F%BA%E4%BA%8Edcgm%E5%92%8Cprometheus%E7%9A%84gpu%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E5%9F%BA%E4%BA%8Edcgm%E5%92%8Cprometheus%E7%9A%84gpu%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</guid>
      
        <description>&lt;h2 id=&#34;基于dcgm和prometheus的gpu监控方案&#34;&gt;基于DCGM和Prometheus的GPU监控方案&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;背景: 在早期的GPU监控中我们会使用一些NVML工具来对GPU卡的基本信息进行采集，并持久化到监控系统的数据存储层。因为我们知道，其实通过&lt;code&gt;nvidia-smi&lt;/code&gt;这样的命令也是可以获取到GPU的基本信息的，但随着整个AI市场的发展和成熟，对于GPU的监控也越来越需要一套标准化的工具体系，也就是本篇文章讲的关于&lt;a href=&#34;https://developer.nvidia.com/dcgm&#34;&gt;DCGM&lt;/a&gt;相关的监控解决方案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;DCGM(Data Center GPU Manager)即数据中心GPU管理器，是一套用于在集群环境中管理和监视&lt;code&gt;Tesla™&lt;/code&gt;GPU的工具。&lt;/p&gt;

&lt;p&gt;它包括主动健康监控，全面诊断，系统警报以及包括电源和时钟管理在内的治理策略。&lt;/p&gt;

&lt;p&gt;它可以由系统管理员独立使用，并且可以轻松地集成到NVIDIA合作伙伴的集群管理，资源调度和监视产品中。&lt;/p&gt;

&lt;p&gt;DCGM简化了数据中心中的GPU管理，提高了资源可靠性和正常运行时间，自动化了管理任务，并有助于提高整体基础架构效率。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 虽然可以通过&lt;code&gt;nvidia-smi&lt;/code&gt;命令将相关的信息采集，并定期汇报到数据存储进行数据分析计算和展现，但是涉及到一整套的监控体系的整合，仍然需要使用方进行一些列的改造。因此这里，我们采用NVIDIA官方提供的DCGM方案来进行GPU数据采集，并通过声称下一代监控系统的Prometheus进行整个监控和告警的集成。&lt;/p&gt;

&lt;h3 id=&#34;dcgm工具部署&#34;&gt;DCGM工具部署&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ git clone https://github.com/NVIDIA/gpu-monitoring-tools.git

# 构建dcgm-exporter工具，其实就是nvidia官方对于nvidia-docker2.x推出的用于gpu数据监控的工具
# 最终会将gpu卡的metrics基本信息存储以metrics的数据格式存储到文件中
$ cd dcgm-exporter
# nvidia/dcgm-exporter:latest
$ make 

$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter nvidia/dcgm-exporter

# 查看dcgm-exporter收集到的gpu metrics数据
$ docker exec -it nvidia-dcgm-exporter tail -n 10  /run/prometheus/dcgm.prom
dcgm_ecc_dbe_aggregate_total{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_sbe Total number of retired pages due to single-bit errors.
# TYPE dcgm_retired_pages_sbe counter
dcgm_retired_pages_sbe{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_dbe Total number of retired pages due to double-bit errors.
# TYPE dcgm_retired_pages_dbe counter
dcgm_retired_pages_dbe{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
# HELP dcgm_retired_pages_pending Total number of pages pending retirement.
# TYPE dcgm_retired_pages_pending counter
dcgm_retired_pages_pending{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;dcgm-exporter采集指标项以及含义:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;指标&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dcgm_fan_speed_percent&lt;/td&gt;
&lt;td&gt;GPU 风扇转速占比（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_sm_clock&lt;/td&gt;
&lt;td&gt;GPU sm 时钟(MHz)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_memory_clock&lt;/td&gt;
&lt;td&gt;GPU 内存时钟(MHz)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_gpu_temp&lt;/td&gt;
&lt;td&gt;GPU 运行的温度(℃)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_power_usage&lt;/td&gt;
&lt;td&gt;GPU 的功率（w）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_tx_throughput&lt;/td&gt;
&lt;td&gt;GPU PCIe TX传输的字节总数 （kb）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_rx_throughput&lt;/td&gt;
&lt;td&gt;GPU PCIe RX接收的字节总数   （kb）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_pcie_replay_counter&lt;/td&gt;
&lt;td&gt;GPU PCIe重试的总数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_gpu_utilization&lt;/td&gt;
&lt;td&gt;GPU 利用率（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_mem_copy_utilization&lt;/td&gt;
&lt;td&gt;GPU 内存利用率（%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_enc_utilization&lt;/td&gt;
&lt;td&gt;GPU 编码器利用率 （%）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_dec_utilization&lt;/td&gt;
&lt;td&gt;GPU 解码器利用率 (%)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_xid_errors&lt;/td&gt;
&lt;td&gt;GPU 上一个xid错误的值&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_power_violation&lt;/td&gt;
&lt;td&gt;GPU 功率限制导致的节流持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_thermal_violation&lt;/td&gt;
&lt;td&gt;GPU 热约束节流持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_sync_boost_violation&lt;/td&gt;
&lt;td&gt;GPU 同步增强限制，限制持续时间(us)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_fb_free&lt;/td&gt;
&lt;td&gt;GPU fb（帧缓存）的剩余（MiB）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;dcgm_fb_used&lt;/td&gt;
&lt;td&gt;GPU fb （帧缓存）的使用 （MiB）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;其实到这，dcgm已经完整的将我们需要的gpu的metrics数据采集出来了，并且是符合prometheus的数据格式和标准的，此时，我们可以根据实际的情况编写一个简单的api程序，将采集到的数据以api的形式暴露出去，就可以让整个prometheus server对各个gpu主机的metrics进行采集和监控。&lt;/p&gt;

&lt;p&gt;不过官方提供了基于kubernetes集群中pod方式的api接口，采用golang语言开发，具体使用情况可参考如下文档。&lt;/p&gt;

&lt;h3 id=&#34;prometheus-gpu-metrics-exporter&#34;&gt;prometheus gpu metrics exporter&lt;/h3&gt;

&lt;p&gt;在&lt;code&gt;gpu-monitoring-tools&lt;/code&gt;项目中，默认提供了一个&lt;code&gt;pod-gpu-metrics-exporter&lt;/code&gt;模块，用于在kubernetes集群中的gpu-metrics的部署，官方的示例步骤如下:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nvidia-k8s-device-plugin&lt;/li&gt;
&lt;li&gt;Deploy GPU Pods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 在使kubernetes集群中部署的前提是你的GPU要托管在k8s集群内部，这也就意味着你得先成功将带GPU的主机成功托管到集群中，并且能够调度GPU资源&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 创建一个监控的命名空间
# Create the monitoring namespace
$ kubectl create namespace monitoring

# Add gpu metrics endpoint to prometheus
$ kubectl create -f prometheus/prometheus-configmap.yaml

# Deploy prometheus
$ kubectl create -f prometheus/prometheus-deployment.yaml

$ kubectl create -f pod-gpu-metrics-exporter-daemonset.yaml

# Open in browser: localhost:9090

# 具体的docker镜像构建和运行
# 依然是gpu-monitoring-tools项目
$ cd  pod-gpu-metrics-exporter
$ docker build -t pod-gpu-metrics-exporter .

# 运行dcgm-exporter
$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter nvidia/dcgm-exporter

# 运行gpu-metrics-exporter
$ docker run -d --privileged --rm -p 9400:9400 -v /var/lib/kubelet/pod-resources:/var/lib/kubelet/pod-resources --volumes-from nvidia-dcgm-exporter:ro nvidia/pod-gpu-metrics-exporter:v1.0.0-alpha

# 此时就将上述的那个dcgm-exporter中采集到数据成功暴露到对外的接口了
$ curl -s localhost:9400/gpu/metrics&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;需要注意的是，在&lt;code&gt;gpu-metrics-exporter&lt;/code&gt;的程序中，是针对pod的方式来采集gpu的metrics的信息，并且附带了pod本身的基本信息，因此如果你的&lt;code&gt;gpu&lt;/code&gt;主机还未在kubernetes集群中托管，官方提供的镜像可能并不能使用，需要对&lt;code&gt;src/http.go&lt;/code&gt;文件中采集的路径进行改变，将默认的&lt;code&gt;gpuPodMetrics&lt;/code&gt;改成&lt;code&gt;gpuMetrics&lt;/code&gt;即可，两者会去读取不同的dcgm-exporter暴露出来的metrics文件，否则访问api接口时会发现无法找到metrics文件.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;func getGPUmetrics(resp http.ResponseWriter, req *http.Request) {
	//metrics, err := ioutil.ReadFile(gpuPodMetrics)
	metrics, err := ioutil.ReadFile(gpuMetrics)
	if err != nil {
		http.Error(resp, err.Error(), http.StatusInternalServerError)
		glog.Errorf(&amp;#34;error responding to %v%v: %v&amp;#34;, req.Host, req.URL, err.Error())
		return
	}
	resp.Write(metrics)
}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;参考&lt;a href=&#34;https://github.com/BGBiao/gpu-monitoring-tools/tree/master/gpu-metrics-exporter&#34;&gt;gpu-metrics-exporter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;图省事的，可以直接下载如下两个镜像，在已经work 的GPU主机上直接运行.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;dcgm-exporter: &lt;code&gt;docker pull bgbiao/dcgm-exporter:latest&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;gpu-metrics-exporter: &lt;code&gt;docker pull bgbiao/gpu-metrics-exporter:latest&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# 确定dcgm-exporter是运行的
$ docker run -d --runtime=nvidia --rm --name=nvidia-dcgm-exporter bgbiao/dcgm-exporter

$ docker run -d --privileged --rm -p 9400:9400  --volumes-from nvidia-dcgm-exporter:ro bgbiao/gpu-metrics-exporter

# 检查gpu暴露出来的基础信息
$ curl -s localhost:9400/gpu/metrics
dcgm_ecc_dbe_aggregate_total{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 0
....
....&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;prometheus采集&#34;&gt;prometheus采集&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;注意:&lt;/code&gt; 有了上述的gpu-metrics-exporter之后，我们的gpu相关的运行数据就可以以premetheus兼容的方式获取了，此时在prometheus-server上配置，去定期pull 数据即可，我们的prometheus-server目前部署在kubernetes集群内部，因此这里分享将gpu的数据采集到kubernetes集群内部的prometheus中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建endpoint以及对应的service&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;# gpu-metrics的endpoint和service配置

$ cat endpoint-gpus.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: gpu-metrics
  namespace: monitoring
  labels:
    app: gpu-metrics
subsets:
- addresses:
  - ip: 172.16.65.234
  ports:
  - port: 9400
    name: http-metrics
    protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  name: gpu-metrics
  labels:
    app: gpu-metrics
spec:
  ports:
  - name: http-metrics
    port: 19400
    targetPort: 9400
    protocol: TCP

$ kubectl  apply -f endpoint-gpus.yaml

# 查看创建的相关资源
$ kubectl  get ep,svc -n monitoring  -l app=gpu-metrics
NAME                    ENDPOINTS            AGE
endpoints/gpu-metrics   172.16.65.234:9400   5m24s

NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
service/gpu-metrics   ClusterIP   10.253.138.97   &amp;lt;none&amp;gt;        19400/TCP   5m24s

# 测试service暴露的端点
# 确保集群内部可以访问service暴露出来的endpoint即可

$ curl 10.253.138.97:19400/gpu/metrics
# HELP dcgm_sm_clock SM clock frequency (in MHz).
# TYPE dcgm_sm_clock gauge
dcgm_sm_clock{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 1328
# HELP dcgm_memory_clock Memory clock frequency (in MHz).
# TYPE dcgm_memory_clock gauge
dcgm_memory_clock{gpu=&amp;#34;0&amp;#34;,uuid=&amp;#34;GPU-b91e30ac-fe77-e236-11ea-078bc2d1f226&amp;#34;} 715&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;创建prometheus抓取数据的规则&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;$ cat prometheus-gpus.yml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: gpu-metrics
  name: gpu-metrics
  namespace: monitoring
spec:
  # 对应的端点是上面创建的svc的ports
  endpoints:
    # 定义endpoint采集的时间和采集的URI
  - interval: 30s
    port: http-metrics
    path: /gpu/metrics
  jobLabel: app
  # 匹配monitoring命名空间的app=gpu-metrics的svc
  namespaceSelector:
    matchNames:
    - monitoring
  selector:
    matchLabels:
      app: gpu-metrics

$ kubectl  apply -f prometheus-gpus.yml
servicemonitor.monitoring.coreos.com/gpu-metrics created

$ kubectl  get servicemonitor  -n monitoring gpu-metrics
NAME          AGE
gpu-metrics   69s&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;当上述资源创建完成后，在集群内部的prometheus-server中就可以找到对应的target，确认状态为up即表示prometheus已正常采集集群外gpu的metrics数据了，接下来数据就会以30s为间隔，源源不断的将数据采集到prometheus存储中.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdiuxv5l47j31pk0aegon.jpg&#34; alt=&#34;prometheus-gpu-targets&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;gpu监控信息的展示&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;到这里，我们已经到万里长征的最后一步了，就是把prometheus中gpu的监控数据用grafana展示出来，以实时去分析一些gpu的基本数据。&lt;/p&gt;

&lt;p&gt;在grafana官网中，已经有大佬制作了gpu监控的相关模板，比如&lt;code&gt;[GPU-Nodes-Metrics](https://grafana.com/grafana/dashboards/12027)&lt;/code&gt;,因此，对于我们使用者来说，在grafana的面板中，将该模板导入即可使用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdiv4s5t9nj30ec0ek0tc.jpg&#34; alt=&#34;选择导入方式创建&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0dzwdmjj31ly0u041p.jpg&#34; alt=&#34;指定模板(dashboard id或json)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0ftc6d8j31nd0u0djg.jpg&#34; alt=&#34;注意:确认prometheus库正确后即可导入&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/00831rSTly1gdj0h15tp5j31oi0u0n5x.jpg&#34; alt=&#34;最终的GPU监控图&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考项目&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/NVIDIA/gpu-monitoring-tools&#34;&gt;gpu-monitor-tools&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/dashboards/11752&#34;&gt;gpu-metrics-grafana&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>构建更小Docker镜像的一些建议</title>
      <link>https://bgbiao.top/post/%E6%9E%84%E5%BB%BA%E6%9B%B4%E5%B0%8Fdocker%E9%95%9C%E5%83%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bgbiao.top/post/%E6%9E%84%E5%BB%BA%E6%9B%B4%E5%B0%8Fdocker%E9%95%9C%E5%83%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;背景: 前两天在群里看到有人提到说，自己构建了一个镜像，明明就只往base镜像中增加了tomcat，但是构建好的镜像大小最终却是两倍的tomcat包的大小，最后看到Dockerfile后才发现作者在把tomcat包拷贝进去之后，又使用&lt;code&gt;RUN&lt;/code&gt;指令，执行了一次&lt;code&gt;chmod a+x tomcat&lt;/code&gt;，我想说，这么搞镜像不大那是不可能的。另外一件事就是前段时间，同事说让搞一个公司级别的base镜像，要稳定并且尽量小，借着这两个事，和大家分享几点Docker镜像相关的事情。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先，镜像的大小最终取决于如下几点:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.业务需求和debug的便利性(比如科学计算和普通的java或者golang程序)&lt;/li&gt;
&lt;li&gt;2.业务镜像构建的依赖特性(构建过程和交付物的依赖关系)&lt;/li&gt;
&lt;li&gt;3.交付物的定义过程(Dockerfile分层过程中的变更层)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来，从三个点来谈谈我个人的想法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、单从镜像大小的角度考虑&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果仅从镜像的大小角度来讲，为了镜像尽可能的小，有如下的base镜像可供选择:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;alpine: 专为容器而生的基础镜像，缺点是默认使用的&lt;code&gt;musl libc&lt;/code&gt;，但是大多数运行在Linux下的程序几乎都是&lt;code&gt;glibc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;scratch: 没有任何&lt;code&gt;杂念&lt;/code&gt;的基础镜像，优点就是没有杂念，缺点也明显就是各种动态链接库，shell等等都没有(所以对应静态依赖的程序还是可以的)&lt;/li&gt;
&lt;li&gt;busybox: 基本也是一个没有太多&lt;code&gt;杂念&lt;/code&gt;的基础镜像，不过生态里包含了很多依赖镜像，比如&lt;code&gt;busybox:glibc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;centos: centos发行版的mini镜像，基础的库和工具包基本都有，base稍微大了点(200M左右吧,不过也可以精简)&lt;/li&gt;
&lt;li&gt;ubuntu: ubuntu发现版的mini镜像，同上，base大概在120M左右，不过两者的稳定性和包的管理有差异&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但以上几种的base均有利弊，而且企业内部通常业务场景也会有一定的变化，因此我们在维护内部的基础base镜像时一般不会为了&lt;code&gt;镜像小&lt;/code&gt;这个伪目标而使用多种base来构建不同镜像，主要是考虑到后期的维护成本较高(稳定性，可操作性).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、考虑业务的需求和debug的便利性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;java: 程序依赖基本包含在程序中，仅对java依赖&lt;/li&gt;
&lt;li&gt;c: 可能需要指定的libc库以及动态链接库的依赖&lt;/li&gt;
&lt;li&gt;golang: 编译好的程序几乎不需要依赖&lt;/li&gt;
&lt;li&gt;python: 需要依赖python以及各个库的支持，同时库可能依赖系统的动态链接库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通常在企业环境中，系统不可能长期只有一种语言来开发，因此不同语言生态下也就诞生了不同的需求。&lt;/p&gt;

&lt;p&gt;比如，当下不论是&lt;code&gt;DL(Deep Learning)&lt;/code&gt;还是&lt;code&gt;ML(Machine Learning)&lt;/code&gt;大部分对外的库基本都是使用Python开发的，因此在这种场景下，通常业务所需要的基础库是相当大，几个G的竟像也是司空见惯的。&lt;/p&gt;

&lt;p&gt;同时，还有一个比较常见的情况，就是我们的技术人员都有可能去容器内部进行简单的debug操作(比如使用curl,netstat等工具)，此时不同的base镜像会包含不同的生态工具，无疑也会增加大家的学习成本，如果对外推广可能会遭遇一定障碍。&lt;/p&gt;

&lt;p&gt;最后，还有一个点就是业务上层的base竟像的精简化。&lt;/p&gt;

&lt;p&gt;很多时候base环境内部可能存在一些基本工具，仅是程序构建时需要的工具，比如c程序的gcc,golang程序的go,java程序的jdk(其实仅jre就可以)，因此为了进一步减少空间，可以将构建过程相关的工具阉割掉。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三、交付物的定义过程&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在传统的CI/CD流水线中，交付物通常是一个静态的压缩包，而在引入以Docker为代表的容器技术之后，交付物就是包含业务代码和其运行时环境的镜像，因此在交付物的定义过程中也可以做一些镜像精简的优化。&lt;/p&gt;

&lt;p&gt;这里主要是Docker的分层思想，在开源的容器市场中，基于&lt;code&gt;overlay&lt;/code&gt;的存储引擎已经是不争的事实，所以，我们可以在分层过程中进行一些优化，对overlay不太了解的可以阅读以前的一篇文章&lt;a href=&#34;https://www.jianshu.com/p/959e8e3da4b2&#34;&gt;overlayfs的探究以及在docker的使用&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;FROM golang as golang-build
WORKDIR /
COPY hello.go .
RUN go build -ldflags &amp;#34;-s -w&amp;#34; -o hello hello.go

FROM alpine
COPY --from=golang-build hello .
RUN chmod a-x hello &amp;amp;&amp;amp; chmod a+x hello
CMD [&amp;#34;./hello&amp;#34;]&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;我们知道，在分层的思想中，每一层都是上一层的可写叠加，而在最新层变更的文件才是整个镜像或者容器增加的数据，所以如上的Dockerfile中，我们在&lt;code&gt;RUN&lt;/code&gt;指令中增加了权限的操作(仅用来说明问题)，你会发现，最终的镜像会比不加&lt;code&gt;RUN&lt;/code&gt;指令整整大了一个&lt;code&gt;hello&lt;/code&gt;程序的空间，这其实就是镜像分层中的一个优化点。&lt;/p&gt;

&lt;p&gt;所以，在企业内部进行容器化改造和上线时，除了需要考虑各个适用方的场景问题和操作便利性，同时在构建过程中也需要进行一定的把控。&lt;/p&gt;

&lt;p&gt;当然啦，尽可能的将镜像压缩到最小，不仅可以减少磁盘的使用，同时在大规模分发镜像时也会表现的相对有效率，但在实际使用过程中，并不是所有的镜像越小越好，同时我们需要在镜像的通用性和可维护性上进行一定权重的考量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gai9amj2lcj30vu0b275p.jpg&#34; alt=&#34;知识星球&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/006tNbRwly1gaexte72s7j31bi0hc418.jpg&#34; alt=&#34;公众号&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
